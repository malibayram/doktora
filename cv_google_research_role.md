# Mehmet Ali Bayram  
**Email:** [malibayram20@gmail.com](mailto:malibayram20@gmail.com)  
**Phone:** +90 551 729 14 10  
**Location:** Ataşehir, Istanbul, Turkey

## Profile Summary
A dedicated PhD candidate in Computer Engineering with a strong linguistic and multicultural background, fluent in Turkish, Kurdish, English, and Arabic, and proficient in communicating in Persian and Zazaki. Currently advancing original research findings in Natural Language Processing (NLP) to develop innovative solutions for low-resource languages, underrepresented dialects, and specialized domains. Skilled in designing and optimizing multilingual tokenizers, fine-tuning large language models (LLMs), and implementing adaptive learning strategies and model merging techniques that enhance both computational efficiency and semantic depth.

With extensive experience in medical and Turkish-focused LLM research, as well as substantial contributions to open-source NLP projects, I bring a unique blend of technical rigor and cross-linguistic insight. My work emphasizes reliable, context-sensitive modeling, ensuring that complex linguistic structures and culturally nuanced semantics are accurately represented. By integrating knowledge from multiple linguistic traditions and leveraging cutting-edge AI frameworks, I strive to create language models that not only perform well on benchmarks but also address real-world communication challenges, ultimately bridging the gap between diverse language communities and advanced computational intelligence.

## Education

**PhD in Computer Engineering (2020 - 2025)**  
*Yıldız Teknik Üniversitesi Fen Bilimleri Enstitüsü, Turkey*  
- Focused on pushing the boundaries of Natural Language Processing (NLP), advanced AI model architectures, and specialized tokenization strategies for low-resource languages and domain-specific Large Language Models (LLMs).  
- Developed and refined techniques for adaptive learning, model merging, and effective utilization of linguistic principles in AI-driven language understanding.

**Visiting PhD Researcher (Feb 2023 - Jul 2023)**  
*Instituto Politécnico de Tomar (Erasmus), Portugal*  
- Engaged in cross-institutional research, collaborating with international scholars and technical experts to explore multilingual NLP frameworks, advanced algorithmic optimization, and state-of-the-art engineering practices.  
- Investigated the integration of diverse linguistic datasets and cutting-edge model architectures to enhance multilingual model performance and adaptability.

**MS in Information Technology (2018 - 2020)**  
*Marmara University, Turkey (GPA: 4.00)*  
- Concentrated on data management systems, machine learning implementations, and information technology methodologies.  
- Completed in-depth research projects addressing practical applications of ML and data analytics, laying a solid foundation for further specialization in NLP and AI research.

**MSc in Information Technology (Short-Term Erasmus, Jan 2020 - May 2020)**  
*Aristotle University of Thessaloniki, Greece*  
- Strengthened international academic ties and broadened methodological perspectives in IT and data science.  
- Collaborated on comparative studies of computational techniques, enabling richer insights into cross-lingual and cross-cultural data processing challenges.

**BS in Computer Engineering (Oct 2020 - Aug 2022)**  
- Built a core understanding of computer engineering principles, algorithms, and software design.  
- Established technical proficiency that now underpins advanced NLP research, from model deployment and scalability considerations to codebase optimization.

**Additional Degrees and Studies**  
- **Web Design and Coding (Associate, Anadolu University, 2018 - 2020):** Gained practical expertise in front-end/back-end development and UI/UX principles.  
- **Emergency & Disaster Management (Bachelor’s, Istanbul University, 2014 - 2018):** Developed crisis management and problem-solving skills transferable to complex data scenarios and strategic project planning in AI research.  
- **Justice (Associate, Anadolu University, 2015 - 2017):** Acquired analytical reasoning and legal comprehension abilities, enhancing the ethical and regulatory perspective necessary for AI applications in sensitive fields.

Collectively, this multidisciplinary educational background—ranging from foundational computer engineering to applied information technology, as well as domain-specific studies—provides a robust platform for addressing diverse challenges in NLP, AI development, and language model refinement.

## Key Skills

- **Artificial Intelligence & NLP Specialization:**  
  - **Large Language Models (LLMs):** Extensive hands-on experience in training, fine-tuning, and evaluating large-scale models, including custom domain adaptations and multilingual support.  
  - **Transformers & Tokenization:** Advanced knowledge of Transformer architectures, tokenization standards, and specialized techniques (LoRA adapters, SLerp merges) to optimize linguistic fidelity, model efficiency, and semantic richness.  
  - **NLP Benchmarking & Evaluation (MMLU):** Skilled in designing and applying rigorous benchmarking methodologies to assess language understanding, contextual sensitivity, and generalization across diverse domains and languages.

- **Research & Development Expertise:**  
  - **Domain Adaptation & Low-Resource Languages:** Proficient in leveraging adaptive learning rates and data quality-driven optimization strategies to improve model performance in specialized domains (e.g., healthcare, legal, and academic) and languages with limited data resources.  
  - **Quality and Standards in Turkish NLP:** Demonstrated ability to establish, refine, and evaluate Turkish NLP standards that align with linguistic complexity, cultural context, and real-world application demands.  
  - **Cross-Lingual Proficiency:** Utilizing multilingual fluency (Turkish, Kurdish, English, Arabic, along with communicative ability in Persian and Zazaki) to inform model training, evaluation, and interpretation, ensuring greater inclusivity and accuracy for global user bases.

- **Technical & Programming Tools:**  
  - **Core Technologies:** Proficient in Python, including extensive use of AI/ML frameworks such as TensorFlow/Keras and PyTorch for model building, training, and deployment.  
  - **Hugging Face Ecosystem & GitHub:** Adept at integrating pre-trained models, custom tokenizers, and datasets from Hugging Face; version controlling complex codebases and collaborating on open-source projects via GitHub.  
  - **DevOps & Infrastructure:** Skilled in Docker-based containerization, continuous integration/continuous delivery (CI/CD), and scalable infrastructure deployment, ensuring reproducible results and efficient model delivery pipelines.

- **Domain-Specific Applications:**  
  - **Healthcare-Focused LLMs:** Expertise in modeling patient-doctor interactions, medical terminology, and diagnostic reasoning to support decision-making in healthcare environments.  
  - **Legal Q&A Modeling:** Ability to capture specialized vocabularies, legal frameworks, and case-based reasoning within LLMs, enhancing model usability in compliance and advisory contexts.  
  - **Academic, E-Commerce & Media Text Analysis:** Experience in benchmarking academic subjects, analyzing product reviews, and examining consumer feedback and media commentary, providing nuanced insights that drive more context-aware, user-centric AI solutions.

## Selected Academic Publications & Research

**Healthcare-Focused Turkish LLM**  
- *Title:* "Healthcare-Focused Turkish LLM: Training on Real Patient-Doctor Q&A Data"  
- **Scope & Methodology:** Fine-tuned a state-of-the-art Llama 3 (8B) model using an extensive dataset of 167,000+ real-world patient-doctor interactions. Incorporated LoRA adapters and SLerp merging techniques to retain domain knowledge while mitigating catastrophic forgetting.  
- **Key Contributions:** Successfully adapted LLM architectures to medical terminology, diagnostic reasoning, and clinical discourse, achieving enhanced performance and reliability.  
- **Validation:** Benchmarked model outputs against GPT-3.5 and subject-matter expert evaluations, ensuring high-quality, context-sensitive responses that align with real-world healthcare consultation scenarios.

**Turkish MMLU Benchmark**  
- *Title:* "Setting Standards in Turkish NLP: TurkishMMLU for Large Language Model Evaluation"  
- **Dataset & Design:** Developed a comprehensive 6,200-question benchmark derived from a pool of over 280,000 questions, spanning 62 sections, 67 disciplines, and 800+ topics.  
- **Impact & Relevance:** This resource establishes a robust, domain-diverse evaluation standard for Turkish LLMs, enabling more accurate and transparent comparisons of linguistic aptitude, reasoning depth, and domain adaptation.  
- **Outcomes:** Elevated the understanding of Turkish NLP challenges, guiding researchers and practitioners in refining their models and identifying areas for improvement in tokenization, semantics, and cross-domain generalization.

**Conference Paper on Adaptive Learning Rate**  
- *Title:* "Data Quality-Based Adaptive Learning Rate: A Case Study on Medical Text Classification"  
- **Approach:** Introduced a novel, data quality-driven adaptive learning rate mechanism, dynamically adjusting training parameters based on content richness, relevance, and complexity.  
- **Results:** Demonstrated improved convergence rates and enhanced model stability across a 167k-sample medical dataset. The approach not only improved model accuracy but also streamlined training efficiency, providing a scalable blueprint for other specialized NLP applications.  
- **Significance:** Reinforced the value of data-centric methodologies in model optimization, particularly in sensitive and high-impact domains like healthcare, where precision, context, and trustworthiness are paramount.

## Model Development & Contributions

**Doctor-Llama & DoctorGemma Series:**  
- **Domain-Specific Adaptation:** Pioneered the development of Turkish medical Large Language Models (LLMs), including the Doctor-Llama and DoctorGemma series, fine-tuned on an extensive corpus of over 167,000 patient-doctor Q&A interactions. These models integrate authentic clinical dialogues, medical terminology, and region-specific healthcare concerns to ensure highly contextualized, trustworthy, and informative responses.  
- **Advanced Techniques for Knowledge Retention:** Employed LoRA (Low-Rank Adaptation) adapters to efficiently tailor large models without extensive retraining and leveraged SLerp (Spherical Linear Interpolation) merges to refine model parameters, preserving domain-relevant knowledge and reducing catastrophic forgetting.  
- **Iterative Enhancement & Semantic Fidelity:** Continuously iterated on model architectures, incorporating linguistic insights drawn from expertise in Turkish, Kurdish, English, Arabic, Persian, and Zazaki. This multidisciplinary linguistic background facilitated the creation of semantically rich, contextually relevant representations capable of handling complex medical reasoning, differential diagnoses, and patient-specific nuances.

**Broader Model Contributions & Open Source Involvement:**  
- Integrated lessons from medical-domain research into general LLM development, contributing best practices back to open-source NLP communities.  
- Experimented with architectural variations, embedding strategies, and attention mechanisms to achieve scalable and reliable NLP models suitable for both healthcare and other specialized use cases such as legal Q&A and academic benchmarking.  
- Collaborated with interdisciplinary teams, incorporating feedback from domain experts and real-world practitioners to ensure that models serve as robust, ethically guided assistants.

## Datasets & Benchmarking

**Turkish MMLU (Multi-task Massive Language Understanding) Suite:**  
- **Comprehensive Evaluation Framework:** Developed a 6,200-question Turkish MMLU benchmark from a 280k-question pool spanning 62 sections, 67 disciplines, and 800+ topics. This suite informs tokenization standards, LLM evaluation metrics, and cross-lingual transfer strategies, guiding the research community towards more accurate, culturally aware, and context-rich NLP solutions.  
- **Raising the Bar for Turkish NLP:** By establishing performance baselines and transparent evaluation criteria, this benchmark plays a critical role in identifying gaps, refining tokenization approaches, and encouraging the development of models that excel beyond general-purpose capabilities.

**Medical Dataset (167k Patient-Doctor Q&A):**  
- **Realistic Clinical Scenarios:** Curated and processed an extensive medical dataset, encompassing authentic patient inquiries, doctor responses, and follow-up clarifications.  
- **Enhanced Medical Reasoning:** This dataset enabled the training of domain-attuned LLMs that excel in medical dialogue comprehension, differential diagnosis reasoning, and specialized terminology handling, bridging the gap between theoretical NLP research and practical healthcare applications.

**Legal, Consumer Review, and Other Specialized Datasets:**  
- **Domain Versatility:** Extended model development and evaluation into legal and consumer review corpora, broadening the applicability of LLMs to domains requiring contextual precision and nuanced semantic understanding.  
- **Multi-Industry Impact:** Through benchmarking models against diverse datasets—ranging from academic evaluations to e-commerce product reviews and media commentaries—the research ensures that LLMs can adapt and excel in rapidly evolving, linguistically diverse, and domain-specific environments.

Collectively, these model development efforts and dataset-driven benchmarks underscore a commitment to delivering language technologies that are not only high-performing on standard metrics but also sensitive to linguistic, cultural, and domain-specific intricacies. This holistic approach to NLP ensures solutions that are both theoretically sound and pragmatically valuable across global contexts.

## Open Source & Community Contributions

**Tokenizer Projects:**  
- [**malibayram/tokenizer**](https://github.com/malibayram/tokenizer) and [**malibayram/tokenizer_benchmark**](https://github.com/malibayram/tokenizer_benchmark)  
  Developed and refined tokenizers grounded in deep linguistic analysis, ensuring semantic richness, morphological integrity, and efficient segmentation for Turkish and other morphologically complex languages. These projects incorporate both theoretical linguistic frameworks and practical NLP heuristics, making them valuable tools for researchers and practitioners working with diverse and low-resource language data.

**Model Architectures:**  
- [**malibayram/model-architectures**](https://github.com/malibayram/model-architectures)  
  Led experimental initiatives on attention mechanisms, embedding techniques, and architectural prototypes for LLMs. This repository demonstrates a systematic approach to exploring architectural variations, performance profiling, and scalability solutions, ultimately contributing to the broader open-source ecosystem by sharing insights and best practices for building robust, context-aware language models.

**Additional Tooling & Optimizations:**  
- Contributed to Apple Silicon optimization strategies (mlx-examples) and performance enhancements for LLM training pipelines (unsloth). These contributions focus on improving resource utilization, memory management, and training throughput, enabling a more efficient and accessible environment for researchers and developers. By reducing computational overhead and accelerating model iteration cycles, these tools foster innovation and collaboration within the AI community.

## Teaching & Mentorship

- **Research Assistant, Yeditepe University:**  
  Actively involved in undergraduate and graduate-level coursework, offering comprehensive support in AI, programming fundamentals, and algorithmic problem-solving. Provided individualized guidance to students, helping them develop strong analytical thinking, effective coding practices, and a deeper understanding of machine learning concepts.

- **Udemy Instructor, “Google Flutter ve Dart Programlama Dili Temel Eğitimi”:**  
  Designed and delivered an in-depth, structured online course for learners worldwide, covering the full spectrum of Flutter and Dart development. Emphasized practical, hands-on learning experiences, enabling participants to confidently create cross-platform mobile applications. Frequently updated course materials based on industry trends, ensuring students received relevant and cutting-edge instruction.

- **Mentorship in Flutter, Android, and NLP Bootcamps & Clubs:**  
  Guided student clubs and industry-oriented bootcamps, helping novices and intermediate developers navigate complex frameworks, optimize code efficiency, and apply NLP techniques to real-world projects. Focused on building a collaborative learning environment, where participants could engage in code reviews, project critiques, and interdisciplinary discussions. Encouraged learners to leverage their linguistic and cultural backgrounds to inform their approach to AI-driven solutions.

By integrating academic, entrepreneurial, and community-driven teaching experiences, consistently fostered a learning culture that values creativity, critical thinking, and the responsible use of emerging technologies. This holistic mentorship approach has produced graduates and practitioners better equipped to tackle global AI and NLP challenges.

## Languages

- **Turkish (Native):** In-depth understanding of linguistic nuances and cultural contexts.  
- **English (Fluent):** Strong academic and professional proficiency, as evidenced by a high offical score.  
- **Additional Language Proficiencies:** Fluent in Kurdish and Arabic; can communicate effectively in Persian and Zazaki, enabling a richer linguistic perspective in multilingual NLP research and teaching contexts.

## Test Scores

- **YÖKDİL (English):** 87.50 – Demonstrates a robust command of academic and technical English, facilitating effective communication and research dissemination in international settings.  
- **DGS (Quantitative):** Ranked 338th among over 300,000 participants – Reflects exceptional quantitative reasoning ability, analytical problem-solving skills, and performance under competitive academic conditions, further underscoring the capacity to excel in complex technical domains.