@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{amari1993backpropagation,
  title={Backpropagation and stochastic gradient descent method},
  author={Amari, Shun-ichi},
  journal={Neurocomputing},
  volume={5},
  number={4-5},
  pages={185--196},
  year={1993},
  publisher={Elsevier}
}

@article{qian1999momentum,
  title={On the momentum term in gradient descent learning algorithms},
  author={Qian, Ning},
  journal={Neural networks},
  volume={12},
  number={1},
  pages={145--151},
  year={1999},
  publisher={Elsevier}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{liu2021gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2103.10385},
  year={2021}
}

@article{qin2021learning,
  title={Learning how to ask: Querying LMs with mixtures of soft prompts},
  author={Qin, Guanghui and Eisner, Jason},
  journal={arXiv preprint arXiv:2104.06599},
  year={2021}
}

@article{wen2023hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2302.03668},
  year={2023}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2021}
}

@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}

@article{gao2020making,
  title={Making pre-trained language models better few-shot learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}

@article{deng2022rlprompt,
  title={Rlprompt: Optimizing discrete text prompts with reinforcement learning},
  author={Deng, Mingkai and Wang, Jianyu and Hsieh, Cheng-Ping and Wang, Yihan and Guo, Han and Shu, Tianmin and Song, Meng and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2205.12548},
  year={2022}
}

@article{chen2023instructzero,
  title={InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models},
  author={Chen, Lichang and Chen, Jiuhai and Goldstein, Tom and Huang, Heng and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2306.03082},
  year={2023}
}

@article{ma2023let,
  title={Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning},
  author={Ma, Xiao and Mishra, Swaroop and Beirami, Ahmad and Beutel, Alex and Chen, Jilin},
  journal={arXiv preprint arXiv:2306.14308},
  year={2023}
}

@article{chen2023you,
  title={When do you need Chain-of-Thought Prompting for ChatGPT?},
  author={Chen, Jiuhai and Chen, Lichang and Huang, Heng and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2304.03262},
  year={2023}
}

@article{pryzant2023automatic,
  title={Automatic prompt optimization with" gradient descent" and beam search},
  author={Pryzant, Reid and Iter, Dan and Li, Jerry and Lee, Yin Tat and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2305.03495},
  year={2023}
}

@article{back1993overview,
  title={An overview of evolutionary algorithms for parameter optimization},
  author={B{\"a}ck, Thomas and Schwefel, Hans-Paul},
  journal={Evolutionary computation},
  volume={1},
  number={1},
  pages={1--23},
  year={1993},
  publisher={mit Press}
}

@article{rios2013derivative,
  title={Derivative-free optimization: a review of algorithms and comparison of software implementations},
  author={Rios, Luis Miguel and Sahinidis, Nikolaos V},
  journal={Journal of Global Optimization},
  volume={56},
  pages={1247--1293},
  year={2013},
  publisher={Springer}
}

@book{reeves1993modern,
  title={Modern heuristic techniques for combinatorial problems},
  author={Reeves, Colin R},
  year={1993},
  publisher={John Wiley \& Sons, Inc.}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={arXiv preprint arXiv:2205.11916},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}

@inproceedings{zhang2022tempera,
  title={Tempera: Test-time prompt editing via reinforcement learning},
  author={Zhang, Tianjun and Wang, Xuezhi and Zhou, Denny and Schuurmans, Dale and Gonzalez, Joseph E},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{suzgun2022challenging,
  title={Challenging BIG-Bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@article{roy2016solving,
  title={Solving general arithmetic word problems},
  author={Roy, Subhro and Roth, Dan},
  journal={arXiv preprint arXiv:1608.01413},
  year={2016}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@article{wei2023larger,
  title={Larger language models do in-context learning differently},
  author={Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2303.03846},
  year={2023}
}

@article{madaan2022text,
  title={Text and patterns: For effective chain of thought, it takes two to tango},
  author={Madaan, Aman and Yazdanbakhsh, Amir},
  journal={arXiv preprint arXiv:2209.07686},
  year={2022}
}

@article{xu2022gps,
  title={GPS: Genetic Prompt Search for Efficient Few-shot Learning},
  author={Xu, Hanwei and Chen, Yujun and Du, Yulun and Shao, Nan and Wang, Yanggang and Li, Haiyu and Yang, Zhilin},
  journal={arXiv preprint arXiv:2210.17041},
  year={2022}
}

@article{prasad2022grips,
  title={Grips: Gradient-free, edit-based instruction search for prompting large language models},
  author={Prasad, Archiki and Hase, Peter and Zhou, Xiang and Bansal, Mohit},
  journal={arXiv preprint arXiv:2203.07281},
  year={2022}
}

@article{ganguli2023capacity,
  title={The Capacity for Moral Self-Correction in Large Language Models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}

@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{chen2023improving,
  title={Improving Code Generation by Training with Natural Language Feedback},
  author={Chen, Angelica and Scheurer, J{\'e}r{\'e}my and Korbak, Tomasz and Campos, Jon Ander and Chan, Jun Shern and Bowman, Samuel R and Cho, Kyunghyun and Perez, Ethan},
  journal={arXiv preprint arXiv:2303.16749},
  year={2023}
}

@article{shinn2023reflexion,
  title={Reflexion: an autonomous agent with dynamic memory and self-reflection},
  author={Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{kim2023language,
  title={Language Models can Solve Computer Tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={arXiv preprint arXiv:2303.17491},
  year={2023}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{chen2023teaching,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}

@article{olausson2023demystifying,
  title={Demystifying GPT Self-Repair for Code Generation},
  author={Olausson, Theo X and Inala, Jeevana Priya and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
  journal={arXiv preprint arXiv:2306.09896},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{yuan2023system,
  title={System-Level Natural Language Feedback},
  author={Yuan, Weizhe and Cho, Kyunghyun and Weston, Jason},
  journal={arXiv preprint arXiv:2306.13588},
  year={2023}
}

@article{madaan2023self,
  title={Self-Refine: Iterative Refinement with Self-Feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{nair2023dera,
  title={DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents},
  author={Nair, Varun and Schumacher, Elliot and Tso, Geoffrey and Kannan, Anitha},
  journal={arXiv preprint arXiv:2303.17071},
  year={2023}
}

@article{chen2023evoprompting,
  title={EvoPrompting: Language Models for Code-Level Neural Architecture Search},
  author={Chen, Angelica and Dohan, David M and So, David R},
  journal={arXiv preprint arXiv:2302.14838},
  year={2023}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{ling2017program,
  title={Program induction by rationale generation: Learning to solve and explain algebraic word problems},
  author={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},
  journal={arXiv preprint arXiv:1705.04146},
  year={2017}
}

@article{chen2022towards,
  title={Towards learning universal hyperparameter optimizers with transformers},
  author={Chen, Yutian and Song, Xingyou and Lee, Chansoo and Wang, Zi and Zhang, Richard and Dohan, David and Kawakami, Kazuya and Kochanski, Greg and Doucet, Arnaud and Ranzato, Marc'aurelio and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32053--32068},
  year={2022}
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@article{lehman2022evolution,
  title={Evolution through Large Models},
  author={Lehman, Joel and Gordon, Jonathan and Jain, Shawn and Ndousse, Kamal and Yeh, Cathy and Stanley, Kenneth O},
  journal={arXiv preprint arXiv:2206.08896},
  year={2022}
}

@article{meyerson2023language,
  title={Language Model Crossover: Variation through Few-Shot Prompting},
  author={Meyerson, Elliot and Nelson, Mark J and Bradley, Herbie and Moradi, Arash and Hoover, Amy K and Lehman, Joel},
  journal={arXiv preprint arXiv:2302.12170},
  year={2023}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{cai2023large,
  title={Large language models as tool makers},
  author={Cai, Tianle and Wang, Xuezhi and Ma, Tengyu and Chen, Xinyun and Zhou, Denny},
  journal={arXiv preprint arXiv:2305.17126},
  year={2023}
}

@article{junger1995traveling,
  title={The traveling salesman problem},
  author={J{\"u}nger, Michael and Reinelt, Gerhard and Rinaldi, Giovanni},
  journal={Handbooks in operations research and management science},
  volume={7},
  pages={225--330},
  year={1995},
  publisher={Elsevier}
}

@book{gutin2006traveling,
  title={The traveling salesman problem and its variations},
  author={Gutin, Gregory and Punnen, Abraham P},
  volume={12},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{rosenkrantz1977analysis,
  title={An analysis of several heuristics for the traveling salesman problem},
  author={Rosenkrantz, Daniel J and Stearns, Richard E and Lewis, II, Philip M},
  journal={SIAM journal on computing},
  volume={6},
  number={3},
  pages={563--581},
  year={1977},
  publisher={SIAM}
}

@article{golden1980approximate,
  title={Approximate traveling salesman algorithms},
  author={Golden, Bruce and Bodin, Lawrence and Doyle, T and Stewart Jr, W},
  journal={Operations research},
  volume={28},
  number={3-part-ii},
  pages={694--711},
  year={1980},
  publisher={INFORMS}
}

@misc{optimization2020gurobi,
  title={Gurobi optimizer reference manual},
  author={Optimization, Gurobi and others},
  year={2020}
}

@misc{applegate2006concorde,
  title={Concorde TSP solver},
  author={Applegate, David and Bixby, Ribert and Chvatal, Vasek and Cook, William},
  year={2006}
}

@article{helsgaun2017extension,
  title={An extension of the Lin-Kernighan-Helsgaun TSP solver for constrained traveling salesman and vehicle routing problems},
  author={Helsgaun, Keld},
  journal={Roskilde: Roskilde University},
  volume={12},
  year={2017}
}

@inproceedings{kool2018attention,
title={Attention, Learn to Solve Routing Problems!},
author={Wouter Kool and Herke van Hoof and Max Welling},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ByxBFsRqYm},
}

@inproceedings{deudon2018learning,
  title={Learning heuristics for the tsp by policy gradient},
  author={Deudon, Michel and Cournut, Pierre and Lacoste, Alexandre and Adulyasak, Yossiri and Rousseau, Louis-Martin},
  booktitle={International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research},
  pages={170--181},
  year={2018},
  organization={Springer}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement Learning for Solving the Vehicle Routing Problem},
  author={Nazari, MohammadReza and Oroojlooy, Afshin and Snyder, Lawrence and Takac, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9861--9871},
  year={2018}
}

@article{chen2019learning,
  title={Learning to perform local rewriting for combinatorial optimization},
  author={Chen, Xinyun and Tian, Yuandong},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@article{mirchandani2023large,
  title={Large language models as general pattern machines},
  author={Mirchandani, Suvir and Xia, Fei and Florence, Pete and Ichter, Brian and Driess, Danny and Arenas, Montserrat Gonzalez and Rao, Kanishka and Sadigh, Dorsa and Zeng, Andy},
  journal={arXiv preprint arXiv:2307.04721},
  year={2023}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{fernando2023promptbreeder,
  title={Promptbreeder: Self-referential self-improvement via prompt evolution},
  author={Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2309.16797},
  year={2023}
}

@article{guo2023connecting,
  title={Connecting large language models with evolutionary algorithms yields powerful prompt optimizers},
  author={Guo, Qingyan and Wang, Rui and Guo, Junliang and Li, Bei and Song, Kaitao and Tan, Xu and Liu, Guoqing and Bian, Jiang and Yang, Yujiu},
  journal={arXiv preprint arXiv:2309.08532},
  year={2023}
}