{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc27b05-599f-4fc0-9b65-91a972162b68",
   "metadata": {
    "language": "python"
   },
   "source": [
    "# Creating Agents Using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc4e87",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=VoWGD4mvKjU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed739e88-f15e-47e7-836b-0d75e6d07572",
   "metadata": {
    "language": "python"
   },
   "source": [
    "## Structured Chat Agent \n",
    "The structured chat agent is capable of using multi-input tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce288b-ddee-4661-97d7-53839cf1ba5f",
   "metadata": {
    "language": "python"
   },
   "source": [
    "In agents, a language model is used as a reasoning engine to determine which actions to take and in which order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc6713-8090-4e06-9efa-9b940fe97c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:50:31.020310Z",
     "iopub.status.busy": "2024-07-25T05:50:31.019763Z",
     "iopub.status.idle": "2024-07-25T05:50:36.125206Z",
     "shell.execute_reply": "2024-07-25T05:50:36.123026Z",
     "shell.execute_reply.started": "2024-07-25T05:50:31.020270Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain-community langchain-openai langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23452fc-fee7-4e29-a7bb-814c11cd95cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:50:38.138590Z",
     "iopub.status.busy": "2024-07-25T05:50:38.138013Z",
     "iopub.status.idle": "2024-07-25T05:50:38.145034Z",
     "shell.execute_reply": "2024-07-25T05:50:38.144491Z",
     "shell.execute_reply.started": "2024-07-25T05:50:38.138561Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391bb78-1d67-4e6b-83b8-a71d5c1bb111",
   "metadata": {
    "language": "python"
   },
   "source": [
    "## Tavily Search to build the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948d508-1e61-4b81-b71d-0100300e0789",
   "metadata": {
    "language": "python"
   },
   "source": [
    "Tavily Search API is a search engine optimized for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545235d6-555c-4b83-8f93-653e11d167f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:50:48.340010Z",
     "iopub.status.busy": "2024-07-25T05:50:48.339686Z",
     "iopub.status.idle": "2024-07-25T05:50:48.344605Z",
     "shell.execute_reply": "2024-07-25T05:50:48.343856Z",
     "shell.execute_reply.started": "2024-07-25T05:50:48.339979Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"tvly-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e66a6d-9bd6-400a-9aa5-ac828b6a0bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:51:17.478226Z",
     "iopub.status.busy": "2024-07-25T05:51:17.477790Z",
     "iopub.status.idle": "2024-07-25T05:51:17.483439Z",
     "shell.execute_reply": "2024-07-25T05:51:17.482820Z",
     "shell.execute_reply.started": "2024-07-25T05:51:17.478189Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b8e9c-e15e-44b6-8ef1-a7d3b5278062",
   "metadata": {
    "language": "python"
   },
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c76b17-dffc-4b26-9e09-aa09f214ecd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:51:34.376450Z",
     "iopub.status.busy": "2024-07-25T05:51:34.376079Z",
     "iopub.status.idle": "2024-07-25T05:51:34.861393Z",
     "shell.execute_reply": "2024-07-25T05:51:34.860397Z",
     "shell.execute_reply.started": "2024-07-25T05:51:34.376416Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alibayram/Library/Python/3.9/lib/python/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5fc04f3-b628-4f26-baae-a9ac559aa71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:51:51.461886Z",
     "iopub.status.busy": "2024-07-25T05:51:51.461486Z",
     "iopub.status.idle": "2024-07-25T05:51:51.465963Z",
     "shell.execute_reply": "2024-07-25T05:51:51.465326Z",
     "shell.execute_reply.started": "2024-07-25T05:51:51.461846Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable for the OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-ORca....\"\n",
    "\n",
    "# Now you can use the API as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc3326c-e941-406b-8972-7bf3ba987886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:52:04.262323Z",
     "iopub.status.busy": "2024-07-25T05:52:04.261983Z",
     "iopub.status.idle": "2024-07-25T05:52:04.297067Z",
     "shell.execute_reply": "2024-07-25T05:52:04.296309Z",
     "shell.execute_reply.started": "2024-07-25T05:52:04.262298Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Construct the JSON agent\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa5c80-cb44-42d1-aab3-7e85260a8fcd",
   "metadata": {
    "language": "python"
   },
   "source": [
    "## Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3eaed55-76cd-4c1e-9ccc-8fa61f5f492a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:52:15.053184Z",
     "iopub.status.busy": "2024-07-25T05:52:15.052862Z",
     "iopub.status.idle": "2024-07-25T05:52:15.056941Z",
     "shell.execute_reply": "2024-07-25T05:52:15.056358Z",
     "shell.execute_reply.started": "2024-07-25T05:52:15.053155Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28b2818e-83bd-42d6-bdfb-350f96051b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T05:52:39.202440Z",
     "iopub.status.busy": "2024-07-25T05:52:39.202066Z",
     "iopub.status.idle": "2024-07-25T05:52:44.844962Z",
     "shell.execute_reply": "2024-07-25T05:52:44.844264Z",
     "shell.execute_reply.started": "2024-07-25T05:52:39.202403Z"
    },
    "language": "python",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI will use the search engine to look up information about LlamaIndex and LangChain to provide accurate and comprehensive information.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": {\"query\": \"LlamaIndex\"}\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.ibm.com/think/topics/llamaindex', 'content': 'LlamaIndex is an open source data orchestration framework for building large language model (LLM) applications. Data agents are LLM-driven AI agents capable of performing a range of tasks on data, including both reading and writing functions.10\\xa0LlamaIndex data agents are LLM-powered knowledge works that can perform the following: LlamaIndex provides tool abstractions that wrap around the existing data query engines and abstractions for functions that can be used by the tool spec class. LlamaIndex has a tutorial on how to build a chatbot that uses a Data Agent. 6 “Loading Data (Ingestion),” LlamaIndex, https://docs.llamaindex.ai/en/stable/understanding/loading/loading/\\xa0(link resides outside ibm.com). 14 “Question-Answering (RAG),” LlamaIndex, \\xa0https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/\\xa0(link resides outside ibm.com). 15 “Agents,” LlamaIndex, https://docs.llamaindex.ai/en/stable/use_cases/agents/\\xa0(link resides outside ibm.com).'}]\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": {\"query\": \"LangChain\"}\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}]\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: LlamaIndex is an open source data orchestration framework for building large language model (LLM) applications. It involves data agents that are LLM-driven AI agents capable of performing various tasks on data, including reading and writing functions. LlamaIndex provides tool abstractions that wrap around existing data query engines and abstractions for functions that can be used by the tool spec class. It also has tutorials on how to build a chatbot that uses a Data Agent.\n",
      "\n",
      "LangChain, on the other hand, is a language model integration framework that includes integrations with various systems and services, such as cloud storage, API wrappers, web scraping subsystems, language models, databases, and more. Its use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "In summary, LlamaIndex is focused on data orchestration for large language model applications, while LangChain is a language model integration framework with a wide range of integrations and use-cases.\n",
      "\n",
      "Final Answer:\n",
      "LlamaIndex is an open source data orchestration framework for building large language model (LLM) applications, while LangChain is a language model integration framework with a wide range of integrations and use-cases.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LlamaIndex is an open source data orchestration framework for building large language model (LLM) applications, while LangChain is a language model integration framework with a wide range of integrations and use-cases.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LlamaIndex and what is the difference between LangChain and LlamaIndex?',\n",
       " 'output': 'LlamaIndex is an open source data orchestration framework for building large language model (LLM) applications, while LangChain is a language model integration framework with a wide range of integrations and use-cases.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LlamaIndex and what is the difference between LangChain and LlamaIndex?\"})"
   ]
  }
 ],
 "metadata": {
  "jupyterlab": {
   "notebooks": {
    "version_major": 6,
    "version_minor": 4
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "singlestore_cell_default_language": "python",
  "singlestore_connection": {
   "connectionID": "a22b6f8b-b11b-4979-98da-98513e9876e6",
   "defaultDatabase": ""
  },
  "singlestore_row_limit": 300
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
