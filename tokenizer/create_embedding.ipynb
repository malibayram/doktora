{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('tr_token_mapping.json') as f:\n",
    "    token_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30158"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5756727ad029420fb91f96f8dc44421f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2Model(\n",
       "  (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-25): 26 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "        (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import Gemma2Model\n",
    "\n",
    "gemma_model = Gemma2Model.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "gemma_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30158, 2304])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty tensor to store the embeddings of the tokens shape (len(token_list), gemma_model.embed_tokens.weight.shape[1])\n",
    "gemma_embeddings = gemma_model.embed_tokens.weight\n",
    "embeddings = torch.zeros(len(token_list), gemma_embeddings.shape[1])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tr_token': 'salavat',\n",
       "  'tr_token_id': 21105,\n",
       "  'llama_token_ids': [19776, 402, 266],\n",
       "  'gemma2_token_ids': [7871, 58714]},\n",
       " tensor([ 0.0039,  0.0043,  0.0183,  ...,  0.0139, -0.0064,  0.0596],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[0], gemma_embeddings[58714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0067, -0.0076,  0.0065,  ...,  0.0170, -0.0135,  0.0192],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = gemma_embeddings[7871]\n",
    "e2 = gemma_embeddings[58714]\n",
    "\n",
    "e1 = e1 + e2\n",
    "average = e1 / 2\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0002, -0.0059,  0.0222,  ...,  0.0152, -0.0074, -0.0119],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each token in the token_list, get the corresponding embedding from the gemma model and store it in the embeddings tensor\n",
    "# if there is more than one token in the token_list that maps to the same index, average the embeddings\n",
    "\n",
    "for token_map in token_list:\n",
    "    index = token_map['tr_token_id']\n",
    "    gemma2_token_ids = token_map['gemma2_token_ids']\n",
    "    embedding = gemma_embeddings[gemma2_token_ids[0]]\n",
    "    sum_embedding = embedding\n",
    "    for gemma2_token_id in gemma2_token_ids[1:]:\n",
    "        embedding = embedding + gemma_embeddings[gemma2_token_id]\n",
    "    if len(gemma2_token_ids) > 1:\n",
    "        embedding = embedding / len(gemma2_token_ids)        \n",
    "    embeddings[index] = embedding\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_zero_embeddings = 0\n",
    "for i in range(len(embeddings)):\n",
    "    if torch.all(embeddings[i] == 0):\n",
    "        count_of_zero_embeddings += 1\n",
    "count_of_zero_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings tensor to a file\n",
    "torch.save(embeddings, 'tr_gemma2_embeddings.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
