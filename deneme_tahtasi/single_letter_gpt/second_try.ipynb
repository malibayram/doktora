{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT modelinin parametre sayısını hesaplamak için aşağıdaki formüller kullanılır:\n",
    "\n",
    "1. **Embedding layer**: \\( vocab\\_size \\times n\\_embd \\)\n",
    "2. **Transformer block**: Her bir Transformer bloğunda toplam parametre sayısı şu şekildedir:\n",
    "   - **LayerNorm**: İki LayerNorm katmanı vardır, her biri \\( 2 \\times n\\_embd \\)\n",
    "   - **Attention (Q, K, V)**: \\( 3 \\times (n\\_embd \\times (n\\_embd // n\\_head) + n\\_embd) \\)\n",
    "   - **Attention output projection**: \\( n\\_embd \\times n\\_embd + n\\_embd \\)\n",
    "   - **MLP (intermediate dense layers)**: \\( 2 \\times (n\\_embd \\times 4 \\times n\\_embd + 4 \\times n\\_embd) \\)\n",
    "\n",
    "Bu formülleri kullanarak parametre sayısını hesaplayalım.\n",
    "\n",
    "### Hesaplamalar\n",
    "\n",
    "#### Embedding Layer\n",
    "\n",
    "\\[\n",
    "50257 \\times 768 = 38,609,856\n",
    "\\]\n",
    "\n",
    "#### Transformer Block\n",
    "\n",
    "Her bir Transformer bloğunda:\n",
    "\n",
    "- **LayerNorm**: \n",
    "  \\[\n",
    "  2 \\times 768 = 1,536\n",
    "  \\]\n",
    "\n",
    "- **Attention (Q, K, V)**:\n",
    "  \\[\n",
    "  3 \\times (768 \\times (768 // 12) + 768) = 3 \\times (768 \\times 64 + 768) = 3 \\times (49,152 + 768) = 3 \\times 49,920 = 149,760\n",
    "  \\]\n",
    "\n",
    "- **Attention output projection**:\n",
    "  \\[\n",
    "  768 \\times 768 + 768 = 590,592 + 768 = 591,360\n",
    "  \\]\n",
    "\n",
    "- **MLP**:\n",
    "  \\[\n",
    "  2 \\times (768 \\times 4 \\times 768 + 4 \\times 768) = 2 \\times (3,145,728 + 3,072) = 2 \\times 3,148,800 = 6,297,600\n",
    "  \\]\n",
    "\n",
    "Her bir Transformer bloğu için toplam:\n",
    "\\[\n",
    "1,536 + 149,760 + 591,360 + 6,297,600 = 7,040,256\n",
    "\\]\n",
    "\n",
    "#### Toplam Transformer Bloğu Parametreleri\n",
    "\\[\n",
    "12 \\times 7,040,256 = 84,483,072\n",
    "\\]\n",
    "\n",
    "#### Toplam Parametreler\n",
    "\\[\n",
    "38,609,856 (Embedding) + 84,483,072 (Transformer blokları) = 123,092,928\n",
    "\\]\n",
    "\n",
    "Bu hesaplamalar, yaklaşık 124 milyon parametreye oldukça yakındır. Modelin toplam parametre sayısının 124M olduğu, verilen konfigürasyon değerlerine göre bu şekilde hesaplanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import inspect\n",
    "import math\n",
    "import os\n",
    "import struct\n",
    "from contextlib import nullcontext\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch._inductor.config as config\n",
    "import torch.nn as nn\n",
    "from torch.distributed.optim import ZeroRedundancyOptimizer\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewGELU(nn.Module):\n",
    "    \"\"\"Careful there are a few versions of GeLU, this one is the exact one used by OpenAI\"\"\"\n",
    "    def forward(self, input):\n",
    "        return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLASH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.LLMC_RESIDUAL_SCALE_FLAG = 1\n",
    "        # regularization\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        # not really a 'bias', more of a mask, but following the OpenAI/HF naming though\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                     .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        if FLASH:\n",
    "            # flashattention\n",
    "            y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            # this materializes the large (T,T) matrix for all the queries and keys\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu    = NewGELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.LLMC_RESIDUAL_SCALE_FLAG = 1 # special flag for residual scaling.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" @dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50257\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768 \"\"\"\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 64\n",
    "    vocab_size: int = 32\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print0(*args, **kwargs):\n",
    "    # modified print that only prints from the master process\n",
    "    # if this is not a distributed run, it's just a print\n",
    "    if int(os.environ.get(\"RANK\", 0)) == 0:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd), # wte: word token embeddings\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd), # wpe: positional embeddings\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]), # h: transformer blocks\n",
    "            ln_f = nn.LayerNorm(config.n_embd), # ln_f: final layer norm before output\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False) # lm_head: head for language modeling\n",
    "        self.lm_head.LLMC_SKIP_INIT = 1 # don't init this one, we will tie weights\n",
    "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "        # init all weights, use a torch rng object to be very careful\n",
    "        self.init_rng = torch.Generator()\n",
    "        self.init_rng.manual_seed(42)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "            std = 0.02 if not hasattr(module, 'LLMC_RESIDUAL_SCALE_FLAG') else 0.02 / math.sqrt(2 * self.config.n_layer)\n",
    "            # we want to skip initializing lm_head, which shares parameters with wte\n",
    "            # and wte was already initialized down below during the Embedding init\n",
    "            if not hasattr(module, 'LLMC_SKIP_INIT'):\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=std, generator=self.init_rng)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02, generator=self.init_rng)\n",
    "\n",
    "    def forward(self, idx, targets=None, return_logits=True):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        # there are performance reasons why not returning logits is prudent, if not needed\n",
    "        if not return_logits:\n",
    "            logits = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type, zero_stage):\n",
    "        # start with all of the candidate parameters\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        # filter out those that do not require grad\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print0(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print0(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        print0(f\"using fused AdamW: {use_fused}\")\n",
    "        if zero_stage == 1:\n",
    "            print0(\"using ZeroRedundancyOptimizer\")\n",
    "            optimizer = ZeroRedundancyOptimizer(**optim_groups[0], optimizer_class=torch.optim.AdamW,\n",
    "                                                lr=learning_rate, betas=betas, fused=use_fused)\n",
    "            optimizer.add_param_group(optim_groups[1])\n",
    "        else:\n",
    "            print0(\"using regular AdamW\")\n",
    "            optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, fused=use_fused)\n",
    "        return optimizer\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            # forward the model to get the logits for the index in the sequence\n",
    "            logits, _ = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _peek_data_shard(filename):\n",
    "    # only reads the header, returns header data\n",
    "    with open(filename, \"rb\") as f:\n",
    "        tokens = f.read()\n",
    "        tokens = [x for x in tokens]\n",
    "    return len(tokens)\n",
    "\n",
    "def _load_data_shard(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        tokens = f.read()\n",
    "        tokens = [x for x in tokens]\n",
    "    return tokens\n",
    "\n",
    "class DistributedDataLoader:\n",
    "    def __init__(self, filename_pattern, B, T, process_rank, num_processes):\n",
    "        self.process_rank = process_rank\n",
    "        self.num_processes = num_processes\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "\n",
    "        # glob files that match the pattern\n",
    "        self.files = sorted(glob.glob(filename_pattern))\n",
    "        assert len(self.files) > 0, f\"did not find any files that match the pattern {filename_pattern}\"\n",
    "\n",
    "        # load and validate all data shards, count number of tokens in total\n",
    "        ntok_total = 0\n",
    "        for fname in self.files:\n",
    "            shard_ntok = _peek_data_shard(fname)\n",
    "            assert shard_ntok >= num_processes * B * T + 1, f\"dataset shard {fname} is too small for the current setting\"\n",
    "            ntok_total += shard_ntok\n",
    "        self.ntok_total = ntok_total\n",
    "        print0(f\"DataLoader: total number of tokens: {ntok_total:,} across {len(self.files)} files\")\n",
    "\n",
    "        # kick things off\n",
    "        self.current_shard = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # we're being a bit clever here: if we already had shard 0 loaded,\n",
    "        # then don't do the work to reload it, just reset the pointer\n",
    "        if self.current_shard != 0:\n",
    "            self.current_shard = 0\n",
    "            self.tokens = _load_data_shard(self.files[self.current_shard])\n",
    "        self.current_position = self.process_rank * self.B * self.T\n",
    "\n",
    "    def advance(self): # advance to next data shard\n",
    "        self.current_shard = (self.current_shard + 1) % len(self.files)\n",
    "        self.current_position = self.process_rank * self.B * self.T\n",
    "        self.tokens = _load_data_shard(self.files[self.current_shard])\n",
    "\n",
    "    def next_batch(self):\n",
    "        B = self.B\n",
    "        T = self.T\n",
    "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
    "        # buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)\n",
    "        buf = torch.tensor(buf, dtype=torch.long)\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the start pointer in current shard\n",
    "        self.current_position += B * T * self.num_processes\n",
    "        # if loading the next batch would be out of bounds advance the shard\n",
    "        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):\n",
    "            self.advance()\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fp16(tensor, file):\n",
    "    t = tensor.detach().cpu().to(torch.float16)\n",
    "    b = t.numpy().tobytes()\n",
    "    file.write(b)\n",
    "\n",
    "def write_fp32(tensor, file):\n",
    "    t = tensor.detach().cpu().to(torch.float32)\n",
    "    b = t.numpy().tobytes()\n",
    "    file.write(b)\n",
    "\n",
    "def write_bf16(tensor, file):\n",
    "    t = tensor.detach().cpu().to(torch.bfloat16)\n",
    "    # numpy doesn't have bf16 datatype so we have to trick it\n",
    "    t = t.view(torch.int16) # trick: reinterpret as int16\n",
    "    b = t.numpy().tobytes()\n",
    "    file.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tensors(model_tensors, L, file, dtype):\n",
    "    # writes the GPT-2 model's weights to a binary file\n",
    "    assert dtype in {\"float16\", \"float32\", \"bfloat16\"}\n",
    "    write_fun = write_fp16 if dtype == \"float16\" else write_fp32 if dtype == \"float32\" else write_bf16\n",
    "    write_fun(model_tensors[\"transformer.wte.weight\"], file) # (V, C)\n",
    "    write_fun(model_tensors[\"transformer.wpe.weight\"], file) # (T, C)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.ln_1.weight\"], file)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.ln_1.bias\"], file)\n",
    "    for i in range(L): # (L, 3C, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.attn.c_attn.weight\"], file)\n",
    "    for i in range(L): # (L, 3C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.attn.c_attn.bias\"], file)\n",
    "    for i in range(L): # (L, C, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.attn.c_proj.weight\"], file)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.attn.c_proj.bias\"], file)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.ln_2.weight\"], file)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.ln_2.bias\"], file)\n",
    "    for i in range(L): # (L, 4C, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.mlp.c_fc.weight\"], file)\n",
    "    for i in range(L): # (L, 4C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.mlp.c_fc.bias\"], file)\n",
    "    for i in range(L): # (L, C, 4C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.mlp.c_proj.weight\"], file)\n",
    "    for i in range(L): # (L, C)\n",
    "        write_fun(model_tensors[f\"transformer.h.{i}.mlp.c_proj.bias\"], file)\n",
    "    write_fun(model_tensors[\"transformer.ln_f.weight\"], file) # (C, )\n",
    "    write_fun(model_tensors[\"transformer.ln_f.bias\"], file) # (C, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pad_vocab(tensor, multiple=128, value=0):\n",
    "    \"\"\"\n",
    "    The dimension of the vocab size in GPT-2 is 50,257\n",
    "    which is unfortunately a very unfriendly number for a lot of\n",
    "    matrix operations on the GPU. So we pad it to the nearest\n",
    "    friendlier multiple, e.g. 50,304 if multiple=128 when we\n",
    "    export the weights into C land. This is a NOOP algorithmically\n",
    "    and is only done to make the tensor operations more efficient.\n",
    "    \"\"\"\n",
    "    assert tensor.ndim == 2\n",
    "    V, C = tensor.shape\n",
    "    # assert V == 50257, \"just being defensive here\"\n",
    "    # calculate padded vocab size by rounding up to nearest multiple\n",
    "    Vp = ((V + multiple - 1) // multiple) * multiple\n",
    "    # pad the tensor\n",
    "    pad_rows = Vp - V\n",
    "    padded = tensor if pad_rows == 0 else F.pad(tensor, (0, 0, 0, pad_rows), value=value)\n",
    "    assert padded.shape == (Vp, C)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(model, filename, dtype):\n",
    "    # everything we need to instantiate the model\n",
    "    # 1) header is: version int, GPTConfig ints, padding to 1024 bytes\n",
    "    assert dtype in {\"float16\", \"float32\", \"bfloat16\"} # float16 todo maybe later\n",
    "    version = {\n",
    "        \"float16\": 2, # 2: all tensors are fp16, padded vocab\n",
    "        \"float32\": 3, # 3: all tensors are fp32, padded vocab\n",
    "        \"bfloat16\": 5, # 5: all tensors are bf16, padded vocab\n",
    "    }[dtype]\n",
    "    header = torch.zeros(256, dtype=torch.int32)\n",
    "    header[0] = 20240326 # magic\n",
    "    header[1] = version # checkpoint version\n",
    "    header[2] = model.config.block_size\n",
    "    header[3] = model.config.vocab_size\n",
    "    header[4] = model.config.n_layer\n",
    "    header[5] = model.config.n_head\n",
    "    header[6] = model.config.n_embd\n",
    "    # 2) the parameters follow the header\n",
    "    params = {name: param.cpu() for name, param in model.named_parameters()}\n",
    "    # pad the vocab to a multiple of 128 here at export, for efficiency in C\n",
    "    wte = params[\"transformer.wte.weight\"] # (V, C)\n",
    "    wte_padded = pad_vocab(wte) # (Vp, C)\n",
    "    params[\"transformer.wte.weight\"] = wte_padded # (Vp, C)\n",
    "    print(f\"padded vocab size from {wte.size(0)} to {wte_padded.size(0)}\")\n",
    "    header[7] = wte_padded.size(0) # padded vocab size store in header\n",
    "    # now write to file\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(header.numpy().tobytes()) # header\n",
    "        write_tensors(params, model.config.n_layer, file, dtype) # params\n",
    "    print(f\"wrote {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_state(model, x, y, logits, loss, filename, dtype=\"float32\"):\n",
    "    # the state is used for debugging.\n",
    "    # it contains information about the input, logits, loss, and the parameter gradients\n",
    "    # this can be used for checking the computation correctness in C\n",
    "    header = torch.zeros(256, dtype=torch.int32)\n",
    "    header[0] = 20240327 # magic\n",
    "    header[1] = 2 # run state version = 2 (1 -> 2 for padded vocab changes)\n",
    "    header[2] = x.size(0) # batch size of the batch, B\n",
    "    header[3] = x.size(1) # temporal extent of the batch, T\n",
    "    grads = {name: param.grad.cpu() for name, param in model.named_parameters()}\n",
    "    # pad the vocab grads here as well, to mirror write_model\n",
    "    wte_grad = grads[\"transformer.wte.weight\"] # (V, C)\n",
    "    wte_grad_padded = pad_vocab(wte_grad, value=0) # (Vp, C) # TODO later maybe pad with nan?\n",
    "    grads[\"transformer.wte.weight\"] = wte_grad_padded # (Vp, C)\n",
    "    print(f\"padded vocab size in reference grads from {wte_grad.size(0)} to {wte_grad_padded.size(0)}\")\n",
    "    with open(filename, \"wb\") as file:\n",
    "        # header\n",
    "        file.write(header.numpy().tobytes())\n",
    "        # input x\n",
    "        file.write(x.cpu().numpy().astype(\"int32\").tobytes()) # (B, T)\n",
    "        # targets y\n",
    "        file.write(y.cpu().numpy().astype(\"int32\").tobytes()) # (B, T)\n",
    "        # logits (result of the model forward pass)\n",
    "        write_fp32(logits.cpu(), file)\n",
    "        # loss (single float, result of the cross entropy loss)\n",
    "        write_fp32(loss.cpu(), file)\n",
    "        # gradients\n",
    "        write_tensors(grads, model.config.n_layer, file, dtype)\n",
    "    print(f\"wrote {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tokenizer(enc, filename):\n",
    "    n = enc.max_token_value + 1\n",
    "    header = torch.zeros(256, dtype=torch.int32)\n",
    "    header[0] = 20240328 # magic\n",
    "    header[1] = 2 # tokenizer version = 2 (1 -> 2: includes EOT token)\n",
    "    header[2] = n # number of tokens\n",
    "    header[3] = enc.eot_token # EOT token\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(header.numpy().tobytes())\n",
    "        for i in range(n):\n",
    "            b = enc.decode_bytes([i])\n",
    "            length = len(b)\n",
    "            assert length < 256, f\"Token length exceeds 255: {length}\"\n",
    "            file.write(struct.pack(\"<B\", length))  # Write the length as a 1-byte unsigned integer\n",
    "            file.write(b)  # Write the actual bytes\n",
    "    print(f\"wrote {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps (cpu)\n"
     ]
    }
   ],
   "source": [
    "# B, T = 2, 4\n",
    "\"\"\" \n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 128\n",
    "    vocab_size: int = 64\n",
    "    n_layer: int = 4\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 16 \"\"\"\n",
    "\n",
    "B, T = 128, 32 # batch size, sequence length\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "print(f\"using device: {device} ({device_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddp_rank = 0\n",
    "ddp_local_rank = 0\n",
    "zero_stage = 0\n",
    "ddp_world_size = 1\n",
    "master_process = True\n",
    "seed_offset = 0\n",
    "total_batch_size = B * T\n",
    "tokens_per_fwdbwd = B * T\n",
    "tokens_per_fwdbwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total desired batch size: 4096\n",
      "=> calculated gradient accumulation steps: 1\n"
     ]
    }
   ],
   "source": [
    "assert total_batch_size % tokens_per_fwdbwd == 0\n",
    "grad_accum_steps = total_batch_size // tokens_per_fwdbwd\n",
    "print0(f\"total desired batch size: {total_batch_size}\")\n",
    "print0(f\"=> calculated gradient accumulation steps: {grad_accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a context manager following the desired dtype and device\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16, 'float8': torch.float8_e4m3fn}['float16']\n",
    "ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype) if device_type == \"cuda\" else nullcontext()\n",
    "# rng / reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(32, 144)\n",
       "    (wpe): Embedding(64, 144)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=144, out_features=432, bias=True)\n",
       "          (c_proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (gelu): NewGELU()\n",
       "          (c_proj): Linear(in_features=576, out_features=144, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=144, out_features=32, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(GPTConfig())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "if False: # args.compile:\n",
    "    if hasattr(config, \"coordinate_descent_tuning\"):\n",
    "        config.coordinate_descent_tuning = True # suggested by @Chillee\n",
    "    print0(\"compiling the model...\")\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader: total number of tokens: 67,625 across 1 files\n",
      "DataLoader: total number of tokens: 8,453 across 1 files\n"
     ]
    }
   ],
   "source": [
    "train_loader = DistributedDataLoader(\"tokenizer/train_tokens2.bin\", B, T, ddp_rank, ddp_world_size)\n",
    "val_loader = DistributedDataLoader(\"tokenizer/val_tokens2.bin\", B, T, ddp_rank, ddp_world_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 32]), torch.Size([128, 32]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_loader.next_batch()\n",
    "x, y = x.to(device), y.to(device)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded vocab size from 32 to 128\n",
      "wrote gpt2_12K.bin\n",
      "padded vocab size from 32 to 128\n",
      "wrote gpt2_12K_bf16.bin\n",
      "padded vocab size in reference grads from 32 to 128\n",
      "wrote gpt2_12K_debug_state.bin\n"
     ]
    }
   ],
   "source": [
    "logits, loss = model(x, y)\n",
    "loss.backward()\n",
    "# save model params, in both float32 and bfloat16\n",
    "model_to_size = {\"gpt1Letter\": \"12K\",  \"gpt2\": \"124M\", \"gpt2-medium\": \"355M\", \"gpt2-large\": \"774M\", \"gpt2-xl\": \"1558M\"}\n",
    "model_to_size.update({f\"d{d}\": f\"d{d}\" for d in [12, 24, 36, 48]})\n",
    "model_size_str = model_to_size[\"gpt1Letter\"] # e.g. \"124M\", or \"d12\"\n",
    "write_model(model, f\"gpt2_{model_size_str}.bin\", dtype=\"float16\")\n",
    "write_model(model, f\"gpt2_{model_size_str}_bf16.bin\", dtype=\"bfloat16\")\n",
    "# save x, y, logits, loss, and parameter gradients, for debugging C\n",
    "# always store these in fp32 to have an accurate reference (?)\n",
    "write_state(model, x, y, logits, loss, f\"gpt2_{model_size_str}_debug_state.bin\")\n",
    "# reset the train_loader for the optimization below\n",
    "train_loader.reset()\n",
    "# clear the grads here explicitly because otherwise we'd have a duplicate grad accumulation\n",
    "# since in the training loop we do a backward() and then zero_grad() at the end of the loop\n",
    "# this would cause an incorrect first training step\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0001\n",
    "learning_rate = 3e-5\n",
    "learning_rate_decay_frac = 0.0001\n",
    "warmup_iters = 0\n",
    "num_iterations = 1000 * 5\n",
    "val_loss_every = 0\n",
    "val_max_steps = 20\n",
    "sample_every = 0\n",
    "overfit_single_batch = 1\n",
    "inference_only = 0\n",
    "grad_clip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 2,999,808 parameters\n",
      "num non-decayed parameter tensors: 98, with 22,752 parameters\n",
      "using fused AdamW: False\n",
      "using regular AdamW\n"
     ]
    }
   ],
   "source": [
    "raw_model = model # always contains the \"raw\" unwrapped model\n",
    "\n",
    "# init the optimizer\n",
    "optimizer = raw_model.configure_optimizers(weight_decay=weight_decay,\n",
    "                                            learning_rate=learning_rate, betas=(0.9, 0.95),\n",
    "                                            device_type=device, zero_stage=zero_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate decay scheduler (cosine with warmup)\n",
    "def get_lr(it):\n",
    "    min_lr = learning_rate * learning_rate_decay_frac\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * (it+1) / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > num_iterations:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (num_iterations - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
    "    return min_lr + coeff * (learning_rate - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "               ' ', ',', '.', '!', '?', '-']\n",
    "\n",
    "def encode(text):\n",
    "  return [letter_list.index(c) for c in text.lower()]\n",
    "\n",
    "def decode(ids):\n",
    "  return ''.join([letter_list[i] for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0385,  0.0297,  0.0180, -0.0421,  0.0136],\n",
       "        [-0.0195,  0.0192,  0.0324,  0.0290,  0.0054],\n",
       "        [ 0.0195, -0.0203, -0.0108, -0.0088, -0.0063],\n",
       "        [-0.0099,  0.0227, -0.0092,  0.0284,  0.0170],\n",
       "        [-0.0161, -0.0224,  0.0039, -0.0156, -0.0358]], device='mps:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step    1/5000 | train loss 3.524274 | norm 8.6716 | lr 3.00e-05 | (325.42 ms | 12587 tok/s)\n",
      "step    2/5000 | train loss 3.371245 | norm 6.5049 | lr 3.00e-05 | (114.01 ms | 35926 tok/s)\n",
      "step    3/5000 | train loss 3.267601 | norm 4.2372 | lr 3.00e-05 | (115.54 ms | 35450 tok/s)\n",
      "step    4/5000 | train loss 3.202091 | norm 2.8389 | lr 3.00e-05 | (118.48 ms | 34571 tok/s)\n",
      "step    5/5000 | train loss 3.159069 | norm 2.1457 | lr 3.00e-05 | (119.58 ms | 34252 tok/s)\n",
      "step    6/5000 | train loss 3.128022 | norm 1.8057 | lr 3.00e-05 | (121.07 ms | 33830 tok/s)\n",
      "step    7/5000 | train loss 3.103455 | norm 1.6640 | lr 3.00e-05 | (134.19 ms | 30524 tok/s)\n",
      "step    8/5000 | train loss 3.082141 | norm 1.6572 | lr 3.00e-05 | (132.83 ms | 30836 tok/s)\n",
      "step    9/5000 | train loss 3.061832 | norm 1.7396 | lr 3.00e-05 | (121.01 ms | 33849 tok/s)\n",
      "step   10/5000 | train loss 3.040890 | norm 1.8665 | lr 3.00e-05 | (120.16 ms | 34088 tok/s)\n",
      "step   11/5000 | train loss 3.018448 | norm 1.9770 | lr 3.00e-05 | (117.07 ms | 34989 tok/s)\n",
      "step   12/5000 | train loss 2.995064 | norm 1.9967 | lr 3.00e-05 | (116.39 ms | 35193 tok/s)\n",
      "step   13/5000 | train loss 2.972974 | norm 2.0541 | lr 3.00e-05 | (116.92 ms | 35032 tok/s)\n",
      "step   14/5000 | train loss 2.953189 | norm 2.2634 | lr 3.00e-05 | (117.69 ms | 34804 tok/s)\n",
      "step   15/5000 | train loss 2.934199 | norm 2.1159 | lr 3.00e-05 | (117.09 ms | 34983 tok/s)\n",
      "step   16/5000 | train loss 2.915818 | norm 1.7256 | lr 3.00e-05 | (115.37 ms | 35503 tok/s)\n",
      "step   17/5000 | train loss 2.898538 | norm 1.5579 | lr 3.00e-05 | (114.92 ms | 35643 tok/s)\n",
      "step   18/5000 | train loss 2.881821 | norm 1.5325 | lr 3.00e-05 | (117.72 ms | 34794 tok/s)\n",
      "step   19/5000 | train loss 2.865211 | norm 1.4666 | lr 3.00e-05 | (116.43 ms | 35179 tok/s)\n",
      "step   20/5000 | train loss 2.848993 | norm 1.3833 | lr 3.00e-05 | (118.07 ms | 34692 tok/s)\n",
      "step   21/5000 | train loss 2.833650 | norm 1.3253 | lr 3.00e-05 | (117.71 ms | 34798 tok/s)\n",
      "step   22/5000 | train loss 2.819403 | norm 1.3113 | lr 3.00e-05 | (115.63 ms | 35423 tok/s)\n",
      "step   23/5000 | train loss 2.806147 | norm 1.2858 | lr 3.00e-05 | (115.05 ms | 35602 tok/s)\n",
      "step   24/5000 | train loss 2.793838 | norm 1.2105 | lr 3.00e-05 | (117.85 ms | 34757 tok/s)\n",
      "step   25/5000 | train loss 2.782518 | norm 1.1802 | lr 3.00e-05 | (117.32 ms | 34912 tok/s)\n",
      "step   26/5000 | train loss 2.771878 | norm 1.1930 | lr 3.00e-05 | (114.59 ms | 35744 tok/s)\n",
      "step   27/5000 | train loss 2.761490 | norm 1.1734 | lr 3.00e-05 | (116.45 ms | 35174 tok/s)\n",
      "step   28/5000 | train loss 2.751241 | norm 1.1479 | lr 3.00e-05 | (115.31 ms | 35521 tok/s)\n",
      "step   29/5000 | train loss 2.741186 | norm 1.1279 | lr 3.00e-05 | (113.81 ms | 35989 tok/s)\n",
      "step   30/5000 | train loss 2.731422 | norm 1.0988 | lr 3.00e-05 | (114.26 ms | 35848 tok/s)\n",
      "step   31/5000 | train loss 2.722083 | norm 1.0702 | lr 3.00e-05 | (117.50 ms | 34859 tok/s)\n",
      "step   32/5000 | train loss 2.713200 | norm 1.0731 | lr 3.00e-05 | (116.05 ms | 35294 tok/s)\n",
      "step   33/5000 | train loss 2.704617 | norm 1.0590 | lr 3.00e-05 | (116.08 ms | 35287 tok/s)\n",
      "step   34/5000 | train loss 2.696199 | norm 1.0713 | lr 3.00e-05 | (114.13 ms | 35889 tok/s)\n",
      "step   35/5000 | train loss 2.687738 | norm 1.0679 | lr 3.00e-05 | (114.31 ms | 35834 tok/s)\n",
      "step   36/5000 | train loss 2.679201 | norm 1.0406 | lr 3.00e-05 | (114.77 ms | 35687 tok/s)\n",
      "step   37/5000 | train loss 2.670748 | norm 1.0563 | lr 3.00e-05 | (114.50 ms | 35773 tok/s)\n",
      "step   38/5000 | train loss 2.662351 | norm 1.0429 | lr 3.00e-05 | (117.06 ms | 34990 tok/s)\n",
      "step   39/5000 | train loss 2.653984 | norm 1.0690 | lr 3.00e-05 | (115.86 ms | 35353 tok/s)\n",
      "step   40/5000 | train loss 2.645474 | norm 1.0703 | lr 3.00e-05 | (114.53 ms | 35765 tok/s)\n",
      "step   41/5000 | train loss 2.636793 | norm 1.0791 | lr 3.00e-05 | (115.61 ms | 35429 tok/s)\n",
      "step   42/5000 | train loss 2.627944 | norm 1.0985 | lr 3.00e-05 | (115.40 ms | 35495 tok/s)\n",
      "step   43/5000 | train loss 2.619092 | norm 1.2244 | lr 3.00e-05 | (114.39 ms | 35808 tok/s)\n",
      "step   44/5000 | train loss 2.610370 | norm 1.6335 | lr 3.00e-05 | (113.42 ms | 36113 tok/s)\n",
      "step   45/5000 | train loss 2.601860 | norm 1.8189 | lr 3.00e-05 | (117.69 ms | 34804 tok/s)\n",
      "step   46/5000 | train loss 2.593306 | norm 1.4317 | lr 3.00e-05 | (117.22 ms | 34942 tok/s)\n",
      "step   47/5000 | train loss 2.584570 | norm 1.3839 | lr 3.00e-05 | (115.40 ms | 35494 tok/s)\n",
      "step   48/5000 | train loss 2.575665 | norm 1.8593 | lr 3.00e-05 | (116.42 ms | 35183 tok/s)\n",
      "step   49/5000 | train loss 2.567058 | norm 2.7577 | lr 3.00e-05 | (117.02 ms | 35001 tok/s)\n",
      "step   50/5000 | train loss 2.558174 | norm 1.6790 | lr 3.00e-05 | (114.76 ms | 35691 tok/s)\n",
      "step   51/5000 | train loss 2.549237 | norm 1.6020 | lr 3.00e-05 | (115.16 ms | 35568 tok/s)\n",
      "step   52/5000 | train loss 2.540504 | norm 3.2292 | lr 3.00e-05 | (115.86 ms | 35351 tok/s)\n",
      "step   53/5000 | train loss 2.531538 | norm 2.9171 | lr 3.00e-05 | (117.27 ms | 34928 tok/s)\n",
      "step   54/5000 | train loss 2.522551 | norm 1.8535 | lr 3.00e-05 | (115.72 ms | 35397 tok/s)\n",
      "step   55/5000 | train loss 2.513660 | norm 3.6659 | lr 3.00e-05 | (116.08 ms | 35287 tok/s)\n",
      "step   56/5000 | train loss 2.504747 | norm 3.6339 | lr 3.00e-05 | (115.71 ms | 35400 tok/s)\n",
      "step   57/5000 | train loss 2.495969 | norm 2.7878 | lr 3.00e-05 | (115.75 ms | 35385 tok/s)\n",
      "step   58/5000 | train loss 2.487827 | norm 4.6917 | lr 3.00e-05 | (115.55 ms | 35449 tok/s)\n",
      "step   59/5000 | train loss 2.478413 | norm 2.7438 | lr 3.00e-05 | (115.21 ms | 35553 tok/s)\n",
      "step   60/5000 | train loss 2.470098 | norm 4.3576 | lr 3.00e-05 | (130.10 ms | 31484 tok/s)\n",
      "step   61/5000 | train loss 2.461467 | norm 5.0651 | lr 3.00e-05 | (115.91 ms | 35339 tok/s)\n",
      "step   62/5000 | train loss 2.452468 | norm 3.8776 | lr 3.00e-05 | (114.04 ms | 35916 tok/s)\n",
      "step   63/5000 | train loss 2.444664 | norm 5.6684 | lr 3.00e-05 | (116.56 ms | 35141 tok/s)\n",
      "step   64/5000 | train loss 2.434935 | norm 3.3881 | lr 3.00e-05 | (113.43 ms | 36112 tok/s)\n",
      "step   65/5000 | train loss 2.428467 | norm 8.7472 | lr 3.00e-05 | (113.25 ms | 36167 tok/s)\n",
      "step   66/5000 | train loss 2.417501 | norm 2.8288 | lr 3.00e-05 | (115.12 ms | 35581 tok/s)\n",
      "step   67/5000 | train loss 2.414482 | norm 11.0322 | lr 3.00e-05 | (115.66 ms | 35413 tok/s)\n",
      "step   68/5000 | train loss 2.405921 | norm 7.8446 | lr 3.00e-05 | (115.60 ms | 35434 tok/s)\n",
      "step   69/5000 | train loss 2.395872 | norm 11.2048 | lr 3.00e-05 | (115.21 ms | 35553 tok/s)\n",
      "step   70/5000 | train loss 2.390024 | norm 8.2943 | lr 3.00e-05 | (112.66 ms | 36357 tok/s)\n",
      "step   71/5000 | train loss 2.380197 | norm 10.3780 | lr 3.00e-05 | (114.35 ms | 35820 tok/s)\n",
      "step   72/5000 | train loss 2.373524 | norm 7.4761 | lr 3.00e-05 | (114.75 ms | 35696 tok/s)\n",
      "step   73/5000 | train loss 2.364078 | norm 9.5268 | lr 3.00e-05 | (115.60 ms | 35432 tok/s)\n",
      "step   74/5000 | train loss 2.357792 | norm 6.9631 | lr 3.00e-05 | (114.23 ms | 35857 tok/s)\n",
      "step   75/5000 | train loss 2.348362 | norm 8.4905 | lr 3.00e-05 | (116.63 ms | 35121 tok/s)\n",
      "step   76/5000 | train loss 2.342602 | norm 10.0575 | lr 3.00e-05 | (161.39 ms | 25379 tok/s)\n",
      "step   77/5000 | train loss 2.334909 | norm 9.3323 | lr 3.00e-05 | (115.35 ms | 35510 tok/s)\n",
      "step   78/5000 | train loss 2.327117 | norm 11.1801 | lr 3.00e-05 | (119.53 ms | 34268 tok/s)\n",
      "step   79/5000 | train loss 2.319385 | norm 8.2590 | lr 3.00e-05 | (119.28 ms | 34341 tok/s)\n",
      "step   80/5000 | train loss 2.311392 | norm 10.0839 | lr 3.00e-05 | (117.88 ms | 34747 tok/s)\n",
      "step   81/5000 | train loss 2.304784 | norm 8.2303 | lr 3.00e-05 | (116.93 ms | 35029 tok/s)\n",
      "step   82/5000 | train loss 2.294636 | norm 7.8224 | lr 3.00e-05 | (117.17 ms | 34959 tok/s)\n",
      "step   83/5000 | train loss 2.289794 | norm 11.6204 | lr 3.00e-05 | (117.01 ms | 35005 tok/s)\n",
      "step   84/5000 | train loss 2.279643 | norm 9.2170 | lr 3.00e-05 | (115.78 ms | 35377 tok/s)\n",
      "step   85/5000 | train loss 2.275508 | norm 18.8995 | lr 3.00e-05 | (117.90 ms | 34741 tok/s)\n",
      "step   86/5000 | train loss 2.267450 | norm 10.8206 | lr 3.00e-05 | (115.52 ms | 35458 tok/s)\n",
      "step   87/5000 | train loss 2.258812 | norm 14.8484 | lr 3.00e-05 | (116.06 ms | 35294 tok/s)\n",
      "step   88/5000 | train loss 2.252482 | norm 15.2077 | lr 3.00e-05 | (115.67 ms | 35412 tok/s)\n",
      "step   89/5000 | train loss 2.245608 | norm 16.6678 | lr 3.00e-05 | (116.92 ms | 35033 tok/s)\n",
      "step   90/5000 | train loss 2.234957 | norm 11.7185 | lr 3.00e-05 | (117.58 ms | 34836 tok/s)\n",
      "step   91/5000 | train loss 2.231048 | norm 17.1559 | lr 3.00e-05 | (117.46 ms | 34871 tok/s)\n",
      "step   92/5000 | train loss 2.225160 | norm 17.5335 | lr 3.00e-05 | (116.28 ms | 35227 tok/s)\n",
      "step   93/5000 | train loss 2.212366 | norm 12.5783 | lr 3.00e-05 | (117.87 ms | 34749 tok/s)\n",
      "step   94/5000 | train loss 2.208489 | norm 19.3090 | lr 3.00e-05 | (114.62 ms | 35736 tok/s)\n",
      "step   95/5000 | train loss 2.200769 | norm 13.7588 | lr 3.00e-05 | (115.94 ms | 35330 tok/s)\n",
      "step   96/5000 | train loss 2.191805 | norm 16.0058 | lr 3.00e-05 | (115.92 ms | 35336 tok/s)\n",
      "step   97/5000 | train loss 2.186195 | norm 17.2699 | lr 3.00e-05 | (119.09 ms | 34393 tok/s)\n",
      "step   98/5000 | train loss 2.179188 | norm 17.9033 | lr 3.00e-05 | (116.10 ms | 35280 tok/s)\n",
      "step   99/5000 | train loss 2.169444 | norm 15.5689 | lr 3.00e-05 | (114.20 ms | 35865 tok/s)\n",
      "step  100/5000 | train loss 2.164495 | norm 20.4415 | lr 3.00e-05 | (115.39 ms | 35497 tok/s)\n",
      "step  101/5000 | train loss 2.156953 | norm 17.7275 | lr 3.00e-05 | (114.53 ms | 35762 tok/s)\n",
      "step  102/5000 | train loss 2.148640 | norm 22.1597 | lr 3.00e-05 | (114.71 ms | 35707 tok/s)\n",
      "step  103/5000 | train loss 2.143956 | norm 25.5359 | lr 3.00e-05 | (116.51 ms | 35157 tok/s)\n",
      "step  104/5000 | train loss 2.136205 | norm 23.7209 | lr 3.00e-05 | (116.22 ms | 35242 tok/s)\n",
      "step  105/5000 | train loss 2.128752 | norm 27.1689 | lr 3.00e-05 | (117.55 ms | 34844 tok/s)\n",
      "step  106/5000 | train loss 2.120192 | norm 20.6898 | lr 3.00e-05 | (116.38 ms | 35194 tok/s)\n",
      "step  107/5000 | train loss 2.116030 | norm 26.8079 | lr 3.00e-05 | (114.03 ms | 35919 tok/s)\n",
      "step  108/5000 | train loss 2.107815 | norm 23.7953 | lr 3.00e-05 | (116.33 ms | 35211 tok/s)\n",
      "step  109/5000 | train loss 2.098302 | norm 21.3734 | lr 3.00e-05 | (116.73 ms | 35090 tok/s)\n",
      "step  110/5000 | train loss 2.099413 | norm 36.7515 | lr 3.00e-05 | (113.71 ms | 36020 tok/s)\n",
      "step  111/5000 | train loss 2.086014 | norm 18.4230 | lr 3.00e-05 | (118.11 ms | 34681 tok/s)\n",
      "step  112/5000 | train loss 2.093132 | norm 46.2314 | lr 3.00e-05 | (118.44 ms | 34582 tok/s)\n",
      "step  113/5000 | train loss 2.083400 | norm 22.8316 | lr 3.00e-05 | (119.62 ms | 34242 tok/s)\n",
      "step  114/5000 | train loss 2.085902 | norm 54.1552 | lr 3.00e-05 | (115.98 ms | 35317 tok/s)\n",
      "step  115/5000 | train loss 2.080116 | norm 36.1977 | lr 3.00e-05 | (116.10 ms | 35281 tok/s)\n",
      "step  116/5000 | train loss 2.078664 | norm 50.5949 | lr 3.00e-05 | (117.65 ms | 34815 tok/s)\n",
      "step  117/5000 | train loss 2.062428 | norm 42.2258 | lr 3.00e-05 | (115.80 ms | 35371 tok/s)\n",
      "step  118/5000 | train loss 2.059726 | norm 40.0350 | lr 3.00e-05 | (117.78 ms | 34776 tok/s)\n",
      "step  119/5000 | train loss 2.055268 | norm 38.6814 | lr 3.00e-05 | (115.65 ms | 35419 tok/s)\n",
      "step  120/5000 | train loss 2.036546 | norm 25.1735 | lr 3.00e-05 | (119.25 ms | 34347 tok/s)\n",
      "step  121/5000 | train loss 2.038740 | norm 30.9961 | lr 3.00e-05 | (120.10 ms | 34104 tok/s)\n",
      "step  122/5000 | train loss 2.029109 | norm 29.7116 | lr 3.00e-05 | (120.74 ms | 33924 tok/s)\n",
      "step  123/5000 | train loss 2.022802 | norm 31.2011 | lr 3.00e-05 | (117.57 ms | 34838 tok/s)\n",
      "step  124/5000 | train loss 2.017931 | norm 29.9317 | lr 3.00e-05 | (117.56 ms | 34841 tok/s)\n",
      "step  125/5000 | train loss 2.013065 | norm 43.8568 | lr 3.00e-05 | (115.94 ms | 35329 tok/s)\n",
      "step  126/5000 | train loss 2.010429 | norm 37.1433 | lr 3.00e-05 | (115.58 ms | 35439 tok/s)\n",
      "step  127/5000 | train loss 1.997629 | norm 30.0248 | lr 3.00e-05 | (117.07 ms | 34986 tok/s)\n",
      "step  128/5000 | train loss 1.993806 | norm 43.6808 | lr 3.00e-05 | (114.64 ms | 35730 tok/s)\n",
      "step  129/5000 | train loss 1.992008 | norm 36.8781 | lr 3.00e-05 | (117.56 ms | 34843 tok/s)\n",
      "step  130/5000 | train loss 1.983237 | norm 43.6504 | lr 3.00e-05 | (117.09 ms | 34980 tok/s)\n",
      "step  131/5000 | train loss 1.974433 | norm 35.8783 | lr 2.99e-05 | (115.18 ms | 35562 tok/s)\n",
      "step  132/5000 | train loss 1.972862 | norm 39.4343 | lr 2.99e-05 | (114.78 ms | 35684 tok/s)\n",
      "step  133/5000 | train loss 1.965797 | norm 45.8478 | lr 2.99e-05 | (116.08 ms | 35285 tok/s)\n",
      "step  134/5000 | train loss 1.955018 | norm 31.2129 | lr 2.99e-05 | (115.83 ms | 35361 tok/s)\n",
      "step  135/5000 | train loss 1.951353 | norm 36.6582 | lr 2.99e-05 | (118.28 ms | 34630 tok/s)\n",
      "step  136/5000 | train loss 1.947449 | norm 44.5040 | lr 2.99e-05 | (117.22 ms | 34942 tok/s)\n",
      "step  137/5000 | train loss 1.939375 | norm 42.5760 | lr 2.99e-05 | (116.09 ms | 35282 tok/s)\n",
      "step  138/5000 | train loss 1.932968 | norm 38.8106 | lr 2.99e-05 | (113.40 ms | 36119 tok/s)\n",
      "step  139/5000 | train loss 1.929252 | norm 50.4513 | lr 2.99e-05 | (114.69 ms | 35713 tok/s)\n",
      "step  140/5000 | train loss 1.919417 | norm 34.7143 | lr 2.99e-05 | (119.12 ms | 34386 tok/s)\n",
      "step  141/5000 | train loss 1.915825 | norm 45.3629 | lr 2.99e-05 | (118.73 ms | 34499 tok/s)\n",
      "step  142/5000 | train loss 1.911667 | norm 43.6779 | lr 2.99e-05 | (116.25 ms | 35235 tok/s)\n",
      "step  143/5000 | train loss 1.898041 | norm 30.6507 | lr 2.99e-05 | (115.96 ms | 35322 tok/s)\n",
      "step  144/5000 | train loss 1.898897 | norm 43.8883 | lr 2.99e-05 | (114.74 ms | 35699 tok/s)\n",
      "step  145/5000 | train loss 1.890036 | norm 40.9884 | lr 2.99e-05 | (115.07 ms | 35595 tok/s)\n",
      "step  146/5000 | train loss 1.894500 | norm 70.5048 | lr 2.99e-05 | (116.12 ms | 35274 tok/s)\n",
      "step  147/5000 | train loss 1.875741 | norm 28.5278 | lr 2.99e-05 | (116.42 ms | 35182 tok/s)\n",
      "step  148/5000 | train loss 1.890880 | norm 62.8413 | lr 2.99e-05 | (116.78 ms | 35076 tok/s)\n",
      "step  149/5000 | train loss 1.883596 | norm 46.1460 | lr 2.99e-05 | (116.20 ms | 35250 tok/s)\n",
      "step  150/5000 | train loss 1.869026 | norm 52.9958 | lr 2.99e-05 | (114.23 ms | 35858 tok/s)\n",
      "step  151/5000 | train loss 1.862401 | norm 41.0715 | lr 2.99e-05 | (115.48 ms | 35470 tok/s)\n",
      "step  152/5000 | train loss 1.869492 | norm 68.0968 | lr 2.99e-05 | (114.32 ms | 35830 tok/s)\n",
      "step  153/5000 | train loss 1.846991 | norm 33.6433 | lr 2.99e-05 | (116.06 ms | 35293 tok/s)\n",
      "step  154/5000 | train loss 1.867494 | norm 67.1934 | lr 2.99e-05 | (115.94 ms | 35330 tok/s)\n",
      "step  155/5000 | train loss 1.866581 | norm 57.9444 | lr 2.99e-05 | (116.25 ms | 35235 tok/s)\n",
      "step  156/5000 | train loss 1.832245 | norm 40.8562 | lr 2.99e-05 | (117.12 ms | 34971 tok/s)\n",
      "step  157/5000 | train loss 1.837468 | norm 52.8835 | lr 2.99e-05 | (116.77 ms | 35078 tok/s)\n",
      "step  158/5000 | train loss 1.830081 | norm 37.4720 | lr 2.99e-05 | (116.57 ms | 35139 tok/s)\n",
      "step  159/5000 | train loss 1.819817 | norm 61.1698 | lr 2.99e-05 | (116.34 ms | 35208 tok/s)\n",
      "step  160/5000 | train loss 1.835462 | norm 64.1916 | lr 2.99e-05 | (116.63 ms | 35119 tok/s)\n",
      "step  161/5000 | train loss 1.815573 | norm 41.0032 | lr 2.99e-05 | (114.90 ms | 35647 tok/s)\n",
      "step  162/5000 | train loss 1.805656 | norm 63.1784 | lr 2.99e-05 | (116.29 ms | 35223 tok/s)\n",
      "step  163/5000 | train loss 1.812738 | norm 46.4070 | lr 2.99e-05 | (114.88 ms | 35655 tok/s)\n",
      "step  164/5000 | train loss 1.791810 | norm 35.6561 | lr 2.99e-05 | (115.85 ms | 35355 tok/s)\n",
      "step  165/5000 | train loss 1.787744 | norm 63.1697 | lr 2.99e-05 | (116.18 ms | 35255 tok/s)\n",
      "step  166/5000 | train loss 1.797952 | norm 42.4559 | lr 2.99e-05 | (113.89 ms | 35963 tok/s)\n",
      "step  167/5000 | train loss 1.785884 | norm 64.3750 | lr 2.99e-05 | (115.13 ms | 35577 tok/s)\n",
      "step  168/5000 | train loss 1.755431 | norm 25.4551 | lr 2.99e-05 | (116.11 ms | 35277 tok/s)\n",
      "step  169/5000 | train loss 1.790960 | norm 89.8866 | lr 2.99e-05 | (116.45 ms | 35174 tok/s)\n",
      "step  170/5000 | train loss 1.785276 | norm 53.7690 | lr 2.99e-05 | (115.12 ms | 35580 tok/s)\n",
      "step  171/5000 | train loss 1.770990 | norm 76.1846 | lr 2.99e-05 | (114.80 ms | 35679 tok/s)\n",
      "step  172/5000 | train loss 1.752116 | norm 55.1323 | lr 2.99e-05 | (116.54 ms | 35145 tok/s)\n",
      "step  173/5000 | train loss 1.754659 | norm 54.7380 | lr 2.99e-05 | (118.40 ms | 34594 tok/s)\n",
      "step  174/5000 | train loss 1.746409 | norm 56.5138 | lr 2.99e-05 | (116.92 ms | 35032 tok/s)\n",
      "step  175/5000 | train loss 1.739107 | norm 63.9806 | lr 2.99e-05 | (117.06 ms | 34990 tok/s)\n",
      "step  176/5000 | train loss 1.726598 | norm 48.4421 | lr 2.99e-05 | (117.61 ms | 34827 tok/s)\n",
      "step  177/5000 | train loss 1.731369 | norm 71.0216 | lr 2.99e-05 | (115.34 ms | 35512 tok/s)\n",
      "step  178/5000 | train loss 1.713993 | norm 43.6511 | lr 2.99e-05 | (115.38 ms | 35500 tok/s)\n",
      "step  179/5000 | train loss 1.703680 | norm 46.3193 | lr 2.99e-05 | (115.42 ms | 35487 tok/s)\n",
      "step  180/5000 | train loss 1.712216 | norm 64.4136 | lr 2.99e-05 | (116.85 ms | 35053 tok/s)\n",
      "step  181/5000 | train loss 1.692883 | norm 42.6745 | lr 2.99e-05 | (117.16 ms | 34962 tok/s)\n",
      "step  182/5000 | train loss 1.684628 | norm 55.1911 | lr 2.99e-05 | (127.62 ms | 32095 tok/s)\n",
      "step  183/5000 | train loss 1.690412 | norm 71.1613 | lr 2.99e-05 | (116.61 ms | 35127 tok/s)\n",
      "step  184/5000 | train loss 1.674020 | norm 37.7399 | lr 2.99e-05 | (115.49 ms | 35467 tok/s)\n",
      "step  185/5000 | train loss 1.671628 | norm 67.0749 | lr 2.99e-05 | (117.03 ms | 35001 tok/s)\n",
      "step  186/5000 | train loss 1.674798 | norm 48.8734 | lr 2.99e-05 | (116.34 ms | 35206 tok/s)\n",
      "step  187/5000 | train loss 1.656610 | norm 48.7837 | lr 2.99e-05 | (117.51 ms | 34857 tok/s)\n",
      "step  188/5000 | train loss 1.658891 | norm 88.7981 | lr 2.99e-05 | (115.94 ms | 35327 tok/s)\n",
      "step  189/5000 | train loss 1.649401 | norm 41.0482 | lr 2.99e-05 | (115.91 ms | 35339 tok/s)\n",
      "step  190/5000 | train loss 1.656475 | norm 95.1807 | lr 2.99e-05 | (115.53 ms | 35454 tok/s)\n",
      "step  191/5000 | train loss 1.632405 | norm 34.8082 | lr 2.99e-05 | (115.06 ms | 35598 tok/s)\n",
      "step  192/5000 | train loss 1.662945 | norm 94.4171 | lr 2.99e-05 | (114.93 ms | 35638 tok/s)\n",
      "step  193/5000 | train loss 1.666465 | norm 69.5616 | lr 2.99e-05 | (117.99 ms | 34714 tok/s)\n",
      "step  194/5000 | train loss 1.637573 | norm 57.7911 | lr 2.99e-05 | (116.19 ms | 35254 tok/s)\n",
      "step  195/5000 | train loss 1.620893 | norm 56.1216 | lr 2.99e-05 | (117.38 ms | 34896 tok/s)\n",
      "step  196/5000 | train loss 1.622023 | norm 59.7323 | lr 2.99e-05 | (113.96 ms | 35944 tok/s)\n",
      "step  197/5000 | train loss 1.621846 | norm 67.4089 | lr 2.99e-05 | (116.59 ms | 35131 tok/s)\n",
      "step  198/5000 | train loss 1.603650 | norm 56.9001 | lr 2.99e-05 | (115.56 ms | 35445 tok/s)\n",
      "step  199/5000 | train loss 1.588835 | norm 48.4023 | lr 2.99e-05 | (115.73 ms | 35392 tok/s)\n",
      "step  200/5000 | train loss 1.590773 | norm 56.6958 | lr 2.99e-05 | (117.37 ms | 34898 tok/s)\n",
      "step  201/5000 | train loss 1.584907 | norm 55.2110 | lr 2.99e-05 | (117.63 ms | 34820 tok/s)\n",
      "step  202/5000 | train loss 1.570849 | norm 58.9941 | lr 2.99e-05 | (114.42 ms | 35798 tok/s)\n",
      "step  203/5000 | train loss 1.564970 | norm 49.1134 | lr 2.99e-05 | (114.93 ms | 35639 tok/s)\n",
      "step  204/5000 | train loss 1.553275 | norm 45.7524 | lr 2.99e-05 | (115.10 ms | 35585 tok/s)\n",
      "step  205/5000 | train loss 1.559143 | norm 74.2756 | lr 2.99e-05 | (116.94 ms | 35027 tok/s)\n",
      "step  206/5000 | train loss 1.546722 | norm 37.6275 | lr 2.99e-05 | (117.37 ms | 34899 tok/s)\n",
      "step  207/5000 | train loss 1.542796 | norm 66.9848 | lr 2.99e-05 | (116.08 ms | 35287 tok/s)\n",
      "step  208/5000 | train loss 1.542853 | norm 48.4694 | lr 2.99e-05 | (116.68 ms | 35106 tok/s)\n",
      "step  209/5000 | train loss 1.527128 | norm 47.1524 | lr 2.99e-05 | (116.25 ms | 35234 tok/s)\n",
      "step  210/5000 | train loss 1.519962 | norm 53.2082 | lr 2.99e-05 | (117.48 ms | 34865 tok/s)\n",
      "step  211/5000 | train loss 1.518858 | norm 55.1315 | lr 2.99e-05 | (118.63 ms | 34526 tok/s)\n",
      "step  212/5000 | train loss 1.504663 | norm 49.4603 | lr 2.99e-05 | (116.76 ms | 35081 tok/s)\n",
      "step  213/5000 | train loss 1.492757 | norm 37.8076 | lr 2.99e-05 | (116.45 ms | 35175 tok/s)\n",
      "step  214/5000 | train loss 1.502017 | norm 73.1583 | lr 2.99e-05 | (114.68 ms | 35716 tok/s)\n",
      "step  215/5000 | train loss 1.490777 | norm 49.5143 | lr 2.99e-05 | (115.35 ms | 35511 tok/s)\n",
      "step  216/5000 | train loss 1.483999 | norm 70.0659 | lr 2.99e-05 | (115.00 ms | 35618 tok/s)\n",
      "step  217/5000 | train loss 1.470853 | norm 37.7697 | lr 2.99e-05 | (112.66 ms | 36357 tok/s)\n",
      "step  218/5000 | train loss 1.471132 | norm 71.2149 | lr 2.99e-05 | (117.63 ms | 34822 tok/s)\n",
      "step  219/5000 | train loss 1.467265 | norm 60.8049 | lr 2.99e-05 | (118.20 ms | 34654 tok/s)\n",
      "step  220/5000 | train loss 1.458430 | norm 40.5015 | lr 2.99e-05 | (117.00 ms | 35009 tok/s)\n",
      "step  221/5000 | train loss 1.438230 | norm 37.1739 | lr 2.99e-05 | (136.12 ms | 30092 tok/s)\n",
      "step  222/5000 | train loss 1.450873 | norm 82.6146 | lr 2.99e-05 | (117.94 ms | 34728 tok/s)\n",
      "step  223/5000 | train loss 1.437446 | norm 43.4141 | lr 2.99e-05 | (117.40 ms | 34888 tok/s)\n",
      "step  224/5000 | train loss 1.435894 | norm 57.8438 | lr 2.99e-05 | (115.02 ms | 35612 tok/s)\n",
      "step  225/5000 | train loss 1.427118 | norm 48.4926 | lr 2.99e-05 | (117.95 ms | 34726 tok/s)\n",
      "step  226/5000 | train loss 1.422767 | norm 50.5877 | lr 2.99e-05 | (117.35 ms | 34903 tok/s)\n",
      "step  227/5000 | train loss 1.406977 | norm 42.1027 | lr 2.98e-05 | (116.69 ms | 35101 tok/s)\n",
      "step  228/5000 | train loss 1.418454 | norm 74.9385 | lr 2.98e-05 | (113.55 ms | 36074 tok/s)\n",
      "step  229/5000 | train loss 1.421057 | norm 56.5607 | lr 2.98e-05 | (112.87 ms | 36288 tok/s)\n",
      "step  230/5000 | train loss 1.386852 | norm 47.3223 | lr 2.98e-05 | (114.30 ms | 35837 tok/s)\n",
      "step  231/5000 | train loss 1.422629 | norm 109.5845 | lr 2.98e-05 | (115.97 ms | 35320 tok/s)\n",
      "step  232/5000 | train loss 1.411948 | norm 64.3460 | lr 2.98e-05 | (116.19 ms | 35252 tok/s)\n",
      "step  233/5000 | train loss 1.412025 | norm 100.5959 | lr 2.98e-05 | (115.15 ms | 35571 tok/s)\n",
      "step  234/5000 | train loss 1.405608 | norm 72.1946 | lr 2.98e-05 | (113.09 ms | 36220 tok/s)\n",
      "step  235/5000 | train loss 1.403278 | norm 87.0620 | lr 2.98e-05 | (113.49 ms | 36093 tok/s)\n",
      "step  236/5000 | train loss 1.381415 | norm 65.1510 | lr 2.98e-05 | (112.11 ms | 36534 tok/s)\n",
      "step  237/5000 | train loss 1.391241 | norm 78.5607 | lr 2.98e-05 | (114.14 ms | 35885 tok/s)\n",
      "step  238/5000 | train loss 1.378870 | norm 74.7164 | lr 2.98e-05 | (114.45 ms | 35788 tok/s)\n",
      "step  239/5000 | train loss 1.350031 | norm 49.1303 | lr 2.98e-05 | (115.12 ms | 35581 tok/s)\n",
      "step  240/5000 | train loss 1.359712 | norm 64.4084 | lr 2.98e-05 | (115.39 ms | 35496 tok/s)\n",
      "step  241/5000 | train loss 1.341209 | norm 46.5167 | lr 2.98e-05 | (116.63 ms | 35119 tok/s)\n",
      "step  242/5000 | train loss 1.346167 | norm 68.5230 | lr 2.98e-05 | (113.03 ms | 36237 tok/s)\n",
      "step  243/5000 | train loss 1.338994 | norm 52.0721 | lr 2.98e-05 | (115.88 ms | 35347 tok/s)\n",
      "step  244/5000 | train loss 1.336701 | norm 66.1176 | lr 2.98e-05 | (114.49 ms | 35775 tok/s)\n",
      "step  245/5000 | train loss 1.330084 | norm 50.7086 | lr 2.98e-05 | (116.14 ms | 35268 tok/s)\n",
      "step  246/5000 | train loss 1.314787 | norm 43.3333 | lr 2.98e-05 | (117.66 ms | 34813 tok/s)\n",
      "step  247/5000 | train loss 1.317666 | norm 72.3411 | lr 2.98e-05 | (115.32 ms | 35520 tok/s)\n",
      "step  248/5000 | train loss 1.321627 | norm 67.2812 | lr 2.98e-05 | (113.96 ms | 35942 tok/s)\n",
      "step  249/5000 | train loss 1.303544 | norm 53.8518 | lr 2.98e-05 | (115.84 ms | 35359 tok/s)\n",
      "step  250/5000 | train loss 1.299272 | norm 66.3507 | lr 2.98e-05 | (112.70 ms | 36344 tok/s)\n",
      "step  251/5000 | train loss 1.299552 | norm 57.5040 | lr 2.98e-05 | (116.91 ms | 35034 tok/s)\n",
      "step  252/5000 | train loss 1.280539 | norm 49.5348 | lr 2.98e-05 | (113.58 ms | 36064 tok/s)\n",
      "step  253/5000 | train loss 1.290258 | norm 73.9354 | lr 2.98e-05 | (113.62 ms | 36050 tok/s)\n",
      "step  254/5000 | train loss 1.277168 | norm 31.7825 | lr 2.98e-05 | (112.42 ms | 36436 tok/s)\n",
      "step  255/5000 | train loss 1.280185 | norm 75.8817 | lr 2.98e-05 | (114.12 ms | 35893 tok/s)\n",
      "step  256/5000 | train loss 1.297224 | norm 57.2849 | lr 2.98e-05 | (115.44 ms | 35481 tok/s)\n",
      "step  257/5000 | train loss 1.263971 | norm 40.1518 | lr 2.98e-05 | (114.86 ms | 35661 tok/s)\n",
      "step  258/5000 | train loss 1.271057 | norm 72.6655 | lr 2.98e-05 | (114.71 ms | 35707 tok/s)\n",
      "step  259/5000 | train loss 1.284141 | norm 57.3043 | lr 2.98e-05 | (115.91 ms | 35338 tok/s)\n",
      "step  260/5000 | train loss 1.259732 | norm 60.7725 | lr 2.98e-05 | (115.37 ms | 35503 tok/s)\n",
      "step  261/5000 | train loss 1.250991 | norm 56.9149 | lr 2.98e-05 | (116.96 ms | 35021 tok/s)\n",
      "step  262/5000 | train loss 1.258870 | norm 68.4326 | lr 2.98e-05 | (113.94 ms | 35949 tok/s)\n",
      "step  263/5000 | train loss 1.246304 | norm 51.2407 | lr 2.98e-05 | (114.82 ms | 35672 tok/s)\n",
      "step  264/5000 | train loss 1.242088 | norm 70.3688 | lr 2.98e-05 | (112.94 ms | 36268 tok/s)\n",
      "step  265/5000 | train loss 1.235951 | norm 51.0633 | lr 2.98e-05 | (113.49 ms | 36092 tok/s)\n",
      "step  266/5000 | train loss 1.229412 | norm 58.5908 | lr 2.98e-05 | (114.17 ms | 35878 tok/s)\n",
      "step  267/5000 | train loss 1.218817 | norm 46.2262 | lr 2.98e-05 | (115.28 ms | 35531 tok/s)\n",
      "step  268/5000 | train loss 1.216749 | norm 55.2468 | lr 2.98e-05 | (114.73 ms | 35702 tok/s)\n",
      "step  269/5000 | train loss 1.223023 | norm 72.8082 | lr 2.98e-05 | (113.91 ms | 35958 tok/s)\n",
      "step  270/5000 | train loss 1.200336 | norm 33.7527 | lr 2.98e-05 | (115.38 ms | 35501 tok/s)\n",
      "step  271/5000 | train loss 1.208858 | norm 67.7904 | lr 2.98e-05 | (115.75 ms | 35386 tok/s)\n",
      "step  272/5000 | train loss 1.198317 | norm 36.0938 | lr 2.98e-05 | (113.96 ms | 35942 tok/s)\n",
      "step  273/5000 | train loss 1.198639 | norm 53.1434 | lr 2.98e-05 | (115.17 ms | 35564 tok/s)\n",
      "step  274/5000 | train loss 1.195364 | norm 56.0007 | lr 2.98e-05 | (114.41 ms | 35800 tok/s)\n",
      "step  275/5000 | train loss 1.188796 | norm 47.3104 | lr 2.98e-05 | (114.03 ms | 35921 tok/s)\n",
      "step  276/5000 | train loss 1.177226 | norm 39.2797 | lr 2.98e-05 | (116.25 ms | 35235 tok/s)\n",
      "step  277/5000 | train loss 1.177277 | norm 57.3764 | lr 2.98e-05 | (116.50 ms | 35160 tok/s)\n",
      "step  278/5000 | train loss 1.185680 | norm 51.3355 | lr 2.98e-05 | (115.05 ms | 35601 tok/s)\n",
      "step  279/5000 | train loss 1.161352 | norm 43.8956 | lr 2.98e-05 | (116.13 ms | 35271 tok/s)\n",
      "step  280/5000 | train loss 1.173258 | norm 69.0216 | lr 2.98e-05 | (115.76 ms | 35382 tok/s)\n",
      "step  281/5000 | train loss 1.176541 | norm 61.7279 | lr 2.98e-05 | (115.17 ms | 35565 tok/s)\n",
      "step  282/5000 | train loss 1.153289 | norm 41.4633 | lr 2.98e-05 | (113.12 ms | 36210 tok/s)\n",
      "step  283/5000 | train loss 1.153825 | norm 54.5567 | lr 2.98e-05 | (113.23 ms | 36176 tok/s)\n",
      "step  284/5000 | train loss 1.143808 | norm 38.4477 | lr 2.98e-05 | (114.68 ms | 35718 tok/s)\n",
      "step  285/5000 | train loss 1.162018 | norm 83.4766 | lr 2.98e-05 | (114.72 ms | 35705 tok/s)\n",
      "step  286/5000 | train loss 1.146801 | norm 43.6276 | lr 2.98e-05 | (114.54 ms | 35761 tok/s)\n",
      "step  287/5000 | train loss 1.150504 | norm 83.5482 | lr 2.98e-05 | (115.80 ms | 35373 tok/s)\n",
      "step  288/5000 | train loss 1.157072 | norm 68.9495 | lr 2.98e-05 | (113.43 ms | 36110 tok/s)\n",
      "step  289/5000 | train loss 1.142135 | norm 64.9312 | lr 2.98e-05 | (113.84 ms | 35979 tok/s)\n",
      "step  290/5000 | train loss 1.128941 | norm 44.0298 | lr 2.98e-05 | (113.77 ms | 36002 tok/s)\n",
      "step  291/5000 | train loss 1.130226 | norm 55.0335 | lr 2.98e-05 | (115.00 ms | 35619 tok/s)\n",
      "step  292/5000 | train loss 1.131378 | norm 69.0278 | lr 2.97e-05 | (114.59 ms | 35746 tok/s)\n",
      "step  293/5000 | train loss 1.115206 | norm 31.8840 | lr 2.97e-05 | (113.67 ms | 36033 tok/s)\n",
      "step  294/5000 | train loss 1.108021 | norm 40.3321 | lr 2.97e-05 | (111.67 ms | 36679 tok/s)\n",
      "step  295/5000 | train loss 1.115221 | norm 53.0645 | lr 2.97e-05 | (116.05 ms | 35294 tok/s)\n",
      "step  296/5000 | train loss 1.114074 | norm 55.5551 | lr 2.97e-05 | (112.50 ms | 36409 tok/s)\n",
      "step  297/5000 | train loss 1.093713 | norm 30.7871 | lr 2.97e-05 | (114.93 ms | 35638 tok/s)\n",
      "step  298/5000 | train loss 1.099168 | norm 63.8301 | lr 2.97e-05 | (113.66 ms | 36038 tok/s)\n",
      "step  299/5000 | train loss 1.103021 | norm 45.2056 | lr 2.97e-05 | (114.67 ms | 35719 tok/s)\n",
      "step  300/5000 | train loss 1.091247 | norm 51.1951 | lr 2.97e-05 | (114.37 ms | 35814 tok/s)\n",
      "step  301/5000 | train loss 1.084731 | norm 38.7936 | lr 2.97e-05 | (116.17 ms | 35258 tok/s)\n",
      "step  302/5000 | train loss 1.074011 | norm 30.3189 | lr 2.97e-05 | (113.71 ms | 36022 tok/s)\n",
      "step  303/5000 | train loss 1.075974 | norm 41.4028 | lr 2.97e-05 | (114.40 ms | 35806 tok/s)\n",
      "step  304/5000 | train loss 1.073362 | norm 44.6890 | lr 2.97e-05 | (118.54 ms | 34554 tok/s)\n",
      "step  305/5000 | train loss 1.062359 | norm 40.2321 | lr 2.97e-05 | (117.44 ms | 34879 tok/s)\n",
      "step  306/5000 | train loss 1.059047 | norm 36.5411 | lr 2.97e-05 | (118.28 ms | 34630 tok/s)\n",
      "step  307/5000 | train loss 1.053800 | norm 35.4763 | lr 2.97e-05 | (116.78 ms | 35075 tok/s)\n",
      "step  308/5000 | train loss 1.060279 | norm 67.3607 | lr 2.97e-05 | (117.06 ms | 34992 tok/s)\n",
      "step  309/5000 | train loss 1.051247 | norm 33.6759 | lr 2.97e-05 | (116.11 ms | 35278 tok/s)\n",
      "step  310/5000 | train loss 1.041608 | norm 37.0852 | lr 2.97e-05 | (117.04 ms | 34996 tok/s)\n",
      "step  311/5000 | train loss 1.049266 | norm 52.2004 | lr 2.97e-05 | (117.60 ms | 34830 tok/s)\n",
      "step  312/5000 | train loss 1.044841 | norm 45.8947 | lr 2.97e-05 | (124.47 ms | 32907 tok/s)\n",
      "step  313/5000 | train loss 1.034130 | norm 43.4758 | lr 2.97e-05 | (123.84 ms | 33076 tok/s)\n",
      "step  314/5000 | train loss 1.038170 | norm 65.4667 | lr 2.97e-05 | (119.78 ms | 34197 tok/s)\n",
      "step  315/5000 | train loss 1.031760 | norm 42.5122 | lr 2.97e-05 | (119.20 ms | 34362 tok/s)\n",
      "step  316/5000 | train loss 1.025357 | norm 43.8817 | lr 2.97e-05 | (116.99 ms | 35011 tok/s)\n",
      "step  317/5000 | train loss 1.022635 | norm 34.5120 | lr 2.97e-05 | (118.41 ms | 34592 tok/s)\n",
      "step  318/5000 | train loss 1.017294 | norm 48.0674 | lr 2.97e-05 | (118.38 ms | 34602 tok/s)\n",
      "step  319/5000 | train loss 1.018682 | norm 42.1383 | lr 2.97e-05 | (121.36 ms | 33751 tok/s)\n",
      "step  320/5000 | train loss 1.010257 | norm 42.4086 | lr 2.97e-05 | (125.94 ms | 32523 tok/s)\n",
      "step  321/5000 | train loss 1.019385 | norm 74.5691 | lr 2.97e-05 | (118.25 ms | 34639 tok/s)\n",
      "step  322/5000 | train loss 1.004850 | norm 29.0978 | lr 2.97e-05 | (120.45 ms | 34007 tok/s)\n",
      "step  323/5000 | train loss 1.013783 | norm 70.7781 | lr 2.97e-05 | (118.60 ms | 34537 tok/s)\n",
      "step  324/5000 | train loss 1.015717 | norm 43.3626 | lr 2.97e-05 | (117.71 ms | 34796 tok/s)\n",
      "step  325/5000 | train loss 1.000850 | norm 46.8798 | lr 2.97e-05 | (116.04 ms | 35297 tok/s)\n",
      "step  326/5000 | train loss 0.999448 | norm 39.8365 | lr 2.97e-05 | (114.04 ms | 35916 tok/s)\n",
      "step  327/5000 | train loss 0.993859 | norm 37.0688 | lr 2.97e-05 | (115.12 ms | 35579 tok/s)\n",
      "step  328/5000 | train loss 0.986595 | norm 31.5376 | lr 2.97e-05 | (113.62 ms | 36051 tok/s)\n",
      "step  329/5000 | train loss 0.986754 | norm 42.9734 | lr 2.97e-05 | (115.14 ms | 35574 tok/s)\n",
      "step  330/5000 | train loss 0.993901 | norm 57.7302 | lr 2.97e-05 | (116.10 ms | 35279 tok/s)\n",
      "step  331/5000 | train loss 0.974117 | norm 26.5201 | lr 2.97e-05 | (114.48 ms | 35779 tok/s)\n",
      "step  332/5000 | train loss 0.987409 | norm 63.3367 | lr 2.97e-05 | (112.24 ms | 36495 tok/s)\n",
      "step  333/5000 | train loss 0.980107 | norm 32.8378 | lr 2.97e-05 | (113.64 ms | 36044 tok/s)\n",
      "step  334/5000 | train loss 0.978153 | norm 54.2856 | lr 2.97e-05 | (111.72 ms | 36664 tok/s)\n",
      "step  335/5000 | train loss 0.972944 | norm 39.1305 | lr 2.97e-05 | (114.39 ms | 35807 tok/s)\n",
      "step  336/5000 | train loss 0.968377 | norm 41.8970 | lr 2.97e-05 | (116.38 ms | 35195 tok/s)\n",
      "step  337/5000 | train loss 0.966270 | norm 38.5772 | lr 2.97e-05 | (120.27 ms | 34056 tok/s)\n",
      "step  338/5000 | train loss 0.955821 | norm 32.6289 | lr 2.97e-05 | (112.98 ms | 36254 tok/s)\n",
      "step  339/5000 | train loss 0.966378 | norm 62.3449 | lr 2.97e-05 | (113.12 ms | 36210 tok/s)\n",
      "step  340/5000 | train loss 0.965975 | norm 49.5450 | lr 2.97e-05 | (112.52 ms | 36403 tok/s)\n",
      "step  341/5000 | train loss 0.960736 | norm 59.3055 | lr 2.97e-05 | (114.42 ms | 35798 tok/s)\n",
      "step  342/5000 | train loss 0.948285 | norm 31.7755 | lr 2.97e-05 | (113.28 ms | 36157 tok/s)\n",
      "step  343/5000 | train loss 0.949430 | norm 45.9964 | lr 2.97e-05 | (114.35 ms | 35820 tok/s)\n",
      "step  344/5000 | train loss 0.945968 | norm 35.1512 | lr 2.97e-05 | (116.38 ms | 35195 tok/s)\n",
      "step  345/5000 | train loss 0.941419 | norm 34.4658 | lr 2.97e-05 | (117.32 ms | 34912 tok/s)\n",
      "step  346/5000 | train loss 0.935187 | norm 27.1982 | lr 2.96e-05 | (118.26 ms | 34636 tok/s)\n",
      "step  347/5000 | train loss 0.933643 | norm 33.6010 | lr 2.96e-05 | (115.77 ms | 35379 tok/s)\n",
      "step  348/5000 | train loss 0.935641 | norm 46.7487 | lr 2.96e-05 | (113.93 ms | 35951 tok/s)\n",
      "step  349/5000 | train loss 0.928441 | norm 26.3924 | lr 2.96e-05 | (114.81 ms | 35677 tok/s)\n",
      "step  350/5000 | train loss 0.924223 | norm 32.7551 | lr 2.96e-05 | (115.12 ms | 35579 tok/s)\n",
      "step  351/5000 | train loss 0.923917 | norm 29.9580 | lr 2.96e-05 | (118.70 ms | 34506 tok/s)\n",
      "step  352/5000 | train loss 0.918050 | norm 31.0907 | lr 2.96e-05 | (117.91 ms | 34737 tok/s)\n",
      "step  353/5000 | train loss 0.917505 | norm 40.0316 | lr 2.96e-05 | (117.65 ms | 34815 tok/s)\n",
      "step  354/5000 | train loss 0.914854 | norm 27.1736 | lr 2.96e-05 | (127.16 ms | 32211 tok/s)\n",
      "step  355/5000 | train loss 0.905992 | norm 28.4949 | lr 2.96e-05 | (118.11 ms | 34678 tok/s)\n",
      "step  356/5000 | train loss 0.913729 | norm 44.0357 | lr 2.96e-05 | (120.99 ms | 33853 tok/s)\n",
      "step  357/5000 | train loss 0.904133 | norm 18.3059 | lr 2.96e-05 | (126.10 ms | 32482 tok/s)\n",
      "step  358/5000 | train loss 0.919185 | norm 83.1414 | lr 2.96e-05 | (115.71 ms | 35399 tok/s)\n",
      "step  359/5000 | train loss 0.928731 | norm 48.1428 | lr 2.96e-05 | (122.77 ms | 33364 tok/s)\n",
      "step  360/5000 | train loss 0.922027 | norm 56.9869 | lr 2.96e-05 | (117.96 ms | 34723 tok/s)\n",
      "step  361/5000 | train loss 0.921241 | norm 61.0838 | lr 2.96e-05 | (125.34 ms | 32679 tok/s)\n",
      "step  362/5000 | train loss 0.903414 | norm 38.2318 | lr 2.96e-05 | (116.64 ms | 35116 tok/s)\n",
      "step  363/5000 | train loss 0.903844 | norm 44.2041 | lr 2.96e-05 | (116.41 ms | 35186 tok/s)\n",
      "step  364/5000 | train loss 0.900950 | norm 29.8074 | lr 2.96e-05 | (116.52 ms | 35153 tok/s)\n",
      "step  365/5000 | train loss 0.891321 | norm 23.5652 | lr 2.96e-05 | (116.79 ms | 35073 tok/s)\n",
      "step  366/5000 | train loss 0.889999 | norm 25.1513 | lr 2.96e-05 | (126.84 ms | 32294 tok/s)\n",
      "step  367/5000 | train loss 0.888163 | norm 25.1576 | lr 2.96e-05 | (116.61 ms | 35127 tok/s)\n",
      "step  368/5000 | train loss 0.881889 | norm 19.7049 | lr 2.96e-05 | (113.59 ms | 36059 tok/s)\n",
      "step  369/5000 | train loss 0.881226 | norm 25.9307 | lr 2.96e-05 | (114.13 ms | 35887 tok/s)\n",
      "step  370/5000 | train loss 0.885851 | norm 35.8964 | lr 2.96e-05 | (112.94 ms | 36268 tok/s)\n",
      "step  371/5000 | train loss 0.876306 | norm 23.5646 | lr 2.96e-05 | (116.00 ms | 35310 tok/s)\n",
      "step  372/5000 | train loss 0.873222 | norm 29.8936 | lr 2.96e-05 | (113.19 ms | 36187 tok/s)\n",
      "step  373/5000 | train loss 0.875270 | norm 25.1890 | lr 2.96e-05 | (114.11 ms | 35896 tok/s)\n",
      "step  374/5000 | train loss 0.865398 | norm 18.3491 | lr 2.96e-05 | (118.10 ms | 34681 tok/s)\n",
      "step  375/5000 | train loss 0.873511 | norm 45.2909 | lr 2.96e-05 | (117.72 ms | 34793 tok/s)\n",
      "step  376/5000 | train loss 0.871211 | norm 23.2095 | lr 2.96e-05 | (117.98 ms | 34717 tok/s)\n",
      "step  377/5000 | train loss 0.865808 | norm 31.2670 | lr 2.96e-05 | (117.06 ms | 34990 tok/s)\n",
      "step  378/5000 | train loss 0.863551 | norm 21.6795 | lr 2.96e-05 | (115.85 ms | 35355 tok/s)\n",
      "step  379/5000 | train loss 0.855784 | norm 20.9868 | lr 2.96e-05 | (115.43 ms | 35485 tok/s)\n",
      "step  380/5000 | train loss 0.856535 | norm 23.0664 | lr 2.96e-05 | (113.39 ms | 36122 tok/s)\n",
      "step  381/5000 | train loss 0.855417 | norm 26.7599 | lr 2.96e-05 | (119.16 ms | 34373 tok/s)\n",
      "step  382/5000 | train loss 0.849795 | norm 20.9126 | lr 2.96e-05 | (115.94 ms | 35330 tok/s)\n",
      "step  383/5000 | train loss 0.849302 | norm 24.0486 | lr 2.96e-05 | (115.24 ms | 35545 tok/s)\n",
      "step  384/5000 | train loss 0.846913 | norm 22.3817 | lr 2.96e-05 | (115.81 ms | 35369 tok/s)\n",
      "step  385/5000 | train loss 0.842292 | norm 26.3172 | lr 2.96e-05 | (117.22 ms | 34944 tok/s)\n",
      "step  386/5000 | train loss 0.839532 | norm 16.4909 | lr 2.96e-05 | (114.43 ms | 35794 tok/s)\n",
      "step  387/5000 | train loss 0.839149 | norm 31.7252 | lr 2.96e-05 | (115.87 ms | 35349 tok/s)\n",
      "step  388/5000 | train loss 0.833907 | norm 16.5713 | lr 2.96e-05 | (113.08 ms | 36221 tok/s)\n",
      "step  389/5000 | train loss 0.832514 | norm 22.1730 | lr 2.96e-05 | (118.18 ms | 34660 tok/s)\n",
      "step  390/5000 | train loss 0.831061 | norm 20.8193 | lr 2.96e-05 | (114.84 ms | 35667 tok/s)\n",
      "step  391/5000 | train loss 0.826475 | norm 19.1753 | lr 2.96e-05 | (114.14 ms | 35885 tok/s)\n",
      "step  392/5000 | train loss 0.825789 | norm 24.0392 | lr 2.95e-05 | (113.76 ms | 36007 tok/s)\n",
      "step  393/5000 | train loss 0.825731 | norm 21.9642 | lr 2.95e-05 | (114.90 ms | 35650 tok/s)\n",
      "step  394/5000 | train loss 0.822124 | norm 28.8685 | lr 2.95e-05 | (112.08 ms | 36546 tok/s)\n",
      "step  395/5000 | train loss 0.822153 | norm 23.6309 | lr 2.95e-05 | (114.86 ms | 35662 tok/s)\n",
      "step  396/5000 | train loss 0.815816 | norm 17.9698 | lr 2.95e-05 | (115.28 ms | 35531 tok/s)\n",
      "step  397/5000 | train loss 0.816791 | norm 27.8053 | lr 2.95e-05 | (116.56 ms | 35141 tok/s)\n",
      "step  398/5000 | train loss 0.818267 | norm 28.6892 | lr 2.95e-05 | (113.04 ms | 36235 tok/s)\n",
      "step  399/5000 | train loss 0.812578 | norm 21.4635 | lr 2.95e-05 | (113.15 ms | 36199 tok/s)\n",
      "step  400/5000 | train loss 0.813184 | norm 32.6653 | lr 2.95e-05 | (114.34 ms | 35824 tok/s)\n",
      "step  401/5000 | train loss 0.810163 | norm 22.9558 | lr 2.95e-05 | (115.46 ms | 35475 tok/s)\n",
      "step  402/5000 | train loss 0.806775 | norm 21.2645 | lr 2.95e-05 | (113.01 ms | 36246 tok/s)\n",
      "step  403/5000 | train loss 0.803905 | norm 21.2596 | lr 2.95e-05 | (114.71 ms | 35708 tok/s)\n",
      "step  404/5000 | train loss 0.800280 | norm 15.0142 | lr 2.95e-05 | (113.09 ms | 36218 tok/s)\n",
      "step  405/5000 | train loss 0.798033 | norm 19.4025 | lr 2.95e-05 | (114.27 ms | 35845 tok/s)\n",
      "step  406/5000 | train loss 0.795173 | norm 15.0005 | lr 2.95e-05 | (113.01 ms | 36245 tok/s)\n",
      "step  407/5000 | train loss 0.792378 | norm 15.2317 | lr 2.95e-05 | (114.01 ms | 35925 tok/s)\n",
      "step  408/5000 | train loss 0.793186 | norm 19.6473 | lr 2.95e-05 | (113.33 ms | 36143 tok/s)\n",
      "step  409/5000 | train loss 0.787420 | norm 12.7182 | lr 2.95e-05 | (115.08 ms | 35591 tok/s)\n",
      "step  410/5000 | train loss 0.788981 | norm 20.8432 | lr 2.95e-05 | (112.38 ms | 36449 tok/s)\n",
      "step  411/5000 | train loss 0.787004 | norm 18.3673 | lr 2.95e-05 | (114.24 ms | 35855 tok/s)\n",
      "step  412/5000 | train loss 0.788642 | norm 26.9576 | lr 2.95e-05 | (113.86 ms | 35974 tok/s)\n",
      "step  413/5000 | train loss 0.781491 | norm 13.2121 | lr 2.95e-05 | (114.48 ms | 35779 tok/s)\n",
      "step  414/5000 | train loss 0.780300 | norm 20.5897 | lr 2.95e-05 | (112.33 ms | 36463 tok/s)\n",
      "step  415/5000 | train loss 0.778986 | norm 19.3225 | lr 2.95e-05 | (114.29 ms | 35840 tok/s)\n",
      "step  416/5000 | train loss 0.777752 | norm 15.0655 | lr 2.95e-05 | (113.75 ms | 36008 tok/s)\n",
      "step  417/5000 | train loss 0.773027 | norm 16.9637 | lr 2.95e-05 | (115.82 ms | 35365 tok/s)\n",
      "step  418/5000 | train loss 0.775945 | norm 32.6715 | lr 2.95e-05 | (112.44 ms | 36429 tok/s)\n",
      "step  419/5000 | train loss 0.776875 | norm 22.3241 | lr 2.95e-05 | (114.70 ms | 35711 tok/s)\n",
      "step  420/5000 | train loss 0.766483 | norm 10.3395 | lr 2.95e-05 | (113.15 ms | 36199 tok/s)\n",
      "step  421/5000 | train loss 0.769750 | norm 26.3001 | lr 2.95e-05 | (115.69 ms | 35405 tok/s)\n",
      "step  422/5000 | train loss 0.774944 | norm 23.7623 | lr 2.95e-05 | (114.22 ms | 35860 tok/s)\n",
      "step  423/5000 | train loss 0.766849 | norm 11.6043 | lr 2.95e-05 | (114.69 ms | 35714 tok/s)\n",
      "step  424/5000 | train loss 0.766113 | norm 24.9445 | lr 2.95e-05 | (113.92 ms | 35955 tok/s)\n",
      "step  425/5000 | train loss 0.774913 | norm 30.7258 | lr 2.95e-05 | (115.70 ms | 35403 tok/s)\n",
      "step  426/5000 | train loss 0.768414 | norm 16.9373 | lr 2.95e-05 | (112.17 ms | 36514 tok/s)\n",
      "step  427/5000 | train loss 0.762477 | norm 21.6678 | lr 2.95e-05 | (113.76 ms | 36006 tok/s)\n",
      "step  428/5000 | train loss 0.760652 | norm 14.6520 | lr 2.95e-05 | (113.29 ms | 36154 tok/s)\n",
      "step  429/5000 | train loss 0.757448 | norm 16.9203 | lr 2.95e-05 | (114.72 ms | 35703 tok/s)\n",
      "step  430/5000 | train loss 0.754848 | norm 14.8459 | lr 2.95e-05 | (112.38 ms | 36449 tok/s)\n",
      "step  431/5000 | train loss 0.753700 | norm 15.4375 | lr 2.95e-05 | (114.54 ms | 35761 tok/s)\n",
      "step  432/5000 | train loss 0.752214 | norm 14.9550 | lr 2.95e-05 | (113.69 ms | 36027 tok/s)\n",
      "step  433/5000 | train loss 0.746507 | norm 13.7138 | lr 2.95e-05 | (115.54 ms | 35451 tok/s)\n",
      "step  434/5000 | train loss 0.748671 | norm 18.3672 | lr 2.94e-05 | (113.34 ms | 36139 tok/s)\n",
      "step  435/5000 | train loss 0.743581 | norm 8.9383 | lr 2.94e-05 | (113.53 ms | 36078 tok/s)\n",
      "step  436/5000 | train loss 0.742599 | norm 18.6800 | lr 2.94e-05 | (112.87 ms | 36289 tok/s)\n",
      "step  437/5000 | train loss 0.743979 | norm 14.2645 | lr 2.94e-05 | (114.19 ms | 35871 tok/s)\n",
      "step  438/5000 | train loss 0.739693 | norm 12.1511 | lr 2.94e-05 | (121.21 ms | 33791 tok/s)\n",
      "step  439/5000 | train loss 0.739110 | norm 22.6808 | lr 2.94e-05 | (124.66 ms | 32858 tok/s)\n",
      "step  440/5000 | train loss 0.738869 | norm 15.0765 | lr 2.94e-05 | (116.75 ms | 35084 tok/s)\n",
      "step  441/5000 | train loss 0.734990 | norm 12.9604 | lr 2.94e-05 | (114.31 ms | 35832 tok/s)\n",
      "step  442/5000 | train loss 0.734278 | norm 16.0547 | lr 2.94e-05 | (112.62 ms | 36371 tok/s)\n",
      "step  443/5000 | train loss 0.729949 | norm 10.8735 | lr 2.94e-05 | (113.38 ms | 36126 tok/s)\n",
      "step  444/5000 | train loss 0.729496 | norm 14.9940 | lr 2.94e-05 | (112.52 ms | 36401 tok/s)\n",
      "step  445/5000 | train loss 0.727351 | norm 11.2608 | lr 2.94e-05 | (117.66 ms | 34811 tok/s)\n",
      "step  446/5000 | train loss 0.725718 | norm 16.9982 | lr 2.94e-05 | (115.76 ms | 35384 tok/s)\n",
      "step  447/5000 | train loss 0.724683 | norm 12.4708 | lr 2.94e-05 | (116.89 ms | 35041 tok/s)\n",
      "step  448/5000 | train loss 0.720562 | norm 11.0985 | lr 2.94e-05 | (114.75 ms | 35696 tok/s)\n",
      "step  449/5000 | train loss 0.721760 | norm 17.4629 | lr 2.94e-05 | (114.54 ms | 35762 tok/s)\n",
      "step  450/5000 | train loss 0.721883 | norm 14.6807 | lr 2.94e-05 | (116.20 ms | 35250 tok/s)\n",
      "step  451/5000 | train loss 0.717075 | norm 12.3087 | lr 2.94e-05 | (122.65 ms | 33395 tok/s)\n",
      "step  452/5000 | train loss 0.715071 | norm 15.0210 | lr 2.94e-05 | (120.43 ms | 34011 tok/s)\n",
      "step  453/5000 | train loss 0.713456 | norm 11.5626 | lr 2.94e-05 | (118.27 ms | 34633 tok/s)\n",
      "step  454/5000 | train loss 0.709631 | norm 9.0896 | lr 2.94e-05 | (118.53 ms | 34556 tok/s)\n",
      "step  455/5000 | train loss 0.712695 | norm 21.9354 | lr 2.94e-05 | (117.50 ms | 34861 tok/s)\n",
      "step  456/5000 | train loss 0.711313 | norm 13.1886 | lr 2.94e-05 | (115.86 ms | 35352 tok/s)\n",
      "step  457/5000 | train loss 0.710272 | norm 19.0790 | lr 2.94e-05 | (123.24 ms | 33235 tok/s)\n",
      "step  458/5000 | train loss 0.714371 | norm 32.9529 | lr 2.94e-05 | (123.09 ms | 33277 tok/s)\n",
      "step  459/5000 | train loss 0.722383 | norm 48.5328 | lr 2.94e-05 | (115.81 ms | 35367 tok/s)\n",
      "step  460/5000 | train loss 0.717493 | norm 27.9606 | lr 2.94e-05 | (112.60 ms | 36377 tok/s)\n",
      "step  461/5000 | train loss 0.707409 | norm 22.2836 | lr 2.94e-05 | (112.99 ms | 36251 tok/s)\n",
      "step  462/5000 | train loss 0.705044 | norm 15.0011 | lr 2.94e-05 | (113.22 ms | 36178 tok/s)\n",
      "step  463/5000 | train loss 0.703610 | norm 20.7625 | lr 2.94e-05 | (124.23 ms | 32972 tok/s)\n",
      "step  464/5000 | train loss 0.703319 | norm 17.0392 | lr 2.94e-05 | (118.86 ms | 34461 tok/s)\n",
      "step  465/5000 | train loss 0.702781 | norm 21.3383 | lr 2.94e-05 | (114.40 ms | 35803 tok/s)\n",
      "step  466/5000 | train loss 0.700053 | norm 16.0555 | lr 2.94e-05 | (113.48 ms | 36094 tok/s)\n",
      "step  467/5000 | train loss 0.696214 | norm 12.6173 | lr 2.94e-05 | (114.97 ms | 35628 tok/s)\n",
      "step  468/5000 | train loss 0.693076 | norm 9.2463 | lr 2.94e-05 | (114.19 ms | 35869 tok/s)\n",
      "step  469/5000 | train loss 0.690796 | norm 11.3320 | lr 2.94e-05 | (120.19 ms | 34079 tok/s)\n",
      "step  470/5000 | train loss 0.690572 | norm 10.0116 | lr 2.94e-05 | (123.02 ms | 33296 tok/s)\n",
      "step  471/5000 | train loss 0.687442 | norm 8.5151 | lr 2.94e-05 | (122.84 ms | 33343 tok/s)\n",
      "step  472/5000 | train loss 0.685827 | norm 11.3949 | lr 2.93e-05 | (114.31 ms | 35834 tok/s)\n",
      "step  473/5000 | train loss 0.686026 | norm 12.6576 | lr 2.93e-05 | (114.83 ms | 35669 tok/s)\n",
      "step  474/5000 | train loss 0.682824 | norm 8.8649 | lr 2.93e-05 | (113.06 ms | 36228 tok/s)\n",
      "step  475/5000 | train loss 0.680570 | norm 9.9209 | lr 2.93e-05 | (113.16 ms | 36198 tok/s)\n",
      "step  476/5000 | train loss 0.679840 | norm 16.0847 | lr 2.93e-05 | (112.29 ms | 36476 tok/s)\n",
      "step  477/5000 | train loss 0.692415 | norm 56.0695 | lr 2.93e-05 | (120.83 ms | 33899 tok/s)\n",
      "step  478/5000 | train loss 0.682890 | norm 13.3854 | lr 2.93e-05 | (120.67 ms | 33944 tok/s)\n",
      "step  479/5000 | train loss 0.703886 | norm 72.1655 | lr 2.93e-05 | (116.42 ms | 35183 tok/s)\n",
      "step  480/5000 | train loss 0.700235 | norm 36.7114 | lr 2.93e-05 | (114.02 ms | 35923 tok/s)\n",
      "step  481/5000 | train loss 0.694860 | norm 50.4889 | lr 2.93e-05 | (123.11 ms | 33271 tok/s)\n",
      "step  482/5000 | train loss 0.682897 | norm 26.1131 | lr 2.93e-05 | (117.14 ms | 34968 tok/s)\n",
      "step  483/5000 | train loss 0.679856 | norm 35.4385 | lr 2.93e-05 | (117.51 ms | 34857 tok/s)\n",
      "step  484/5000 | train loss 0.680006 | norm 24.8697 | lr 2.93e-05 | (115.48 ms | 35469 tok/s)\n",
      "step  485/5000 | train loss 0.675458 | norm 22.3596 | lr 2.93e-05 | (114.79 ms | 35682 tok/s)\n",
      "step  486/5000 | train loss 0.670303 | norm 14.4715 | lr 2.93e-05 | (113.67 ms | 36034 tok/s)\n",
      "step  487/5000 | train loss 0.669881 | norm 12.2935 | lr 2.93e-05 | (114.36 ms | 35817 tok/s)\n",
      "step  488/5000 | train loss 0.667391 | norm 14.2441 | lr 2.93e-05 | (112.78 ms | 36319 tok/s)\n",
      "step  489/5000 | train loss 0.665902 | norm 9.5770 | lr 2.93e-05 | (119.51 ms | 34274 tok/s)\n",
      "step  490/5000 | train loss 0.663791 | norm 16.1381 | lr 2.93e-05 | (115.12 ms | 35579 tok/s)\n",
      "step  491/5000 | train loss 0.663227 | norm 9.2832 | lr 2.93e-05 | (115.47 ms | 35472 tok/s)\n",
      "step  492/5000 | train loss 0.661881 | norm 12.3872 | lr 2.93e-05 | (121.69 ms | 33658 tok/s)\n",
      "step  493/5000 | train loss 0.660035 | norm 8.4312 | lr 2.93e-05 | (117.89 ms | 34744 tok/s)\n",
      "step  494/5000 | train loss 0.658327 | norm 10.1902 | lr 2.93e-05 | (112.11 ms | 36535 tok/s)\n",
      "step  495/5000 | train loss 0.657848 | norm 13.8574 | lr 2.93e-05 | (113.37 ms | 36130 tok/s)\n",
      "step  496/5000 | train loss 0.655038 | norm 8.4659 | lr 2.93e-05 | (112.54 ms | 36396 tok/s)\n",
      "step  497/5000 | train loss 0.653471 | norm 8.2059 | lr 2.93e-05 | (114.58 ms | 35748 tok/s)\n",
      "step  498/5000 | train loss 0.650107 | norm 7.6590 | lr 2.93e-05 | (113.49 ms | 36090 tok/s)\n",
      "step  499/5000 | train loss 0.650592 | norm 8.6274 | lr 2.93e-05 | (115.41 ms | 35490 tok/s)\n",
      "step  500/5000 | train loss 0.648697 | norm 8.9972 | lr 2.93e-05 | (113.54 ms | 36076 tok/s)\n",
      "step  501/5000 | train loss 0.646276 | norm 6.1982 | lr 2.93e-05 | (113.88 ms | 35966 tok/s)\n",
      "step  502/5000 | train loss 0.646505 | norm 10.0101 | lr 2.93e-05 | (112.51 ms | 36405 tok/s)\n",
      "step  503/5000 | train loss 0.643791 | norm 6.7570 | lr 2.93e-05 | (115.87 ms | 35349 tok/s)\n",
      "step  504/5000 | train loss 0.641098 | norm 7.3610 | lr 2.93e-05 | (114.34 ms | 35824 tok/s)\n",
      "step  505/5000 | train loss 0.639950 | norm 7.1100 | lr 2.93e-05 | (116.07 ms | 35288 tok/s)\n",
      "step  506/5000 | train loss 0.637466 | norm 6.8932 | lr 2.93e-05 | (113.71 ms | 36021 tok/s)\n",
      "step  507/5000 | train loss 0.636601 | norm 10.3276 | lr 2.92e-05 | (113.93 ms | 35952 tok/s)\n",
      "step  508/5000 | train loss 0.638370 | norm 13.8027 | lr 2.92e-05 | (118.24 ms | 34642 tok/s)\n",
      "step  509/5000 | train loss 0.634163 | norm 6.8453 | lr 2.92e-05 | (115.45 ms | 35478 tok/s)\n",
      "step  510/5000 | train loss 0.631299 | norm 7.2845 | lr 2.92e-05 | (113.93 ms | 35953 tok/s)\n",
      "step  511/5000 | train loss 0.630508 | norm 8.9874 | lr 2.92e-05 | (114.90 ms | 35648 tok/s)\n",
      "step  512/5000 | train loss 0.628773 | norm 6.9454 | lr 2.92e-05 | (113.20 ms | 36183 tok/s)\n",
      "step  513/5000 | train loss 0.626378 | norm 6.7929 | lr 2.92e-05 | (120.22 ms | 34071 tok/s)\n",
      "step  514/5000 | train loss 0.624621 | norm 6.0625 | lr 2.92e-05 | (119.81 ms | 34188 tok/s)\n",
      "step  515/5000 | train loss 0.622515 | norm 5.3738 | lr 2.92e-05 | (116.43 ms | 35181 tok/s)\n",
      "step  516/5000 | train loss 0.621059 | norm 7.1501 | lr 2.92e-05 | (115.61 ms | 35428 tok/s)\n",
      "step  517/5000 | train loss 0.620722 | norm 7.6151 | lr 2.92e-05 | (114.77 ms | 35688 tok/s)\n",
      "step  518/5000 | train loss 0.617678 | norm 5.6325 | lr 2.92e-05 | (123.54 ms | 33154 tok/s)\n",
      "step  519/5000 | train loss 0.616014 | norm 6.3752 | lr 2.92e-05 | (115.30 ms | 35525 tok/s)\n",
      "step  520/5000 | train loss 0.614851 | norm 6.2178 | lr 2.92e-05 | (113.80 ms | 35993 tok/s)\n",
      "step  521/5000 | train loss 0.611815 | norm 4.7919 | lr 2.92e-05 | (114.05 ms | 35914 tok/s)\n",
      "step  522/5000 | train loss 0.611469 | norm 7.1917 | lr 2.92e-05 | (117.52 ms | 34855 tok/s)\n",
      "step  523/5000 | train loss 0.610668 | norm 9.1006 | lr 2.92e-05 | (116.68 ms | 35106 tok/s)\n",
      "step  524/5000 | train loss 0.608026 | norm 5.0601 | lr 2.92e-05 | (113.08 ms | 36221 tok/s)\n",
      "step  525/5000 | train loss 0.606875 | norm 6.9061 | lr 2.92e-05 | (114.17 ms | 35876 tok/s)\n",
      "step  526/5000 | train loss 0.605520 | norm 5.4832 | lr 2.92e-05 | (115.59 ms | 35436 tok/s)\n",
      "step  527/5000 | train loss 0.602526 | norm 4.5881 | lr 2.92e-05 | (117.56 ms | 34843 tok/s)\n",
      "step  528/5000 | train loss 0.600728 | norm 4.0561 | lr 2.92e-05 | (114.82 ms | 35674 tok/s)\n",
      "step  529/5000 | train loss 0.600318 | norm 6.2206 | lr 2.92e-05 | (131.50 ms | 31147 tok/s)\n",
      "step  530/5000 | train loss 0.598397 | norm 5.4801 | lr 2.92e-05 | (116.12 ms | 35274 tok/s)\n",
      "step  531/5000 | train loss 0.596437 | norm 4.9853 | lr 2.92e-05 | (116.64 ms | 35116 tok/s)\n",
      "step  532/5000 | train loss 0.595248 | norm 5.9312 | lr 2.92e-05 | (118.27 ms | 34633 tok/s)\n",
      "step  533/5000 | train loss 0.594977 | norm 7.1390 | lr 2.92e-05 | (125.38 ms | 32669 tok/s)\n",
      "step  534/5000 | train loss 0.591310 | norm 4.1738 | lr 2.92e-05 | (123.19 ms | 33248 tok/s)\n",
      "step  535/5000 | train loss 0.591488 | norm 7.2101 | lr 2.92e-05 | (123.71 ms | 33108 tok/s)\n",
      "step  536/5000 | train loss 0.590084 | norm 6.5495 | lr 2.92e-05 | (120.39 ms | 34023 tok/s)\n",
      "step  537/5000 | train loss 0.589076 | norm 7.4535 | lr 2.92e-05 | (121.35 ms | 33754 tok/s)\n",
      "step  538/5000 | train loss 0.586108 | norm 5.0771 | lr 2.92e-05 | (119.17 ms | 34372 tok/s)\n",
      "step  539/5000 | train loss 0.584286 | norm 4.5855 | lr 2.92e-05 | (118.40 ms | 34595 tok/s)\n",
      "step  540/5000 | train loss 0.582551 | norm 4.6952 | lr 2.91e-05 | (114.03 ms | 35921 tok/s)\n",
      "step  541/5000 | train loss 0.581812 | norm 6.5165 | lr 2.91e-05 | (115.74 ms | 35389 tok/s)\n",
      "step  542/5000 | train loss 0.579625 | norm 4.3100 | lr 2.91e-05 | (116.07 ms | 35290 tok/s)\n",
      "step  543/5000 | train loss 0.578360 | norm 4.9926 | lr 2.91e-05 | (116.27 ms | 35230 tok/s)\n",
      "step  544/5000 | train loss 0.576857 | norm 8.2655 | lr 2.91e-05 | (113.46 ms | 36102 tok/s)\n",
      "step  545/5000 | train loss 0.576506 | norm 7.6920 | lr 2.91e-05 | (113.95 ms | 35945 tok/s)\n",
      "step  546/5000 | train loss 0.573776 | norm 4.9478 | lr 2.91e-05 | (113.04 ms | 36236 tok/s)\n",
      "step  547/5000 | train loss 0.572420 | norm 8.0399 | lr 2.91e-05 | (113.63 ms | 36046 tok/s)\n",
      "step  548/5000 | train loss 0.571751 | norm 6.3377 | lr 2.91e-05 | (119.42 ms | 34299 tok/s)\n",
      "step  549/5000 | train loss 0.570402 | norm 8.3438 | lr 2.91e-05 | (122.49 ms | 33440 tok/s)\n",
      "step  550/5000 | train loss 0.568394 | norm 8.6083 | lr 2.91e-05 | (118.78 ms | 34485 tok/s)\n",
      "step  551/5000 | train loss 0.573679 | norm 23.6226 | lr 2.91e-05 | (115.31 ms | 35522 tok/s)\n",
      "step  552/5000 | train loss 0.574078 | norm 20.5629 | lr 2.91e-05 | (112.93 ms | 36270 tok/s)\n",
      "step  553/5000 | train loss 0.582884 | norm 51.0288 | lr 2.91e-05 | (117.99 ms | 34716 tok/s)\n",
      "step  554/5000 | train loss 0.580638 | norm 31.5022 | lr 2.91e-05 | (117.73 ms | 34791 tok/s)\n",
      "step  555/5000 | train loss 0.605210 | norm 81.0733 | lr 2.91e-05 | (117.10 ms | 34978 tok/s)\n",
      "step  556/5000 | train loss 0.571887 | norm 20.6520 | lr 2.91e-05 | (116.86 ms | 35052 tok/s)\n",
      "step  557/5000 | train loss 0.572929 | norm 28.5343 | lr 2.91e-05 | (116.28 ms | 35226 tok/s)\n",
      "step  558/5000 | train loss 0.579219 | norm 45.5170 | lr 2.91e-05 | (114.66 ms | 35724 tok/s)\n",
      "step  559/5000 | train loss 0.563013 | norm 8.6083 | lr 2.91e-05 | (114.79 ms | 35682 tok/s)\n",
      "step  560/5000 | train loss 0.566065 | norm 25.5062 | lr 2.91e-05 | (112.80 ms | 36312 tok/s)\n",
      "step  561/5000 | train loss 0.570886 | norm 26.0535 | lr 2.91e-05 | (116.19 ms | 35254 tok/s)\n",
      "step  562/5000 | train loss 0.561303 | norm 9.7399 | lr 2.91e-05 | (114.44 ms | 35793 tok/s)\n",
      "step  563/5000 | train loss 0.557413 | norm 8.5917 | lr 2.91e-05 | (114.70 ms | 35710 tok/s)\n",
      "step  564/5000 | train loss 0.556621 | norm 8.6031 | lr 2.91e-05 | (112.31 ms | 36469 tok/s)\n",
      "step  565/5000 | train loss 0.555126 | norm 7.2783 | lr 2.91e-05 | (114.27 ms | 35844 tok/s)\n",
      "step  566/5000 | train loss 0.553679 | norm 6.7235 | lr 2.91e-05 | (113.61 ms | 36053 tok/s)\n",
      "step  567/5000 | train loss 0.553414 | norm 7.4795 | lr 2.91e-05 | (114.70 ms | 35711 tok/s)\n",
      "step  568/5000 | train loss 0.550662 | norm 5.3304 | lr 2.91e-05 | (112.13 ms | 36530 tok/s)\n",
      "step  569/5000 | train loss 0.548925 | norm 5.0342 | lr 2.91e-05 | (125.26 ms | 32699 tok/s)\n",
      "step  570/5000 | train loss 0.548522 | norm 5.5726 | lr 2.91e-05 | (117.18 ms | 34956 tok/s)\n",
      "step  571/5000 | train loss 0.546004 | norm 4.2262 | lr 2.90e-05 | (116.93 ms | 35030 tok/s)\n",
      "step  572/5000 | train loss 0.544413 | norm 4.9748 | lr 2.90e-05 | (114.39 ms | 35806 tok/s)\n",
      "step  573/5000 | train loss 0.543107 | norm 4.3954 | lr 2.90e-05 | (114.03 ms | 35920 tok/s)\n",
      "step  574/5000 | train loss 0.541156 | norm 4.3961 | lr 2.90e-05 | (111.61 ms | 36698 tok/s)\n",
      "step  575/5000 | train loss 0.539718 | norm 4.1897 | lr 2.90e-05 | (114.22 ms | 35862 tok/s)\n",
      "step  576/5000 | train loss 0.537317 | norm 3.7320 | lr 2.90e-05 | (114.30 ms | 35835 tok/s)\n",
      "step  577/5000 | train loss 0.535495 | norm 4.0413 | lr 2.90e-05 | (115.34 ms | 35514 tok/s)\n",
      "step  578/5000 | train loss 0.533631 | norm 3.5384 | lr 2.90e-05 | (113.67 ms | 36034 tok/s)\n",
      "step  579/5000 | train loss 0.531595 | norm 3.8008 | lr 2.90e-05 | (117.59 ms | 34833 tok/s)\n",
      "step  580/5000 | train loss 0.530302 | norm 4.0292 | lr 2.90e-05 | (113.98 ms | 35936 tok/s)\n",
      "step  581/5000 | train loss 0.527944 | norm 3.7380 | lr 2.90e-05 | (115.56 ms | 35446 tok/s)\n",
      "step  582/5000 | train loss 0.526554 | norm 4.5747 | lr 2.90e-05 | (116.17 ms | 35260 tok/s)\n",
      "step  583/5000 | train loss 0.525013 | norm 4.6533 | lr 2.90e-05 | (117.72 ms | 34795 tok/s)\n",
      "step  584/5000 | train loss 0.522563 | norm 3.1568 | lr 2.90e-05 | (114.21 ms | 35863 tok/s)\n",
      "step  585/5000 | train loss 0.521365 | norm 4.0782 | lr 2.90e-05 | (114.42 ms | 35797 tok/s)\n",
      "step  586/5000 | train loss 0.519597 | norm 4.0023 | lr 2.90e-05 | (113.86 ms | 35973 tok/s)\n",
      "step  587/5000 | train loss 0.517773 | norm 3.5728 | lr 2.90e-05 | (113.60 ms | 36056 tok/s)\n",
      "step  588/5000 | train loss 0.516723 | norm 4.8047 | lr 2.90e-05 | (112.20 ms | 36507 tok/s)\n",
      "step  589/5000 | train loss 0.514333 | norm 2.9508 | lr 2.90e-05 | (113.25 ms | 36167 tok/s)\n",
      "step  590/5000 | train loss 0.513124 | norm 3.6840 | lr 2.90e-05 | (112.89 ms | 36283 tok/s)\n",
      "step  591/5000 | train loss 0.511497 | norm 4.0032 | lr 2.90e-05 | (113.98 ms | 35936 tok/s)\n",
      "step  592/5000 | train loss 0.509946 | norm 3.4298 | lr 2.90e-05 | (113.70 ms | 36024 tok/s)\n",
      "step  593/5000 | train loss 0.508423 | norm 3.5866 | lr 2.90e-05 | (114.63 ms | 35731 tok/s)\n",
      "step  594/5000 | train loss 0.507104 | norm 3.6804 | lr 2.90e-05 | (112.82 ms | 36304 tok/s)\n",
      "step  595/5000 | train loss 0.504819 | norm 2.7483 | lr 2.90e-05 | (113.27 ms | 36163 tok/s)\n",
      "step  596/5000 | train loss 0.504157 | norm 3.6063 | lr 2.90e-05 | (112.94 ms | 36267 tok/s)\n",
      "step  597/5000 | train loss 0.502977 | norm 4.5986 | lr 2.90e-05 | (113.91 ms | 35957 tok/s)\n",
      "step  598/5000 | train loss 0.500625 | norm 2.5560 | lr 2.90e-05 | (112.53 ms | 36400 tok/s)\n",
      "step  599/5000 | train loss 0.500033 | norm 3.9288 | lr 2.90e-05 | (114.85 ms | 35662 tok/s)\n",
      "step  600/5000 | train loss 0.498524 | norm 4.0614 | lr 2.90e-05 | (114.31 ms | 35831 tok/s)\n",
      "step  601/5000 | train loss 0.496582 | norm 2.9691 | lr 2.89e-05 | (115.12 ms | 35580 tok/s)\n",
      "step  602/5000 | train loss 0.496385 | norm 4.6127 | lr 2.89e-05 | (113.18 ms | 36191 tok/s)\n",
      "step  603/5000 | train loss 0.494141 | norm 3.0393 | lr 2.89e-05 | (114.34 ms | 35822 tok/s)\n",
      "step  604/5000 | train loss 0.493591 | norm 4.7326 | lr 2.89e-05 | (112.17 ms | 36516 tok/s)\n",
      "step  605/5000 | train loss 0.493053 | norm 9.0761 | lr 2.89e-05 | (113.67 ms | 36034 tok/s)\n",
      "step  606/5000 | train loss 0.495576 | norm 7.2419 | lr 2.89e-05 | (113.74 ms | 36013 tok/s)\n",
      "step  607/5000 | train loss 0.492729 | norm 6.5092 | lr 2.89e-05 | (116.37 ms | 35198 tok/s)\n",
      "step  608/5000 | train loss 0.495005 | norm 22.4941 | lr 2.89e-05 | (114.65 ms | 35725 tok/s)\n",
      "step  609/5000 | train loss 0.497492 | norm 15.4263 | lr 2.89e-05 | (117.25 ms | 34935 tok/s)\n",
      "step  610/5000 | train loss 0.500408 | norm 17.9078 | lr 2.89e-05 | (113.38 ms | 36127 tok/s)\n",
      "step  611/5000 | train loss 0.495402 | norm 17.3224 | lr 2.89e-05 | (113.30 ms | 36151 tok/s)\n",
      "step  612/5000 | train loss 0.495795 | norm 33.1448 | lr 2.89e-05 | (112.67 ms | 36354 tok/s)\n",
      "step  613/5000 | train loss 0.494106 | norm 15.7868 | lr 2.89e-05 | (113.87 ms | 35972 tok/s)\n",
      "step  614/5000 | train loss 0.513924 | norm 44.8882 | lr 2.89e-05 | (113.22 ms | 36176 tok/s)\n",
      "step  615/5000 | train loss 0.495084 | norm 15.3840 | lr 2.89e-05 | (114.86 ms | 35661 tok/s)\n",
      "step  616/5000 | train loss 0.495218 | norm 28.3918 | lr 2.89e-05 | (115.19 ms | 35560 tok/s)\n",
      "step  617/5000 | train loss 0.488915 | norm 8.4704 | lr 2.89e-05 | (113.99 ms | 35933 tok/s)\n",
      "step  618/5000 | train loss 0.483702 | norm 5.7124 | lr 2.89e-05 | (114.09 ms | 35902 tok/s)\n",
      "step  619/5000 | train loss 0.483581 | norm 6.6292 | lr 2.89e-05 | (115.83 ms | 35362 tok/s)\n",
      "step  620/5000 | train loss 0.482782 | norm 7.0763 | lr 2.89e-05 | (113.24 ms | 36171 tok/s)\n",
      "step  621/5000 | train loss 0.482256 | norm 6.9967 | lr 2.89e-05 | (114.74 ms | 35697 tok/s)\n",
      "step  622/5000 | train loss 0.481451 | norm 10.4978 | lr 2.89e-05 | (114.75 ms | 35694 tok/s)\n",
      "step  623/5000 | train loss 0.484134 | norm 16.5141 | lr 2.89e-05 | (116.33 ms | 35211 tok/s)\n",
      "step  624/5000 | train loss 0.485730 | norm 19.7521 | lr 2.89e-05 | (112.72 ms | 36339 tok/s)\n",
      "step  625/5000 | train loss 0.487254 | norm 20.7830 | lr 2.89e-05 | (115.50 ms | 35463 tok/s)\n",
      "step  626/5000 | train loss 0.492327 | norm 22.6995 | lr 2.89e-05 | (113.49 ms | 36091 tok/s)\n",
      "step  627/5000 | train loss 0.493234 | norm 25.5789 | lr 2.89e-05 | (113.99 ms | 35933 tok/s)\n",
      "step  628/5000 | train loss 0.484136 | norm 11.7248 | lr 2.89e-05 | (113.53 ms | 36080 tok/s)\n",
      "step  629/5000 | train loss 0.483889 | norm 16.7636 | lr 2.88e-05 | (117.56 ms | 34840 tok/s)\n",
      "step  630/5000 | train loss 0.486201 | norm 25.6368 | lr 2.88e-05 | (120.34 ms | 34038 tok/s)\n",
      "step  631/5000 | train loss 0.482233 | norm 13.2894 | lr 2.88e-05 | (117.22 ms | 34942 tok/s)\n",
      "step  632/5000 | train loss 0.485320 | norm 21.2107 | lr 2.88e-05 | (115.18 ms | 35562 tok/s)\n",
      "step  633/5000 | train loss 0.477562 | norm 9.6767 | lr 2.88e-05 | (115.41 ms | 35492 tok/s)\n",
      "step  634/5000 | train loss 0.478445 | norm 13.4768 | lr 2.88e-05 | (112.38 ms | 36449 tok/s)\n",
      "step  635/5000 | train loss 0.476497 | norm 9.7476 | lr 2.88e-05 | (113.32 ms | 36146 tok/s)\n",
      "step  636/5000 | train loss 0.476854 | norm 15.1655 | lr 2.88e-05 | (114.53 ms | 35764 tok/s)\n",
      "step  637/5000 | train loss 0.476368 | norm 10.8140 | lr 2.88e-05 | (115.00 ms | 35618 tok/s)\n",
      "step  638/5000 | train loss 0.476831 | norm 15.7803 | lr 2.88e-05 | (116.71 ms | 35094 tok/s)\n",
      "step  639/5000 | train loss 0.477859 | norm 20.8937 | lr 2.88e-05 | (113.41 ms | 36118 tok/s)\n",
      "step  640/5000 | train loss 0.481960 | norm 23.8501 | lr 2.88e-05 | (111.97 ms | 36581 tok/s)\n",
      "step  641/5000 | train loss 0.479542 | norm 26.3276 | lr 2.88e-05 | (115.28 ms | 35529 tok/s)\n",
      "step  642/5000 | train loss 0.475564 | norm 16.3965 | lr 2.88e-05 | (117.96 ms | 34724 tok/s)\n",
      "step  643/5000 | train loss 0.475287 | norm 23.4174 | lr 2.88e-05 | (116.48 ms | 35164 tok/s)\n",
      "step  644/5000 | train loss 0.473851 | norm 11.2191 | lr 2.88e-05 | (118.24 ms | 34640 tok/s)\n",
      "step  645/5000 | train loss 0.474898 | norm 19.3446 | lr 2.88e-05 | (117.39 ms | 34891 tok/s)\n",
      "step  646/5000 | train loss 0.472944 | norm 11.3000 | lr 2.88e-05 | (120.29 ms | 34052 tok/s)\n",
      "step  647/5000 | train loss 0.474600 | norm 25.2798 | lr 2.88e-05 | (117.52 ms | 34854 tok/s)\n",
      "step  648/5000 | train loss 0.468487 | norm 6.1211 | lr 2.88e-05 | (116.56 ms | 35140 tok/s)\n",
      "step  649/5000 | train loss 0.465066 | norm 4.5351 | lr 2.88e-05 | (125.89 ms | 32535 tok/s)\n",
      "step  650/5000 | train loss 0.464685 | norm 7.2924 | lr 2.88e-05 | (124.65 ms | 32861 tok/s)\n",
      "step  651/5000 | train loss 0.463855 | norm 4.6813 | lr 2.88e-05 | (125.11 ms | 32739 tok/s)\n",
      "step  652/5000 | train loss 0.461910 | norm 3.9651 | lr 2.88e-05 | (117.91 ms | 34738 tok/s)\n",
      "step  653/5000 | train loss 0.460242 | norm 3.7165 | lr 2.88e-05 | (117.95 ms | 34728 tok/s)\n",
      "step  654/5000 | train loss 0.459172 | norm 3.2943 | lr 2.88e-05 | (116.57 ms | 35138 tok/s)\n",
      "step  655/5000 | train loss 0.458139 | norm 3.3553 | lr 2.88e-05 | (115.49 ms | 35466 tok/s)\n",
      "step  656/5000 | train loss 0.456450 | norm 3.1860 | lr 2.87e-05 | (114.03 ms | 35919 tok/s)\n",
      "step  657/5000 | train loss 0.455094 | norm 3.2283 | lr 2.87e-05 | (115.86 ms | 35352 tok/s)\n",
      "step  658/5000 | train loss 0.453497 | norm 2.6646 | lr 2.87e-05 | (112.86 ms | 36291 tok/s)\n",
      "step  659/5000 | train loss 0.452057 | norm 2.7855 | lr 2.87e-05 | (113.69 ms | 36027 tok/s)\n",
      "step  660/5000 | train loss 0.450927 | norm 3.3590 | lr 2.87e-05 | (113.59 ms | 36061 tok/s)\n",
      "step  661/5000 | train loss 0.449466 | norm 2.6197 | lr 2.87e-05 | (113.62 ms | 36051 tok/s)\n",
      "step  662/5000 | train loss 0.448050 | norm 2.5495 | lr 2.87e-05 | (114.74 ms | 35698 tok/s)\n",
      "step  663/5000 | train loss 0.447105 | norm 3.0614 | lr 2.87e-05 | (115.95 ms | 35325 tok/s)\n",
      "step  664/5000 | train loss 0.445306 | norm 2.6763 | lr 2.87e-05 | (114.54 ms | 35759 tok/s)\n",
      "step  665/5000 | train loss 0.444044 | norm 2.6788 | lr 2.87e-05 | (113.86 ms | 35973 tok/s)\n",
      "step  666/5000 | train loss 0.442286 | norm 1.9888 | lr 2.87e-05 | (114.03 ms | 35922 tok/s)\n",
      "step  667/5000 | train loss 0.441340 | norm 2.4393 | lr 2.87e-05 | (114.36 ms | 35816 tok/s)\n",
      "step  668/5000 | train loss 0.440051 | norm 2.5028 | lr 2.87e-05 | (115.18 ms | 35561 tok/s)\n",
      "step  669/5000 | train loss 0.438819 | norm 2.6395 | lr 2.87e-05 | (117.77 ms | 34779 tok/s)\n",
      "step  670/5000 | train loss 0.437237 | norm 2.3214 | lr 2.87e-05 | (117.60 ms | 34829 tok/s)\n",
      "step  671/5000 | train loss 0.435928 | norm 2.3913 | lr 2.87e-05 | (116.86 ms | 35052 tok/s)\n",
      "step  672/5000 | train loss 0.434955 | norm 2.7854 | lr 2.87e-05 | (113.31 ms | 36148 tok/s)\n",
      "step  673/5000 | train loss 0.433424 | norm 2.4433 | lr 2.87e-05 | (114.93 ms | 35639 tok/s)\n",
      "step  674/5000 | train loss 0.432387 | norm 2.6138 | lr 2.87e-05 | (116.35 ms | 35205 tok/s)\n",
      "step  675/5000 | train loss 0.430404 | norm 1.7557 | lr 2.87e-05 | (117.68 ms | 34807 tok/s)\n",
      "step  676/5000 | train loss 0.430287 | norm 3.3033 | lr 2.87e-05 | (119.51 ms | 34273 tok/s)\n",
      "step  677/5000 | train loss 0.428913 | norm 2.7660 | lr 2.87e-05 | (117.59 ms | 34834 tok/s)\n",
      "step  678/5000 | train loss 0.427787 | norm 2.7859 | lr 2.87e-05 | (119.92 ms | 34156 tok/s)\n",
      "step  679/5000 | train loss 0.426740 | norm 2.8281 | lr 2.87e-05 | (119.35 ms | 34319 tok/s)\n",
      "step  680/5000 | train loss 0.425062 | norm 2.3956 | lr 2.87e-05 | (119.83 ms | 34181 tok/s)\n",
      "step  681/5000 | train loss 0.423575 | norm 1.9537 | lr 2.87e-05 | (121.05 ms | 33838 tok/s)\n",
      "step  682/5000 | train loss 0.423041 | norm 2.9176 | lr 2.86e-05 | (118.36 ms | 34607 tok/s)\n",
      "step  683/5000 | train loss 0.421476 | norm 2.4773 | lr 2.86e-05 | (119.32 ms | 34329 tok/s)\n",
      "step  684/5000 | train loss 0.420275 | norm 2.3400 | lr 2.86e-05 | (114.63 ms | 35732 tok/s)\n",
      "step  685/5000 | train loss 0.418961 | norm 2.3006 | lr 2.86e-05 | (114.39 ms | 35808 tok/s)\n",
      "step  686/5000 | train loss 0.417796 | norm 2.2104 | lr 2.86e-05 | (117.20 ms | 34949 tok/s)\n",
      "step  687/5000 | train loss 0.416725 | norm 2.4430 | lr 2.86e-05 | (116.61 ms | 35125 tok/s)\n",
      "step  688/5000 | train loss 0.415509 | norm 2.2136 | lr 2.86e-05 | (114.05 ms | 35913 tok/s)\n",
      "step  689/5000 | train loss 0.414470 | norm 2.3674 | lr 2.86e-05 | (114.92 ms | 35641 tok/s)\n",
      "step  690/5000 | train loss 0.412975 | norm 1.9840 | lr 2.86e-05 | (115.86 ms | 35353 tok/s)\n",
      "step  691/5000 | train loss 0.411749 | norm 1.9552 | lr 2.86e-05 | (114.77 ms | 35690 tok/s)\n",
      "step  692/5000 | train loss 0.410867 | norm 2.4078 | lr 2.86e-05 | (113.99 ms | 35932 tok/s)\n",
      "step  693/5000 | train loss 0.409575 | norm 2.4931 | lr 2.86e-05 | (113.16 ms | 36195 tok/s)\n",
      "step  694/5000 | train loss 0.408290 | norm 1.9642 | lr 2.86e-05 | (112.95 ms | 36265 tok/s)\n",
      "step  695/5000 | train loss 0.407193 | norm 2.0241 | lr 2.86e-05 | (114.60 ms | 35741 tok/s)\n",
      "step  696/5000 | train loss 0.406449 | norm 2.3756 | lr 2.86e-05 | (113.00 ms | 36248 tok/s)\n",
      "step  697/5000 | train loss 0.404671 | norm 1.8285 | lr 2.86e-05 | (114.32 ms | 35830 tok/s)\n",
      "step  698/5000 | train loss 0.404031 | norm 2.3017 | lr 2.86e-05 | (114.57 ms | 35750 tok/s)\n",
      "step  699/5000 | train loss 0.402642 | norm 2.0703 | lr 2.86e-05 | (114.54 ms | 35760 tok/s)\n",
      "step  700/5000 | train loss 0.401737 | norm 2.3126 | lr 2.86e-05 | (112.02 ms | 36565 tok/s)\n",
      "step  701/5000 | train loss 0.400655 | norm 2.4353 | lr 2.86e-05 | (113.68 ms | 36030 tok/s)\n",
      "step  702/5000 | train loss 0.399631 | norm 2.3435 | lr 2.86e-05 | (112.14 ms | 36525 tok/s)\n",
      "step  703/5000 | train loss 0.398417 | norm 2.2449 | lr 2.86e-05 | (114.80 ms | 35678 tok/s)\n",
      "step  704/5000 | train loss 0.397498 | norm 2.3129 | lr 2.86e-05 | (113.87 ms | 35971 tok/s)\n",
      "step  705/5000 | train loss 0.395972 | norm 1.8451 | lr 2.86e-05 | (116.85 ms | 35053 tok/s)\n",
      "step  706/5000 | train loss 0.395295 | norm 2.2481 | lr 2.86e-05 | (114.16 ms | 35879 tok/s)\n",
      "step  707/5000 | train loss 0.394128 | norm 2.1868 | lr 2.85e-05 | (113.65 ms | 36042 tok/s)\n",
      "step  708/5000 | train loss 0.392907 | norm 1.9102 | lr 2.85e-05 | (113.25 ms | 36169 tok/s)\n",
      "step  709/5000 | train loss 0.391755 | norm 2.0284 | lr 2.85e-05 | (114.50 ms | 35772 tok/s)\n",
      "step  710/5000 | train loss 0.391054 | norm 2.3743 | lr 2.85e-05 | (113.22 ms | 36176 tok/s)\n",
      "step  711/5000 | train loss 0.389560 | norm 1.7591 | lr 2.85e-05 | (115.68 ms | 35408 tok/s)\n",
      "step  712/5000 | train loss 0.388958 | norm 2.1313 | lr 2.85e-05 | (113.52 ms | 36083 tok/s)\n",
      "step  713/5000 | train loss 0.387510 | norm 1.8720 | lr 2.85e-05 | (117.73 ms | 34790 tok/s)\n",
      "step  714/5000 | train loss 0.387083 | norm 2.7458 | lr 2.85e-05 | (115.12 ms | 35580 tok/s)\n",
      "step  715/5000 | train loss 0.385752 | norm 2.0143 | lr 2.85e-05 | (114.90 ms | 35649 tok/s)\n",
      "step  716/5000 | train loss 0.385137 | norm 2.6652 | lr 2.85e-05 | (128.56 ms | 31860 tok/s)\n",
      "step  717/5000 | train loss 0.383666 | norm 1.9382 | lr 2.85e-05 | (116.30 ms | 35219 tok/s)\n",
      "step  718/5000 | train loss 0.382975 | norm 2.2996 | lr 2.85e-05 | (117.74 ms | 34788 tok/s)\n",
      "step  719/5000 | train loss 0.381762 | norm 1.8922 | lr 2.85e-05 | (117.66 ms | 34811 tok/s)\n",
      "step  720/5000 | train loss 0.380542 | norm 1.8008 | lr 2.85e-05 | (112.70 ms | 36345 tok/s)\n",
      "step  721/5000 | train loss 0.379513 | norm 1.8199 | lr 2.85e-05 | (112.90 ms | 36280 tok/s)\n",
      "step  722/5000 | train loss 0.378383 | norm 1.7536 | lr 2.85e-05 | (115.24 ms | 35544 tok/s)\n",
      "step  723/5000 | train loss 0.377690 | norm 2.0713 | lr 2.85e-05 | (116.57 ms | 35138 tok/s)\n",
      "step  724/5000 | train loss 0.376152 | norm 1.5802 | lr 2.85e-05 | (114.17 ms | 35876 tok/s)\n",
      "step  725/5000 | train loss 0.375508 | norm 1.9481 | lr 2.85e-05 | (114.31 ms | 35831 tok/s)\n",
      "step  726/5000 | train loss 0.374257 | norm 1.8049 | lr 2.85e-05 | (113.32 ms | 36145 tok/s)\n",
      "step  727/5000 | train loss 0.373502 | norm 2.0846 | lr 2.85e-05 | (114.78 ms | 35687 tok/s)\n",
      "step  728/5000 | train loss 0.372280 | norm 1.7789 | lr 2.85e-05 | (113.55 ms | 36071 tok/s)\n",
      "step  729/5000 | train loss 0.371369 | norm 1.9509 | lr 2.85e-05 | (114.35 ms | 35820 tok/s)\n",
      "step  730/5000 | train loss 0.370469 | norm 1.9616 | lr 2.85e-05 | (111.58 ms | 36708 tok/s)\n",
      "step  731/5000 | train loss 0.369011 | norm 1.6975 | lr 2.84e-05 | (112.94 ms | 36268 tok/s)\n",
      "step  732/5000 | train loss 0.368478 | norm 1.9209 | lr 2.84e-05 | (113.00 ms | 36249 tok/s)\n",
      "step  733/5000 | train loss 0.367648 | norm 2.1225 | lr 2.84e-05 | (114.99 ms | 35620 tok/s)\n",
      "step  734/5000 | train loss 0.366222 | norm 1.6535 | lr 2.84e-05 | (114.27 ms | 35844 tok/s)\n",
      "step  735/5000 | train loss 0.365565 | norm 1.9927 | lr 2.84e-05 | (115.79 ms | 35373 tok/s)\n",
      "step  736/5000 | train loss 0.364396 | norm 1.7341 | lr 2.84e-05 | (113.16 ms | 36196 tok/s)\n",
      "step  737/5000 | train loss 0.363595 | norm 1.8918 | lr 2.84e-05 | (112.80 ms | 36314 tok/s)\n",
      "step  738/5000 | train loss 0.362460 | norm 1.8093 | lr 2.84e-05 | (112.81 ms | 36308 tok/s)\n",
      "step  739/5000 | train loss 0.361721 | norm 2.1165 | lr 2.84e-05 | (114.77 ms | 35688 tok/s)\n",
      "step  740/5000 | train loss 0.360515 | norm 1.8041 | lr 2.84e-05 | (113.56 ms | 36070 tok/s)\n",
      "step  741/5000 | train loss 0.359909 | norm 2.0363 | lr 2.84e-05 | (114.77 ms | 35688 tok/s)\n",
      "step  742/5000 | train loss 0.358543 | norm 1.6860 | lr 2.84e-05 | (112.35 ms | 36457 tok/s)\n",
      "step  743/5000 | train loss 0.357729 | norm 1.8659 | lr 2.84e-05 | (114.07 ms | 35908 tok/s)\n",
      "step  744/5000 | train loss 0.356846 | norm 1.9231 | lr 2.84e-05 | (113.17 ms | 36195 tok/s)\n",
      "step  745/5000 | train loss 0.355770 | norm 1.7868 | lr 2.84e-05 | (118.60 ms | 34537 tok/s)\n",
      "step  746/5000 | train loss 0.354783 | norm 1.8883 | lr 2.84e-05 | (118.37 ms | 34604 tok/s)\n",
      "step  747/5000 | train loss 0.353765 | norm 1.6073 | lr 2.84e-05 | (118.04 ms | 34701 tok/s)\n",
      "step  748/5000 | train loss 0.353157 | norm 1.8938 | lr 2.84e-05 | (114.27 ms | 35844 tok/s)\n",
      "step  749/5000 | train loss 0.351999 | norm 1.7567 | lr 2.84e-05 | (115.35 ms | 35511 tok/s)\n",
      "step  750/5000 | train loss 0.350894 | norm 1.5751 | lr 2.84e-05 | (112.84 ms | 36299 tok/s)\n",
      "step  751/5000 | train loss 0.350039 | norm 1.6473 | lr 2.84e-05 | (114.72 ms | 35705 tok/s)\n",
      "step  752/5000 | train loss 0.349260 | norm 1.9289 | lr 2.84e-05 | (114.15 ms | 35883 tok/s)\n",
      "step  753/5000 | train loss 0.348078 | norm 1.5426 | lr 2.84e-05 | (113.83 ms | 35982 tok/s)\n",
      "step  754/5000 | train loss 0.347307 | norm 1.6663 | lr 2.84e-05 | (113.61 ms | 36055 tok/s)\n",
      "step  755/5000 | train loss 0.346347 | norm 1.7116 | lr 2.83e-05 | (115.89 ms | 35343 tok/s)\n",
      "step  756/5000 | train loss 0.345317 | norm 1.7104 | lr 2.83e-05 | (114.00 ms | 35930 tok/s)\n",
      "step  757/5000 | train loss 0.344560 | norm 1.7613 | lr 2.83e-05 | (114.05 ms | 35915 tok/s)\n",
      "step  758/5000 | train loss 0.343735 | norm 1.8235 | lr 2.83e-05 | (113.13 ms | 36205 tok/s)\n",
      "step  759/5000 | train loss 0.342392 | norm 1.4018 | lr 2.83e-05 | (114.15 ms | 35882 tok/s)\n",
      "step  760/5000 | train loss 0.341824 | norm 1.7559 | lr 2.83e-05 | (112.83 ms | 36302 tok/s)\n",
      "step  761/5000 | train loss 0.340870 | norm 1.7269 | lr 2.83e-05 | (113.83 ms | 35983 tok/s)\n",
      "step  762/5000 | train loss 0.340172 | norm 1.9639 | lr 2.83e-05 | (114.20 ms | 35868 tok/s)\n",
      "step  763/5000 | train loss 0.338943 | norm 1.7020 | lr 2.83e-05 | (115.22 ms | 35548 tok/s)\n",
      "step  764/5000 | train loss 0.338058 | norm 1.5764 | lr 2.83e-05 | (113.82 ms | 35986 tok/s)\n",
      "step  765/5000 | train loss 0.337374 | norm 2.0785 | lr 2.83e-05 | (115.08 ms | 35593 tok/s)\n",
      "step  766/5000 | train loss 0.336448 | norm 1.9294 | lr 2.83e-05 | (114.33 ms | 35825 tok/s)\n",
      "step  767/5000 | train loss 0.335676 | norm 1.7886 | lr 2.83e-05 | (114.11 ms | 35896 tok/s)\n",
      "step  768/5000 | train loss 0.334745 | norm 1.7534 | lr 2.83e-05 | (113.46 ms | 36101 tok/s)\n",
      "step  769/5000 | train loss 0.333973 | norm 1.7873 | lr 2.83e-05 | (116.34 ms | 35208 tok/s)\n",
      "step  770/5000 | train loss 0.332945 | norm 1.6550 | lr 2.83e-05 | (114.23 ms | 35858 tok/s)\n",
      "step  771/5000 | train loss 0.332023 | norm 1.6139 | lr 2.83e-05 | (116.53 ms | 35151 tok/s)\n",
      "step  772/5000 | train loss 0.331380 | norm 1.8720 | lr 2.83e-05 | (118.30 ms | 34624 tok/s)\n",
      "step  773/5000 | train loss 0.330221 | norm 1.4154 | lr 2.83e-05 | (120.04 ms | 34121 tok/s)\n",
      "step  774/5000 | train loss 0.329765 | norm 1.8837 | lr 2.83e-05 | (115.87 ms | 35349 tok/s)\n",
      "step  775/5000 | train loss 0.328604 | norm 1.5207 | lr 2.83e-05 | (117.52 ms | 34855 tok/s)\n",
      "step  776/5000 | train loss 0.327905 | norm 1.6754 | lr 2.83e-05 | (118.28 ms | 34629 tok/s)\n",
      "step  777/5000 | train loss 0.326936 | norm 1.6958 | lr 2.83e-05 | (117.81 ms | 34767 tok/s)\n",
      "step  778/5000 | train loss 0.326231 | norm 1.7423 | lr 2.82e-05 | (115.90 ms | 35342 tok/s)\n",
      "step  779/5000 | train loss 0.325217 | norm 1.5306 | lr 2.82e-05 | (116.67 ms | 35107 tok/s)\n",
      "step  780/5000 | train loss 0.324415 | norm 1.7298 | lr 2.82e-05 | (115.72 ms | 35397 tok/s)\n",
      "step  781/5000 | train loss 0.323390 | norm 1.4826 | lr 2.82e-05 | (122.51 ms | 33433 tok/s)\n",
      "step  782/5000 | train loss 0.322842 | norm 1.8712 | lr 2.82e-05 | (114.52 ms | 35768 tok/s)\n",
      "step  783/5000 | train loss 0.321790 | norm 1.4050 | lr 2.82e-05 | (115.55 ms | 35446 tok/s)\n",
      "step  784/5000 | train loss 0.320970 | norm 1.5292 | lr 2.82e-05 | (115.06 ms | 35600 tok/s)\n",
      "step  785/5000 | train loss 0.320175 | norm 1.6568 | lr 2.82e-05 | (115.73 ms | 35392 tok/s)\n",
      "step  786/5000 | train loss 0.319198 | norm 1.5374 | lr 2.82e-05 | (114.24 ms | 35854 tok/s)\n",
      "step  787/5000 | train loss 0.318183 | norm 1.2547 | lr 2.82e-05 | (115.61 ms | 35429 tok/s)\n",
      "step  788/5000 | train loss 0.317826 | norm 1.7322 | lr 2.82e-05 | (113.39 ms | 36123 tok/s)\n",
      "step  789/5000 | train loss 0.316748 | norm 1.5316 | lr 2.82e-05 | (114.85 ms | 35663 tok/s)\n",
      "step  790/5000 | train loss 0.315870 | norm 1.5371 | lr 2.82e-05 | (113.79 ms | 35996 tok/s)\n",
      "step  791/5000 | train loss 0.314902 | norm 1.3759 | lr 2.82e-05 | (114.78 ms | 35687 tok/s)\n",
      "step  792/5000 | train loss 0.314377 | norm 1.5585 | lr 2.82e-05 | (113.32 ms | 36145 tok/s)\n",
      "step  793/5000 | train loss 0.313304 | norm 1.4562 | lr 2.82e-05 | (115.56 ms | 35445 tok/s)\n",
      "step  794/5000 | train loss 0.312764 | norm 1.6016 | lr 2.82e-05 | (112.62 ms | 36369 tok/s)\n",
      "step  795/5000 | train loss 0.311554 | norm 1.2851 | lr 2.82e-05 | (114.18 ms | 35875 tok/s)\n",
      "step  796/5000 | train loss 0.310929 | norm 1.5550 | lr 2.82e-05 | (113.75 ms | 36008 tok/s)\n",
      "step  797/5000 | train loss 0.310236 | norm 1.5942 | lr 2.82e-05 | (117.03 ms | 35001 tok/s)\n",
      "step  798/5000 | train loss 0.309102 | norm 1.2816 | lr 2.82e-05 | (115.01 ms | 35613 tok/s)\n",
      "step  799/5000 | train loss 0.308596 | norm 1.6219 | lr 2.82e-05 | (117.84 ms | 34758 tok/s)\n",
      "step  800/5000 | train loss 0.307458 | norm 1.3287 | lr 2.81e-05 | (119.12 ms | 34386 tok/s)\n",
      "step  801/5000 | train loss 0.306954 | norm 1.5786 | lr 2.81e-05 | (116.57 ms | 35139 tok/s)\n",
      "step  802/5000 | train loss 0.305793 | norm 1.1954 | lr 2.81e-05 | (113.69 ms | 36027 tok/s)\n",
      "step  803/5000 | train loss 0.305605 | norm 1.7269 | lr 2.81e-05 | (113.86 ms | 35973 tok/s)\n",
      "step  804/5000 | train loss 0.304345 | norm 1.2624 | lr 2.81e-05 | (115.17 ms | 35564 tok/s)\n",
      "step  805/5000 | train loss 0.303945 | norm 1.6100 | lr 2.81e-05 | (121.03 ms | 33844 tok/s)\n",
      "step  806/5000 | train loss 0.302849 | norm 1.4264 | lr 2.81e-05 | (114.81 ms | 35676 tok/s)\n",
      "step  807/5000 | train loss 0.302238 | norm 1.7473 | lr 2.81e-05 | (115.17 ms | 35566 tok/s)\n",
      "step  808/5000 | train loss 0.301310 | norm 1.3407 | lr 2.81e-05 | (113.18 ms | 36190 tok/s)\n",
      "step  809/5000 | train loss 0.300509 | norm 1.4726 | lr 2.81e-05 | (119.04 ms | 34407 tok/s)\n",
      "step  810/5000 | train loss 0.299838 | norm 1.6388 | lr 2.81e-05 | (116.43 ms | 35180 tok/s)\n",
      "step  811/5000 | train loss 0.298919 | norm 1.3327 | lr 2.81e-05 | (114.95 ms | 35632 tok/s)\n",
      "step  812/5000 | train loss 0.298446 | norm 1.7870 | lr 2.81e-05 | (113.97 ms | 35941 tok/s)\n",
      "step  813/5000 | train loss 0.297552 | norm 1.4637 | lr 2.81e-05 | (114.91 ms | 35647 tok/s)\n",
      "step  814/5000 | train loss 0.296628 | norm 1.4482 | lr 2.81e-05 | (113.75 ms | 36010 tok/s)\n",
      "step  815/5000 | train loss 0.295967 | norm 1.3996 | lr 2.81e-05 | (114.51 ms | 35769 tok/s)\n",
      "step  816/5000 | train loss 0.295202 | norm 1.4938 | lr 2.81e-05 | (112.55 ms | 36391 tok/s)\n",
      "step  817/5000 | train loss 0.294356 | norm 1.4653 | lr 2.81e-05 | (119.57 ms | 34256 tok/s)\n",
      "step  818/5000 | train loss 0.293700 | norm 1.5309 | lr 2.81e-05 | (119.56 ms | 34259 tok/s)\n",
      "step  819/5000 | train loss 0.292866 | norm 1.4082 | lr 2.81e-05 | (119.32 ms | 34329 tok/s)\n",
      "step  820/5000 | train loss 0.292103 | norm 1.4415 | lr 2.81e-05 | (125.63 ms | 32603 tok/s)\n",
      "step  821/5000 | train loss 0.291367 | norm 1.3972 | lr 2.81e-05 | (115.44 ms | 35482 tok/s)\n",
      "step  822/5000 | train loss 0.290654 | norm 1.4281 | lr 2.80e-05 | (114.39 ms | 35807 tok/s)\n",
      "step  823/5000 | train loss 0.289716 | norm 1.3222 | lr 2.80e-05 | (114.52 ms | 35768 tok/s)\n",
      "step  824/5000 | train loss 0.289152 | norm 1.4093 | lr 2.80e-05 | (114.70 ms | 35711 tok/s)\n",
      "step  825/5000 | train loss 0.288191 | norm 1.2756 | lr 2.80e-05 | (115.33 ms | 35516 tok/s)\n",
      "step  826/5000 | train loss 0.287725 | norm 1.6227 | lr 2.80e-05 | (113.72 ms | 36018 tok/s)\n",
      "step  827/5000 | train loss 0.286712 | norm 1.1728 | lr 2.80e-05 | (114.59 ms | 35745 tok/s)\n",
      "step  828/5000 | train loss 0.286467 | norm 1.6985 | lr 2.80e-05 | (113.68 ms | 36032 tok/s)\n",
      "step  829/5000 | train loss 0.285397 | norm 1.2844 | lr 2.80e-05 | (114.35 ms | 35820 tok/s)\n",
      "step  830/5000 | train loss 0.284718 | norm 1.3920 | lr 2.80e-05 | (114.21 ms | 35864 tok/s)\n",
      "step  831/5000 | train loss 0.283902 | norm 1.3644 | lr 2.80e-05 | (119.09 ms | 34394 tok/s)\n",
      "step  832/5000 | train loss 0.283159 | norm 1.2651 | lr 2.80e-05 | (120.05 ms | 34119 tok/s)\n",
      "step  833/5000 | train loss 0.282341 | norm 1.3395 | lr 2.80e-05 | (115.66 ms | 35414 tok/s)\n",
      "step  834/5000 | train loss 0.281918 | norm 1.5659 | lr 2.80e-05 | (113.27 ms | 36162 tok/s)\n",
      "step  835/5000 | train loss 0.280933 | norm 1.2521 | lr 2.80e-05 | (115.20 ms | 35557 tok/s)\n",
      "step  836/5000 | train loss 0.280330 | norm 1.5122 | lr 2.80e-05 | (113.39 ms | 36122 tok/s)\n",
      "step  837/5000 | train loss 0.279669 | norm 1.3491 | lr 2.80e-05 | (113.91 ms | 35957 tok/s)\n",
      "step  838/5000 | train loss 0.278805 | norm 1.2754 | lr 2.80e-05 | (114.03 ms | 35921 tok/s)\n",
      "step  839/5000 | train loss 0.278226 | norm 1.3510 | lr 2.80e-05 | (115.17 ms | 35565 tok/s)\n",
      "step  840/5000 | train loss 0.277486 | norm 1.3932 | lr 2.80e-05 | (112.95 ms | 36263 tok/s)\n",
      "step  841/5000 | train loss 0.276608 | norm 1.1940 | lr 2.80e-05 | (115.06 ms | 35597 tok/s)\n",
      "step  842/5000 | train loss 0.276051 | norm 1.3450 | lr 2.80e-05 | (113.87 ms | 35971 tok/s)\n",
      "step  843/5000 | train loss 0.275334 | norm 1.3023 | lr 2.79e-05 | (113.95 ms | 35947 tok/s)\n",
      "step  844/5000 | train loss 0.274526 | norm 1.2592 | lr 2.79e-05 | (113.57 ms | 36065 tok/s)\n",
      "step  845/5000 | train loss 0.274019 | norm 1.4144 | lr 2.79e-05 | (115.08 ms | 35593 tok/s)\n",
      "step  846/5000 | train loss 0.272869 | norm 0.9195 | lr 2.79e-05 | (112.95 ms | 36262 tok/s)\n",
      "step  847/5000 | train loss 0.272729 | norm 1.5339 | lr 2.79e-05 | (115.51 ms | 35461 tok/s)\n",
      "step  848/5000 | train loss 0.271821 | norm 1.4252 | lr 2.79e-05 | (112.86 ms | 36291 tok/s)\n",
      "step  849/5000 | train loss 0.271073 | norm 1.2235 | lr 2.79e-05 | (113.80 ms | 35993 tok/s)\n",
      "step  850/5000 | train loss 0.270352 | norm 1.1913 | lr 2.79e-05 | (113.17 ms | 36195 tok/s)\n",
      "step  851/5000 | train loss 0.269767 | norm 1.4396 | lr 2.79e-05 | (114.20 ms | 35868 tok/s)\n",
      "step  852/5000 | train loss 0.269043 | norm 1.3270 | lr 2.79e-05 | (115.46 ms | 35477 tok/s)\n",
      "step  853/5000 | train loss 0.268339 | norm 1.3427 | lr 2.79e-05 | (118.96 ms | 34433 tok/s)\n",
      "step  854/5000 | train loss 0.267843 | norm 1.5139 | lr 2.79e-05 | (114.00 ms | 35931 tok/s)\n",
      "step  855/5000 | train loss 0.266728 | norm 0.9766 | lr 2.79e-05 | (116.79 ms | 35072 tok/s)\n",
      "step  856/5000 | train loss 0.266644 | norm 1.5392 | lr 2.79e-05 | (115.07 ms | 35596 tok/s)\n",
      "step  857/5000 | train loss 0.265463 | norm 1.0662 | lr 2.79e-05 | (115.34 ms | 35511 tok/s)\n",
      "step  858/5000 | train loss 0.265212 | norm 1.4707 | lr 2.79e-05 | (114.54 ms | 35760 tok/s)\n",
      "step  859/5000 | train loss 0.264147 | norm 1.0810 | lr 2.79e-05 | (114.69 ms | 35713 tok/s)\n",
      "step  860/5000 | train loss 0.263886 | norm 1.5139 | lr 2.79e-05 | (119.79 ms | 34192 tok/s)\n",
      "step  861/5000 | train loss 0.262955 | norm 1.1844 | lr 2.79e-05 | (116.68 ms | 35104 tok/s)\n",
      "step  862/5000 | train loss 0.262351 | norm 1.2098 | lr 2.79e-05 | (113.50 ms | 36088 tok/s)\n",
      "step  863/5000 | train loss 0.261666 | norm 1.2789 | lr 2.79e-05 | (116.91 ms | 35036 tok/s)\n",
      "step  864/5000 | train loss 0.261058 | norm 1.3135 | lr 2.78e-05 | (114.11 ms | 35894 tok/s)\n",
      "step  865/5000 | train loss 0.260420 | norm 1.1650 | lr 2.78e-05 | (114.74 ms | 35699 tok/s)\n",
      "step  866/5000 | train loss 0.259618 | norm 1.1830 | lr 2.78e-05 | (114.21 ms | 35863 tok/s)\n",
      "step  867/5000 | train loss 0.259305 | norm 1.4313 | lr 2.78e-05 | (114.77 ms | 35688 tok/s)\n",
      "step  868/5000 | train loss 0.258272 | norm 1.0468 | lr 2.78e-05 | (114.69 ms | 35714 tok/s)\n",
      "step  869/5000 | train loss 0.258030 | norm 1.4931 | lr 2.78e-05 | (115.74 ms | 35389 tok/s)\n",
      "step  870/5000 | train loss 0.257342 | norm 1.3015 | lr 2.78e-05 | (113.48 ms | 36095 tok/s)\n",
      "step  871/5000 | train loss 0.256610 | norm 1.3863 | lr 2.78e-05 | (115.04 ms | 35605 tok/s)\n",
      "step  872/5000 | train loss 0.255946 | norm 1.1202 | lr 2.78e-05 | (115.72 ms | 35397 tok/s)\n",
      "step  873/5000 | train loss 0.255298 | norm 1.2535 | lr 2.78e-05 | (114.60 ms | 35742 tok/s)\n",
      "step  874/5000 | train loss 0.254944 | norm 1.4774 | lr 2.78e-05 | (113.22 ms | 36176 tok/s)\n",
      "step  875/5000 | train loss 0.254071 | norm 1.2007 | lr 2.78e-05 | (116.37 ms | 35199 tok/s)\n",
      "step  876/5000 | train loss 0.253451 | norm 1.3235 | lr 2.78e-05 | (113.59 ms | 36059 tok/s)\n",
      "step  877/5000 | train loss 0.252741 | norm 1.2429 | lr 2.78e-05 | (114.34 ms | 35823 tok/s)\n",
      "step  878/5000 | train loss 0.252222 | norm 1.3160 | lr 2.78e-05 | (113.75 ms | 36007 tok/s)\n",
      "step  879/5000 | train loss 0.251375 | norm 1.0872 | lr 2.78e-05 | (115.88 ms | 35348 tok/s)\n",
      "step  880/5000 | train loss 0.251110 | norm 1.4132 | lr 2.78e-05 | (114.89 ms | 35652 tok/s)\n",
      "step  881/5000 | train loss 0.250235 | norm 1.3107 | lr 2.78e-05 | (115.61 ms | 35429 tok/s)\n",
      "step  882/5000 | train loss 0.249795 | norm 1.5872 | lr 2.78e-05 | (114.01 ms | 35927 tok/s)\n",
      "step  883/5000 | train loss 0.251249 | norm 12.0371 | lr 2.78e-05 | (114.57 ms | 35751 tok/s)\n",
      "step  884/5000 | train loss 0.249228 | norm 1.8712 | lr 2.78e-05 | (113.74 ms | 36013 tok/s)\n",
      "step  885/5000 | train loss 0.254211 | norm 19.9810 | lr 2.77e-05 | (114.26 ms | 35847 tok/s)\n",
      "step  886/5000 | train loss 0.251604 | norm 12.4311 | lr 2.77e-05 | (112.78 ms | 36319 tok/s)\n",
      "step  887/5000 | train loss 0.251043 | norm 5.7529 | lr 2.77e-05 | (114.13 ms | 35889 tok/s)\n",
      "step  888/5000 | train loss 0.251096 | norm 10.4895 | lr 2.77e-05 | (112.30 ms | 36473 tok/s)\n",
      "step  889/5000 | train loss 0.260855 | norm 24.5185 | lr 2.77e-05 | (112.69 ms | 36347 tok/s)\n",
      "step  890/5000 | train loss 0.253706 | norm 14.5643 | lr 2.77e-05 | (111.83 ms | 36627 tok/s)\n",
      "step  891/5000 | train loss 0.254293 | norm 17.9822 | lr 2.77e-05 | (112.81 ms | 36308 tok/s)\n",
      "step  892/5000 | train loss 0.266041 | norm 29.1116 | lr 2.77e-05 | (111.82 ms | 36629 tok/s)\n",
      "step  893/5000 | train loss 0.261815 | norm 18.5384 | lr 2.77e-05 | (113.03 ms | 36238 tok/s)\n",
      "step  894/5000 | train loss 0.251545 | norm 6.4667 | lr 2.77e-05 | (112.19 ms | 36511 tok/s)\n",
      "step  895/5000 | train loss 0.253630 | norm 17.9699 | lr 2.77e-05 | (111.51 ms | 36734 tok/s)\n",
      "step  896/5000 | train loss 0.253597 | norm 15.3510 | lr 2.77e-05 | (111.35 ms | 36785 tok/s)\n",
      "step  897/5000 | train loss 0.255663 | norm 15.0398 | lr 2.77e-05 | (113.28 ms | 36159 tok/s)\n",
      "step  898/5000 | train loss 0.265331 | norm 39.1535 | lr 2.77e-05 | (112.37 ms | 36452 tok/s)\n",
      "step  899/5000 | train loss 0.259259 | norm 23.5117 | lr 2.77e-05 | (115.62 ms | 35427 tok/s)\n",
      "step  900/5000 | train loss 0.256341 | norm 16.7696 | lr 2.77e-05 | (114.26 ms | 35847 tok/s)\n",
      "step  901/5000 | train loss 0.250298 | norm 9.0810 | lr 2.77e-05 | (114.71 ms | 35707 tok/s)\n",
      "step  902/5000 | train loss 0.253451 | norm 16.7895 | lr 2.77e-05 | (112.96 ms | 36262 tok/s)\n",
      "step  903/5000 | train loss 0.251572 | norm 12.9116 | lr 2.77e-05 | (114.85 ms | 35664 tok/s)\n",
      "step  904/5000 | train loss 0.249282 | norm 10.1741 | lr 2.76e-05 | (113.87 ms | 35971 tok/s)\n",
      "step  905/5000 | train loss 0.250213 | norm 10.8698 | lr 2.76e-05 | (114.97 ms | 35626 tok/s)\n",
      "step  906/5000 | train loss 0.248437 | norm 11.6220 | lr 2.76e-05 | (112.68 ms | 36352 tok/s)\n",
      "step  907/5000 | train loss 0.253141 | norm 20.8069 | lr 2.76e-05 | (121.86 ms | 33613 tok/s)\n",
      "step  908/5000 | train loss 0.253906 | norm 16.4060 | lr 2.76e-05 | (113.03 ms | 36238 tok/s)\n",
      "step  909/5000 | train loss 0.247164 | norm 3.6268 | lr 2.76e-05 | (115.09 ms | 35589 tok/s)\n",
      "step  910/5000 | train loss 0.248906 | norm 13.5545 | lr 2.76e-05 | (113.93 ms | 35952 tok/s)\n",
      "step  911/5000 | train loss 0.248802 | norm 13.2726 | lr 2.76e-05 | (113.64 ms | 36044 tok/s)\n",
      "step  912/5000 | train loss 0.248848 | norm 8.7500 | lr 2.76e-05 | (112.79 ms | 36315 tok/s)\n",
      "step  913/5000 | train loss 0.263368 | norm 26.6441 | lr 2.76e-05 | (115.40 ms | 35494 tok/s)\n",
      "step  914/5000 | train loss 0.256210 | norm 18.9165 | lr 2.76e-05 | (112.97 ms | 36257 tok/s)\n",
      "step  915/5000 | train loss 0.254615 | norm 18.8981 | lr 2.76e-05 | (115.00 ms | 35617 tok/s)\n",
      "step  916/5000 | train loss 0.253223 | norm 15.1660 | lr 2.76e-05 | (112.68 ms | 36350 tok/s)\n",
      "step  917/5000 | train loss 0.248695 | norm 12.5798 | lr 2.76e-05 | (114.58 ms | 35748 tok/s)\n",
      "step  918/5000 | train loss 0.253361 | norm 35.9528 | lr 2.76e-05 | (113.32 ms | 36144 tok/s)\n",
      "step  919/5000 | train loss 0.264388 | norm 25.7378 | lr 2.76e-05 | (114.31 ms | 35831 tok/s)\n",
      "step  920/5000 | train loss 0.273894 | norm 50.4808 | lr 2.76e-05 | (114.15 ms | 35883 tok/s)\n",
      "step  921/5000 | train loss 0.263069 | norm 19.4731 | lr 2.76e-05 | (113.46 ms | 36102 tok/s)\n",
      "step  922/5000 | train loss 0.268598 | norm 39.1229 | lr 2.76e-05 | (113.57 ms | 36067 tok/s)\n",
      "step  923/5000 | train loss 0.257636 | norm 14.5484 | lr 2.76e-05 | (113.66 ms | 36037 tok/s)\n",
      "step  924/5000 | train loss 0.252824 | norm 9.0477 | lr 2.75e-05 | (113.67 ms | 36034 tok/s)\n",
      "step  925/5000 | train loss 0.250578 | norm 9.4624 | lr 2.75e-05 | (113.71 ms | 36020 tok/s)\n",
      "step  926/5000 | train loss 0.251821 | norm 11.3709 | lr 2.75e-05 | (112.98 ms | 36254 tok/s)\n",
      "step  927/5000 | train loss 0.254723 | norm 19.8851 | lr 2.75e-05 | (114.00 ms | 35929 tok/s)\n",
      "step  928/5000 | train loss 0.248206 | norm 10.0640 | lr 2.75e-05 | (112.36 ms | 36456 tok/s)\n",
      "step  929/5000 | train loss 0.247338 | norm 10.4114 | lr 2.75e-05 | (113.14 ms | 36203 tok/s)\n",
      "step  930/5000 | train loss 0.246186 | norm 9.2826 | lr 2.75e-05 | (112.64 ms | 36365 tok/s)\n",
      "step  931/5000 | train loss 0.246393 | norm 9.9604 | lr 2.75e-05 | (114.71 ms | 35707 tok/s)\n",
      "step  932/5000 | train loss 0.244276 | norm 3.0577 | lr 2.75e-05 | (113.40 ms | 36119 tok/s)\n",
      "step  933/5000 | train loss 0.242106 | norm 2.1151 | lr 2.75e-05 | (113.74 ms | 36012 tok/s)\n",
      "step  934/5000 | train loss 0.241005 | norm 1.5675 | lr 2.75e-05 | (113.47 ms | 36096 tok/s)\n",
      "step  935/5000 | train loss 0.240170 | norm 1.7261 | lr 2.75e-05 | (113.71 ms | 36021 tok/s)\n",
      "step  936/5000 | train loss 0.239549 | norm 1.5660 | lr 2.75e-05 | (114.50 ms | 35773 tok/s)\n",
      "step  937/5000 | train loss 0.238970 | norm 1.3725 | lr 2.75e-05 | (113.79 ms | 35997 tok/s)\n",
      "step  938/5000 | train loss 0.238209 | norm 1.2083 | lr 2.75e-05 | (112.52 ms | 36403 tok/s)\n",
      "step  939/5000 | train loss 0.237493 | norm 1.2825 | lr 2.75e-05 | (114.41 ms | 35802 tok/s)\n",
      "step  940/5000 | train loss 0.236813 | norm 1.2071 | lr 2.75e-05 | (113.83 ms | 35984 tok/s)\n",
      "step  941/5000 | train loss 0.236219 | norm 1.3015 | lr 2.75e-05 | (114.44 ms | 35790 tok/s)\n",
      "step  942/5000 | train loss 0.235329 | norm 1.0086 | lr 2.75e-05 | (113.99 ms | 35932 tok/s)\n",
      "step  943/5000 | train loss 0.234782 | norm 1.1504 | lr 2.74e-05 | (115.66 ms | 35415 tok/s)\n",
      "step  944/5000 | train loss 0.234027 | norm 1.1100 | lr 2.74e-05 | (113.97 ms | 35940 tok/s)\n",
      "step  945/5000 | train loss 0.233560 | norm 1.2833 | lr 2.74e-05 | (113.17 ms | 36193 tok/s)\n",
      "step  946/5000 | train loss 0.232657 | norm 1.0651 | lr 2.74e-05 | (112.92 ms | 36273 tok/s)\n",
      "step  947/5000 | train loss 0.232127 | norm 1.1272 | lr 2.74e-05 | (113.84 ms | 35980 tok/s)\n",
      "step  948/5000 | train loss 0.231380 | norm 1.0460 | lr 2.74e-05 | (111.33 ms | 36791 tok/s)\n",
      "step  949/5000 | train loss 0.230692 | norm 0.9928 | lr 2.74e-05 | (114.78 ms | 35684 tok/s)\n",
      "step  950/5000 | train loss 0.229938 | norm 0.9467 | lr 2.74e-05 | (114.26 ms | 35848 tok/s)\n",
      "step  951/5000 | train loss 0.229532 | norm 1.1361 | lr 2.74e-05 | (115.90 ms | 35340 tok/s)\n",
      "step  952/5000 | train loss 0.228757 | norm 0.9850 | lr 2.74e-05 | (114.64 ms | 35729 tok/s)\n",
      "step  953/5000 | train loss 0.228069 | norm 0.9156 | lr 2.74e-05 | (112.55 ms | 36392 tok/s)\n",
      "step  954/5000 | train loss 0.227398 | norm 0.9268 | lr 2.74e-05 | (115.39 ms | 35498 tok/s)\n",
      "step  955/5000 | train loss 0.226732 | norm 0.8925 | lr 2.74e-05 | (114.69 ms | 35713 tok/s)\n",
      "step  956/5000 | train loss 0.226202 | norm 0.9817 | lr 2.74e-05 | (113.51 ms | 36084 tok/s)\n",
      "step  957/5000 | train loss 0.225554 | norm 1.0149 | lr 2.74e-05 | (114.47 ms | 35783 tok/s)\n",
      "step  958/5000 | train loss 0.224944 | norm 1.0386 | lr 2.74e-05 | (113.51 ms | 36085 tok/s)\n",
      "step  959/5000 | train loss 0.224428 | norm 1.1810 | lr 2.74e-05 | (113.13 ms | 36206 tok/s)\n",
      "step  960/5000 | train loss 0.223764 | norm 1.0276 | lr 2.74e-05 | (113.09 ms | 36217 tok/s)\n",
      "step  961/5000 | train loss 0.223032 | norm 0.9083 | lr 2.74e-05 | (113.34 ms | 36138 tok/s)\n",
      "step  962/5000 | train loss 0.222610 | norm 1.0331 | lr 2.73e-05 | (113.28 ms | 36158 tok/s)\n",
      "step  963/5000 | train loss 0.221884 | norm 0.9614 | lr 2.73e-05 | (114.39 ms | 35808 tok/s)\n",
      "step  964/5000 | train loss 0.221513 | norm 1.1054 | lr 2.73e-05 | (114.43 ms | 35794 tok/s)\n",
      "step  965/5000 | train loss 0.220657 | norm 0.9080 | lr 2.73e-05 | (122.18 ms | 33524 tok/s)\n",
      "step  966/5000 | train loss 0.220094 | norm 0.8856 | lr 2.73e-05 | (116.30 ms | 35220 tok/s)\n",
      "step  967/5000 | train loss 0.219557 | norm 0.8991 | lr 2.73e-05 | (116.24 ms | 35238 tok/s)\n",
      "step  968/5000 | train loss 0.218864 | norm 0.7862 | lr 2.73e-05 | (114.18 ms | 35874 tok/s)\n",
      "step  969/5000 | train loss 0.218391 | norm 0.9002 | lr 2.73e-05 | (115.26 ms | 35536 tok/s)\n",
      "step  970/5000 | train loss 0.217808 | norm 0.8782 | lr 2.73e-05 | (113.54 ms | 36076 tok/s)\n",
      "step  971/5000 | train loss 0.217238 | norm 0.8920 | lr 2.73e-05 | (116.57 ms | 35138 tok/s)\n",
      "step  972/5000 | train loss 0.216791 | norm 1.0007 | lr 2.73e-05 | (118.12 ms | 34675 tok/s)\n",
      "step  973/5000 | train loss 0.216231 | norm 1.0357 | lr 2.73e-05 | (118.17 ms | 34662 tok/s)\n",
      "step  974/5000 | train loss 0.215709 | norm 1.0237 | lr 2.73e-05 | (119.85 ms | 34176 tok/s)\n",
      "step  975/5000 | train loss 0.215023 | norm 0.9238 | lr 2.73e-05 | (118.51 ms | 34562 tok/s)\n",
      "step  976/5000 | train loss 0.214653 | norm 1.0836 | lr 2.73e-05 | (113.36 ms | 36131 tok/s)\n",
      "step  977/5000 | train loss 0.214052 | norm 1.0536 | lr 2.73e-05 | (114.51 ms | 35769 tok/s)\n",
      "step  978/5000 | train loss 0.213555 | norm 1.0040 | lr 2.73e-05 | (114.44 ms | 35792 tok/s)\n",
      "step  979/5000 | train loss 0.212813 | norm 0.8640 | lr 2.73e-05 | (115.33 ms | 35517 tok/s)\n",
      "step  980/5000 | train loss 0.212440 | norm 0.9761 | lr 2.73e-05 | (113.34 ms | 36140 tok/s)\n",
      "step  981/5000 | train loss 0.211635 | norm 0.6786 | lr 2.72e-05 | (131.67 ms | 31108 tok/s)\n",
      "step  982/5000 | train loss 0.211307 | norm 0.8885 | lr 2.72e-05 | (116.77 ms | 35076 tok/s)\n",
      "step  983/5000 | train loss 0.210780 | norm 0.8901 | lr 2.72e-05 | (114.96 ms | 35631 tok/s)\n",
      "step  984/5000 | train loss 0.210283 | norm 0.8871 | lr 2.72e-05 | (113.46 ms | 36101 tok/s)\n",
      "step  985/5000 | train loss 0.209651 | norm 0.7677 | lr 2.72e-05 | (114.85 ms | 35665 tok/s)\n",
      "step  986/5000 | train loss 0.209244 | norm 0.8760 | lr 2.72e-05 | (113.73 ms | 36015 tok/s)\n",
      "step  987/5000 | train loss 0.208702 | norm 0.8585 | lr 2.72e-05 | (116.51 ms | 35156 tok/s)\n",
      "step  988/5000 | train loss 0.208175 | norm 0.8390 | lr 2.72e-05 | (113.46 ms | 36100 tok/s)\n",
      "step  989/5000 | train loss 0.207734 | norm 0.9376 | lr 2.72e-05 | (115.69 ms | 35404 tok/s)\n",
      "step  990/5000 | train loss 0.207399 | norm 1.0701 | lr 2.72e-05 | (113.02 ms | 36241 tok/s)\n",
      "step  991/5000 | train loss 0.206720 | norm 0.8893 | lr 2.72e-05 | (114.51 ms | 35769 tok/s)\n",
      "step  992/5000 | train loss 0.206364 | norm 1.0052 | lr 2.72e-05 | (114.15 ms | 35884 tok/s)\n",
      "step  993/5000 | train loss 0.205951 | norm 1.0327 | lr 2.72e-05 | (114.26 ms | 35847 tok/s)\n",
      "step  994/5000 | train loss 0.205173 | norm 0.8112 | lr 2.72e-05 | (119.50 ms | 34277 tok/s)\n",
      "step  995/5000 | train loss 0.204987 | norm 1.0962 | lr 2.72e-05 | (118.85 ms | 34462 tok/s)\n",
      "step  996/5000 | train loss 0.204349 | norm 0.9235 | lr 2.72e-05 | (114.74 ms | 35699 tok/s)\n",
      "step  997/5000 | train loss 0.203877 | norm 0.9087 | lr 2.72e-05 | (115.25 ms | 35541 tok/s)\n",
      "step  998/5000 | train loss 0.203506 | norm 1.0388 | lr 2.72e-05 | (113.84 ms | 35981 tok/s)\n",
      "step  999/5000 | train loss 0.203027 | norm 1.0748 | lr 2.71e-05 | (115.56 ms | 35446 tok/s)\n",
      "step 1000/5000 | train loss 0.202372 | norm 0.8743 | lr 2.71e-05 | (113.90 ms | 35962 tok/s)\n",
      "step 1001/5000 | train loss 0.202046 | norm 0.9654 | lr 2.71e-05 | (115.15 ms | 35572 tok/s)\n",
      "step 1002/5000 | train loss 0.201372 | norm 0.7928 | lr 2.71e-05 | (115.16 ms | 35568 tok/s)\n",
      "step 1003/5000 | train loss 0.200950 | norm 0.7700 | lr 2.71e-05 | (115.35 ms | 35510 tok/s)\n",
      "step 1004/5000 | train loss 0.200440 | norm 0.7938 | lr 2.71e-05 | (113.49 ms | 36092 tok/s)\n",
      "step 1005/5000 | train loss 0.200098 | norm 0.8959 | lr 2.71e-05 | (113.40 ms | 36119 tok/s)\n",
      "step 1006/5000 | train loss 0.199538 | norm 0.8801 | lr 2.71e-05 | (113.11 ms | 36212 tok/s)\n",
      "step 1007/5000 | train loss 0.199216 | norm 0.9191 | lr 2.71e-05 | (118.10 ms | 34683 tok/s)\n",
      "step 1008/5000 | train loss 0.198584 | norm 0.7914 | lr 2.71e-05 | (113.61 ms | 36052 tok/s)\n",
      "step 1009/5000 | train loss 0.198189 | norm 0.8420 | lr 2.71e-05 | (114.25 ms | 35850 tok/s)\n",
      "step 1010/5000 | train loss 0.197783 | norm 0.9038 | lr 2.71e-05 | (113.38 ms | 36127 tok/s)\n",
      "step 1011/5000 | train loss 0.197359 | norm 0.9752 | lr 2.71e-05 | (113.73 ms | 36014 tok/s)\n",
      "step 1012/5000 | train loss 0.196921 | norm 0.9986 | lr 2.71e-05 | (120.27 ms | 34058 tok/s)\n",
      "step 1013/5000 | train loss 0.196446 | norm 0.9709 | lr 2.71e-05 | (117.03 ms | 35001 tok/s)\n",
      "step 1014/5000 | train loss 0.195947 | norm 0.8481 | lr 2.71e-05 | (113.60 ms | 36057 tok/s)\n",
      "step 1015/5000 | train loss 0.195422 | norm 0.7788 | lr 2.71e-05 | (114.73 ms | 35702 tok/s)\n",
      "step 1016/5000 | train loss 0.195083 | norm 0.9013 | lr 2.71e-05 | (114.18 ms | 35873 tok/s)\n",
      "step 1017/5000 | train loss 0.194700 | norm 0.9894 | lr 2.70e-05 | (115.15 ms | 35572 tok/s)\n",
      "step 1018/5000 | train loss 0.194191 | norm 0.8516 | lr 2.70e-05 | (114.01 ms | 35926 tok/s)\n",
      "step 1019/5000 | train loss 0.193764 | norm 0.8775 | lr 2.70e-05 | (114.46 ms | 35785 tok/s)\n",
      "step 1020/5000 | train loss 0.193286 | norm 0.8597 | lr 2.70e-05 | (114.34 ms | 35823 tok/s)\n",
      "step 1021/5000 | train loss 0.192825 | norm 0.8060 | lr 2.70e-05 | (114.43 ms | 35796 tok/s)\n",
      "step 1022/5000 | train loss 0.192343 | norm 0.7558 | lr 2.70e-05 | (111.65 ms | 36685 tok/s)\n",
      "step 1023/5000 | train loss 0.191832 | norm 0.6472 | lr 2.70e-05 | (114.98 ms | 35623 tok/s)\n",
      "step 1024/5000 | train loss 0.191378 | norm 0.6608 | lr 2.70e-05 | (112.90 ms | 36279 tok/s)\n",
      "step 1025/5000 | train loss 0.190963 | norm 0.6918 | lr 2.70e-05 | (115.41 ms | 35490 tok/s)\n",
      "step 1026/5000 | train loss 0.190564 | norm 0.7297 | lr 2.70e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 1027/5000 | train loss 0.190116 | norm 0.7210 | lr 2.70e-05 | (114.86 ms | 35661 tok/s)\n",
      "step 1028/5000 | train loss 0.189740 | norm 0.8089 | lr 2.70e-05 | (112.85 ms | 36296 tok/s)\n",
      "step 1029/5000 | train loss 0.189425 | norm 0.8757 | lr 2.70e-05 | (120.18 ms | 34083 tok/s)\n",
      "step 1030/5000 | train loss 0.188883 | norm 0.7968 | lr 2.70e-05 | (116.90 ms | 35038 tok/s)\n",
      "step 1031/5000 | train loss 0.188411 | norm 0.6854 | lr 2.70e-05 | (114.25 ms | 35850 tok/s)\n",
      "step 1032/5000 | train loss 0.187917 | norm 0.6283 | lr 2.70e-05 | (115.13 ms | 35576 tok/s)\n",
      "step 1033/5000 | train loss 0.187629 | norm 0.7993 | lr 2.70e-05 | (117.58 ms | 34836 tok/s)\n",
      "step 1034/5000 | train loss 0.187254 | norm 0.8666 | lr 2.70e-05 | (117.35 ms | 34905 tok/s)\n",
      "step 1035/5000 | train loss 0.186842 | norm 0.9018 | lr 2.69e-05 | (116.35 ms | 35205 tok/s)\n",
      "step 1036/5000 | train loss 0.186648 | norm 1.1171 | lr 2.69e-05 | (115.80 ms | 35372 tok/s)\n",
      "step 1037/5000 | train loss 0.186060 | norm 0.9002 | lr 2.69e-05 | (116.36 ms | 35201 tok/s)\n",
      "step 1038/5000 | train loss 0.185575 | norm 0.8118 | lr 2.69e-05 | (113.87 ms | 35970 tok/s)\n",
      "step 1039/5000 | train loss 0.185273 | norm 0.9453 | lr 2.69e-05 | (117.55 ms | 34845 tok/s)\n",
      "step 1040/5000 | train loss 0.184906 | norm 0.9404 | lr 2.69e-05 | (117.73 ms | 34792 tok/s)\n",
      "step 1041/5000 | train loss 0.184266 | norm 0.6900 | lr 2.69e-05 | (114.30 ms | 35835 tok/s)\n",
      "step 1042/5000 | train loss 0.183934 | norm 0.7939 | lr 2.69e-05 | (115.44 ms | 35482 tok/s)\n",
      "step 1043/5000 | train loss 0.183576 | norm 0.8305 | lr 2.69e-05 | (117.61 ms | 34826 tok/s)\n",
      "step 1044/5000 | train loss 0.183072 | norm 0.6899 | lr 2.69e-05 | (115.97 ms | 35319 tok/s)\n",
      "step 1045/5000 | train loss 0.182666 | norm 0.7079 | lr 2.69e-05 | (115.85 ms | 35356 tok/s)\n",
      "step 1046/5000 | train loss 0.182321 | norm 0.7901 | lr 2.69e-05 | (113.19 ms | 36187 tok/s)\n",
      "step 1047/5000 | train loss 0.181914 | norm 0.7474 | lr 2.69e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 1048/5000 | train loss 0.181444 | norm 0.6724 | lr 2.69e-05 | (113.69 ms | 36029 tok/s)\n",
      "step 1049/5000 | train loss 0.181153 | norm 0.7915 | lr 2.69e-05 | (116.18 ms | 35256 tok/s)\n",
      "step 1050/5000 | train loss 0.180750 | norm 0.8172 | lr 2.69e-05 | (114.07 ms | 35907 tok/s)\n",
      "step 1051/5000 | train loss 0.180328 | norm 0.7906 | lr 2.69e-05 | (115.25 ms | 35540 tok/s)\n",
      "step 1052/5000 | train loss 0.179955 | norm 0.7952 | lr 2.68e-05 | (114.03 ms | 35921 tok/s)\n",
      "step 1053/5000 | train loss 0.179516 | norm 0.7231 | lr 2.68e-05 | (115.67 ms | 35410 tok/s)\n",
      "step 1054/5000 | train loss 0.179045 | norm 0.6016 | lr 2.68e-05 | (112.88 ms | 36285 tok/s)\n",
      "step 1055/5000 | train loss 0.178690 | norm 0.6719 | lr 2.68e-05 | (114.87 ms | 35659 tok/s)\n",
      "step 1056/5000 | train loss 0.178443 | norm 0.8305 | lr 2.68e-05 | (118.46 ms | 34578 tok/s)\n",
      "step 1057/5000 | train loss 0.177999 | norm 0.8201 | lr 2.68e-05 | (118.39 ms | 34598 tok/s)\n",
      "step 1058/5000 | train loss 0.177792 | norm 0.9507 | lr 2.68e-05 | (116.11 ms | 35277 tok/s)\n",
      "step 1059/5000 | train loss 0.177459 | norm 1.0468 | lr 2.68e-05 | (118.27 ms | 34633 tok/s)\n",
      "step 1060/5000 | train loss 0.176999 | norm 0.9384 | lr 2.68e-05 | (115.99 ms | 35315 tok/s)\n",
      "step 1061/5000 | train loss 0.176662 | norm 1.0098 | lr 2.68e-05 | (114.86 ms | 35660 tok/s)\n",
      "step 1062/5000 | train loss 0.176377 | norm 1.0501 | lr 2.68e-05 | (113.52 ms | 36080 tok/s)\n",
      "step 1063/5000 | train loss 0.175699 | norm 0.6993 | lr 2.68e-05 | (113.55 ms | 36072 tok/s)\n",
      "step 1064/5000 | train loss 0.175509 | norm 0.9373 | lr 2.68e-05 | (113.70 ms | 36025 tok/s)\n",
      "step 1065/5000 | train loss 0.175159 | norm 0.9268 | lr 2.68e-05 | (116.19 ms | 35254 tok/s)\n",
      "step 1066/5000 | train loss 0.174575 | norm 0.7092 | lr 2.68e-05 | (118.24 ms | 34643 tok/s)\n",
      "step 1067/5000 | train loss 0.174452 | norm 0.9730 | lr 2.68e-05 | (114.27 ms | 35845 tok/s)\n",
      "step 1068/5000 | train loss 0.173858 | norm 0.7791 | lr 2.68e-05 | (112.10 ms | 36538 tok/s)\n",
      "step 1069/5000 | train loss 0.173608 | norm 0.8205 | lr 2.67e-05 | (116.21 ms | 35247 tok/s)\n",
      "step 1070/5000 | train loss 0.173092 | norm 0.7252 | lr 2.67e-05 | (122.14 ms | 33535 tok/s)\n",
      "step 1071/5000 | train loss 0.172835 | norm 0.7774 | lr 2.67e-05 | (120.06 ms | 34115 tok/s)\n",
      "step 1072/5000 | train loss 0.172411 | norm 0.7651 | lr 2.67e-05 | (113.70 ms | 36024 tok/s)\n",
      "step 1073/5000 | train loss 0.172059 | norm 0.7375 | lr 2.67e-05 | (114.72 ms | 35703 tok/s)\n",
      "step 1074/5000 | train loss 0.171573 | norm 0.6321 | lr 2.67e-05 | (114.09 ms | 35902 tok/s)\n",
      "step 1075/5000 | train loss 0.171247 | norm 0.6366 | lr 2.67e-05 | (116.09 ms | 35284 tok/s)\n",
      "step 1076/5000 | train loss 0.170838 | norm 0.6231 | lr 2.67e-05 | (119.90 ms | 34162 tok/s)\n",
      "step 1077/5000 | train loss 0.170564 | norm 0.7106 | lr 2.67e-05 | (117.24 ms | 34938 tok/s)\n",
      "step 1078/5000 | train loss 0.170137 | norm 0.6633 | lr 2.67e-05 | (114.29 ms | 35839 tok/s)\n",
      "step 1079/5000 | train loss 0.169827 | norm 0.6966 | lr 2.67e-05 | (119.11 ms | 34388 tok/s)\n",
      "step 1080/5000 | train loss 0.169400 | norm 0.6146 | lr 2.67e-05 | (113.63 ms | 36048 tok/s)\n",
      "step 1081/5000 | train loss 0.169101 | norm 0.6720 | lr 2.67e-05 | (114.60 ms | 35742 tok/s)\n",
      "step 1082/5000 | train loss 0.168726 | norm 0.6672 | lr 2.67e-05 | (113.55 ms | 36072 tok/s)\n",
      "step 1083/5000 | train loss 0.168400 | norm 0.7019 | lr 2.67e-05 | (118.15 ms | 34667 tok/s)\n",
      "step 1084/5000 | train loss 0.168025 | norm 0.6997 | lr 2.67e-05 | (116.71 ms | 35095 tok/s)\n",
      "step 1085/5000 | train loss 0.167743 | norm 0.7436 | lr 2.67e-05 | (116.67 ms | 35108 tok/s)\n",
      "step 1086/5000 | train loss 0.167295 | norm 0.6469 | lr 2.66e-05 | (119.88 ms | 34168 tok/s)\n",
      "step 1087/5000 | train loss 0.167032 | norm 0.7318 | lr 2.66e-05 | (118.13 ms | 34673 tok/s)\n",
      "step 1088/5000 | train loss 0.166689 | norm 0.7672 | lr 2.66e-05 | (116.39 ms | 35192 tok/s)\n",
      "step 1089/5000 | train loss 0.166367 | norm 0.7625 | lr 2.66e-05 | (118.12 ms | 34676 tok/s)\n",
      "step 1090/5000 | train loss 0.166000 | norm 0.7463 | lr 2.66e-05 | (113.72 ms | 36019 tok/s)\n",
      "step 1091/5000 | train loss 0.165595 | norm 0.6905 | lr 2.66e-05 | (115.43 ms | 35484 tok/s)\n",
      "step 1092/5000 | train loss 0.165319 | norm 0.7338 | lr 2.66e-05 | (113.63 ms | 36048 tok/s)\n",
      "step 1093/5000 | train loss 0.164943 | norm 0.7112 | lr 2.66e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 1094/5000 | train loss 0.164620 | norm 0.7589 | lr 2.66e-05 | (114.17 ms | 35877 tok/s)\n",
      "step 1095/5000 | train loss 0.164353 | norm 0.8660 | lr 2.66e-05 | (121.68 ms | 33661 tok/s)\n",
      "step 1096/5000 | train loss 0.164055 | norm 0.8995 | lr 2.66e-05 | (118.09 ms | 34685 tok/s)\n",
      "step 1097/5000 | train loss 0.163685 | norm 0.8509 | lr 2.66e-05 | (122.22 ms | 33513 tok/s)\n",
      "step 1098/5000 | train loss 0.163444 | norm 0.9717 | lr 2.66e-05 | (121.45 ms | 33727 tok/s)\n",
      "step 1099/5000 | train loss 0.163342 | norm 1.0123 | lr 2.66e-05 | (116.66 ms | 35111 tok/s)\n",
      "step 1100/5000 | train loss 0.162595 | norm 0.7372 | lr 2.66e-05 | (114.09 ms | 35902 tok/s)\n",
      "step 1101/5000 | train loss 0.162618 | norm 1.0786 | lr 2.66e-05 | (116.26 ms | 35233 tok/s)\n",
      "step 1102/5000 | train loss 0.162025 | norm 0.7707 | lr 2.66e-05 | (113.78 ms | 35998 tok/s)\n",
      "step 1103/5000 | train loss 0.161776 | norm 0.8273 | lr 2.65e-05 | (115.37 ms | 35503 tok/s)\n",
      "step 1104/5000 | train loss 0.161462 | norm 0.9116 | lr 2.65e-05 | (114.34 ms | 35823 tok/s)\n",
      "step 1105/5000 | train loss 0.161016 | norm 0.7324 | lr 2.65e-05 | (114.86 ms | 35662 tok/s)\n",
      "step 1106/5000 | train loss 0.160697 | norm 0.7551 | lr 2.65e-05 | (113.75 ms | 36010 tok/s)\n",
      "step 1107/5000 | train loss 0.160297 | norm 0.6556 | lr 2.65e-05 | (114.57 ms | 35750 tok/s)\n",
      "step 1108/5000 | train loss 0.159965 | norm 0.6519 | lr 2.65e-05 | (113.84 ms | 35979 tok/s)\n",
      "step 1109/5000 | train loss 0.159634 | norm 0.6266 | lr 2.65e-05 | (115.71 ms | 35399 tok/s)\n",
      "step 1110/5000 | train loss 0.159264 | norm 0.5692 | lr 2.65e-05 | (113.76 ms | 36007 tok/s)\n",
      "step 1111/5000 | train loss 0.158930 | norm 0.5393 | lr 2.65e-05 | (114.94 ms | 35637 tok/s)\n",
      "step 1112/5000 | train loss 0.158605 | norm 0.5493 | lr 2.65e-05 | (113.21 ms | 36181 tok/s)\n",
      "step 1113/5000 | train loss 0.158228 | norm 0.4818 | lr 2.65e-05 | (113.29 ms | 36154 tok/s)\n",
      "step 1114/5000 | train loss 0.157938 | norm 0.5213 | lr 2.65e-05 | (113.66 ms | 36036 tok/s)\n",
      "step 1115/5000 | train loss 0.157571 | norm 0.4893 | lr 2.65e-05 | (113.84 ms | 35980 tok/s)\n",
      "step 1116/5000 | train loss 0.157362 | norm 0.6231 | lr 2.65e-05 | (113.02 ms | 36240 tok/s)\n",
      "step 1117/5000 | train loss 0.157070 | norm 0.7022 | lr 2.65e-05 | (113.32 ms | 36145 tok/s)\n",
      "step 1118/5000 | train loss 0.156981 | norm 0.9240 | lr 2.65e-05 | (113.40 ms | 36120 tok/s)\n",
      "step 1119/5000 | train loss 0.156697 | norm 0.9987 | lr 2.64e-05 | (114.31 ms | 35834 tok/s)\n",
      "step 1120/5000 | train loss 0.156346 | norm 0.9355 | lr 2.64e-05 | (113.25 ms | 36168 tok/s)\n",
      "step 1121/5000 | train loss 0.156082 | norm 0.9079 | lr 2.64e-05 | (114.85 ms | 35665 tok/s)\n",
      "step 1122/5000 | train loss 0.155715 | norm 0.8755 | lr 2.64e-05 | (114.32 ms | 35828 tok/s)\n",
      "step 1123/5000 | train loss 0.155338 | norm 0.7939 | lr 2.64e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 1124/5000 | train loss 0.155025 | norm 0.7741 | lr 2.64e-05 | (115.81 ms | 35369 tok/s)\n",
      "step 1125/5000 | train loss 0.154730 | norm 0.7579 | lr 2.64e-05 | (115.91 ms | 35338 tok/s)\n",
      "step 1126/5000 | train loss 0.154328 | norm 0.6834 | lr 2.64e-05 | (114.18 ms | 35872 tok/s)\n",
      "step 1127/5000 | train loss 0.154103 | norm 0.7239 | lr 2.64e-05 | (114.31 ms | 35833 tok/s)\n",
      "step 1128/5000 | train loss 0.153657 | norm 0.5984 | lr 2.64e-05 | (113.60 ms | 36055 tok/s)\n",
      "step 1129/5000 | train loss 0.153353 | norm 0.5732 | lr 2.64e-05 | (112.69 ms | 36347 tok/s)\n",
      "step 1130/5000 | train loss 0.153083 | norm 0.6093 | lr 2.64e-05 | (113.20 ms | 36185 tok/s)\n",
      "step 1131/5000 | train loss 0.152690 | norm 0.5085 | lr 2.64e-05 | (113.61 ms | 36054 tok/s)\n",
      "step 1132/5000 | train loss 0.152399 | norm 0.5026 | lr 2.64e-05 | (113.51 ms | 36084 tok/s)\n",
      "step 1133/5000 | train loss 0.152093 | norm 0.5323 | lr 2.64e-05 | (114.90 ms | 35649 tok/s)\n",
      "step 1134/5000 | train loss 0.151838 | norm 0.5808 | lr 2.64e-05 | (112.75 ms | 36327 tok/s)\n",
      "step 1135/5000 | train loss 0.151506 | norm 0.5632 | lr 2.64e-05 | (114.62 ms | 35735 tok/s)\n",
      "step 1136/5000 | train loss 0.151292 | norm 0.6543 | lr 2.63e-05 | (113.21 ms | 36179 tok/s)\n",
      "step 1137/5000 | train loss 0.151047 | norm 0.7617 | lr 2.63e-05 | (113.51 ms | 36085 tok/s)\n",
      "step 1138/5000 | train loss 0.150903 | norm 0.8789 | lr 2.63e-05 | (113.56 ms | 36069 tok/s)\n",
      "step 1139/5000 | train loss 0.150461 | norm 0.7600 | lr 2.63e-05 | (115.08 ms | 35594 tok/s)\n",
      "step 1140/5000 | train loss 0.150153 | norm 0.6961 | lr 2.63e-05 | (113.36 ms | 36133 tok/s)\n",
      "step 1141/5000 | train loss 0.149833 | norm 0.6566 | lr 2.63e-05 | (113.77 ms | 36004 tok/s)\n",
      "step 1142/5000 | train loss 0.149655 | norm 0.7735 | lr 2.63e-05 | (113.31 ms | 36149 tok/s)\n",
      "step 1143/5000 | train loss 0.149398 | norm 0.8320 | lr 2.63e-05 | (115.48 ms | 35470 tok/s)\n",
      "step 1144/5000 | train loss 0.148988 | norm 0.6665 | lr 2.63e-05 | (113.58 ms | 36061 tok/s)\n",
      "step 1145/5000 | train loss 0.148710 | norm 0.6952 | lr 2.63e-05 | (114.42 ms | 35797 tok/s)\n",
      "step 1146/5000 | train loss 0.148415 | norm 0.7024 | lr 2.63e-05 | (113.11 ms | 36213 tok/s)\n",
      "step 1147/5000 | train loss 0.148148 | norm 0.7013 | lr 2.63e-05 | (112.83 ms | 36303 tok/s)\n",
      "step 1148/5000 | train loss 0.147838 | norm 0.6539 | lr 2.63e-05 | (112.81 ms | 36308 tok/s)\n",
      "step 1149/5000 | train loss 0.147486 | norm 0.5785 | lr 2.63e-05 | (115.23 ms | 35548 tok/s)\n",
      "step 1150/5000 | train loss 0.147213 | norm 0.5909 | lr 2.63e-05 | (115.00 ms | 35618 tok/s)\n",
      "step 1151/5000 | train loss 0.146920 | norm 0.5881 | lr 2.63e-05 | (115.08 ms | 35593 tok/s)\n",
      "step 1152/5000 | train loss 0.146668 | norm 0.6347 | lr 2.62e-05 | (112.97 ms | 36258 tok/s)\n",
      "step 1153/5000 | train loss 0.146375 | norm 0.5865 | lr 2.62e-05 | (114.02 ms | 35924 tok/s)\n",
      "step 1154/5000 | train loss 0.146095 | norm 0.6129 | lr 2.62e-05 | (113.75 ms | 36010 tok/s)\n",
      "step 1155/5000 | train loss 0.145838 | norm 0.6376 | lr 2.62e-05 | (113.47 ms | 36099 tok/s)\n",
      "step 1156/5000 | train loss 0.145553 | norm 0.6195 | lr 2.62e-05 | (114.97 ms | 35625 tok/s)\n",
      "step 1157/5000 | train loss 0.145260 | norm 0.5872 | lr 2.62e-05 | (114.08 ms | 35906 tok/s)\n",
      "step 1158/5000 | train loss 0.144935 | norm 0.5417 | lr 2.62e-05 | (113.55 ms | 36072 tok/s)\n",
      "step 1159/5000 | train loss 0.144714 | norm 0.5954 | lr 2.62e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 1160/5000 | train loss 0.144417 | norm 0.5956 | lr 2.62e-05 | (114.38 ms | 35811 tok/s)\n",
      "step 1161/5000 | train loss 0.144215 | norm 0.6917 | lr 2.62e-05 | (114.73 ms | 35701 tok/s)\n",
      "step 1162/5000 | train loss 0.144085 | norm 0.8167 | lr 2.62e-05 | (113.73 ms | 36015 tok/s)\n",
      "step 1163/5000 | train loss 0.143716 | norm 0.7486 | lr 2.62e-05 | (114.49 ms | 35777 tok/s)\n",
      "step 1164/5000 | train loss 0.143394 | norm 0.6512 | lr 2.62e-05 | (112.36 ms | 36453 tok/s)\n",
      "step 1165/5000 | train loss 0.143095 | norm 0.6295 | lr 2.62e-05 | (114.95 ms | 35634 tok/s)\n",
      "step 1166/5000 | train loss 0.142914 | norm 0.7274 | lr 2.62e-05 | (113.36 ms | 36131 tok/s)\n",
      "step 1167/5000 | train loss 0.142593 | norm 0.6571 | lr 2.62e-05 | (114.56 ms | 35755 tok/s)\n",
      "step 1168/5000 | train loss 0.142286 | norm 0.5914 | lr 2.61e-05 | (113.20 ms | 36182 tok/s)\n",
      "step 1169/5000 | train loss 0.142023 | norm 0.6159 | lr 2.61e-05 | (113.87 ms | 35971 tok/s)\n",
      "step 1170/5000 | train loss 0.141817 | norm 0.6843 | lr 2.61e-05 | (112.84 ms | 36300 tok/s)\n",
      "step 1171/5000 | train loss 0.141550 | norm 0.6758 | lr 2.61e-05 | (113.61 ms | 36054 tok/s)\n",
      "step 1172/5000 | train loss 0.141277 | norm 0.6592 | lr 2.61e-05 | (112.98 ms | 36255 tok/s)\n",
      "step 1173/5000 | train loss 0.141143 | norm 0.7686 | lr 2.61e-05 | (114.19 ms | 35870 tok/s)\n",
      "step 1174/5000 | train loss 0.140861 | norm 0.7506 | lr 2.61e-05 | (113.55 ms | 36073 tok/s)\n",
      "step 1175/5000 | train loss 0.140529 | norm 0.6807 | lr 2.61e-05 | (113.29 ms | 36155 tok/s)\n",
      "step 1176/5000 | train loss 0.140249 | norm 0.6234 | lr 2.61e-05 | (113.11 ms | 36214 tok/s)\n",
      "step 1177/5000 | train loss 0.139958 | norm 0.5741 | lr 2.61e-05 | (112.87 ms | 36289 tok/s)\n",
      "step 1178/5000 | train loss 0.139680 | norm 0.5939 | lr 2.61e-05 | (112.96 ms | 36261 tok/s)\n",
      "step 1179/5000 | train loss 0.139459 | norm 0.6179 | lr 2.61e-05 | (112.41 ms | 36440 tok/s)\n",
      "step 1180/5000 | train loss 0.139109 | norm 0.5003 | lr 2.61e-05 | (113.01 ms | 36246 tok/s)\n",
      "step 1181/5000 | train loss 0.138934 | norm 0.5839 | lr 2.61e-05 | (132.85 ms | 30831 tok/s)\n",
      "step 1182/5000 | train loss 0.138599 | norm 0.4980 | lr 2.61e-05 | (114.86 ms | 35660 tok/s)\n",
      "step 1183/5000 | train loss 0.138358 | norm 0.5041 | lr 2.61e-05 | (114.05 ms | 35914 tok/s)\n",
      "step 1184/5000 | train loss 0.138097 | norm 0.4984 | lr 2.60e-05 | (113.22 ms | 36178 tok/s)\n",
      "step 1185/5000 | train loss 0.137825 | norm 0.4771 | lr 2.60e-05 | (114.60 ms | 35741 tok/s)\n",
      "step 1186/5000 | train loss 0.137590 | norm 0.5111 | lr 2.60e-05 | (113.62 ms | 36050 tok/s)\n",
      "step 1187/5000 | train loss 0.137393 | norm 0.5896 | lr 2.60e-05 | (113.34 ms | 36139 tok/s)\n",
      "step 1188/5000 | train loss 0.137214 | norm 0.6724 | lr 2.60e-05 | (113.56 ms | 36069 tok/s)\n",
      "step 1189/5000 | train loss 0.137057 | norm 0.7972 | lr 2.60e-05 | (113.21 ms | 36180 tok/s)\n",
      "step 1190/5000 | train loss 0.136937 | norm 0.9305 | lr 2.60e-05 | (113.23 ms | 36173 tok/s)\n",
      "step 1191/5000 | train loss 0.136755 | norm 0.9249 | lr 2.60e-05 | (114.81 ms | 35676 tok/s)\n",
      "step 1192/5000 | train loss 0.136264 | norm 0.6783 | lr 2.60e-05 | (112.47 ms | 36417 tok/s)\n",
      "step 1193/5000 | train loss 0.136014 | norm 0.6616 | lr 2.60e-05 | (114.09 ms | 35901 tok/s)\n",
      "step 1194/5000 | train loss 0.135866 | norm 0.7843 | lr 2.60e-05 | (113.59 ms | 36059 tok/s)\n",
      "step 1195/5000 | train loss 0.135522 | norm 0.6528 | lr 2.60e-05 | (115.31 ms | 35521 tok/s)\n",
      "step 1196/5000 | train loss 0.135203 | norm 0.5673 | lr 2.60e-05 | (113.45 ms | 36105 tok/s)\n",
      "step 1197/5000 | train loss 0.135088 | norm 0.7038 | lr 2.60e-05 | (113.74 ms | 36013 tok/s)\n",
      "step 1198/5000 | train loss 0.134687 | norm 0.5182 | lr 2.60e-05 | (113.16 ms | 36195 tok/s)\n",
      "step 1199/5000 | train loss 0.134500 | norm 0.5467 | lr 2.59e-05 | (114.14 ms | 35887 tok/s)\n",
      "step 1200/5000 | train loss 0.134236 | norm 0.5667 | lr 2.59e-05 | (113.54 ms | 36075 tok/s)\n",
      "step 1201/5000 | train loss 0.133992 | norm 0.5183 | lr 2.59e-05 | (115.72 ms | 35396 tok/s)\n",
      "step 1202/5000 | train loss 0.133696 | norm 0.4752 | lr 2.59e-05 | (114.10 ms | 35899 tok/s)\n",
      "step 1203/5000 | train loss 0.133566 | norm 0.5997 | lr 2.59e-05 | (115.94 ms | 35328 tok/s)\n",
      "step 1204/5000 | train loss 0.133265 | norm 0.5140 | lr 2.59e-05 | (113.95 ms | 35947 tok/s)\n",
      "step 1205/5000 | train loss 0.132995 | norm 0.4719 | lr 2.59e-05 | (113.62 ms | 36050 tok/s)\n",
      "step 1206/5000 | train loss 0.132835 | norm 0.5669 | lr 2.59e-05 | (112.72 ms | 36338 tok/s)\n",
      "step 1207/5000 | train loss 0.132542 | norm 0.4933 | lr 2.59e-05 | (114.10 ms | 35898 tok/s)\n",
      "step 1208/5000 | train loss 0.132317 | norm 0.5050 | lr 2.59e-05 | (113.64 ms | 36045 tok/s)\n",
      "step 1209/5000 | train loss 0.132148 | norm 0.6213 | lr 2.59e-05 | (113.91 ms | 35957 tok/s)\n",
      "step 1210/5000 | train loss 0.132047 | norm 0.7233 | lr 2.59e-05 | (113.19 ms | 36187 tok/s)\n",
      "step 1211/5000 | train loss 0.131811 | norm 0.7414 | lr 2.59e-05 | (113.66 ms | 36039 tok/s)\n",
      "step 1212/5000 | train loss 0.131613 | norm 0.7467 | lr 2.59e-05 | (113.01 ms | 36246 tok/s)\n",
      "step 1213/5000 | train loss 0.131255 | norm 0.6340 | lr 2.59e-05 | (115.73 ms | 35392 tok/s)\n",
      "step 1214/5000 | train loss 0.131072 | norm 0.6916 | lr 2.59e-05 | (113.72 ms | 36020 tok/s)\n",
      "step 1215/5000 | train loss 0.130870 | norm 0.7090 | lr 2.58e-05 | (114.75 ms | 35696 tok/s)\n",
      "step 1216/5000 | train loss 0.130527 | norm 0.5375 | lr 2.58e-05 | (114.61 ms | 35738 tok/s)\n",
      "step 1217/5000 | train loss 0.130252 | norm 0.4625 | lr 2.58e-05 | (114.68 ms | 35715 tok/s)\n",
      "step 1218/5000 | train loss 0.130131 | norm 0.6048 | lr 2.58e-05 | (113.05 ms | 36232 tok/s)\n",
      "step 1219/5000 | train loss 0.129857 | norm 0.5565 | lr 2.58e-05 | (115.43 ms | 35484 tok/s)\n",
      "step 1220/5000 | train loss 0.129632 | norm 0.5271 | lr 2.58e-05 | (127.31 ms | 32173 tok/s)\n",
      "step 1221/5000 | train loss 0.129429 | norm 0.5685 | lr 2.58e-05 | (115.03 ms | 35609 tok/s)\n",
      "step 1222/5000 | train loss 0.129202 | norm 0.5698 | lr 2.58e-05 | (112.23 ms | 36496 tok/s)\n",
      "step 1223/5000 | train loss 0.128931 | norm 0.5098 | lr 2.58e-05 | (115.60 ms | 35433 tok/s)\n",
      "step 1224/5000 | train loss 0.128712 | norm 0.5170 | lr 2.58e-05 | (112.98 ms | 36253 tok/s)\n",
      "step 1225/5000 | train loss 0.128484 | norm 0.5009 | lr 2.58e-05 | (116.98 ms | 35015 tok/s)\n",
      "step 1226/5000 | train loss 0.128265 | norm 0.4855 | lr 2.58e-05 | (114.35 ms | 35820 tok/s)\n",
      "step 1227/5000 | train loss 0.128019 | norm 0.4758 | lr 2.58e-05 | (114.58 ms | 35748 tok/s)\n",
      "step 1228/5000 | train loss 0.127898 | norm 0.5804 | lr 2.58e-05 | (112.50 ms | 36409 tok/s)\n",
      "step 1229/5000 | train loss 0.127730 | norm 0.6459 | lr 2.58e-05 | (114.93 ms | 35638 tok/s)\n",
      "step 1230/5000 | train loss 0.127458 | norm 0.5970 | lr 2.57e-05 | (112.75 ms | 36327 tok/s)\n",
      "step 1231/5000 | train loss 0.127241 | norm 0.6100 | lr 2.57e-05 | (114.69 ms | 35713 tok/s)\n",
      "step 1232/5000 | train loss 0.127131 | norm 0.7006 | lr 2.57e-05 | (113.04 ms | 36233 tok/s)\n",
      "step 1233/5000 | train loss 0.126947 | norm 0.7270 | lr 2.57e-05 | (114.47 ms | 35781 tok/s)\n",
      "step 1234/5000 | train loss 0.126703 | norm 0.6704 | lr 2.57e-05 | (113.23 ms | 36173 tok/s)\n",
      "step 1235/5000 | train loss 0.126412 | norm 0.5504 | lr 2.57e-05 | (114.50 ms | 35774 tok/s)\n",
      "step 1236/5000 | train loss 0.126204 | norm 0.5758 | lr 2.57e-05 | (112.88 ms | 36286 tok/s)\n",
      "step 1237/5000 | train loss 0.126015 | norm 0.5903 | lr 2.57e-05 | (115.48 ms | 35468 tok/s)\n",
      "step 1238/5000 | train loss 0.125728 | norm 0.5251 | lr 2.57e-05 | (113.67 ms | 36034 tok/s)\n",
      "step 1239/5000 | train loss 0.125522 | norm 0.5002 | lr 2.57e-05 | (112.26 ms | 36487 tok/s)\n",
      "step 1240/5000 | train loss 0.125297 | norm 0.5036 | lr 2.57e-05 | (113.18 ms | 36190 tok/s)\n",
      "step 1241/5000 | train loss 0.125154 | norm 0.5655 | lr 2.57e-05 | (113.95 ms | 35945 tok/s)\n",
      "step 1242/5000 | train loss 0.124872 | norm 0.4982 | lr 2.57e-05 | (112.96 ms | 36260 tok/s)\n",
      "step 1243/5000 | train loss 0.124741 | norm 0.6108 | lr 2.57e-05 | (113.20 ms | 36183 tok/s)\n",
      "step 1244/5000 | train loss 0.124602 | norm 0.6730 | lr 2.57e-05 | (113.03 ms | 36238 tok/s)\n",
      "step 1245/5000 | train loss 0.124353 | norm 0.6531 | lr 2.56e-05 | (113.97 ms | 35941 tok/s)\n",
      "step 1246/5000 | train loss 0.124327 | norm 0.8109 | lr 2.56e-05 | (113.38 ms | 36127 tok/s)\n",
      "step 1247/5000 | train loss 0.124100 | norm 0.7751 | lr 2.56e-05 | (113.90 ms | 35963 tok/s)\n",
      "step 1248/5000 | train loss 0.123715 | norm 0.5530 | lr 2.56e-05 | (112.89 ms | 36284 tok/s)\n",
      "step 1249/5000 | train loss 0.123493 | norm 0.5320 | lr 2.56e-05 | (114.36 ms | 35818 tok/s)\n",
      "step 1250/5000 | train loss 0.123355 | norm 0.6155 | lr 2.56e-05 | (113.78 ms | 36000 tok/s)\n",
      "step 1251/5000 | train loss 0.123102 | norm 0.5519 | lr 2.56e-05 | (114.28 ms | 35843 tok/s)\n",
      "step 1252/5000 | train loss 0.122848 | norm 0.4840 | lr 2.56e-05 | (111.82 ms | 36632 tok/s)\n",
      "step 1253/5000 | train loss 0.122674 | norm 0.5087 | lr 2.56e-05 | (114.27 ms | 35844 tok/s)\n",
      "step 1254/5000 | train loss 0.122448 | norm 0.4707 | lr 2.56e-05 | (113.78 ms | 35999 tok/s)\n",
      "step 1255/5000 | train loss 0.122209 | norm 0.4161 | lr 2.56e-05 | (114.65 ms | 35728 tok/s)\n",
      "step 1256/5000 | train loss 0.122072 | norm 0.4671 | lr 2.56e-05 | (113.74 ms | 36012 tok/s)\n",
      "step 1257/5000 | train loss 0.121839 | norm 0.4577 | lr 2.56e-05 | (113.79 ms | 35996 tok/s)\n",
      "step 1258/5000 | train loss 0.121721 | norm 0.5480 | lr 2.56e-05 | (113.16 ms | 36196 tok/s)\n",
      "step 1259/5000 | train loss 0.121452 | norm 0.4788 | lr 2.56e-05 | (115.25 ms | 35540 tok/s)\n",
      "step 1260/5000 | train loss 0.121308 | norm 0.5387 | lr 2.55e-05 | (114.87 ms | 35656 tok/s)\n",
      "step 1261/5000 | train loss 0.121166 | norm 0.6055 | lr 2.55e-05 | (114.91 ms | 35645 tok/s)\n",
      "step 1262/5000 | train loss 0.120932 | norm 0.5807 | lr 2.55e-05 | (113.42 ms | 36114 tok/s)\n",
      "step 1263/5000 | train loss 0.120735 | norm 0.5568 | lr 2.55e-05 | (114.25 ms | 35851 tok/s)\n",
      "step 1264/5000 | train loss 0.120524 | norm 0.5351 | lr 2.55e-05 | (112.85 ms | 36295 tok/s)\n",
      "step 1265/5000 | train loss 0.120385 | norm 0.6024 | lr 2.55e-05 | (114.65 ms | 35727 tok/s)\n",
      "step 1266/5000 | train loss 0.120200 | norm 0.5781 | lr 2.55e-05 | (113.76 ms | 36006 tok/s)\n",
      "step 1267/5000 | train loss 0.119907 | norm 0.4740 | lr 2.55e-05 | (114.85 ms | 35663 tok/s)\n",
      "step 1268/5000 | train loss 0.119785 | norm 0.5314 | lr 2.55e-05 | (113.98 ms | 35935 tok/s)\n",
      "step 1269/5000 | train loss 0.119539 | norm 0.4899 | lr 2.55e-05 | (114.36 ms | 35818 tok/s)\n",
      "step 1270/5000 | train loss 0.119330 | norm 0.4426 | lr 2.55e-05 | (112.85 ms | 36297 tok/s)\n",
      "step 1271/5000 | train loss 0.119152 | norm 0.4618 | lr 2.55e-05 | (114.58 ms | 35748 tok/s)\n",
      "step 1272/5000 | train loss 0.119015 | norm 0.5447 | lr 2.55e-05 | (113.60 ms | 36057 tok/s)\n",
      "step 1273/5000 | train loss 0.118850 | norm 0.5757 | lr 2.55e-05 | (114.08 ms | 35904 tok/s)\n",
      "step 1274/5000 | train loss 0.118759 | norm 0.6601 | lr 2.55e-05 | (112.56 ms | 36389 tok/s)\n",
      "step 1275/5000 | train loss 0.118693 | norm 0.7897 | lr 2.54e-05 | (114.92 ms | 35642 tok/s)\n",
      "step 1276/5000 | train loss 0.118419 | norm 0.6644 | lr 2.54e-05 | (113.23 ms | 36174 tok/s)\n",
      "step 1277/5000 | train loss 0.118108 | norm 0.5199 | lr 2.54e-05 | (115.30 ms | 35525 tok/s)\n",
      "step 1278/5000 | train loss 0.118037 | norm 0.6412 | lr 2.54e-05 | (113.83 ms | 35982 tok/s)\n",
      "step 1279/5000 | train loss 0.117791 | norm 0.5850 | lr 2.54e-05 | (115.37 ms | 35504 tok/s)\n",
      "step 1280/5000 | train loss 0.117581 | norm 0.5637 | lr 2.54e-05 | (113.45 ms | 36105 tok/s)\n",
      "step 1281/5000 | train loss 0.117491 | norm 0.6099 | lr 2.54e-05 | (114.12 ms | 35893 tok/s)\n",
      "step 1282/5000 | train loss 0.117187 | norm 0.5047 | lr 2.54e-05 | (114.01 ms | 35928 tok/s)\n",
      "step 1283/5000 | train loss 0.117153 | norm 0.6667 | lr 2.54e-05 | (115.04 ms | 35606 tok/s)\n",
      "step 1284/5000 | train loss 0.116888 | norm 0.5394 | lr 2.54e-05 | (120.56 ms | 33974 tok/s)\n",
      "step 1285/5000 | train loss 0.116719 | norm 0.5294 | lr 2.54e-05 | (120.84 ms | 33897 tok/s)\n",
      "step 1286/5000 | train loss 0.116475 | norm 0.4832 | lr 2.54e-05 | (115.64 ms | 35420 tok/s)\n",
      "step 1287/5000 | train loss 0.116270 | norm 0.4500 | lr 2.54e-05 | (115.59 ms | 35434 tok/s)\n",
      "step 1288/5000 | train loss 0.116138 | norm 0.4814 | lr 2.54e-05 | (112.91 ms | 36277 tok/s)\n",
      "step 1289/5000 | train loss 0.115954 | norm 0.4641 | lr 2.54e-05 | (122.94 ms | 33318 tok/s)\n",
      "step 1290/5000 | train loss 0.115759 | norm 0.4860 | lr 2.53e-05 | (119.52 ms | 34269 tok/s)\n",
      "step 1291/5000 | train loss 0.115596 | norm 0.4916 | lr 2.53e-05 | (116.16 ms | 35263 tok/s)\n",
      "step 1292/5000 | train loss 0.115429 | norm 0.5170 | lr 2.53e-05 | (113.62 ms | 36051 tok/s)\n",
      "step 1293/5000 | train loss 0.115273 | norm 0.5208 | lr 2.53e-05 | (115.98 ms | 35315 tok/s)\n",
      "step 1294/5000 | train loss 0.115082 | norm 0.5292 | lr 2.53e-05 | (113.22 ms | 36177 tok/s)\n",
      "step 1295/5000 | train loss 0.114991 | norm 0.6329 | lr 2.53e-05 | (114.49 ms | 35777 tok/s)\n",
      "step 1296/5000 | train loss 0.114841 | norm 0.6366 | lr 2.53e-05 | (113.65 ms | 36039 tok/s)\n",
      "step 1297/5000 | train loss 0.114605 | norm 0.5803 | lr 2.53e-05 | (115.32 ms | 35519 tok/s)\n",
      "step 1298/5000 | train loss 0.114428 | norm 0.5590 | lr 2.53e-05 | (113.28 ms | 36159 tok/s)\n",
      "step 1299/5000 | train loss 0.114365 | norm 0.6721 | lr 2.53e-05 | (114.88 ms | 35656 tok/s)\n",
      "step 1300/5000 | train loss 0.114182 | norm 0.6302 | lr 2.53e-05 | (113.85 ms | 35977 tok/s)\n",
      "step 1301/5000 | train loss 0.113923 | norm 0.5231 | lr 2.53e-05 | (114.18 ms | 35874 tok/s)\n",
      "step 1302/5000 | train loss 0.113742 | norm 0.5508 | lr 2.53e-05 | (113.39 ms | 36124 tok/s)\n",
      "step 1303/5000 | train loss 0.113657 | norm 0.6202 | lr 2.53e-05 | (114.53 ms | 35762 tok/s)\n",
      "step 1304/5000 | train loss 0.113372 | norm 0.4876 | lr 2.52e-05 | (113.96 ms | 35942 tok/s)\n",
      "step 1305/5000 | train loss 0.113168 | norm 0.4310 | lr 2.52e-05 | (117.45 ms | 34875 tok/s)\n",
      "step 1306/5000 | train loss 0.113067 | norm 0.5333 | lr 2.52e-05 | (115.02 ms | 35612 tok/s)\n",
      "step 1307/5000 | train loss 0.112884 | norm 0.4938 | lr 2.52e-05 | (116.21 ms | 35247 tok/s)\n",
      "step 1308/5000 | train loss 0.112673 | norm 0.4374 | lr 2.52e-05 | (114.22 ms | 35861 tok/s)\n",
      "step 1309/5000 | train loss 0.112580 | norm 0.5354 | lr 2.52e-05 | (115.17 ms | 35564 tok/s)\n",
      "step 1310/5000 | train loss 0.112423 | norm 0.5200 | lr 2.52e-05 | (114.65 ms | 35725 tok/s)\n",
      "step 1311/5000 | train loss 0.112150 | norm 0.4039 | lr 2.52e-05 | (115.24 ms | 35544 tok/s)\n",
      "step 1312/5000 | train loss 0.112086 | norm 0.4906 | lr 2.52e-05 | (113.94 ms | 35947 tok/s)\n",
      "step 1313/5000 | train loss 0.111846 | norm 0.4243 | lr 2.52e-05 | (113.06 ms | 36229 tok/s)\n",
      "step 1314/5000 | train loss 0.111650 | norm 0.3458 | lr 2.52e-05 | (113.99 ms | 35933 tok/s)\n",
      "step 1315/5000 | train loss 0.111499 | norm 0.3912 | lr 2.52e-05 | (115.93 ms | 35333 tok/s)\n",
      "step 1316/5000 | train loss 0.111356 | norm 0.4291 | lr 2.52e-05 | (113.26 ms | 36165 tok/s)\n",
      "step 1317/5000 | train loss 0.111199 | norm 0.4569 | lr 2.52e-05 | (115.01 ms | 35615 tok/s)\n",
      "step 1318/5000 | train loss 0.111153 | norm 0.5787 | lr 2.52e-05 | (113.09 ms | 36217 tok/s)\n",
      "step 1319/5000 | train loss 0.111007 | norm 0.6267 | lr 2.51e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 1320/5000 | train loss 0.110880 | norm 0.6368 | lr 2.51e-05 | (112.89 ms | 36282 tok/s)\n",
      "step 1321/5000 | train loss 0.110710 | norm 0.6095 | lr 2.51e-05 | (114.11 ms | 35897 tok/s)\n",
      "step 1322/5000 | train loss 0.110465 | norm 0.5250 | lr 2.51e-05 | (113.44 ms | 36108 tok/s)\n",
      "step 1323/5000 | train loss 0.110330 | norm 0.5417 | lr 2.51e-05 | (114.09 ms | 35903 tok/s)\n",
      "step 1324/5000 | train loss 0.110229 | norm 0.6294 | lr 2.51e-05 | (113.63 ms | 36047 tok/s)\n",
      "step 1325/5000 | train loss 0.110076 | norm 0.5748 | lr 2.51e-05 | (115.82 ms | 35367 tok/s)\n",
      "step 1326/5000 | train loss 0.109786 | norm 0.4459 | lr 2.51e-05 | (113.90 ms | 35962 tok/s)\n",
      "step 1327/5000 | train loss 0.109801 | norm 0.6628 | lr 2.51e-05 | (115.04 ms | 35604 tok/s)\n",
      "step 1328/5000 | train loss 0.109643 | norm 0.6196 | lr 2.51e-05 | (113.59 ms | 36059 tok/s)\n",
      "step 1329/5000 | train loss 0.109393 | norm 0.5057 | lr 2.51e-05 | (113.77 ms | 36004 tok/s)\n",
      "step 1330/5000 | train loss 0.109328 | norm 0.6469 | lr 2.51e-05 | (113.18 ms | 36190 tok/s)\n",
      "step 1331/5000 | train loss 0.109159 | norm 0.6103 | lr 2.51e-05 | (113.78 ms | 36000 tok/s)\n",
      "step 1332/5000 | train loss 0.109022 | norm 0.5993 | lr 2.51e-05 | (113.38 ms | 36126 tok/s)\n",
      "step 1333/5000 | train loss 0.108836 | norm 0.5795 | lr 2.50e-05 | (113.78 ms | 35998 tok/s)\n",
      "step 1334/5000 | train loss 0.108661 | norm 0.5539 | lr 2.50e-05 | (113.51 ms | 36084 tok/s)\n",
      "step 1335/5000 | train loss 0.108499 | norm 0.5058 | lr 2.50e-05 | (114.48 ms | 35780 tok/s)\n",
      "step 1336/5000 | train loss 0.108248 | norm 0.4090 | lr 2.50e-05 | (113.69 ms | 36027 tok/s)\n",
      "step 1337/5000 | train loss 0.108216 | norm 0.5209 | lr 2.50e-05 | (113.37 ms | 36130 tok/s)\n",
      "step 1338/5000 | train loss 0.107962 | norm 0.4129 | lr 2.50e-05 | (113.31 ms | 36149 tok/s)\n",
      "step 1339/5000 | train loss 0.107834 | norm 0.4251 | lr 2.50e-05 | (115.82 ms | 35364 tok/s)\n",
      "step 1340/5000 | train loss 0.107656 | norm 0.4013 | lr 2.50e-05 | (113.14 ms | 36203 tok/s)\n",
      "step 1341/5000 | train loss 0.107493 | norm 0.3645 | lr 2.50e-05 | (113.86 ms | 35974 tok/s)\n",
      "step 1342/5000 | train loss 0.107349 | norm 0.3805 | lr 2.50e-05 | (113.22 ms | 36179 tok/s)\n",
      "step 1343/5000 | train loss 0.107215 | norm 0.3982 | lr 2.50e-05 | (114.16 ms | 35879 tok/s)\n",
      "step 1344/5000 | train loss 0.107051 | norm 0.3951 | lr 2.50e-05 | (112.82 ms | 36306 tok/s)\n",
      "step 1345/5000 | train loss 0.106898 | norm 0.3751 | lr 2.50e-05 | (113.30 ms | 36152 tok/s)\n",
      "step 1346/5000 | train loss 0.106762 | norm 0.3999 | lr 2.50e-05 | (112.72 ms | 36339 tok/s)\n",
      "step 1347/5000 | train loss 0.106631 | norm 0.4255 | lr 2.49e-05 | (113.69 ms | 36027 tok/s)\n",
      "step 1348/5000 | train loss 0.106542 | norm 0.5092 | lr 2.49e-05 | (112.58 ms | 36385 tok/s)\n",
      "step 1349/5000 | train loss 0.106479 | norm 0.5950 | lr 2.49e-05 | (114.26 ms | 35850 tok/s)\n",
      "step 1350/5000 | train loss 0.106347 | norm 0.6310 | lr 2.49e-05 | (112.89 ms | 36282 tok/s)\n",
      "step 1351/5000 | train loss 0.106220 | norm 0.6288 | lr 2.49e-05 | (112.79 ms | 36314 tok/s)\n",
      "step 1352/5000 | train loss 0.106085 | norm 0.6585 | lr 2.49e-05 | (111.98 ms | 36578 tok/s)\n",
      "step 1353/5000 | train loss 0.106049 | norm 0.7210 | lr 2.49e-05 | (115.30 ms | 35524 tok/s)\n",
      "step 1354/5000 | train loss 0.105814 | norm 0.6406 | lr 2.49e-05 | (113.80 ms | 35994 tok/s)\n",
      "step 1355/5000 | train loss 0.105640 | norm 0.6123 | lr 2.49e-05 | (114.98 ms | 35622 tok/s)\n",
      "step 1356/5000 | train loss 0.105689 | norm 0.7466 | lr 2.49e-05 | (113.33 ms | 36142 tok/s)\n",
      "step 1357/5000 | train loss 0.105320 | norm 0.5446 | lr 2.49e-05 | (114.27 ms | 35846 tok/s)\n",
      "step 1358/5000 | train loss 0.105261 | norm 0.6094 | lr 2.49e-05 | (113.15 ms | 36199 tok/s)\n",
      "step 1359/5000 | train loss 0.105132 | norm 0.6295 | lr 2.49e-05 | (114.73 ms | 35702 tok/s)\n",
      "step 1360/5000 | train loss 0.104860 | norm 0.4456 | lr 2.49e-05 | (113.03 ms | 36237 tok/s)\n",
      "step 1361/5000 | train loss 0.104839 | norm 0.6148 | lr 2.48e-05 | (113.97 ms | 35939 tok/s)\n",
      "step 1362/5000 | train loss 0.104637 | norm 0.5221 | lr 2.48e-05 | (112.66 ms | 36356 tok/s)\n",
      "step 1363/5000 | train loss 0.104428 | norm 0.4340 | lr 2.48e-05 | (114.81 ms | 35678 tok/s)\n",
      "step 1364/5000 | train loss 0.104334 | norm 0.4628 | lr 2.48e-05 | (112.80 ms | 36311 tok/s)\n",
      "step 1365/5000 | train loss 0.104108 | norm 0.3649 | lr 2.48e-05 | (114.55 ms | 35756 tok/s)\n",
      "step 1366/5000 | train loss 0.104069 | norm 0.4830 | lr 2.48e-05 | (111.94 ms | 36590 tok/s)\n",
      "step 1367/5000 | train loss 0.103826 | norm 0.3394 | lr 2.48e-05 | (114.83 ms | 35670 tok/s)\n",
      "step 1368/5000 | train loss 0.103735 | norm 0.4103 | lr 2.48e-05 | (114.38 ms | 35809 tok/s)\n",
      "step 1369/5000 | train loss 0.103596 | norm 0.4062 | lr 2.48e-05 | (113.93 ms | 35950 tok/s)\n",
      "step 1370/5000 | train loss 0.103428 | norm 0.3848 | lr 2.48e-05 | (113.49 ms | 36092 tok/s)\n",
      "step 1371/5000 | train loss 0.103341 | norm 0.4227 | lr 2.48e-05 | (114.85 ms | 35663 tok/s)\n",
      "step 1372/5000 | train loss 0.103190 | norm 0.4264 | lr 2.48e-05 | (113.38 ms | 36128 tok/s)\n",
      "step 1373/5000 | train loss 0.103115 | norm 0.4958 | lr 2.48e-05 | (114.15 ms | 35881 tok/s)\n",
      "step 1374/5000 | train loss 0.102970 | norm 0.4882 | lr 2.48e-05 | (113.22 ms | 36176 tok/s)\n",
      "step 1375/5000 | train loss 0.102855 | norm 0.5039 | lr 2.47e-05 | (113.61 ms | 36054 tok/s)\n",
      "step 1376/5000 | train loss 0.102709 | norm 0.4932 | lr 2.47e-05 | (113.34 ms | 36137 tok/s)\n",
      "step 1377/5000 | train loss 0.102581 | norm 0.4964 | lr 2.47e-05 | (114.36 ms | 35816 tok/s)\n",
      "step 1378/5000 | train loss 0.102512 | norm 0.5671 | lr 2.47e-05 | (113.53 ms | 36079 tok/s)\n",
      "step 1379/5000 | train loss 0.102379 | norm 0.5780 | lr 2.47e-05 | (114.87 ms | 35658 tok/s)\n",
      "step 1380/5000 | train loss 0.102222 | norm 0.5171 | lr 2.47e-05 | (113.83 ms | 35984 tok/s)\n",
      "step 1381/5000 | train loss 0.101994 | norm 0.3879 | lr 2.47e-05 | (114.57 ms | 35752 tok/s)\n",
      "step 1382/5000 | train loss 0.101918 | norm 0.4693 | lr 2.47e-05 | (112.81 ms | 36307 tok/s)\n",
      "step 1383/5000 | train loss 0.101813 | norm 0.4884 | lr 2.47e-05 | (113.73 ms | 36015 tok/s)\n",
      "step 1384/5000 | train loss 0.101614 | norm 0.3675 | lr 2.47e-05 | (113.05 ms | 36233 tok/s)\n",
      "step 1385/5000 | train loss 0.101442 | norm 0.3142 | lr 2.47e-05 | (114.99 ms | 35620 tok/s)\n",
      "step 1386/5000 | train loss 0.101394 | norm 0.4410 | lr 2.47e-05 | (113.64 ms | 36043 tok/s)\n",
      "step 1387/5000 | train loss 0.101274 | norm 0.4506 | lr 2.47e-05 | (114.51 ms | 35771 tok/s)\n",
      "step 1388/5000 | train loss 0.101101 | norm 0.3892 | lr 2.47e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 1389/5000 | train loss 0.101023 | norm 0.4663 | lr 2.46e-05 | (113.69 ms | 36027 tok/s)\n",
      "step 1390/5000 | train loss 0.101012 | norm 0.5757 | lr 2.46e-05 | (113.56 ms | 36069 tok/s)\n",
      "step 1391/5000 | train loss 0.100881 | norm 0.5925 | lr 2.46e-05 | (114.72 ms | 35705 tok/s)\n",
      "step 1392/5000 | train loss 0.100732 | norm 0.5392 | lr 2.46e-05 | (113.31 ms | 36149 tok/s)\n",
      "step 1393/5000 | train loss 0.100529 | norm 0.4530 | lr 2.46e-05 | (114.34 ms | 35824 tok/s)\n",
      "step 1394/5000 | train loss 0.100413 | norm 0.4594 | lr 2.46e-05 | (113.17 ms | 36192 tok/s)\n",
      "step 1395/5000 | train loss 0.100348 | norm 0.5177 | lr 2.46e-05 | (114.27 ms | 35845 tok/s)\n",
      "step 1396/5000 | train loss 0.100183 | norm 0.4738 | lr 2.46e-05 | (115.43 ms | 35483 tok/s)\n",
      "step 1397/5000 | train loss 0.100022 | norm 0.4085 | lr 2.46e-05 | (115.12 ms | 35581 tok/s)\n",
      "step 1398/5000 | train loss 0.099914 | norm 0.4393 | lr 2.46e-05 | (114.14 ms | 35886 tok/s)\n",
      "step 1399/5000 | train loss 0.099806 | norm 0.4611 | lr 2.46e-05 | (115.57 ms | 35443 tok/s)\n",
      "step 1400/5000 | train loss 0.099626 | norm 0.3788 | lr 2.46e-05 | (113.68 ms | 36030 tok/s)\n",
      "step 1401/5000 | train loss 0.099527 | norm 0.4075 | lr 2.46e-05 | (113.64 ms | 36045 tok/s)\n",
      "step 1402/5000 | train loss 0.099419 | norm 0.4269 | lr 2.46e-05 | (113.12 ms | 36209 tok/s)\n",
      "step 1403/5000 | train loss 0.099288 | norm 0.4138 | lr 2.45e-05 | (114.60 ms | 35741 tok/s)\n",
      "step 1404/5000 | train loss 0.099183 | norm 0.4504 | lr 2.45e-05 | (113.03 ms | 36238 tok/s)\n",
      "step 1405/5000 | train loss 0.099227 | norm 0.6328 | lr 2.45e-05 | (114.19 ms | 35869 tok/s)\n",
      "step 1406/5000 | train loss 0.099172 | norm 0.6725 | lr 2.45e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 1407/5000 | train loss 0.098890 | norm 0.5091 | lr 2.45e-05 | (115.78 ms | 35379 tok/s)\n",
      "step 1408/5000 | train loss 0.098764 | norm 0.4795 | lr 2.45e-05 | (114.30 ms | 35836 tok/s)\n",
      "step 1409/5000 | train loss 0.098679 | norm 0.5057 | lr 2.45e-05 | (114.45 ms | 35789 tok/s)\n",
      "step 1410/5000 | train loss 0.098492 | norm 0.4464 | lr 2.45e-05 | (113.65 ms | 36041 tok/s)\n",
      "step 1411/5000 | train loss 0.098390 | norm 0.4281 | lr 2.45e-05 | (114.22 ms | 35859 tok/s)\n",
      "step 1412/5000 | train loss 0.098236 | norm 0.3853 | lr 2.45e-05 | (114.06 ms | 35911 tok/s)\n",
      "step 1413/5000 | train loss 0.098117 | norm 0.3936 | lr 2.45e-05 | (113.81 ms | 35990 tok/s)\n",
      "step 1414/5000 | train loss 0.098018 | norm 0.4096 | lr 2.45e-05 | (113.08 ms | 36222 tok/s)\n",
      "step 1415/5000 | train loss 0.097871 | norm 0.3639 | lr 2.45e-05 | (115.18 ms | 35562 tok/s)\n",
      "step 1416/5000 | train loss 0.097742 | norm 0.3432 | lr 2.45e-05 | (114.19 ms | 35870 tok/s)\n",
      "step 1417/5000 | train loss 0.097678 | norm 0.4171 | lr 2.44e-05 | (115.52 ms | 35457 tok/s)\n",
      "step 1418/5000 | train loss 0.097558 | norm 0.4233 | lr 2.44e-05 | (113.33 ms | 36141 tok/s)\n",
      "step 1419/5000 | train loss 0.097453 | norm 0.4291 | lr 2.44e-05 | (114.87 ms | 35658 tok/s)\n",
      "step 1420/5000 | train loss 0.097317 | norm 0.4143 | lr 2.44e-05 | (113.11 ms | 36213 tok/s)\n",
      "step 1421/5000 | train loss 0.097202 | norm 0.3852 | lr 2.44e-05 | (114.17 ms | 35878 tok/s)\n",
      "step 1422/5000 | train loss 0.097066 | norm 0.3714 | lr 2.44e-05 | (113.23 ms | 36174 tok/s)\n",
      "step 1423/5000 | train loss 0.096987 | norm 0.4137 | lr 2.44e-05 | (114.42 ms | 35797 tok/s)\n",
      "step 1424/5000 | train loss 0.096899 | norm 0.4385 | lr 2.44e-05 | (113.28 ms | 36159 tok/s)\n",
      "step 1425/5000 | train loss 0.096810 | norm 0.4647 | lr 2.44e-05 | (113.24 ms | 36171 tok/s)\n",
      "step 1426/5000 | train loss 0.096710 | norm 0.4976 | lr 2.44e-05 | (113.40 ms | 36120 tok/s)\n",
      "step 1427/5000 | train loss 0.096632 | norm 0.5304 | lr 2.44e-05 | (114.50 ms | 35774 tok/s)\n",
      "step 1428/5000 | train loss 0.096471 | norm 0.4751 | lr 2.44e-05 | (113.58 ms | 36061 tok/s)\n",
      "step 1429/5000 | train loss 0.096345 | norm 0.4299 | lr 2.44e-05 | (114.73 ms | 35702 tok/s)\n",
      "step 1430/5000 | train loss 0.096281 | norm 0.4917 | lr 2.43e-05 | (113.54 ms | 36076 tok/s)\n",
      "step 1431/5000 | train loss 0.096157 | norm 0.4745 | lr 2.43e-05 | (115.18 ms | 35561 tok/s)\n",
      "step 1432/5000 | train loss 0.096000 | norm 0.4044 | lr 2.43e-05 | (113.04 ms | 36236 tok/s)\n",
      "step 1433/5000 | train loss 0.095896 | norm 0.4152 | lr 2.43e-05 | (116.28 ms | 35225 tok/s)\n",
      "step 1434/5000 | train loss 0.095798 | norm 0.4382 | lr 2.43e-05 | (113.90 ms | 35963 tok/s)\n",
      "step 1435/5000 | train loss 0.095726 | norm 0.4782 | lr 2.43e-05 | (115.73 ms | 35392 tok/s)\n",
      "step 1436/5000 | train loss 0.095632 | norm 0.4740 | lr 2.43e-05 | (113.61 ms | 36055 tok/s)\n",
      "step 1437/5000 | train loss 0.095462 | norm 0.4196 | lr 2.43e-05 | (114.75 ms | 35694 tok/s)\n",
      "step 1438/5000 | train loss 0.095417 | norm 0.4780 | lr 2.43e-05 | (113.59 ms | 36059 tok/s)\n",
      "step 1439/5000 | train loss 0.095371 | norm 0.5508 | lr 2.43e-05 | (113.51 ms | 36084 tok/s)\n",
      "step 1440/5000 | train loss 0.095263 | norm 0.5246 | lr 2.43e-05 | (114.05 ms | 35914 tok/s)\n",
      "step 1441/5000 | train loss 0.095171 | norm 0.5314 | lr 2.43e-05 | (118.10 ms | 34683 tok/s)\n",
      "step 1442/5000 | train loss 0.095013 | norm 0.4968 | lr 2.43e-05 | (115.12 ms | 35579 tok/s)\n",
      "step 1443/5000 | train loss 0.094909 | norm 0.4783 | lr 2.43e-05 | (116.28 ms | 35227 tok/s)\n",
      "step 1444/5000 | train loss 0.094753 | norm 0.4286 | lr 2.42e-05 | (114.20 ms | 35868 tok/s)\n",
      "step 1445/5000 | train loss 0.094709 | norm 0.4716 | lr 2.42e-05 | (114.92 ms | 35643 tok/s)\n",
      "step 1446/5000 | train loss 0.094531 | norm 0.3983 | lr 2.42e-05 | (114.12 ms | 35891 tok/s)\n",
      "step 1447/5000 | train loss 0.094442 | norm 0.3921 | lr 2.42e-05 | (115.80 ms | 35371 tok/s)\n",
      "step 1448/5000 | train loss 0.094307 | norm 0.3714 | lr 2.42e-05 | (112.97 ms | 36256 tok/s)\n",
      "step 1449/5000 | train loss 0.094194 | norm 0.3509 | lr 2.42e-05 | (116.01 ms | 35306 tok/s)\n",
      "step 1450/5000 | train loss 0.094090 | norm 0.3377 | lr 2.42e-05 | (114.11 ms | 35895 tok/s)\n",
      "step 1451/5000 | train loss 0.093967 | norm 0.3090 | lr 2.42e-05 | (115.25 ms | 35541 tok/s)\n",
      "step 1452/5000 | train loss 0.093854 | norm 0.2916 | lr 2.42e-05 | (114.00 ms | 35931 tok/s)\n",
      "step 1453/5000 | train loss 0.093774 | norm 0.3395 | lr 2.42e-05 | (114.29 ms | 35838 tok/s)\n",
      "step 1454/5000 | train loss 0.093688 | norm 0.3602 | lr 2.42e-05 | (112.99 ms | 36251 tok/s)\n",
      "step 1455/5000 | train loss 0.093614 | norm 0.4223 | lr 2.42e-05 | (114.92 ms | 35641 tok/s)\n",
      "step 1456/5000 | train loss 0.093647 | norm 0.5444 | lr 2.42e-05 | (113.39 ms | 36122 tok/s)\n",
      "step 1457/5000 | train loss 0.093523 | norm 0.5450 | lr 2.41e-05 | (115.57 ms | 35441 tok/s)\n",
      "step 1458/5000 | train loss 0.093401 | norm 0.5191 | lr 2.41e-05 | (112.88 ms | 36288 tok/s)\n",
      "step 1459/5000 | train loss 0.093299 | norm 0.5227 | lr 2.41e-05 | (114.35 ms | 35821 tok/s)\n",
      "step 1460/5000 | train loss 0.093194 | norm 0.5102 | lr 2.41e-05 | (113.70 ms | 36026 tok/s)\n",
      "step 1461/5000 | train loss 0.093087 | norm 0.4891 | lr 2.41e-05 | (114.25 ms | 35851 tok/s)\n",
      "step 1462/5000 | train loss 0.092974 | norm 0.4779 | lr 2.41e-05 | (113.31 ms | 36150 tok/s)\n",
      "step 1463/5000 | train loss 0.092924 | norm 0.5155 | lr 2.41e-05 | (116.20 ms | 35250 tok/s)\n",
      "step 1464/5000 | train loss 0.092780 | norm 0.4725 | lr 2.41e-05 | (114.36 ms | 35818 tok/s)\n",
      "step 1465/5000 | train loss 0.092682 | norm 0.4544 | lr 2.41e-05 | (114.46 ms | 35784 tok/s)\n",
      "step 1466/5000 | train loss 0.092544 | norm 0.3963 | lr 2.41e-05 | (114.04 ms | 35919 tok/s)\n",
      "step 1467/5000 | train loss 0.092417 | norm 0.3662 | lr 2.41e-05 | (115.77 ms | 35381 tok/s)\n",
      "step 1468/5000 | train loss 0.092363 | norm 0.4008 | lr 2.41e-05 | (114.64 ms | 35731 tok/s)\n",
      "step 1469/5000 | train loss 0.092212 | norm 0.3444 | lr 2.41e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 1470/5000 | train loss 0.092152 | norm 0.3839 | lr 2.41e-05 | (114.64 ms | 35729 tok/s)\n",
      "step 1471/5000 | train loss 0.092048 | norm 0.3981 | lr 2.40e-05 | (115.52 ms | 35456 tok/s)\n",
      "step 1472/5000 | train loss 0.092024 | norm 0.4760 | lr 2.40e-05 | (113.72 ms | 36019 tok/s)\n",
      "step 1473/5000 | train loss 0.091993 | norm 0.5412 | lr 2.40e-05 | (114.30 ms | 35834 tok/s)\n",
      "step 1474/5000 | train loss 0.091866 | norm 0.5278 | lr 2.40e-05 | (115.21 ms | 35554 tok/s)\n",
      "step 1475/5000 | train loss 0.091750 | norm 0.4685 | lr 2.40e-05 | (115.11 ms | 35583 tok/s)\n",
      "step 1476/5000 | train loss 0.091614 | norm 0.4224 | lr 2.40e-05 | (114.64 ms | 35730 tok/s)\n",
      "step 1477/5000 | train loss 0.091563 | norm 0.4606 | lr 2.40e-05 | (114.74 ms | 35697 tok/s)\n",
      "step 1478/5000 | train loss 0.091429 | norm 0.4341 | lr 2.40e-05 | (113.27 ms | 36160 tok/s)\n",
      "step 1479/5000 | train loss 0.091353 | norm 0.4418 | lr 2.40e-05 | (116.58 ms | 35135 tok/s)\n",
      "step 1480/5000 | train loss 0.091252 | norm 0.4337 | lr 2.40e-05 | (114.07 ms | 35907 tok/s)\n",
      "step 1481/5000 | train loss 0.091145 | norm 0.3991 | lr 2.40e-05 | (115.85 ms | 35355 tok/s)\n",
      "step 1482/5000 | train loss 0.091024 | norm 0.3594 | lr 2.40e-05 | (114.37 ms | 35814 tok/s)\n",
      "step 1483/5000 | train loss 0.090940 | norm 0.3745 | lr 2.40e-05 | (113.79 ms | 35996 tok/s)\n",
      "step 1484/5000 | train loss 0.090865 | norm 0.3797 | lr 2.39e-05 | (112.90 ms | 36281 tok/s)\n",
      "step 1485/5000 | train loss 0.090734 | norm 0.3473 | lr 2.39e-05 | (115.63 ms | 35424 tok/s)\n",
      "step 1486/5000 | train loss 0.090681 | norm 0.3613 | lr 2.39e-05 | (115.32 ms | 35519 tok/s)\n",
      "step 1487/5000 | train loss 0.090518 | norm 0.2972 | lr 2.39e-05 | (115.55 ms | 35447 tok/s)\n",
      "step 1488/5000 | train loss 0.090509 | norm 0.3881 | lr 2.39e-05 | (113.41 ms | 36116 tok/s)\n",
      "step 1489/5000 | train loss 0.090398 | norm 0.3959 | lr 2.39e-05 | (114.92 ms | 35642 tok/s)\n",
      "step 1490/5000 | train loss 0.090334 | norm 0.4131 | lr 2.39e-05 | (114.01 ms | 35926 tok/s)\n",
      "step 1491/5000 | train loss 0.090232 | norm 0.4131 | lr 2.39e-05 | (113.22 ms | 36176 tok/s)\n",
      "step 1492/5000 | train loss 0.090154 | norm 0.4123 | lr 2.39e-05 | (113.23 ms | 36174 tok/s)\n",
      "step 1493/5000 | train loss 0.090081 | norm 0.4324 | lr 2.39e-05 | (113.74 ms | 36011 tok/s)\n",
      "step 1494/5000 | train loss 0.089989 | norm 0.4438 | lr 2.39e-05 | (113.06 ms | 36229 tok/s)\n",
      "step 1495/5000 | train loss 0.089937 | norm 0.4579 | lr 2.39e-05 | (115.74 ms | 35391 tok/s)\n",
      "step 1496/5000 | train loss 0.089834 | norm 0.4555 | lr 2.39e-05 | (113.84 ms | 35982 tok/s)\n",
      "step 1497/5000 | train loss 0.089767 | norm 0.4542 | lr 2.38e-05 | (113.10 ms | 36216 tok/s)\n",
      "step 1498/5000 | train loss 0.089622 | norm 0.3967 | lr 2.38e-05 | (113.04 ms | 36235 tok/s)\n",
      "step 1499/5000 | train loss 0.089582 | norm 0.4475 | lr 2.38e-05 | (114.27 ms | 35846 tok/s)\n",
      "step 1500/5000 | train loss 0.089519 | norm 0.4935 | lr 2.38e-05 | (112.53 ms | 36398 tok/s)\n",
      "step 1501/5000 | train loss 0.089439 | norm 0.4834 | lr 2.38e-05 | (115.13 ms | 35576 tok/s)\n",
      "step 1502/5000 | train loss 0.089237 | norm 0.3254 | lr 2.38e-05 | (113.35 ms | 36135 tok/s)\n",
      "step 1503/5000 | train loss 0.089172 | norm 0.3594 | lr 2.38e-05 | (115.76 ms | 35383 tok/s)\n",
      "step 1504/5000 | train loss 0.089156 | norm 0.4488 | lr 2.38e-05 | (113.55 ms | 36071 tok/s)\n",
      "step 1505/5000 | train loss 0.089035 | norm 0.4148 | lr 2.38e-05 | (114.32 ms | 35831 tok/s)\n",
      "step 1506/5000 | train loss 0.088955 | norm 0.4124 | lr 2.38e-05 | (113.74 ms | 36013 tok/s)\n",
      "step 1507/5000 | train loss 0.088946 | norm 0.4948 | lr 2.38e-05 | (113.72 ms | 36017 tok/s)\n",
      "step 1508/5000 | train loss 0.088781 | norm 0.4136 | lr 2.38e-05 | (112.98 ms | 36255 tok/s)\n",
      "step 1509/5000 | train loss 0.088676 | norm 0.3634 | lr 2.38e-05 | (113.47 ms | 36097 tok/s)\n",
      "step 1510/5000 | train loss 0.088608 | norm 0.4033 | lr 2.37e-05 | (113.72 ms | 36018 tok/s)\n",
      "step 1511/5000 | train loss 0.088535 | norm 0.3922 | lr 2.37e-05 | (115.18 ms | 35561 tok/s)\n",
      "step 1512/5000 | train loss 0.088394 | norm 0.3128 | lr 2.37e-05 | (113.82 ms | 35986 tok/s)\n",
      "step 1513/5000 | train loss 0.088326 | norm 0.3204 | lr 2.37e-05 | (113.82 ms | 35986 tok/s)\n",
      "step 1514/5000 | train loss 0.088261 | norm 0.3586 | lr 2.37e-05 | (112.41 ms | 36438 tok/s)\n",
      "step 1515/5000 | train loss 0.088176 | norm 0.3483 | lr 2.37e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 1516/5000 | train loss 0.088078 | norm 0.3458 | lr 2.37e-05 | (113.19 ms | 36186 tok/s)\n",
      "step 1517/5000 | train loss 0.088047 | norm 0.4106 | lr 2.37e-05 | (115.20 ms | 35557 tok/s)\n",
      "step 1518/5000 | train loss 0.087948 | norm 0.4079 | lr 2.37e-05 | (113.37 ms | 36131 tok/s)\n",
      "step 1519/5000 | train loss 0.087884 | norm 0.4187 | lr 2.37e-05 | (115.03 ms | 35609 tok/s)\n",
      "step 1520/5000 | train loss 0.087809 | norm 0.4163 | lr 2.37e-05 | (114.03 ms | 35919 tok/s)\n",
      "step 1521/5000 | train loss 0.087680 | norm 0.3632 | lr 2.37e-05 | (115.65 ms | 35418 tok/s)\n",
      "step 1522/5000 | train loss 0.087633 | norm 0.3899 | lr 2.37e-05 | (113.87 ms | 35971 tok/s)\n",
      "step 1523/5000 | train loss 0.087579 | norm 0.4378 | lr 2.36e-05 | (115.83 ms | 35362 tok/s)\n",
      "step 1524/5000 | train loss 0.087569 | norm 0.5201 | lr 2.36e-05 | (127.77 ms | 32058 tok/s)\n",
      "step 1525/5000 | train loss 0.087530 | norm 0.5526 | lr 2.36e-05 | (114.62 ms | 35737 tok/s)\n",
      "step 1526/5000 | train loss 0.087348 | norm 0.4614 | lr 2.36e-05 | (114.04 ms | 35917 tok/s)\n",
      "step 1527/5000 | train loss 0.087321 | norm 0.4822 | lr 2.36e-05 | (115.40 ms | 35494 tok/s)\n",
      "step 1528/5000 | train loss 0.087216 | norm 0.4915 | lr 2.36e-05 | (114.50 ms | 35774 tok/s)\n",
      "step 1529/5000 | train loss 0.087120 | norm 0.4653 | lr 2.36e-05 | (114.14 ms | 35886 tok/s)\n",
      "step 1530/5000 | train loss 0.087039 | norm 0.4447 | lr 2.36e-05 | (117.04 ms | 34996 tok/s)\n",
      "step 1531/5000 | train loss 0.086948 | norm 0.4114 | lr 2.36e-05 | (118.26 ms | 34635 tok/s)\n",
      "step 1532/5000 | train loss 0.086831 | norm 0.3596 | lr 2.36e-05 | (114.36 ms | 35815 tok/s)\n",
      "step 1533/5000 | train loss 0.086753 | norm 0.3527 | lr 2.36e-05 | (114.96 ms | 35630 tok/s)\n",
      "step 1534/5000 | train loss 0.086671 | norm 0.3445 | lr 2.36e-05 | (113.64 ms | 36045 tok/s)\n",
      "step 1535/5000 | train loss 0.086574 | norm 0.3110 | lr 2.36e-05 | (113.67 ms | 36033 tok/s)\n",
      "step 1536/5000 | train loss 0.086509 | norm 0.3234 | lr 2.35e-05 | (114.05 ms | 35915 tok/s)\n",
      "step 1537/5000 | train loss 0.086415 | norm 0.3064 | lr 2.35e-05 | (115.16 ms | 35569 tok/s)\n",
      "step 1538/5000 | train loss 0.086333 | norm 0.2941 | lr 2.35e-05 | (113.20 ms | 36184 tok/s)\n",
      "step 1539/5000 | train loss 0.086262 | norm 0.2935 | lr 2.35e-05 | (117.09 ms | 34983 tok/s)\n",
      "step 1540/5000 | train loss 0.086154 | norm 0.2601 | lr 2.35e-05 | (114.73 ms | 35701 tok/s)\n",
      "step 1541/5000 | train loss 0.086119 | norm 0.3152 | lr 2.35e-05 | (114.84 ms | 35668 tok/s)\n",
      "step 1542/5000 | train loss 0.086050 | norm 0.3587 | lr 2.35e-05 | (112.85 ms | 36295 tok/s)\n",
      "step 1543/5000 | train loss 0.086068 | norm 0.4837 | lr 2.35e-05 | (114.37 ms | 35813 tok/s)\n",
      "step 1544/5000 | train loss 0.086077 | norm 0.5710 | lr 2.35e-05 | (114.59 ms | 35745 tok/s)\n",
      "step 1545/5000 | train loss 0.086013 | norm 0.5834 | lr 2.35e-05 | (114.04 ms | 35916 tok/s)\n",
      "step 1546/5000 | train loss 0.085862 | norm 0.4792 | lr 2.35e-05 | (112.81 ms | 36308 tok/s)\n",
      "step 1547/5000 | train loss 0.085711 | norm 0.4038 | lr 2.35e-05 | (113.74 ms | 36013 tok/s)\n",
      "step 1548/5000 | train loss 0.085797 | norm 0.5748 | lr 2.35e-05 | (114.25 ms | 35850 tok/s)\n",
      "step 1549/5000 | train loss 0.085677 | norm 0.5119 | lr 2.34e-05 | (114.14 ms | 35887 tok/s)\n",
      "step 1550/5000 | train loss 0.085451 | norm 0.3012 | lr 2.34e-05 | (113.80 ms | 35994 tok/s)\n",
      "step 1551/5000 | train loss 0.085478 | norm 0.4501 | lr 2.34e-05 | (114.46 ms | 35786 tok/s)\n",
      "step 1552/5000 | train loss 0.085434 | norm 0.4831 | lr 2.34e-05 | (114.11 ms | 35896 tok/s)\n",
      "step 1553/5000 | train loss 0.085246 | norm 0.3119 | lr 2.34e-05 | (114.93 ms | 35638 tok/s)\n",
      "step 1554/5000 | train loss 0.085209 | norm 0.3780 | lr 2.34e-05 | (114.30 ms | 35836 tok/s)\n",
      "step 1555/5000 | train loss 0.085185 | norm 0.4257 | lr 2.34e-05 | (114.56 ms | 35755 tok/s)\n",
      "step 1556/5000 | train loss 0.085023 | norm 0.3076 | lr 2.34e-05 | (114.47 ms | 35783 tok/s)\n",
      "step 1557/5000 | train loss 0.085049 | norm 0.4240 | lr 2.34e-05 | (114.21 ms | 35865 tok/s)\n",
      "step 1558/5000 | train loss 0.084920 | norm 0.3571 | lr 2.34e-05 | (113.46 ms | 36101 tok/s)\n",
      "step 1559/5000 | train loss 0.084853 | norm 0.3466 | lr 2.34e-05 | (114.94 ms | 35636 tok/s)\n",
      "step 1560/5000 | train loss 0.084829 | norm 0.4103 | lr 2.34e-05 | (113.63 ms | 36048 tok/s)\n",
      "step 1561/5000 | train loss 0.084689 | norm 0.3428 | lr 2.34e-05 | (113.72 ms | 36020 tok/s)\n",
      "step 1562/5000 | train loss 0.084714 | norm 0.4412 | lr 2.33e-05 | (114.51 ms | 35771 tok/s)\n",
      "step 1563/5000 | train loss 0.084626 | norm 0.4401 | lr 2.33e-05 | (123.04 ms | 33291 tok/s)\n",
      "step 1564/5000 | train loss 0.084571 | norm 0.4542 | lr 2.33e-05 | (114.60 ms | 35742 tok/s)\n",
      "step 1565/5000 | train loss 0.084477 | norm 0.4014 | lr 2.33e-05 | (114.70 ms | 35709 tok/s)\n",
      "step 1566/5000 | train loss 0.084336 | norm 0.3140 | lr 2.33e-05 | (113.50 ms | 36087 tok/s)\n",
      "step 1567/5000 | train loss 0.084309 | norm 0.3693 | lr 2.33e-05 | (115.45 ms | 35479 tok/s)\n",
      "step 1568/5000 | train loss 0.084217 | norm 0.3476 | lr 2.33e-05 | (113.51 ms | 36085 tok/s)\n",
      "step 1569/5000 | train loss 0.084189 | norm 0.3924 | lr 2.33e-05 | (115.67 ms | 35410 tok/s)\n",
      "step 1570/5000 | train loss 0.084078 | norm 0.3557 | lr 2.33e-05 | (113.42 ms | 36113 tok/s)\n",
      "step 1571/5000 | train loss 0.084012 | norm 0.3330 | lr 2.33e-05 | (122.01 ms | 33572 tok/s)\n",
      "step 1572/5000 | train loss 0.083914 | norm 0.2919 | lr 2.33e-05 | (118.64 ms | 34525 tok/s)\n",
      "step 1573/5000 | train loss 0.083859 | norm 0.3126 | lr 2.33e-05 | (115.88 ms | 35346 tok/s)\n",
      "step 1574/5000 | train loss 0.083832 | norm 0.3782 | lr 2.33e-05 | (115.45 ms | 35478 tok/s)\n",
      "step 1575/5000 | train loss 0.083802 | norm 0.4286 | lr 2.32e-05 | (113.51 ms | 36086 tok/s)\n",
      "step 1576/5000 | train loss 0.083729 | norm 0.4177 | lr 2.32e-05 | (114.27 ms | 35846 tok/s)\n",
      "step 1577/5000 | train loss 0.083629 | norm 0.3925 | lr 2.32e-05 | (114.37 ms | 35813 tok/s)\n",
      "step 1578/5000 | train loss 0.083672 | norm 0.5108 | lr 2.32e-05 | (115.21 ms | 35554 tok/s)\n",
      "step 1579/5000 | train loss 0.083679 | norm 0.5865 | lr 2.32e-05 | (114.48 ms | 35779 tok/s)\n",
      "step 1580/5000 | train loss 0.083551 | norm 0.5301 | lr 2.32e-05 | (113.95 ms | 35946 tok/s)\n",
      "step 1581/5000 | train loss 0.083418 | norm 0.4499 | lr 2.32e-05 | (115.58 ms | 35439 tok/s)\n",
      "step 1582/5000 | train loss 0.083416 | norm 0.4943 | lr 2.32e-05 | (114.88 ms | 35654 tok/s)\n",
      "step 1583/5000 | train loss 0.083270 | norm 0.4192 | lr 2.32e-05 | (115.82 ms | 35365 tok/s)\n",
      "step 1584/5000 | train loss 0.083213 | norm 0.3914 | lr 2.32e-05 | (123.95 ms | 33046 tok/s)\n",
      "step 1585/5000 | train loss 0.083089 | norm 0.3319 | lr 2.32e-05 | (118.08 ms | 34688 tok/s)\n",
      "step 1586/5000 | train loss 0.083075 | norm 0.3820 | lr 2.32e-05 | (114.72 ms | 35706 tok/s)\n",
      "step 1587/5000 | train loss 0.082966 | norm 0.3400 | lr 2.31e-05 | (114.69 ms | 35714 tok/s)\n",
      "step 1588/5000 | train loss 0.082897 | norm 0.3116 | lr 2.31e-05 | (114.05 ms | 35915 tok/s)\n",
      "step 1589/5000 | train loss 0.082836 | norm 0.3303 | lr 2.31e-05 | (121.90 ms | 33602 tok/s)\n",
      "step 1590/5000 | train loss 0.082762 | norm 0.3083 | lr 2.31e-05 | (123.17 ms | 33254 tok/s)\n",
      "step 1591/5000 | train loss 0.082661 | norm 0.2488 | lr 2.31e-05 | (119.39 ms | 34307 tok/s)\n",
      "step 1592/5000 | train loss 0.082638 | norm 0.3081 | lr 2.31e-05 | (114.16 ms | 35879 tok/s)\n",
      "step 1593/5000 | train loss 0.082546 | norm 0.2687 | lr 2.31e-05 | (114.46 ms | 35784 tok/s)\n",
      "step 1594/5000 | train loss 0.082460 | norm 0.2350 | lr 2.31e-05 | (113.24 ms | 36171 tok/s)\n",
      "step 1595/5000 | train loss 0.082437 | norm 0.3017 | lr 2.31e-05 | (118.68 ms | 34513 tok/s)\n",
      "step 1596/5000 | train loss 0.082372 | norm 0.3112 | lr 2.31e-05 | (119.68 ms | 34224 tok/s)\n",
      "step 1597/5000 | train loss 0.082334 | norm 0.3556 | lr 2.31e-05 | (122.34 ms | 33481 tok/s)\n",
      "step 1598/5000 | train loss 0.082331 | norm 0.4365 | lr 2.31e-05 | (117.76 ms | 34784 tok/s)\n",
      "step 1599/5000 | train loss 0.082278 | norm 0.4538 | lr 2.31e-05 | (115.74 ms | 35390 tok/s)\n",
      "step 1600/5000 | train loss 0.082211 | norm 0.4508 | lr 2.30e-05 | (113.86 ms | 35975 tok/s)\n",
      "step 1601/5000 | train loss 0.082189 | norm 0.4756 | lr 2.30e-05 | (114.35 ms | 35819 tok/s)\n",
      "step 1602/5000 | train loss 0.082099 | norm 0.4696 | lr 2.30e-05 | (114.17 ms | 35878 tok/s)\n",
      "step 1603/5000 | train loss 0.082133 | norm 0.5738 | lr 2.30e-05 | (116.60 ms | 35129 tok/s)\n",
      "step 1604/5000 | train loss 0.082060 | norm 0.5178 | lr 2.30e-05 | (113.97 ms | 35939 tok/s)\n",
      "step 1605/5000 | train loss 0.081841 | norm 0.3312 | lr 2.30e-05 | (113.32 ms | 36145 tok/s)\n",
      "step 1606/5000 | train loss 0.081900 | norm 0.4831 | lr 2.30e-05 | (116.34 ms | 35207 tok/s)\n",
      "step 1607/5000 | train loss 0.081808 | norm 0.4393 | lr 2.30e-05 | (118.17 ms | 34663 tok/s)\n",
      "step 1608/5000 | train loss 0.081684 | norm 0.3534 | lr 2.30e-05 | (115.32 ms | 35519 tok/s)\n",
      "step 1609/5000 | train loss 0.081686 | norm 0.4235 | lr 2.30e-05 | (115.91 ms | 35338 tok/s)\n",
      "step 1610/5000 | train loss 0.081540 | norm 0.3236 | lr 2.30e-05 | (114.25 ms | 35852 tok/s)\n",
      "step 1611/5000 | train loss 0.081540 | norm 0.3670 | lr 2.30e-05 | (114.47 ms | 35781 tok/s)\n",
      "step 1612/5000 | train loss 0.081404 | norm 0.3005 | lr 2.30e-05 | (113.65 ms | 36042 tok/s)\n",
      "step 1613/5000 | train loss 0.081384 | norm 0.3300 | lr 2.29e-05 | (115.25 ms | 35540 tok/s)\n",
      "step 1614/5000 | train loss 0.081294 | norm 0.2912 | lr 2.29e-05 | (113.99 ms | 35932 tok/s)\n",
      "step 1615/5000 | train loss 0.081244 | norm 0.3017 | lr 2.29e-05 | (115.81 ms | 35367 tok/s)\n",
      "step 1616/5000 | train loss 0.081188 | norm 0.3072 | lr 2.29e-05 | (114.21 ms | 35865 tok/s)\n",
      "step 1617/5000 | train loss 0.081119 | norm 0.2926 | lr 2.29e-05 | (112.98 ms | 36253 tok/s)\n",
      "step 1618/5000 | train loss 0.081063 | norm 0.3034 | lr 2.29e-05 | (113.23 ms | 36175 tok/s)\n",
      "step 1619/5000 | train loss 0.081007 | norm 0.3104 | lr 2.29e-05 | (114.41 ms | 35801 tok/s)\n",
      "step 1620/5000 | train loss 0.080954 | norm 0.3245 | lr 2.29e-05 | (113.02 ms | 36241 tok/s)\n",
      "step 1621/5000 | train loss 0.080923 | norm 0.3650 | lr 2.29e-05 | (123.56 ms | 33149 tok/s)\n",
      "step 1622/5000 | train loss 0.080910 | norm 0.4312 | lr 2.29e-05 | (114.32 ms | 35831 tok/s)\n",
      "step 1623/5000 | train loss 0.080861 | norm 0.4400 | lr 2.29e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 1624/5000 | train loss 0.080800 | norm 0.4190 | lr 2.29e-05 | (112.81 ms | 36309 tok/s)\n",
      "step 1625/5000 | train loss 0.080671 | norm 0.3292 | lr 2.28e-05 | (115.44 ms | 35481 tok/s)\n",
      "step 1626/5000 | train loss 0.080619 | norm 0.3258 | lr 2.28e-05 | (114.06 ms | 35912 tok/s)\n",
      "step 1627/5000 | train loss 0.080609 | norm 0.4077 | lr 2.28e-05 | (121.31 ms | 33764 tok/s)\n",
      "step 1628/5000 | train loss 0.080597 | norm 0.4482 | lr 2.28e-05 | (116.55 ms | 35143 tok/s)\n",
      "step 1629/5000 | train loss 0.080473 | norm 0.3742 | lr 2.28e-05 | (115.01 ms | 35613 tok/s)\n",
      "step 1630/5000 | train loss 0.080442 | norm 0.3967 | lr 2.28e-05 | (113.76 ms | 36005 tok/s)\n",
      "step 1631/5000 | train loss 0.080431 | norm 0.4437 | lr 2.28e-05 | (114.84 ms | 35668 tok/s)\n",
      "step 1632/5000 | train loss 0.080334 | norm 0.3891 | lr 2.28e-05 | (115.72 ms | 35396 tok/s)\n",
      "step 1633/5000 | train loss 0.080234 | norm 0.3402 | lr 2.28e-05 | (116.42 ms | 35184 tok/s)\n",
      "step 1634/5000 | train loss 0.080253 | norm 0.4359 | lr 2.28e-05 | (114.58 ms | 35749 tok/s)\n",
      "step 1635/5000 | train loss 0.080179 | norm 0.4260 | lr 2.28e-05 | (121.11 ms | 33822 tok/s)\n",
      "step 1636/5000 | train loss 0.080096 | norm 0.3690 | lr 2.28e-05 | (117.28 ms | 34926 tok/s)\n",
      "step 1637/5000 | train loss 0.080036 | norm 0.3702 | lr 2.27e-05 | (114.97 ms | 35627 tok/s)\n",
      "step 1638/5000 | train loss 0.080000 | norm 0.3844 | lr 2.27e-05 | (115.23 ms | 35547 tok/s)\n",
      "step 1639/5000 | train loss 0.079881 | norm 0.3024 | lr 2.27e-05 | (114.74 ms | 35697 tok/s)\n",
      "step 1640/5000 | train loss 0.079866 | norm 0.3339 | lr 2.27e-05 | (113.83 ms | 35985 tok/s)\n",
      "step 1641/5000 | train loss 0.079778 | norm 0.2992 | lr 2.27e-05 | (114.46 ms | 35786 tok/s)\n",
      "step 1642/5000 | train loss 0.079710 | norm 0.2760 | lr 2.27e-05 | (113.87 ms | 35970 tok/s)\n",
      "step 1643/5000 | train loss 0.079681 | norm 0.3016 | lr 2.27e-05 | (116.02 ms | 35305 tok/s)\n",
      "step 1644/5000 | train loss 0.079585 | norm 0.2481 | lr 2.27e-05 | (114.27 ms | 35845 tok/s)\n",
      "step 1645/5000 | train loss 0.079539 | norm 0.2506 | lr 2.27e-05 | (114.85 ms | 35664 tok/s)\n",
      "step 1646/5000 | train loss 0.079495 | norm 0.2826 | lr 2.27e-05 | (112.68 ms | 36349 tok/s)\n",
      "step 1647/5000 | train loss 0.079440 | norm 0.2805 | lr 2.27e-05 | (116.46 ms | 35171 tok/s)\n",
      "step 1648/5000 | train loss 0.079388 | norm 0.2797 | lr 2.27e-05 | (113.71 ms | 36021 tok/s)\n",
      "step 1649/5000 | train loss 0.079356 | norm 0.3121 | lr 2.27e-05 | (113.69 ms | 36027 tok/s)\n",
      "step 1650/5000 | train loss 0.079305 | norm 0.3143 | lr 2.26e-05 | (113.44 ms | 36107 tok/s)\n",
      "step 1651/5000 | train loss 0.079237 | norm 0.3020 | lr 2.26e-05 | (116.09 ms | 35282 tok/s)\n",
      "step 1652/5000 | train loss 0.079237 | norm 0.3654 | lr 2.26e-05 | (113.16 ms | 36198 tok/s)\n",
      "step 1653/5000 | train loss 0.079246 | norm 0.4507 | lr 2.26e-05 | (114.19 ms | 35870 tok/s)\n",
      "step 1654/5000 | train loss 0.079246 | norm 0.5012 | lr 2.26e-05 | (117.44 ms | 34876 tok/s)\n",
      "step 1655/5000 | train loss 0.079215 | norm 0.5214 | lr 2.26e-05 | (115.64 ms | 35421 tok/s)\n",
      "step 1656/5000 | train loss 0.079147 | norm 0.5089 | lr 2.26e-05 | (113.83 ms | 35983 tok/s)\n",
      "step 1657/5000 | train loss 0.079050 | norm 0.4488 | lr 2.26e-05 | (114.95 ms | 35633 tok/s)\n",
      "step 1658/5000 | train loss 0.078945 | norm 0.3937 | lr 2.26e-05 | (112.82 ms | 36305 tok/s)\n",
      "step 1659/5000 | train loss 0.078985 | norm 0.5046 | lr 2.26e-05 | (121.49 ms | 33716 tok/s)\n",
      "step 1660/5000 | train loss 0.078906 | norm 0.4702 | lr 2.26e-05 | (118.20 ms | 34652 tok/s)\n",
      "step 1661/5000 | train loss 0.078813 | norm 0.4273 | lr 2.26e-05 | (115.67 ms | 35412 tok/s)\n",
      "step 1662/5000 | train loss 0.078875 | norm 0.5238 | lr 2.25e-05 | (113.36 ms | 36133 tok/s)\n",
      "step 1663/5000 | train loss 0.078683 | norm 0.3804 | lr 2.25e-05 | (113.92 ms | 35955 tok/s)\n",
      "step 1664/5000 | train loss 0.078667 | norm 0.3894 | lr 2.25e-05 | (113.55 ms | 36072 tok/s)\n",
      "step 1665/5000 | train loss 0.078589 | norm 0.3582 | lr 2.25e-05 | (117.70 ms | 34801 tok/s)\n",
      "step 1666/5000 | train loss 0.078505 | norm 0.3074 | lr 2.25e-05 | (116.31 ms | 35217 tok/s)\n",
      "step 1667/5000 | train loss 0.078492 | norm 0.3517 | lr 2.25e-05 | (114.78 ms | 35686 tok/s)\n",
      "step 1668/5000 | train loss 0.078401 | norm 0.3003 | lr 2.25e-05 | (113.14 ms | 36203 tok/s)\n",
      "step 1669/5000 | train loss 0.078361 | norm 0.2995 | lr 2.25e-05 | (113.64 ms | 36045 tok/s)\n",
      "step 1670/5000 | train loss 0.078285 | norm 0.2649 | lr 2.25e-05 | (114.22 ms | 35860 tok/s)\n",
      "step 1671/5000 | train loss 0.078248 | norm 0.2790 | lr 2.25e-05 | (115.86 ms | 35354 tok/s)\n",
      "step 1672/5000 | train loss 0.078199 | norm 0.2801 | lr 2.25e-05 | (114.60 ms | 35743 tok/s)\n",
      "step 1673/5000 | train loss 0.078145 | norm 0.2798 | lr 2.25e-05 | (114.82 ms | 35674 tok/s)\n",
      "step 1674/5000 | train loss 0.078098 | norm 0.2699 | lr 2.24e-05 | (112.61 ms | 36374 tok/s)\n",
      "step 1675/5000 | train loss 0.078039 | norm 0.2593 | lr 2.24e-05 | (116.53 ms | 35150 tok/s)\n",
      "step 1676/5000 | train loss 0.078004 | norm 0.2786 | lr 2.24e-05 | (118.89 ms | 34452 tok/s)\n",
      "step 1677/5000 | train loss 0.077944 | norm 0.2799 | lr 2.24e-05 | (132.82 ms | 30839 tok/s)\n",
      "step 1678/5000 | train loss 0.077951 | norm 0.3524 | lr 2.24e-05 | (114.45 ms | 35787 tok/s)\n",
      "step 1679/5000 | train loss 0.077902 | norm 0.3631 | lr 2.24e-05 | (115.62 ms | 35427 tok/s)\n",
      "step 1680/5000 | train loss 0.077877 | norm 0.3771 | lr 2.24e-05 | (113.64 ms | 36044 tok/s)\n",
      "step 1681/5000 | train loss 0.077801 | norm 0.3552 | lr 2.24e-05 | (113.69 ms | 36028 tok/s)\n",
      "step 1682/5000 | train loss 0.077765 | norm 0.3739 | lr 2.24e-05 | (112.96 ms | 36260 tok/s)\n",
      "step 1683/5000 | train loss 0.077744 | norm 0.4136 | lr 2.24e-05 | (114.40 ms | 35804 tok/s)\n",
      "step 1684/5000 | train loss 0.077715 | norm 0.4290 | lr 2.24e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 1685/5000 | train loss 0.077678 | norm 0.4287 | lr 2.24e-05 | (114.37 ms | 35813 tok/s)\n",
      "step 1686/5000 | train loss 0.077637 | norm 0.4343 | lr 2.24e-05 | (116.05 ms | 35295 tok/s)\n",
      "step 1687/5000 | train loss 0.077627 | norm 0.4599 | lr 2.23e-05 | (112.86 ms | 36293 tok/s)\n",
      "step 1688/5000 | train loss 0.077514 | norm 0.3944 | lr 2.23e-05 | (113.00 ms | 36248 tok/s)\n",
      "step 1689/5000 | train loss 0.077459 | norm 0.3381 | lr 2.23e-05 | (114.83 ms | 35669 tok/s)\n",
      "step 1690/5000 | train loss 0.077379 | norm 0.3319 | lr 2.23e-05 | (113.32 ms | 36145 tok/s)\n",
      "step 1691/5000 | train loss 0.077367 | norm 0.3595 | lr 2.23e-05 | (115.60 ms | 35433 tok/s)\n",
      "step 1692/5000 | train loss 0.077262 | norm 0.2857 | lr 2.23e-05 | (113.80 ms | 35992 tok/s)\n",
      "step 1693/5000 | train loss 0.077231 | norm 0.2898 | lr 2.23e-05 | (114.67 ms | 35719 tok/s)\n",
      "step 1694/5000 | train loss 0.077162 | norm 0.2739 | lr 2.23e-05 | (113.53 ms | 36080 tok/s)\n",
      "step 1695/5000 | train loss 0.077139 | norm 0.2951 | lr 2.23e-05 | (113.29 ms | 36156 tok/s)\n",
      "step 1696/5000 | train loss 0.077074 | norm 0.2598 | lr 2.23e-05 | (113.91 ms | 35957 tok/s)\n",
      "step 1697/5000 | train loss 0.076996 | norm 0.2242 | lr 2.23e-05 | (114.27 ms | 35846 tok/s)\n",
      "step 1698/5000 | train loss 0.077017 | norm 0.3091 | lr 2.23e-05 | (113.19 ms | 36186 tok/s)\n",
      "step 1699/5000 | train loss 0.076935 | norm 0.2851 | lr 2.22e-05 | (113.23 ms | 36174 tok/s)\n",
      "step 1700/5000 | train loss 0.076929 | norm 0.3241 | lr 2.22e-05 | (112.60 ms | 36376 tok/s)\n",
      "step 1701/5000 | train loss 0.076894 | norm 0.3630 | lr 2.22e-05 | (114.26 ms | 35847 tok/s)\n",
      "step 1702/5000 | train loss 0.076923 | norm 0.4384 | lr 2.22e-05 | (114.10 ms | 35899 tok/s)\n",
      "step 1703/5000 | train loss 0.076836 | norm 0.3954 | lr 2.22e-05 | (114.81 ms | 35676 tok/s)\n",
      "step 1704/5000 | train loss 0.076714 | norm 0.2785 | lr 2.22e-05 | (113.89 ms | 35965 tok/s)\n",
      "step 1705/5000 | train loss 0.076708 | norm 0.3125 | lr 2.22e-05 | (114.40 ms | 35804 tok/s)\n",
      "step 1706/5000 | train loss 0.076663 | norm 0.3382 | lr 2.22e-05 | (112.71 ms | 36342 tok/s)\n",
      "step 1707/5000 | train loss 0.076633 | norm 0.3469 | lr 2.22e-05 | (115.50 ms | 35464 tok/s)\n",
      "step 1708/5000 | train loss 0.076563 | norm 0.3116 | lr 2.22e-05 | (115.70 ms | 35402 tok/s)\n",
      "step 1709/5000 | train loss 0.076548 | norm 0.3638 | lr 2.22e-05 | (115.14 ms | 35573 tok/s)\n",
      "step 1710/5000 | train loss 0.076601 | norm 0.4727 | lr 2.22e-05 | (113.58 ms | 36063 tok/s)\n",
      "step 1711/5000 | train loss 0.076554 | norm 0.4876 | lr 2.21e-05 | (115.53 ms | 35455 tok/s)\n",
      "step 1712/5000 | train loss 0.076517 | norm 0.4773 | lr 2.21e-05 | (113.50 ms | 36089 tok/s)\n",
      "step 1713/5000 | train loss 0.076494 | norm 0.4832 | lr 2.21e-05 | (113.80 ms | 35994 tok/s)\n",
      "step 1714/5000 | train loss 0.076404 | norm 0.4292 | lr 2.21e-05 | (113.10 ms | 36215 tok/s)\n",
      "step 1715/5000 | train loss 0.076375 | norm 0.4476 | lr 2.21e-05 | (114.51 ms | 35769 tok/s)\n",
      "step 1716/5000 | train loss 0.076319 | norm 0.4228 | lr 2.21e-05 | (112.87 ms | 36291 tok/s)\n",
      "step 1717/5000 | train loss 0.076216 | norm 0.3348 | lr 2.21e-05 | (113.34 ms | 36139 tok/s)\n",
      "step 1718/5000 | train loss 0.076198 | norm 0.3733 | lr 2.21e-05 | (112.81 ms | 36308 tok/s)\n",
      "step 1719/5000 | train loss 0.076138 | norm 0.3434 | lr 2.21e-05 | (114.90 ms | 35649 tok/s)\n",
      "step 1720/5000 | train loss 0.076064 | norm 0.2824 | lr 2.21e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 1721/5000 | train loss 0.076026 | norm 0.2965 | lr 2.21e-05 | (114.33 ms | 35826 tok/s)\n",
      "step 1722/5000 | train loss 0.075988 | norm 0.3030 | lr 2.21e-05 | (113.44 ms | 36107 tok/s)\n",
      "step 1723/5000 | train loss 0.075943 | norm 0.2841 | lr 2.20e-05 | (113.66 ms | 36036 tok/s)\n",
      "step 1724/5000 | train loss 0.075887 | norm 0.2693 | lr 2.20e-05 | (150.10 ms | 27288 tok/s)\n",
      "step 1725/5000 | train loss 0.075845 | norm 0.2626 | lr 2.20e-05 | (117.56 ms | 34843 tok/s)\n",
      "step 1726/5000 | train loss 0.075802 | norm 0.2516 | lr 2.20e-05 | (113.36 ms | 36131 tok/s)\n",
      "step 1727/5000 | train loss 0.075744 | norm 0.2426 | lr 2.20e-05 | (115.36 ms | 35505 tok/s)\n",
      "step 1728/5000 | train loss 0.075734 | norm 0.2779 | lr 2.20e-05 | (114.41 ms | 35800 tok/s)\n",
      "step 1729/5000 | train loss 0.075653 | norm 0.2419 | lr 2.20e-05 | (114.07 ms | 35907 tok/s)\n",
      "step 1730/5000 | train loss 0.075679 | norm 0.3391 | lr 2.20e-05 | (113.64 ms | 36043 tok/s)\n",
      "step 1731/5000 | train loss 0.075661 | norm 0.3826 | lr 2.20e-05 | (113.35 ms | 36137 tok/s)\n",
      "step 1732/5000 | train loss 0.075669 | norm 0.4382 | lr 2.20e-05 | (112.66 ms | 36356 tok/s)\n",
      "step 1733/5000 | train loss 0.075595 | norm 0.3941 | lr 2.20e-05 | (114.30 ms | 35837 tok/s)\n",
      "step 1734/5000 | train loss 0.075465 | norm 0.2478 | lr 2.20e-05 | (113.12 ms | 36209 tok/s)\n",
      "step 1735/5000 | train loss 0.075414 | norm 0.2362 | lr 2.19e-05 | (113.87 ms | 35969 tok/s)\n",
      "step 1736/5000 | train loss 0.075446 | norm 0.3553 | lr 2.19e-05 | (113.71 ms | 36022 tok/s)\n",
      "step 1737/5000 | train loss 0.075388 | norm 0.3427 | lr 2.19e-05 | (113.72 ms | 36018 tok/s)\n",
      "step 1738/5000 | train loss 0.075338 | norm 0.3121 | lr 2.19e-05 | (113.37 ms | 36129 tok/s)\n",
      "step 1739/5000 | train loss 0.075337 | norm 0.3702 | lr 2.19e-05 | (113.25 ms | 36168 tok/s)\n",
      "step 1740/5000 | train loss 0.075341 | norm 0.4388 | lr 2.19e-05 | (114.09 ms | 35901 tok/s)\n",
      "step 1741/5000 | train loss 0.075316 | norm 0.4576 | lr 2.19e-05 | (114.39 ms | 35806 tok/s)\n",
      "step 1742/5000 | train loss 0.075216 | norm 0.3634 | lr 2.19e-05 | (115.16 ms | 35567 tok/s)\n",
      "step 1743/5000 | train loss 0.075142 | norm 0.3070 | lr 2.19e-05 | (117.28 ms | 34924 tok/s)\n",
      "step 1744/5000 | train loss 0.075151 | norm 0.3699 | lr 2.19e-05 | (114.34 ms | 35825 tok/s)\n",
      "step 1745/5000 | train loss 0.075092 | norm 0.3507 | lr 2.19e-05 | (115.83 ms | 35364 tok/s)\n",
      "step 1746/5000 | train loss 0.075067 | norm 0.3530 | lr 2.19e-05 | (113.45 ms | 36104 tok/s)\n",
      "step 1747/5000 | train loss 0.075001 | norm 0.3234 | lr 2.18e-05 | (114.62 ms | 35735 tok/s)\n",
      "step 1748/5000 | train loss 0.074953 | norm 0.3036 | lr 2.18e-05 | (114.32 ms | 35829 tok/s)\n",
      "step 1749/5000 | train loss 0.074942 | norm 0.3436 | lr 2.18e-05 | (116.03 ms | 35300 tok/s)\n",
      "step 1750/5000 | train loss 0.074910 | norm 0.3490 | lr 2.18e-05 | (114.90 ms | 35648 tok/s)\n",
      "step 1751/5000 | train loss 0.074835 | norm 0.3054 | lr 2.18e-05 | (115.84 ms | 35358 tok/s)\n",
      "step 1752/5000 | train loss 0.074839 | norm 0.3509 | lr 2.18e-05 | (113.91 ms | 35957 tok/s)\n",
      "step 1753/5000 | train loss 0.074785 | norm 0.3452 | lr 2.18e-05 | (115.91 ms | 35337 tok/s)\n",
      "step 1754/5000 | train loss 0.074747 | norm 0.3319 | lr 2.18e-05 | (113.19 ms | 36188 tok/s)\n",
      "step 1755/5000 | train loss 0.074720 | norm 0.3408 | lr 2.18e-05 | (119.84 ms | 34180 tok/s)\n",
      "step 1756/5000 | train loss 0.074671 | norm 0.3389 | lr 2.18e-05 | (116.22 ms | 35244 tok/s)\n",
      "step 1757/5000 | train loss 0.074633 | norm 0.3228 | lr 2.18e-05 | (115.01 ms | 35613 tok/s)\n",
      "step 1758/5000 | train loss 0.074575 | norm 0.2930 | lr 2.18e-05 | (113.49 ms | 36092 tok/s)\n",
      "step 1759/5000 | train loss 0.074551 | norm 0.3081 | lr 2.17e-05 | (112.85 ms | 36295 tok/s)\n",
      "step 1760/5000 | train loss 0.074497 | norm 0.2902 | lr 2.17e-05 | (113.06 ms | 36229 tok/s)\n",
      "step 1761/5000 | train loss 0.074473 | norm 0.2957 | lr 2.17e-05 | (114.94 ms | 35634 tok/s)\n",
      "step 1762/5000 | train loss 0.074431 | norm 0.2915 | lr 2.17e-05 | (113.77 ms | 36002 tok/s)\n",
      "step 1763/5000 | train loss 0.074399 | norm 0.3014 | lr 2.17e-05 | (115.02 ms | 35610 tok/s)\n",
      "step 1764/5000 | train loss 0.074367 | norm 0.3080 | lr 2.17e-05 | (113.58 ms | 36062 tok/s)\n",
      "step 1765/5000 | train loss 0.074340 | norm 0.3270 | lr 2.17e-05 | (114.82 ms | 35673 tok/s)\n",
      "step 1766/5000 | train loss 0.074327 | norm 0.3575 | lr 2.17e-05 | (112.99 ms | 36252 tok/s)\n",
      "step 1767/5000 | train loss 0.074265 | norm 0.3369 | lr 2.17e-05 | (114.40 ms | 35805 tok/s)\n",
      "step 1768/5000 | train loss 0.074231 | norm 0.3248 | lr 2.17e-05 | (115.69 ms | 35405 tok/s)\n",
      "step 1769/5000 | train loss 0.074202 | norm 0.3413 | lr 2.17e-05 | (115.18 ms | 35563 tok/s)\n",
      "step 1770/5000 | train loss 0.074203 | norm 0.3798 | lr 2.17e-05 | (114.26 ms | 35847 tok/s)\n",
      "step 1771/5000 | train loss 0.074146 | norm 0.3687 | lr 2.16e-05 | (113.82 ms | 35986 tok/s)\n",
      "step 1772/5000 | train loss 0.074139 | norm 0.3821 | lr 2.16e-05 | (114.94 ms | 35636 tok/s)\n",
      "step 1773/5000 | train loss 0.074071 | norm 0.3454 | lr 2.16e-05 | (115.92 ms | 35335 tok/s)\n",
      "step 1774/5000 | train loss 0.074013 | norm 0.2957 | lr 2.16e-05 | (113.83 ms | 35984 tok/s)\n",
      "step 1775/5000 | train loss 0.073953 | norm 0.2651 | lr 2.16e-05 | (115.23 ms | 35546 tok/s)\n",
      "step 1776/5000 | train loss 0.073941 | norm 0.2987 | lr 2.16e-05 | (114.63 ms | 35733 tok/s)\n",
      "step 1777/5000 | train loss 0.073902 | norm 0.3013 | lr 2.16e-05 | (116.59 ms | 35133 tok/s)\n",
      "step 1778/5000 | train loss 0.073873 | norm 0.2976 | lr 2.16e-05 | (114.00 ms | 35930 tok/s)\n",
      "step 1779/5000 | train loss 0.073814 | norm 0.2650 | lr 2.16e-05 | (114.61 ms | 35739 tok/s)\n",
      "step 1780/5000 | train loss 0.073790 | norm 0.2831 | lr 2.16e-05 | (114.69 ms | 35715 tok/s)\n",
      "step 1781/5000 | train loss 0.073765 | norm 0.3017 | lr 2.16e-05 | (117.32 ms | 34914 tok/s)\n",
      "step 1782/5000 | train loss 0.073714 | norm 0.2762 | lr 2.15e-05 | (113.37 ms | 36131 tok/s)\n",
      "step 1783/5000 | train loss 0.073694 | norm 0.3115 | lr 2.15e-05 | (115.07 ms | 35597 tok/s)\n",
      "step 1784/5000 | train loss 0.073681 | norm 0.3441 | lr 2.15e-05 | (113.04 ms | 36233 tok/s)\n",
      "step 1785/5000 | train loss 0.073645 | norm 0.3377 | lr 2.15e-05 | (115.30 ms | 35525 tok/s)\n",
      "step 1786/5000 | train loss 0.073625 | norm 0.3486 | lr 2.15e-05 | (113.49 ms | 36091 tok/s)\n",
      "step 1787/5000 | train loss 0.073594 | norm 0.3606 | lr 2.15e-05 | (114.22 ms | 35860 tok/s)\n",
      "step 1788/5000 | train loss 0.073573 | norm 0.3723 | lr 2.15e-05 | (113.91 ms | 35960 tok/s)\n",
      "step 1789/5000 | train loss 0.073490 | norm 0.3190 | lr 2.15e-05 | (115.58 ms | 35438 tok/s)\n",
      "step 1790/5000 | train loss 0.073495 | norm 0.3455 | lr 2.15e-05 | (113.53 ms | 36079 tok/s)\n",
      "step 1791/5000 | train loss 0.073462 | norm 0.3589 | lr 2.15e-05 | (114.79 ms | 35684 tok/s)\n",
      "step 1792/5000 | train loss 0.073440 | norm 0.3621 | lr 2.15e-05 | (112.97 ms | 36258 tok/s)\n",
      "step 1793/5000 | train loss 0.073384 | norm 0.3375 | lr 2.15e-05 | (114.77 ms | 35690 tok/s)\n",
      "step 1794/5000 | train loss 0.073323 | norm 0.2954 | lr 2.14e-05 | (113.53 ms | 36078 tok/s)\n",
      "step 1795/5000 | train loss 0.073301 | norm 0.2991 | lr 2.14e-05 | (115.22 ms | 35549 tok/s)\n",
      "step 1796/5000 | train loss 0.073240 | norm 0.2587 | lr 2.14e-05 | (113.66 ms | 36036 tok/s)\n",
      "step 1797/5000 | train loss 0.073211 | norm 0.2661 | lr 2.14e-05 | (114.79 ms | 35683 tok/s)\n",
      "step 1798/5000 | train loss 0.073204 | norm 0.3088 | lr 2.14e-05 | (113.64 ms | 36043 tok/s)\n",
      "step 1799/5000 | train loss 0.073169 | norm 0.3040 | lr 2.14e-05 | (114.61 ms | 35740 tok/s)\n",
      "step 1800/5000 | train loss 0.073125 | norm 0.2910 | lr 2.14e-05 | (113.19 ms | 36188 tok/s)\n",
      "step 1801/5000 | train loss 0.073116 | norm 0.3122 | lr 2.14e-05 | (114.65 ms | 35727 tok/s)\n",
      "step 1802/5000 | train loss 0.073093 | norm 0.3270 | lr 2.14e-05 | (113.33 ms | 36143 tok/s)\n",
      "step 1803/5000 | train loss 0.073059 | norm 0.3256 | lr 2.14e-05 | (115.48 ms | 35468 tok/s)\n",
      "step 1804/5000 | train loss 0.072998 | norm 0.2824 | lr 2.14e-05 | (114.48 ms | 35779 tok/s)\n",
      "step 1805/5000 | train loss 0.072968 | norm 0.2768 | lr 2.14e-05 | (115.33 ms | 35516 tok/s)\n",
      "step 1806/5000 | train loss 0.072931 | norm 0.2788 | lr 2.13e-05 | (113.11 ms | 36214 tok/s)\n",
      "step 1807/5000 | train loss 0.072913 | norm 0.3044 | lr 2.13e-05 | (115.66 ms | 35414 tok/s)\n",
      "step 1808/5000 | train loss 0.072919 | norm 0.3547 | lr 2.13e-05 | (115.44 ms | 35482 tok/s)\n",
      "step 1809/5000 | train loss 0.072877 | norm 0.3584 | lr 2.13e-05 | (114.17 ms | 35877 tok/s)\n",
      "step 1810/5000 | train loss 0.072866 | norm 0.3750 | lr 2.13e-05 | (113.19 ms | 36188 tok/s)\n",
      "step 1811/5000 | train loss 0.072846 | norm 0.3897 | lr 2.13e-05 | (115.77 ms | 35381 tok/s)\n",
      "step 1812/5000 | train loss 0.072823 | norm 0.3990 | lr 2.13e-05 | (113.08 ms | 36223 tok/s)\n",
      "step 1813/5000 | train loss 0.072776 | norm 0.3715 | lr 2.13e-05 | (113.63 ms | 36047 tok/s)\n",
      "step 1814/5000 | train loss 0.072701 | norm 0.3124 | lr 2.13e-05 | (112.60 ms | 36377 tok/s)\n",
      "step 1815/5000 | train loss 0.072712 | norm 0.3555 | lr 2.13e-05 | (114.57 ms | 35750 tok/s)\n",
      "step 1816/5000 | train loss 0.072656 | norm 0.3293 | lr 2.13e-05 | (113.16 ms | 36198 tok/s)\n",
      "step 1817/5000 | train loss 0.072610 | norm 0.2973 | lr 2.13e-05 | (114.61 ms | 35737 tok/s)\n",
      "step 1818/5000 | train loss 0.072573 | norm 0.2963 | lr 2.12e-05 | (111.63 ms | 36693 tok/s)\n",
      "step 1819/5000 | train loss 0.072550 | norm 0.2985 | lr 2.12e-05 | (115.15 ms | 35572 tok/s)\n",
      "step 1820/5000 | train loss 0.072528 | norm 0.3070 | lr 2.12e-05 | (113.27 ms | 36160 tok/s)\n",
      "step 1821/5000 | train loss 0.072476 | norm 0.2799 | lr 2.12e-05 | (114.93 ms | 35640 tok/s)\n",
      "step 1822/5000 | train loss 0.072439 | norm 0.2771 | lr 2.12e-05 | (115.44 ms | 35480 tok/s)\n",
      "step 1823/5000 | train loss 0.072449 | norm 0.3344 | lr 2.12e-05 | (115.95 ms | 35326 tok/s)\n",
      "step 1824/5000 | train loss 0.072390 | norm 0.2958 | lr 2.12e-05 | (113.88 ms | 35969 tok/s)\n",
      "step 1825/5000 | train loss 0.072356 | norm 0.2719 | lr 2.12e-05 | (114.66 ms | 35722 tok/s)\n",
      "step 1826/5000 | train loss 0.072334 | norm 0.2816 | lr 2.12e-05 | (113.84 ms | 35981 tok/s)\n",
      "step 1827/5000 | train loss 0.072286 | norm 0.2628 | lr 2.12e-05 | (114.85 ms | 35663 tok/s)\n",
      "step 1828/5000 | train loss 0.072267 | norm 0.2918 | lr 2.12e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 1829/5000 | train loss 0.072241 | norm 0.2865 | lr 2.11e-05 | (114.50 ms | 35773 tok/s)\n",
      "step 1830/5000 | train loss 0.072211 | norm 0.2948 | lr 2.11e-05 | (113.13 ms | 36205 tok/s)\n",
      "step 1831/5000 | train loss 0.072209 | norm 0.3390 | lr 2.11e-05 | (114.24 ms | 35853 tok/s)\n",
      "step 1832/5000 | train loss 0.072173 | norm 0.3247 | lr 2.11e-05 | (115.34 ms | 35511 tok/s)\n",
      "step 1833/5000 | train loss 0.072120 | norm 0.2839 | lr 2.11e-05 | (114.36 ms | 35815 tok/s)\n",
      "step 1834/5000 | train loss 0.072096 | norm 0.2969 | lr 2.11e-05 | (113.16 ms | 36196 tok/s)\n",
      "step 1835/5000 | train loss 0.072091 | norm 0.3340 | lr 2.11e-05 | (114.86 ms | 35660 tok/s)\n",
      "step 1836/5000 | train loss 0.072067 | norm 0.3251 | lr 2.11e-05 | (113.95 ms | 35945 tok/s)\n",
      "step 1837/5000 | train loss 0.071988 | norm 0.2573 | lr 2.11e-05 | (120.05 ms | 34119 tok/s)\n",
      "step 1838/5000 | train loss 0.071978 | norm 0.2864 | lr 2.11e-05 | (115.37 ms | 35503 tok/s)\n",
      "step 1839/5000 | train loss 0.072003 | norm 0.3787 | lr 2.11e-05 | (116.50 ms | 35159 tok/s)\n",
      "step 1840/5000 | train loss 0.072023 | norm 0.4297 | lr 2.11e-05 | (112.67 ms | 36353 tok/s)\n",
      "step 1841/5000 | train loss 0.071966 | norm 0.3966 | lr 2.10e-05 | (116.95 ms | 35024 tok/s)\n",
      "step 1842/5000 | train loss 0.071904 | norm 0.3541 | lr 2.10e-05 | (117.25 ms | 34934 tok/s)\n",
      "step 1843/5000 | train loss 0.071870 | norm 0.3281 | lr 2.10e-05 | (117.21 ms | 34945 tok/s)\n",
      "step 1844/5000 | train loss 0.071825 | norm 0.3086 | lr 2.10e-05 | (114.56 ms | 35755 tok/s)\n",
      "step 1845/5000 | train loss 0.071795 | norm 0.3214 | lr 2.10e-05 | (114.69 ms | 35713 tok/s)\n",
      "step 1846/5000 | train loss 0.071794 | norm 0.3486 | lr 2.10e-05 | (113.42 ms | 36114 tok/s)\n",
      "step 1847/5000 | train loss 0.071719 | norm 0.2849 | lr 2.10e-05 | (115.94 ms | 35330 tok/s)\n",
      "step 1848/5000 | train loss 0.071690 | norm 0.2689 | lr 2.10e-05 | (119.58 ms | 34254 tok/s)\n",
      "step 1849/5000 | train loss 0.071683 | norm 0.3146 | lr 2.10e-05 | (118.40 ms | 34595 tok/s)\n",
      "step 1850/5000 | train loss 0.071648 | norm 0.2950 | lr 2.10e-05 | (113.48 ms | 36093 tok/s)\n",
      "step 1851/5000 | train loss 0.071611 | norm 0.2905 | lr 2.10e-05 | (113.85 ms | 35976 tok/s)\n",
      "step 1852/5000 | train loss 0.071614 | norm 0.3391 | lr 2.09e-05 | (113.37 ms | 36129 tok/s)\n",
      "step 1853/5000 | train loss 0.071571 | norm 0.3123 | lr 2.09e-05 | (114.87 ms | 35657 tok/s)\n",
      "step 1854/5000 | train loss 0.071507 | norm 0.2506 | lr 2.09e-05 | (113.13 ms | 36207 tok/s)\n",
      "step 1855/5000 | train loss 0.071479 | norm 0.2409 | lr 2.09e-05 | (113.91 ms | 35960 tok/s)\n",
      "step 1856/5000 | train loss 0.071454 | norm 0.2490 | lr 2.09e-05 | (112.54 ms | 36395 tok/s)\n",
      "step 1857/5000 | train loss 0.071442 | norm 0.2679 | lr 2.09e-05 | (121.70 ms | 33655 tok/s)\n",
      "step 1858/5000 | train loss 0.071427 | norm 0.2904 | lr 2.09e-05 | (117.25 ms | 34934 tok/s)\n",
      "step 1859/5000 | train loss 0.071418 | norm 0.3143 | lr 2.09e-05 | (115.79 ms | 35375 tok/s)\n",
      "step 1860/5000 | train loss 0.071396 | norm 0.3269 | lr 2.09e-05 | (114.89 ms | 35651 tok/s)\n",
      "step 1861/5000 | train loss 0.071359 | norm 0.3113 | lr 2.09e-05 | (118.11 ms | 34680 tok/s)\n",
      "step 1862/5000 | train loss 0.071317 | norm 0.2858 | lr 2.09e-05 | (118.99 ms | 34422 tok/s)\n",
      "step 1863/5000 | train loss 0.071300 | norm 0.2974 | lr 2.09e-05 | (118.07 ms | 34690 tok/s)\n",
      "step 1864/5000 | train loss 0.071271 | norm 0.3005 | lr 2.08e-05 | (114.73 ms | 35702 tok/s)\n",
      "step 1865/5000 | train loss 0.071292 | norm 0.3575 | lr 2.08e-05 | (116.22 ms | 35244 tok/s)\n",
      "step 1866/5000 | train loss 0.071262 | norm 0.3652 | lr 2.08e-05 | (114.59 ms | 35746 tok/s)\n",
      "step 1867/5000 | train loss 0.071185 | norm 0.2882 | lr 2.08e-05 | (117.59 ms | 34832 tok/s)\n",
      "step 1868/5000 | train loss 0.071159 | norm 0.2726 | lr 2.08e-05 | (113.56 ms | 36070 tok/s)\n",
      "step 1869/5000 | train loss 0.071156 | norm 0.3171 | lr 2.08e-05 | (115.06 ms | 35599 tok/s)\n",
      "step 1870/5000 | train loss 0.071134 | norm 0.3197 | lr 2.08e-05 | (112.80 ms | 36313 tok/s)\n",
      "step 1871/5000 | train loss 0.071083 | norm 0.2834 | lr 2.08e-05 | (114.64 ms | 35731 tok/s)\n",
      "step 1872/5000 | train loss 0.071061 | norm 0.2898 | lr 2.08e-05 | (112.72 ms | 36338 tok/s)\n",
      "step 1873/5000 | train loss 0.071044 | norm 0.3086 | lr 2.08e-05 | (114.19 ms | 35872 tok/s)\n",
      "step 1874/5000 | train loss 0.071046 | norm 0.3547 | lr 2.08e-05 | (113.51 ms | 36086 tok/s)\n",
      "step 1875/5000 | train loss 0.071048 | norm 0.4014 | lr 2.07e-05 | (116.31 ms | 35218 tok/s)\n",
      "step 1876/5000 | train loss 0.071012 | norm 0.4005 | lr 2.07e-05 | (119.19 ms | 34366 tok/s)\n",
      "step 1877/5000 | train loss 0.070966 | norm 0.3482 | lr 2.07e-05 | (133.98 ms | 30573 tok/s)\n",
      "step 1878/5000 | train loss 0.070913 | norm 0.2967 | lr 2.07e-05 | (113.21 ms | 36180 tok/s)\n",
      "step 1879/5000 | train loss 0.070896 | norm 0.3260 | lr 2.07e-05 | (113.60 ms | 36055 tok/s)\n",
      "step 1880/5000 | train loss 0.070910 | norm 0.3659 | lr 2.07e-05 | (112.54 ms | 36396 tok/s)\n",
      "step 1881/5000 | train loss 0.070838 | norm 0.2977 | lr 2.07e-05 | (114.02 ms | 35923 tok/s)\n",
      "step 1882/5000 | train loss 0.070806 | norm 0.2659 | lr 2.07e-05 | (116.44 ms | 35178 tok/s)\n",
      "step 1883/5000 | train loss 0.070783 | norm 0.2911 | lr 2.07e-05 | (117.56 ms | 34842 tok/s)\n",
      "step 1884/5000 | train loss 0.070761 | norm 0.2805 | lr 2.07e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 1885/5000 | train loss 0.070724 | norm 0.2797 | lr 2.07e-05 | (114.50 ms | 35774 tok/s)\n",
      "step 1886/5000 | train loss 0.070732 | norm 0.3270 | lr 2.07e-05 | (113.37 ms | 36129 tok/s)\n",
      "step 1887/5000 | train loss 0.070676 | norm 0.2790 | lr 2.06e-05 | (114.31 ms | 35833 tok/s)\n",
      "step 1888/5000 | train loss 0.070650 | norm 0.2757 | lr 2.06e-05 | (120.79 ms | 33911 tok/s)\n",
      "step 1889/5000 | train loss 0.070651 | norm 0.3123 | lr 2.06e-05 | (119.47 ms | 34283 tok/s)\n",
      "step 1890/5000 | train loss 0.070596 | norm 0.2683 | lr 2.06e-05 | (120.47 ms | 34000 tok/s)\n",
      "step 1891/5000 | train loss 0.070596 | norm 0.3016 | lr 2.06e-05 | (116.65 ms | 35113 tok/s)\n",
      "step 1892/5000 | train loss 0.070565 | norm 0.2898 | lr 2.06e-05 | (113.47 ms | 36098 tok/s)\n",
      "step 1893/5000 | train loss 0.070509 | norm 0.2383 | lr 2.06e-05 | (118.09 ms | 34686 tok/s)\n",
      "step 1894/5000 | train loss 0.070503 | norm 0.2581 | lr 2.06e-05 | (116.50 ms | 35159 tok/s)\n",
      "step 1895/5000 | train loss 0.070449 | norm 0.2281 | lr 2.06e-05 | (115.46 ms | 35474 tok/s)\n",
      "step 1896/5000 | train loss 0.070467 | norm 0.2779 | lr 2.06e-05 | (114.11 ms | 35894 tok/s)\n",
      "step 1897/5000 | train loss 0.070459 | norm 0.3111 | lr 2.06e-05 | (114.61 ms | 35737 tok/s)\n",
      "step 1898/5000 | train loss 0.070449 | norm 0.3373 | lr 2.05e-05 | (113.25 ms | 36168 tok/s)\n",
      "step 1899/5000 | train loss 0.070454 | norm 0.3788 | lr 2.05e-05 | (130.15 ms | 31472 tok/s)\n",
      "step 1900/5000 | train loss 0.070471 | norm 0.4193 | lr 2.05e-05 | (114.16 ms | 35881 tok/s)\n",
      "step 1901/5000 | train loss 0.070438 | norm 0.3948 | lr 2.05e-05 | (114.43 ms | 35796 tok/s)\n",
      "step 1902/5000 | train loss 0.070332 | norm 0.2918 | lr 2.05e-05 | (119.09 ms | 34395 tok/s)\n",
      "step 1903/5000 | train loss 0.070328 | norm 0.3146 | lr 2.05e-05 | (122.28 ms | 33498 tok/s)\n",
      "step 1904/5000 | train loss 0.070321 | norm 0.3406 | lr 2.05e-05 | (116.48 ms | 35166 tok/s)\n",
      "step 1905/5000 | train loss 0.070258 | norm 0.2810 | lr 2.05e-05 | (115.29 ms | 35527 tok/s)\n",
      "step 1906/5000 | train loss 0.070220 | norm 0.2508 | lr 2.05e-05 | (114.23 ms | 35858 tok/s)\n",
      "step 1907/5000 | train loss 0.070213 | norm 0.2783 | lr 2.05e-05 | (114.61 ms | 35740 tok/s)\n",
      "step 1908/5000 | train loss 0.070179 | norm 0.2692 | lr 2.05e-05 | (112.84 ms | 36299 tok/s)\n",
      "step 1909/5000 | train loss 0.070141 | norm 0.2336 | lr 2.05e-05 | (115.26 ms | 35536 tok/s)\n",
      "step 1910/5000 | train loss 0.070124 | norm 0.2449 | lr 2.04e-05 | (112.61 ms | 36373 tok/s)\n",
      "step 1911/5000 | train loss 0.070094 | norm 0.2428 | lr 2.04e-05 | (115.17 ms | 35564 tok/s)\n",
      "step 1912/5000 | train loss 0.070079 | norm 0.2533 | lr 2.04e-05 | (115.32 ms | 35518 tok/s)\n",
      "step 1913/5000 | train loss 0.070063 | norm 0.2696 | lr 2.04e-05 | (115.13 ms | 35578 tok/s)\n",
      "step 1914/5000 | train loss 0.070053 | norm 0.3002 | lr 2.04e-05 | (114.38 ms | 35810 tok/s)\n",
      "step 1915/5000 | train loss 0.070066 | norm 0.3525 | lr 2.04e-05 | (114.30 ms | 35836 tok/s)\n",
      "step 1916/5000 | train loss 0.070050 | norm 0.3685 | lr 2.04e-05 | (114.02 ms | 35923 tok/s)\n",
      "step 1917/5000 | train loss 0.070038 | norm 0.3738 | lr 2.04e-05 | (114.83 ms | 35671 tok/s)\n",
      "step 1918/5000 | train loss 0.069956 | norm 0.2824 | lr 2.04e-05 | (114.24 ms | 35855 tok/s)\n",
      "step 1919/5000 | train loss 0.069904 | norm 0.2203 | lr 2.04e-05 | (114.51 ms | 35770 tok/s)\n",
      "step 1920/5000 | train loss 0.069928 | norm 0.2953 | lr 2.04e-05 | (113.81 ms | 35989 tok/s)\n",
      "step 1921/5000 | train loss 0.069919 | norm 0.3180 | lr 2.03e-05 | (113.60 ms | 36055 tok/s)\n",
      "step 1922/5000 | train loss 0.069885 | norm 0.2973 | lr 2.03e-05 | (115.58 ms | 35440 tok/s)\n",
      "step 1923/5000 | train loss 0.069848 | norm 0.2757 | lr 2.03e-05 | (114.93 ms | 35638 tok/s)\n",
      "step 1924/5000 | train loss 0.069817 | norm 0.2606 | lr 2.03e-05 | (112.98 ms | 36253 tok/s)\n",
      "step 1925/5000 | train loss 0.069812 | norm 0.3040 | lr 2.03e-05 | (114.72 ms | 35706 tok/s)\n",
      "step 1926/5000 | train loss 0.069813 | norm 0.3266 | lr 2.03e-05 | (113.21 ms | 36181 tok/s)\n",
      "step 1927/5000 | train loss 0.069753 | norm 0.2677 | lr 2.03e-05 | (114.01 ms | 35927 tok/s)\n",
      "step 1928/5000 | train loss 0.069725 | norm 0.2557 | lr 2.03e-05 | (114.37 ms | 35814 tok/s)\n",
      "step 1929/5000 | train loss 0.069703 | norm 0.2709 | lr 2.03e-05 | (114.79 ms | 35684 tok/s)\n",
      "step 1930/5000 | train loss 0.069713 | norm 0.3107 | lr 2.03e-05 | (112.78 ms | 36319 tok/s)\n",
      "step 1931/5000 | train loss 0.069684 | norm 0.2961 | lr 2.03e-05 | (114.08 ms | 35905 tok/s)\n",
      "step 1932/5000 | train loss 0.069652 | norm 0.2854 | lr 2.03e-05 | (112.61 ms | 36372 tok/s)\n",
      "step 1933/5000 | train loss 0.069669 | norm 0.3371 | lr 2.02e-05 | (114.37 ms | 35814 tok/s)\n",
      "step 1934/5000 | train loss 0.069627 | norm 0.3282 | lr 2.02e-05 | (113.27 ms | 36163 tok/s)\n",
      "step 1935/5000 | train loss 0.069601 | norm 0.3113 | lr 2.02e-05 | (113.37 ms | 36130 tok/s)\n",
      "step 1936/5000 | train loss 0.069580 | norm 0.3176 | lr 2.02e-05 | (113.82 ms | 35988 tok/s)\n",
      "step 1937/5000 | train loss 0.069583 | norm 0.3418 | lr 2.02e-05 | (113.92 ms | 35956 tok/s)\n",
      "step 1938/5000 | train loss 0.069546 | norm 0.3145 | lr 2.02e-05 | (113.01 ms | 36246 tok/s)\n",
      "step 1939/5000 | train loss 0.069493 | norm 0.2635 | lr 2.02e-05 | (114.53 ms | 35762 tok/s)\n",
      "step 1940/5000 | train loss 0.069476 | norm 0.2748 | lr 2.02e-05 | (112.84 ms | 36301 tok/s)\n",
      "step 1941/5000 | train loss 0.069474 | norm 0.2888 | lr 2.02e-05 | (113.89 ms | 35965 tok/s)\n",
      "step 1942/5000 | train loss 0.069397 | norm 0.2037 | lr 2.02e-05 | (112.55 ms | 36394 tok/s)\n",
      "step 1943/5000 | train loss 0.069399 | norm 0.2356 | lr 2.02e-05 | (115.79 ms | 35373 tok/s)\n",
      "step 1944/5000 | train loss 0.069382 | norm 0.2487 | lr 2.01e-05 | (113.63 ms | 36048 tok/s)\n",
      "step 1945/5000 | train loss 0.069347 | norm 0.2203 | lr 2.01e-05 | (113.49 ms | 36091 tok/s)\n",
      "step 1946/5000 | train loss 0.069320 | norm 0.2150 | lr 2.01e-05 | (113.03 ms | 36239 tok/s)\n",
      "step 1947/5000 | train loss 0.069310 | norm 0.2269 | lr 2.01e-05 | (114.98 ms | 35625 tok/s)\n",
      "step 1948/5000 | train loss 0.069274 | norm 0.2133 | lr 2.01e-05 | (112.98 ms | 36255 tok/s)\n",
      "step 1949/5000 | train loss 0.069273 | norm 0.2356 | lr 2.01e-05 | (113.41 ms | 36117 tok/s)\n",
      "step 1950/5000 | train loss 0.069244 | norm 0.2430 | lr 2.01e-05 | (112.99 ms | 36249 tok/s)\n",
      "step 1951/5000 | train loss 0.069276 | norm 0.3201 | lr 2.01e-05 | (112.88 ms | 36285 tok/s)\n",
      "step 1952/5000 | train loss 0.069296 | norm 0.3799 | lr 2.01e-05 | (112.90 ms | 36281 tok/s)\n",
      "step 1953/5000 | train loss 0.069306 | norm 0.4070 | lr 2.01e-05 | (115.08 ms | 35593 tok/s)\n",
      "step 1954/5000 | train loss 0.069261 | norm 0.3690 | lr 2.01e-05 | (114.07 ms | 35909 tok/s)\n",
      "step 1955/5000 | train loss 0.069223 | norm 0.3585 | lr 2.00e-05 | (114.15 ms | 35883 tok/s)\n",
      "step 1956/5000 | train loss 0.069294 | norm 0.4298 | lr 2.00e-05 | (113.70 ms | 36025 tok/s)\n",
      "step 1957/5000 | train loss 0.069181 | norm 0.3408 | lr 2.00e-05 | (114.35 ms | 35821 tok/s)\n",
      "step 1958/5000 | train loss 0.069193 | norm 0.3884 | lr 2.00e-05 | (112.52 ms | 36403 tok/s)\n",
      "step 1959/5000 | train loss 0.069225 | norm 0.4108 | lr 2.00e-05 | (113.30 ms | 36153 tok/s)\n",
      "step 1960/5000 | train loss 0.069084 | norm 0.2641 | lr 2.00e-05 | (114.10 ms | 35898 tok/s)\n",
      "step 1961/5000 | train loss 0.069140 | norm 0.3541 | lr 2.00e-05 | (114.07 ms | 35909 tok/s)\n",
      "step 1962/5000 | train loss 0.069014 | norm 0.2249 | lr 2.00e-05 | (113.53 ms | 36080 tok/s)\n",
      "step 1963/5000 | train loss 0.069071 | norm 0.3084 | lr 2.00e-05 | (115.67 ms | 35410 tok/s)\n",
      "step 1964/5000 | train loss 0.068972 | norm 0.2123 | lr 2.00e-05 | (113.58 ms | 36063 tok/s)\n",
      "step 1965/5000 | train loss 0.069000 | norm 0.2744 | lr 2.00e-05 | (115.17 ms | 35565 tok/s)\n",
      "step 1966/5000 | train loss 0.068945 | norm 0.2229 | lr 1.99e-05 | (113.56 ms | 36071 tok/s)\n",
      "step 1967/5000 | train loss 0.068924 | norm 0.2117 | lr 1.99e-05 | (113.04 ms | 36235 tok/s)\n",
      "step 1968/5000 | train loss 0.068890 | norm 0.1959 | lr 1.99e-05 | (112.97 ms | 36256 tok/s)\n",
      "step 1969/5000 | train loss 0.068887 | norm 0.2279 | lr 1.99e-05 | (115.67 ms | 35411 tok/s)\n",
      "step 1970/5000 | train loss 0.068848 | norm 0.1935 | lr 1.99e-05 | (113.82 ms | 35987 tok/s)\n",
      "step 1971/5000 | train loss 0.068850 | norm 0.2263 | lr 1.99e-05 | (115.50 ms | 35462 tok/s)\n",
      "step 1972/5000 | train loss 0.068824 | norm 0.2406 | lr 1.99e-05 | (113.16 ms | 36195 tok/s)\n",
      "step 1973/5000 | train loss 0.068850 | norm 0.3059 | lr 1.99e-05 | (114.51 ms | 35770 tok/s)\n",
      "step 1974/5000 | train loss 0.068840 | norm 0.3507 | lr 1.99e-05 | (114.69 ms | 35714 tok/s)\n",
      "step 1975/5000 | train loss 0.068890 | norm 0.4138 | lr 1.99e-05 | (115.60 ms | 35434 tok/s)\n",
      "step 1976/5000 | train loss 0.068828 | norm 0.3872 | lr 1.99e-05 | (114.26 ms | 35849 tok/s)\n",
      "step 1977/5000 | train loss 0.068844 | norm 0.4047 | lr 1.99e-05 | (114.73 ms | 35701 tok/s)\n",
      "step 1978/5000 | train loss 0.068836 | norm 0.4281 | lr 1.98e-05 | (113.13 ms | 36205 tok/s)\n",
      "step 1979/5000 | train loss 0.068793 | norm 0.3876 | lr 1.98e-05 | (113.87 ms | 35970 tok/s)\n",
      "step 1980/5000 | train loss 0.068704 | norm 0.2939 | lr 1.98e-05 | (112.55 ms | 36392 tok/s)\n",
      "step 1981/5000 | train loss 0.068760 | norm 0.3850 | lr 1.98e-05 | (115.63 ms | 35423 tok/s)\n",
      "step 1982/5000 | train loss 0.068710 | norm 0.3538 | lr 1.98e-05 | (114.47 ms | 35783 tok/s)\n",
      "step 1983/5000 | train loss 0.068637 | norm 0.2528 | lr 1.98e-05 | (112.76 ms | 36325 tok/s)\n",
      "step 1984/5000 | train loss 0.068675 | norm 0.3326 | lr 1.98e-05 | (112.83 ms | 36303 tok/s)\n",
      "step 1985/5000 | train loss 0.068617 | norm 0.2936 | lr 1.98e-05 | (113.64 ms | 36043 tok/s)\n",
      "step 1986/5000 | train loss 0.068570 | norm 0.2373 | lr 1.98e-05 | (111.71 ms | 36666 tok/s)\n",
      "step 1987/5000 | train loss 0.068609 | norm 0.3181 | lr 1.98e-05 | (114.77 ms | 35690 tok/s)\n",
      "step 1988/5000 | train loss 0.068528 | norm 0.2323 | lr 1.98e-05 | (113.72 ms | 36018 tok/s)\n",
      "step 1989/5000 | train loss 0.068524 | norm 0.2445 | lr 1.97e-05 | (114.01 ms | 35926 tok/s)\n",
      "step 1990/5000 | train loss 0.068521 | norm 0.2839 | lr 1.97e-05 | (113.31 ms | 36148 tok/s)\n",
      "step 1991/5000 | train loss 0.068467 | norm 0.2057 | lr 1.97e-05 | (115.61 ms | 35428 tok/s)\n",
      "step 1992/5000 | train loss 0.068459 | norm 0.2338 | lr 1.97e-05 | (112.52 ms | 36401 tok/s)\n",
      "step 1993/5000 | train loss 0.068479 | norm 0.2892 | lr 1.97e-05 | (115.15 ms | 35571 tok/s)\n",
      "step 1994/5000 | train loss 0.068433 | norm 0.2552 | lr 1.97e-05 | (113.34 ms | 36138 tok/s)\n",
      "step 1995/5000 | train loss 0.068447 | norm 0.3060 | lr 1.97e-05 | (114.74 ms | 35698 tok/s)\n",
      "step 1996/5000 | train loss 0.068425 | norm 0.3037 | lr 1.97e-05 | (113.15 ms | 36199 tok/s)\n",
      "step 1997/5000 | train loss 0.068385 | norm 0.2708 | lr 1.97e-05 | (114.58 ms | 35748 tok/s)\n",
      "step 1998/5000 | train loss 0.068412 | norm 0.3366 | lr 1.97e-05 | (114.24 ms | 35854 tok/s)\n",
      "step 1999/5000 | train loss 0.068418 | norm 0.3773 | lr 1.97e-05 | (114.47 ms | 35783 tok/s)\n",
      "step 2000/5000 | train loss 0.068415 | norm 0.3894 | lr 1.96e-05 | (113.75 ms | 36007 tok/s)\n",
      "step 2001/5000 | train loss 0.068365 | norm 0.3416 | lr 1.96e-05 | (115.13 ms | 35578 tok/s)\n",
      "step 2002/5000 | train loss 0.068319 | norm 0.2910 | lr 1.96e-05 | (113.61 ms | 36054 tok/s)\n",
      "step 2003/5000 | train loss 0.068304 | norm 0.2939 | lr 1.96e-05 | (112.80 ms | 36313 tok/s)\n",
      "step 2004/5000 | train loss 0.068271 | norm 0.2687 | lr 1.96e-05 | (113.82 ms | 35988 tok/s)\n",
      "step 2005/5000 | train loss 0.068239 | norm 0.2493 | lr 1.96e-05 | (114.29 ms | 35840 tok/s)\n",
      "step 2006/5000 | train loss 0.068241 | norm 0.2769 | lr 1.96e-05 | (114.34 ms | 35823 tok/s)\n",
      "step 2007/5000 | train loss 0.068207 | norm 0.2491 | lr 1.96e-05 | (116.97 ms | 35017 tok/s)\n",
      "step 2008/5000 | train loss 0.068171 | norm 0.2058 | lr 1.96e-05 | (114.22 ms | 35860 tok/s)\n",
      "step 2009/5000 | train loss 0.068161 | norm 0.2279 | lr 1.96e-05 | (117.83 ms | 34762 tok/s)\n",
      "step 2010/5000 | train loss 0.068145 | norm 0.2306 | lr 1.96e-05 | (116.59 ms | 35131 tok/s)\n",
      "step 2011/5000 | train loss 0.068116 | norm 0.1945 | lr 1.95e-05 | (116.35 ms | 35203 tok/s)\n",
      "step 2012/5000 | train loss 0.068088 | norm 0.1841 | lr 1.95e-05 | (113.33 ms | 36143 tok/s)\n",
      "step 2013/5000 | train loss 0.068095 | norm 0.2247 | lr 1.95e-05 | (114.66 ms | 35723 tok/s)\n",
      "step 2014/5000 | train loss 0.068070 | norm 0.2154 | lr 1.95e-05 | (115.16 ms | 35567 tok/s)\n",
      "step 2015/5000 | train loss 0.068058 | norm 0.2266 | lr 1.95e-05 | (114.96 ms | 35629 tok/s)\n",
      "step 2016/5000 | train loss 0.068068 | norm 0.2878 | lr 1.95e-05 | (113.22 ms | 36178 tok/s)\n",
      "step 2017/5000 | train loss 0.068096 | norm 0.3425 | lr 1.95e-05 | (120.52 ms | 33987 tok/s)\n",
      "step 2018/5000 | train loss 0.068069 | norm 0.3348 | lr 1.95e-05 | (115.81 ms | 35367 tok/s)\n",
      "step 2019/5000 | train loss 0.068029 | norm 0.2996 | lr 1.95e-05 | (114.46 ms | 35784 tok/s)\n",
      "step 2020/5000 | train loss 0.068007 | norm 0.2915 | lr 1.95e-05 | (115.78 ms | 35376 tok/s)\n",
      "step 2021/5000 | train loss 0.067993 | norm 0.3002 | lr 1.95e-05 | (119.18 ms | 34368 tok/s)\n",
      "step 2022/5000 | train loss 0.067968 | norm 0.2767 | lr 1.94e-05 | (117.48 ms | 34866 tok/s)\n",
      "step 2023/5000 | train loss 0.067933 | norm 0.2443 | lr 1.94e-05 | (117.10 ms | 34977 tok/s)\n",
      "step 2024/5000 | train loss 0.067939 | norm 0.2815 | lr 1.94e-05 | (113.61 ms | 36052 tok/s)\n",
      "step 2025/5000 | train loss 0.067930 | norm 0.2944 | lr 1.94e-05 | (114.64 ms | 35729 tok/s)\n",
      "step 2026/5000 | train loss 0.067893 | norm 0.2653 | lr 1.94e-05 | (117.30 ms | 34920 tok/s)\n",
      "step 2027/5000 | train loss 0.067881 | norm 0.2781 | lr 1.94e-05 | (119.84 ms | 34178 tok/s)\n",
      "step 2028/5000 | train loss 0.067879 | norm 0.2873 | lr 1.94e-05 | (115.41 ms | 35490 tok/s)\n",
      "step 2029/5000 | train loss 0.067824 | norm 0.2348 | lr 1.94e-05 | (114.78 ms | 35686 tok/s)\n",
      "step 2030/5000 | train loss 0.067842 | norm 0.2898 | lr 1.94e-05 | (114.62 ms | 35736 tok/s)\n",
      "step 2031/5000 | train loss 0.067835 | norm 0.3066 | lr 1.94e-05 | (115.84 ms | 35359 tok/s)\n",
      "step 2032/5000 | train loss 0.067785 | norm 0.2483 | lr 1.94e-05 | (115.71 ms | 35398 tok/s)\n",
      "step 2033/5000 | train loss 0.067765 | norm 0.2341 | lr 1.93e-05 | (116.16 ms | 35260 tok/s)\n",
      "step 2034/5000 | train loss 0.067762 | norm 0.2505 | lr 1.93e-05 | (113.11 ms | 36212 tok/s)\n",
      "step 2035/5000 | train loss 0.067737 | norm 0.2494 | lr 1.93e-05 | (115.51 ms | 35461 tok/s)\n",
      "step 2036/5000 | train loss 0.067762 | norm 0.3057 | lr 1.93e-05 | (119.57 ms | 34256 tok/s)\n",
      "step 2037/5000 | train loss 0.067754 | norm 0.3237 | lr 1.93e-05 | (119.18 ms | 34367 tok/s)\n",
      "step 2038/5000 | train loss 0.067752 | norm 0.3452 | lr 1.93e-05 | (116.87 ms | 35047 tok/s)\n",
      "step 2039/5000 | train loss 0.067742 | norm 0.3574 | lr 1.93e-05 | (118.90 ms | 34449 tok/s)\n",
      "step 2040/5000 | train loss 0.067707 | norm 0.3191 | lr 1.93e-05 | (118.82 ms | 34472 tok/s)\n",
      "step 2041/5000 | train loss 0.067659 | norm 0.2673 | lr 1.93e-05 | (117.32 ms | 34914 tok/s)\n",
      "step 2042/5000 | train loss 0.067649 | norm 0.2810 | lr 1.93e-05 | (113.26 ms | 36166 tok/s)\n",
      "step 2043/5000 | train loss 0.067648 | norm 0.2904 | lr 1.93e-05 | (117.18 ms | 34954 tok/s)\n",
      "step 2044/5000 | train loss 0.067603 | norm 0.2440 | lr 1.92e-05 | (113.32 ms | 36144 tok/s)\n",
      "step 2045/5000 | train loss 0.067589 | norm 0.2481 | lr 1.92e-05 | (113.92 ms | 35956 tok/s)\n",
      "step 2046/5000 | train loss 0.067567 | norm 0.2320 | lr 1.92e-05 | (113.78 ms | 35999 tok/s)\n",
      "step 2047/5000 | train loss 0.067560 | norm 0.2489 | lr 1.92e-05 | (115.36 ms | 35505 tok/s)\n",
      "step 2048/5000 | train loss 0.067553 | norm 0.2649 | lr 1.92e-05 | (116.36 ms | 35200 tok/s)\n",
      "step 2049/5000 | train loss 0.067516 | norm 0.2260 | lr 1.92e-05 | (119.07 ms | 34401 tok/s)\n",
      "step 2050/5000 | train loss 0.067535 | norm 0.2762 | lr 1.92e-05 | (114.01 ms | 35925 tok/s)\n",
      "step 2051/5000 | train loss 0.067523 | norm 0.2988 | lr 1.92e-05 | (115.75 ms | 35386 tok/s)\n",
      "step 2052/5000 | train loss 0.067521 | norm 0.3114 | lr 1.92e-05 | (113.66 ms | 36038 tok/s)\n",
      "step 2053/5000 | train loss 0.067486 | norm 0.2816 | lr 1.92e-05 | (115.16 ms | 35566 tok/s)\n",
      "step 2054/5000 | train loss 0.067447 | norm 0.2423 | lr 1.92e-05 | (118.17 ms | 34663 tok/s)\n",
      "step 2055/5000 | train loss 0.067447 | norm 0.2547 | lr 1.91e-05 | (115.85 ms | 35357 tok/s)\n",
      "step 2056/5000 | train loss 0.067409 | norm 0.2299 | lr 1.91e-05 | (114.18 ms | 35873 tok/s)\n",
      "step 2057/5000 | train loss 0.067421 | norm 0.2688 | lr 1.91e-05 | (115.27 ms | 35535 tok/s)\n",
      "step 2058/5000 | train loss 0.067387 | norm 0.2538 | lr 1.91e-05 | (113.63 ms | 36047 tok/s)\n",
      "step 2059/5000 | train loss 0.067385 | norm 0.2679 | lr 1.91e-05 | (116.98 ms | 35016 tok/s)\n",
      "step 2060/5000 | train loss 0.067382 | norm 0.2902 | lr 1.91e-05 | (118.58 ms | 34543 tok/s)\n",
      "step 2061/5000 | train loss 0.067378 | norm 0.3110 | lr 1.91e-05 | (118.80 ms | 34478 tok/s)\n",
      "step 2062/5000 | train loss 0.067364 | norm 0.3171 | lr 1.91e-05 | (118.38 ms | 34601 tok/s)\n",
      "step 2063/5000 | train loss 0.067314 | norm 0.2489 | lr 1.91e-05 | (119.96 ms | 34144 tok/s)\n",
      "step 2064/5000 | train loss 0.067278 | norm 0.1968 | lr 1.91e-05 | (117.12 ms | 34971 tok/s)\n",
      "step 2065/5000 | train loss 0.067281 | norm 0.2376 | lr 1.91e-05 | (117.88 ms | 34746 tok/s)\n",
      "step 2066/5000 | train loss 0.067270 | norm 0.2545 | lr 1.91e-05 | (118.33 ms | 34614 tok/s)\n",
      "step 2067/5000 | train loss 0.067250 | norm 0.2349 | lr 1.90e-05 | (118.91 ms | 34446 tok/s)\n",
      "step 2068/5000 | train loss 0.067238 | norm 0.2305 | lr 1.90e-05 | (114.71 ms | 35708 tok/s)\n",
      "step 2069/5000 | train loss 0.067245 | norm 0.2783 | lr 1.90e-05 | (115.98 ms | 35317 tok/s)\n",
      "step 2070/5000 | train loss 0.067255 | norm 0.3057 | lr 1.90e-05 | (115.19 ms | 35559 tok/s)\n",
      "step 2071/5000 | train loss 0.067196 | norm 0.2398 | lr 1.90e-05 | (116.93 ms | 35029 tok/s)\n",
      "step 2072/5000 | train loss 0.067164 | norm 0.2038 | lr 1.90e-05 | (120.86 ms | 33891 tok/s)\n",
      "step 2073/5000 | train loss 0.067161 | norm 0.2304 | lr 1.90e-05 | (117.23 ms | 34940 tok/s)\n",
      "step 2074/5000 | train loss 0.067161 | norm 0.2538 | lr 1.90e-05 | (119.35 ms | 34320 tok/s)\n",
      "step 2075/5000 | train loss 0.067139 | norm 0.2479 | lr 1.90e-05 | (117.17 ms | 34959 tok/s)\n",
      "step 2076/5000 | train loss 0.067150 | norm 0.2930 | lr 1.90e-05 | (114.59 ms | 35745 tok/s)\n",
      "step 2077/5000 | train loss 0.067171 | norm 0.3454 | lr 1.90e-05 | (117.25 ms | 34935 tok/s)\n",
      "step 2078/5000 | train loss 0.067142 | norm 0.3234 | lr 1.89e-05 | (112.85 ms | 36295 tok/s)\n",
      "step 2079/5000 | train loss 0.067106 | norm 0.2931 | lr 1.89e-05 | (112.55 ms | 36394 tok/s)\n",
      "step 2080/5000 | train loss 0.067100 | norm 0.2900 | lr 1.89e-05 | (112.03 ms | 36561 tok/s)\n",
      "step 2081/5000 | train loss 0.067070 | norm 0.2895 | lr 1.89e-05 | (113.13 ms | 36207 tok/s)\n",
      "step 2082/5000 | train loss 0.067134 | norm 0.3728 | lr 1.89e-05 | (115.45 ms | 35477 tok/s)\n",
      "step 2083/5000 | train loss 0.067056 | norm 0.3088 | lr 1.89e-05 | (115.45 ms | 35479 tok/s)\n",
      "step 2084/5000 | train loss 0.067041 | norm 0.2708 | lr 1.89e-05 | (113.74 ms | 36011 tok/s)\n",
      "step 2085/5000 | train loss 0.067005 | norm 0.2569 | lr 1.89e-05 | (114.48 ms | 35780 tok/s)\n",
      "step 2086/5000 | train loss 0.067015 | norm 0.2782 | lr 1.89e-05 | (115.56 ms | 35444 tok/s)\n",
      "step 2087/5000 | train loss 0.066990 | norm 0.2655 | lr 1.89e-05 | (116.69 ms | 35100 tok/s)\n",
      "step 2088/5000 | train loss 0.066974 | norm 0.2570 | lr 1.89e-05 | (113.39 ms | 36123 tok/s)\n",
      "step 2089/5000 | train loss 0.066931 | norm 0.2112 | lr 1.88e-05 | (114.88 ms | 35655 tok/s)\n",
      "step 2090/5000 | train loss 0.066928 | norm 0.2265 | lr 1.88e-05 | (114.05 ms | 35913 tok/s)\n",
      "step 2091/5000 | train loss 0.066916 | norm 0.2266 | lr 1.88e-05 | (116.20 ms | 35248 tok/s)\n",
      "step 2092/5000 | train loss 0.066877 | norm 0.1764 | lr 1.88e-05 | (115.32 ms | 35520 tok/s)\n",
      "step 2093/5000 | train loss 0.066891 | norm 0.2304 | lr 1.88e-05 | (121.31 ms | 33766 tok/s)\n",
      "step 2094/5000 | train loss 0.066878 | norm 0.2420 | lr 1.88e-05 | (116.58 ms | 35136 tok/s)\n",
      "step 2095/5000 | train loss 0.066876 | norm 0.2593 | lr 1.88e-05 | (118.01 ms | 34710 tok/s)\n",
      "step 2096/5000 | train loss 0.066887 | norm 0.3048 | lr 1.88e-05 | (120.30 ms | 34048 tok/s)\n",
      "step 2097/5000 | train loss 0.066890 | norm 0.3306 | lr 1.88e-05 | (121.53 ms | 33702 tok/s)\n",
      "step 2098/5000 | train loss 0.066857 | norm 0.3148 | lr 1.88e-05 | (121.10 ms | 33824 tok/s)\n",
      "step 2099/5000 | train loss 0.066848 | norm 0.2993 | lr 1.87e-05 | (124.47 ms | 32907 tok/s)\n",
      "step 2100/5000 | train loss 0.066799 | norm 0.2410 | lr 1.87e-05 | (118.92 ms | 34443 tok/s)\n",
      "step 2101/5000 | train loss 0.066801 | norm 0.2637 | lr 1.87e-05 | (119.50 ms | 34275 tok/s)\n",
      "step 2102/5000 | train loss 0.066791 | norm 0.2838 | lr 1.87e-05 | (120.77 ms | 33917 tok/s)\n",
      "step 2103/5000 | train loss 0.066763 | norm 0.2649 | lr 1.87e-05 | (131.08 ms | 31249 tok/s)\n",
      "step 2104/5000 | train loss 0.066765 | norm 0.2667 | lr 1.87e-05 | (124.03 ms | 33024 tok/s)\n",
      "step 2105/5000 | train loss 0.066730 | norm 0.2340 | lr 1.87e-05 | (124.55 ms | 32887 tok/s)\n",
      "step 2106/5000 | train loss 0.066716 | norm 0.2340 | lr 1.87e-05 | (124.00 ms | 33032 tok/s)\n",
      "step 2107/5000 | train loss 0.066714 | norm 0.2561 | lr 1.87e-05 | (123.06 ms | 33284 tok/s)\n",
      "step 2108/5000 | train loss 0.066686 | norm 0.2266 | lr 1.87e-05 | (121.58 ms | 33691 tok/s)\n",
      "step 2109/5000 | train loss 0.066666 | norm 0.2204 | lr 1.87e-05 | (121.99 ms | 33576 tok/s)\n",
      "step 2110/5000 | train loss 0.066679 | norm 0.2693 | lr 1.86e-05 | (124.97 ms | 32775 tok/s)\n",
      "step 2111/5000 | train loss 0.066676 | norm 0.2862 | lr 1.86e-05 | (121.51 ms | 33709 tok/s)\n",
      "step 2112/5000 | train loss 0.066650 | norm 0.2604 | lr 1.86e-05 | (124.11 ms | 33004 tok/s)\n",
      "step 2113/5000 | train loss 0.066620 | norm 0.2283 | lr 1.86e-05 | (123.63 ms | 33130 tok/s)\n",
      "step 2114/5000 | train loss 0.066609 | norm 0.2254 | lr 1.86e-05 | (123.43 ms | 33184 tok/s)\n",
      "step 2115/5000 | train loss 0.066603 | norm 0.2339 | lr 1.86e-05 | (124.07 ms | 33015 tok/s)\n",
      "step 2116/5000 | train loss 0.066575 | norm 0.2176 | lr 1.86e-05 | (122.52 ms | 33431 tok/s)\n",
      "step 2117/5000 | train loss 0.066595 | norm 0.2664 | lr 1.86e-05 | (123.20 ms | 33248 tok/s)\n",
      "step 2118/5000 | train loss 0.066591 | norm 0.2879 | lr 1.86e-05 | (120.81 ms | 33904 tok/s)\n",
      "step 2119/5000 | train loss 0.066570 | norm 0.2752 | lr 1.86e-05 | (121.03 ms | 33842 tok/s)\n",
      "step 2120/5000 | train loss 0.066533 | norm 0.2312 | lr 1.86e-05 | (123.47 ms | 33175 tok/s)\n",
      "step 2121/5000 | train loss 0.066516 | norm 0.2095 | lr 1.85e-05 | (121.49 ms | 33714 tok/s)\n",
      "step 2122/5000 | train loss 0.066500 | norm 0.2248 | lr 1.85e-05 | (118.77 ms | 34487 tok/s)\n",
      "step 2123/5000 | train loss 0.066519 | norm 0.2755 | lr 1.85e-05 | (121.27 ms | 33776 tok/s)\n",
      "step 2124/5000 | train loss 0.066506 | norm 0.2753 | lr 1.85e-05 | (125.11 ms | 32738 tok/s)\n",
      "step 2125/5000 | train loss 0.066510 | norm 0.2897 | lr 1.85e-05 | (123.67 ms | 33119 tok/s)\n",
      "step 2126/5000 | train loss 0.066505 | norm 0.3063 | lr 1.85e-05 | (122.45 ms | 33451 tok/s)\n",
      "step 2127/5000 | train loss 0.066491 | norm 0.3038 | lr 1.85e-05 | (120.57 ms | 33971 tok/s)\n",
      "step 2128/5000 | train loss 0.066465 | norm 0.2879 | lr 1.85e-05 | (118.91 ms | 34445 tok/s)\n",
      "step 2129/5000 | train loss 0.066458 | norm 0.2869 | lr 1.85e-05 | (121.79 ms | 33631 tok/s)\n",
      "step 2130/5000 | train loss 0.066437 | norm 0.2723 | lr 1.85e-05 | (122.52 ms | 33431 tok/s)\n",
      "step 2131/5000 | train loss 0.066410 | norm 0.2359 | lr 1.85e-05 | (120.22 ms | 34072 tok/s)\n",
      "step 2132/5000 | train loss 0.066382 | norm 0.2140 | lr 1.84e-05 | (120.49 ms | 33994 tok/s)\n",
      "step 2133/5000 | train loss 0.066385 | norm 0.2456 | lr 1.84e-05 | (124.40 ms | 32926 tok/s)\n",
      "step 2134/5000 | train loss 0.066369 | norm 0.2397 | lr 1.84e-05 | (123.19 ms | 33251 tok/s)\n",
      "step 2135/5000 | train loss 0.066351 | norm 0.2189 | lr 1.84e-05 | (123.87 ms | 33068 tok/s)\n",
      "step 2136/5000 | train loss 0.066322 | norm 0.1925 | lr 1.84e-05 | (122.00 ms | 33572 tok/s)\n",
      "step 2137/5000 | train loss 0.066320 | norm 0.2069 | lr 1.84e-05 | (120.70 ms | 33937 tok/s)\n",
      "step 2138/5000 | train loss 0.066307 | norm 0.2055 | lr 1.84e-05 | (117.65 ms | 34814 tok/s)\n",
      "step 2139/5000 | train loss 0.066288 | norm 0.2005 | lr 1.84e-05 | (120.72 ms | 33929 tok/s)\n",
      "step 2140/5000 | train loss 0.066296 | norm 0.2398 | lr 1.84e-05 | (118.83 ms | 34470 tok/s)\n",
      "step 2141/5000 | train loss 0.066304 | norm 0.2873 | lr 1.84e-05 | (120.55 ms | 33978 tok/s)\n",
      "step 2142/5000 | train loss 0.066322 | norm 0.3306 | lr 1.84e-05 | (123.15 ms | 33260 tok/s)\n",
      "step 2143/5000 | train loss 0.066289 | norm 0.3053 | lr 1.83e-05 | (119.37 ms | 34314 tok/s)\n",
      "step 2144/5000 | train loss 0.066258 | norm 0.2590 | lr 1.83e-05 | (120.78 ms | 33914 tok/s)\n",
      "step 2145/5000 | train loss 0.066236 | norm 0.2372 | lr 1.83e-05 | (120.72 ms | 33930 tok/s)\n",
      "step 2146/5000 | train loss 0.066231 | norm 0.2513 | lr 1.83e-05 | (115.71 ms | 35400 tok/s)\n",
      "step 2147/5000 | train loss 0.066228 | norm 0.2734 | lr 1.83e-05 | (117.28 ms | 34924 tok/s)\n",
      "step 2148/5000 | train loss 0.066235 | norm 0.3031 | lr 1.83e-05 | (118.63 ms | 34527 tok/s)\n",
      "step 2149/5000 | train loss 0.066218 | norm 0.2890 | lr 1.83e-05 | (138.43 ms | 29589 tok/s)\n",
      "step 2150/5000 | train loss 0.066200 | norm 0.2854 | lr 1.83e-05 | (114.87 ms | 35657 tok/s)\n",
      "step 2151/5000 | train loss 0.066227 | norm 0.3291 | lr 1.83e-05 | (116.80 ms | 35067 tok/s)\n",
      "step 2152/5000 | train loss 0.066189 | norm 0.3059 | lr 1.83e-05 | (113.62 ms | 36049 tok/s)\n",
      "step 2153/5000 | train loss 0.066166 | norm 0.2585 | lr 1.83e-05 | (113.97 ms | 35940 tok/s)\n",
      "step 2154/5000 | train loss 0.066129 | norm 0.2378 | lr 1.82e-05 | (113.94 ms | 35949 tok/s)\n",
      "step 2155/5000 | train loss 0.066155 | norm 0.2931 | lr 1.82e-05 | (114.21 ms | 35864 tok/s)\n",
      "step 2156/5000 | train loss 0.066120 | norm 0.2516 | lr 1.82e-05 | (113.20 ms | 36182 tok/s)\n",
      "step 2157/5000 | train loss 0.066086 | norm 0.2076 | lr 1.82e-05 | (114.82 ms | 35674 tok/s)\n",
      "step 2158/5000 | train loss 0.066096 | norm 0.2514 | lr 1.82e-05 | (114.11 ms | 35895 tok/s)\n",
      "step 2159/5000 | train loss 0.066070 | norm 0.2273 | lr 1.82e-05 | (116.74 ms | 35088 tok/s)\n",
      "step 2160/5000 | train loss 0.066046 | norm 0.1907 | lr 1.82e-05 | (112.94 ms | 36267 tok/s)\n",
      "step 2161/5000 | train loss 0.066035 | norm 0.2013 | lr 1.82e-05 | (114.36 ms | 35817 tok/s)\n",
      "step 2162/5000 | train loss 0.066032 | norm 0.2175 | lr 1.82e-05 | (113.32 ms | 36146 tok/s)\n",
      "step 2163/5000 | train loss 0.066030 | norm 0.2167 | lr 1.82e-05 | (115.08 ms | 35592 tok/s)\n",
      "step 2164/5000 | train loss 0.065996 | norm 0.1888 | lr 1.82e-05 | (113.74 ms | 36011 tok/s)\n",
      "step 2165/5000 | train loss 0.066005 | norm 0.2248 | lr 1.81e-05 | (114.18 ms | 35874 tok/s)\n",
      "step 2166/5000 | train loss 0.065991 | norm 0.2243 | lr 1.81e-05 | (112.46 ms | 36422 tok/s)\n",
      "step 2167/5000 | train loss 0.065984 | norm 0.2203 | lr 1.81e-05 | (112.62 ms | 36370 tok/s)\n",
      "step 2168/5000 | train loss 0.065953 | norm 0.1907 | lr 1.81e-05 | (113.08 ms | 36224 tok/s)\n",
      "step 2169/5000 | train loss 0.065963 | norm 0.2292 | lr 1.81e-05 | (115.12 ms | 35579 tok/s)\n",
      "step 2170/5000 | train loss 0.065982 | norm 0.2731 | lr 1.81e-05 | (115.39 ms | 35497 tok/s)\n",
      "step 2171/5000 | train loss 0.065965 | norm 0.2735 | lr 1.81e-05 | (114.43 ms | 35795 tok/s)\n",
      "step 2172/5000 | train loss 0.065954 | norm 0.2675 | lr 1.81e-05 | (113.47 ms | 36099 tok/s)\n",
      "step 2173/5000 | train loss 0.065916 | norm 0.2204 | lr 1.81e-05 | (114.41 ms | 35802 tok/s)\n",
      "step 2174/5000 | train loss 0.065892 | norm 0.2008 | lr 1.81e-05 | (113.99 ms | 35932 tok/s)\n",
      "step 2175/5000 | train loss 0.065911 | norm 0.2518 | lr 1.81e-05 | (130.67 ms | 31346 tok/s)\n",
      "step 2176/5000 | train loss 0.065902 | norm 0.2635 | lr 1.80e-05 | (117.01 ms | 35004 tok/s)\n",
      "step 2177/5000 | train loss 0.065874 | norm 0.2411 | lr 1.80e-05 | (116.34 ms | 35208 tok/s)\n",
      "step 2178/5000 | train loss 0.065888 | norm 0.2866 | lr 1.80e-05 | (117.52 ms | 34854 tok/s)\n",
      "step 2179/5000 | train loss 0.065902 | norm 0.3192 | lr 1.80e-05 | (115.83 ms | 35361 tok/s)\n",
      "step 2180/5000 | train loss 0.065854 | norm 0.2629 | lr 1.80e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 2181/5000 | train loss 0.065839 | norm 0.2421 | lr 1.80e-05 | (114.18 ms | 35872 tok/s)\n",
      "step 2182/5000 | train loss 0.065851 | norm 0.2736 | lr 1.80e-05 | (115.35 ms | 35510 tok/s)\n",
      "step 2183/5000 | train loss 0.065829 | norm 0.2564 | lr 1.80e-05 | (114.69 ms | 35713 tok/s)\n",
      "step 2184/5000 | train loss 0.065802 | norm 0.2395 | lr 1.80e-05 | (113.77 ms | 36003 tok/s)\n",
      "step 2185/5000 | train loss 0.065821 | norm 0.2800 | lr 1.80e-05 | (114.84 ms | 35668 tok/s)\n",
      "step 2186/5000 | train loss 0.065802 | norm 0.2788 | lr 1.80e-05 | (114.22 ms | 35862 tok/s)\n",
      "step 2187/5000 | train loss 0.065820 | norm 0.3197 | lr 1.79e-05 | (114.59 ms | 35745 tok/s)\n",
      "step 2188/5000 | train loss 0.065813 | norm 0.3248 | lr 1.79e-05 | (113.92 ms | 35956 tok/s)\n",
      "step 2189/5000 | train loss 0.065759 | norm 0.2538 | lr 1.79e-05 | (116.33 ms | 35210 tok/s)\n",
      "step 2190/5000 | train loss 0.065751 | norm 0.2446 | lr 1.79e-05 | (120.77 ms | 33916 tok/s)\n",
      "step 2191/5000 | train loss 0.065740 | norm 0.2530 | lr 1.79e-05 | (121.35 ms | 33754 tok/s)\n",
      "step 2192/5000 | train loss 0.065732 | norm 0.2582 | lr 1.79e-05 | (116.86 ms | 35050 tok/s)\n",
      "step 2193/5000 | train loss 0.065713 | norm 0.2414 | lr 1.79e-05 | (117.08 ms | 34984 tok/s)\n",
      "step 2194/5000 | train loss 0.065692 | norm 0.2123 | lr 1.79e-05 | (114.02 ms | 35924 tok/s)\n",
      "step 2195/5000 | train loss 0.065675 | norm 0.2017 | lr 1.79e-05 | (114.20 ms | 35866 tok/s)\n",
      "step 2196/5000 | train loss 0.065662 | norm 0.1968 | lr 1.79e-05 | (114.80 ms | 35680 tok/s)\n",
      "step 2197/5000 | train loss 0.065647 | norm 0.1898 | lr 1.78e-05 | (117.54 ms | 34848 tok/s)\n",
      "step 2198/5000 | train loss 0.065651 | norm 0.2138 | lr 1.78e-05 | (119.09 ms | 34396 tok/s)\n",
      "step 2199/5000 | train loss 0.065640 | norm 0.2188 | lr 1.78e-05 | (129.04 ms | 31743 tok/s)\n",
      "step 2200/5000 | train loss 0.065639 | norm 0.2426 | lr 1.78e-05 | (119.58 ms | 34252 tok/s)\n",
      "step 2201/5000 | train loss 0.065646 | norm 0.2765 | lr 1.78e-05 | (118.43 ms | 34586 tok/s)\n",
      "step 2202/5000 | train loss 0.065636 | norm 0.2818 | lr 1.78e-05 | (119.71 ms | 34216 tok/s)\n",
      "step 2203/5000 | train loss 0.065619 | norm 0.2563 | lr 1.78e-05 | (120.27 ms | 34056 tok/s)\n",
      "step 2204/5000 | train loss 0.065581 | norm 0.2069 | lr 1.78e-05 | (120.68 ms | 33941 tok/s)\n",
      "step 2205/5000 | train loss 0.065597 | norm 0.2333 | lr 1.78e-05 | (119.47 ms | 34284 tok/s)\n",
      "step 2206/5000 | train loss 0.065580 | norm 0.2365 | lr 1.78e-05 | (114.85 ms | 35664 tok/s)\n",
      "step 2207/5000 | train loss 0.065584 | norm 0.2610 | lr 1.78e-05 | (114.52 ms | 35766 tok/s)\n",
      "step 2208/5000 | train loss 0.065567 | norm 0.2497 | lr 1.77e-05 | (113.61 ms | 36053 tok/s)\n",
      "step 2209/5000 | train loss 0.065547 | norm 0.2286 | lr 1.77e-05 | (115.55 ms | 35447 tok/s)\n",
      "step 2210/5000 | train loss 0.065526 | norm 0.2145 | lr 1.77e-05 | (117.62 ms | 34825 tok/s)\n",
      "step 2211/5000 | train loss 0.065530 | norm 0.2365 | lr 1.77e-05 | (115.73 ms | 35391 tok/s)\n",
      "step 2212/5000 | train loss 0.065523 | norm 0.2389 | lr 1.77e-05 | (116.12 ms | 35275 tok/s)\n",
      "step 2213/5000 | train loss 0.065493 | norm 0.1997 | lr 1.77e-05 | (117.10 ms | 34980 tok/s)\n",
      "step 2214/5000 | train loss 0.065473 | norm 0.1821 | lr 1.77e-05 | (114.13 ms | 35889 tok/s)\n",
      "step 2215/5000 | train loss 0.065471 | norm 0.2047 | lr 1.77e-05 | (115.38 ms | 35500 tok/s)\n",
      "step 2216/5000 | train loss 0.065473 | norm 0.2212 | lr 1.77e-05 | (115.31 ms | 35521 tok/s)\n",
      "step 2217/5000 | train loss 0.065453 | norm 0.2076 | lr 1.77e-05 | (115.21 ms | 35552 tok/s)\n",
      "step 2218/5000 | train loss 0.065458 | norm 0.2352 | lr 1.77e-05 | (114.87 ms | 35658 tok/s)\n",
      "step 2219/5000 | train loss 0.065474 | norm 0.2778 | lr 1.76e-05 | (115.67 ms | 35412 tok/s)\n",
      "step 2220/5000 | train loss 0.065477 | norm 0.3060 | lr 1.76e-05 | (116.08 ms | 35287 tok/s)\n",
      "step 2221/5000 | train loss 0.065470 | norm 0.3095 | lr 1.76e-05 | (115.92 ms | 35336 tok/s)\n",
      "step 2222/5000 | train loss 0.065448 | norm 0.2835 | lr 1.76e-05 | (114.12 ms | 35892 tok/s)\n",
      "step 2223/5000 | train loss 0.065421 | norm 0.2558 | lr 1.76e-05 | (115.14 ms | 35574 tok/s)\n",
      "step 2224/5000 | train loss 0.065430 | norm 0.2835 | lr 1.76e-05 | (114.52 ms | 35768 tok/s)\n",
      "step 2225/5000 | train loss 0.065417 | norm 0.2835 | lr 1.76e-05 | (116.33 ms | 35210 tok/s)\n",
      "step 2226/5000 | train loss 0.065383 | norm 0.2344 | lr 1.76e-05 | (113.54 ms | 36075 tok/s)\n",
      "step 2227/5000 | train loss 0.065359 | norm 0.1979 | lr 1.76e-05 | (113.64 ms | 36045 tok/s)\n",
      "step 2228/5000 | train loss 0.065356 | norm 0.2241 | lr 1.76e-05 | (114.26 ms | 35849 tok/s)\n",
      "step 2229/5000 | train loss 0.065378 | norm 0.2724 | lr 1.76e-05 | (114.54 ms | 35760 tok/s)\n",
      "step 2230/5000 | train loss 0.065345 | norm 0.2342 | lr 1.75e-05 | (113.82 ms | 35987 tok/s)\n",
      "step 2231/5000 | train loss 0.065326 | norm 0.2162 | lr 1.75e-05 | (115.04 ms | 35605 tok/s)\n",
      "step 2232/5000 | train loss 0.065342 | norm 0.2659 | lr 1.75e-05 | (114.31 ms | 35832 tok/s)\n",
      "step 2233/5000 | train loss 0.065330 | norm 0.2611 | lr 1.75e-05 | (116.85 ms | 35054 tok/s)\n",
      "step 2234/5000 | train loss 0.065308 | norm 0.2246 | lr 1.75e-05 | (113.27 ms | 36162 tok/s)\n",
      "step 2235/5000 | train loss 0.065299 | norm 0.2366 | lr 1.75e-05 | (114.41 ms | 35803 tok/s)\n",
      "step 2236/5000 | train loss 0.065301 | norm 0.2618 | lr 1.75e-05 | (115.50 ms | 35462 tok/s)\n",
      "step 2237/5000 | train loss 0.065286 | norm 0.2495 | lr 1.75e-05 | (115.88 ms | 35347 tok/s)\n",
      "step 2238/5000 | train loss 0.065289 | norm 0.2616 | lr 1.75e-05 | (113.69 ms | 36028 tok/s)\n",
      "step 2239/5000 | train loss 0.065272 | norm 0.2579 | lr 1.75e-05 | (115.02 ms | 35612 tok/s)\n",
      "step 2240/5000 | train loss 0.065258 | norm 0.2345 | lr 1.75e-05 | (112.92 ms | 36274 tok/s)\n",
      "step 2241/5000 | train loss 0.065227 | norm 0.1929 | lr 1.74e-05 | (115.46 ms | 35475 tok/s)\n",
      "step 2242/5000 | train loss 0.065234 | norm 0.2191 | lr 1.74e-05 | (113.35 ms | 36136 tok/s)\n",
      "step 2243/5000 | train loss 0.065233 | norm 0.2342 | lr 1.74e-05 | (114.76 ms | 35690 tok/s)\n",
      "step 2244/5000 | train loss 0.065195 | norm 0.1922 | lr 1.74e-05 | (114.80 ms | 35679 tok/s)\n",
      "step 2245/5000 | train loss 0.065206 | norm 0.2120 | lr 1.74e-05 | (115.68 ms | 35408 tok/s)\n",
      "step 2246/5000 | train loss 0.065163 | norm 0.1510 | lr 1.74e-05 | (115.84 ms | 35358 tok/s)\n",
      "step 2247/5000 | train loss 0.065162 | norm 0.1711 | lr 1.74e-05 | (116.98 ms | 35015 tok/s)\n",
      "step 2248/5000 | train loss 0.065175 | norm 0.2179 | lr 1.74e-05 | (114.51 ms | 35769 tok/s)\n",
      "step 2249/5000 | train loss 0.065159 | norm 0.2142 | lr 1.74e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 2250/5000 | train loss 0.065155 | norm 0.2192 | lr 1.74e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 2251/5000 | train loss 0.065153 | norm 0.2278 | lr 1.73e-05 | (113.96 ms | 35941 tok/s)\n",
      "step 2252/5000 | train loss 0.065167 | norm 0.2724 | lr 1.73e-05 | (113.89 ms | 35966 tok/s)\n",
      "step 2253/5000 | train loss 0.065184 | norm 0.3105 | lr 1.73e-05 | (116.44 ms | 35177 tok/s)\n",
      "step 2254/5000 | train loss 0.065174 | norm 0.3077 | lr 1.73e-05 | (115.64 ms | 35419 tok/s)\n",
      "step 2255/5000 | train loss 0.065149 | norm 0.2896 | lr 1.73e-05 | (115.69 ms | 35406 tok/s)\n",
      "step 2256/5000 | train loss 0.065150 | norm 0.3028 | lr 1.73e-05 | (120.04 ms | 34123 tok/s)\n",
      "step 2257/5000 | train loss 0.065126 | norm 0.2794 | lr 1.73e-05 | (117.57 ms | 34840 tok/s)\n",
      "step 2258/5000 | train loss 0.065122 | norm 0.2740 | lr 1.73e-05 | (114.89 ms | 35651 tok/s)\n",
      "step 2259/5000 | train loss 0.065107 | norm 0.2694 | lr 1.73e-05 | (116.85 ms | 35054 tok/s)\n",
      "step 2260/5000 | train loss 0.065082 | norm 0.2458 | lr 1.73e-05 | (114.16 ms | 35881 tok/s)\n",
      "step 2261/5000 | train loss 0.065071 | norm 0.2299 | lr 1.73e-05 | (114.33 ms | 35826 tok/s)\n",
      "step 2262/5000 | train loss 0.065058 | norm 0.2185 | lr 1.72e-05 | (112.83 ms | 36303 tok/s)\n",
      "step 2263/5000 | train loss 0.065034 | norm 0.2012 | lr 1.72e-05 | (114.04 ms | 35918 tok/s)\n",
      "step 2264/5000 | train loss 0.065044 | norm 0.2258 | lr 1.72e-05 | (113.25 ms | 36169 tok/s)\n",
      "step 2265/5000 | train loss 0.065019 | norm 0.2040 | lr 1.72e-05 | (114.33 ms | 35827 tok/s)\n",
      "step 2266/5000 | train loss 0.065013 | norm 0.2038 | lr 1.72e-05 | (113.09 ms | 36221 tok/s)\n",
      "step 2267/5000 | train loss 0.065006 | norm 0.2105 | lr 1.72e-05 | (114.02 ms | 35923 tok/s)\n",
      "step 2268/5000 | train loss 0.065004 | norm 0.2196 | lr 1.72e-05 | (129.01 ms | 31750 tok/s)\n",
      "step 2269/5000 | train loss 0.064997 | norm 0.2200 | lr 1.72e-05 | (116.46 ms | 35171 tok/s)\n",
      "step 2270/5000 | train loss 0.064981 | norm 0.2151 | lr 1.72e-05 | (114.48 ms | 35779 tok/s)\n",
      "step 2271/5000 | train loss 0.064988 | norm 0.2349 | lr 1.72e-05 | (116.17 ms | 35260 tok/s)\n",
      "step 2272/5000 | train loss 0.064954 | norm 0.1942 | lr 1.72e-05 | (113.17 ms | 36195 tok/s)\n",
      "step 2273/5000 | train loss 0.064944 | norm 0.1794 | lr 1.71e-05 | (115.19 ms | 35560 tok/s)\n",
      "step 2274/5000 | train loss 0.064940 | norm 0.1922 | lr 1.71e-05 | (113.73 ms | 36014 tok/s)\n",
      "step 2275/5000 | train loss 0.064937 | norm 0.2027 | lr 1.71e-05 | (115.60 ms | 35431 tok/s)\n",
      "step 2276/5000 | train loss 0.064924 | norm 0.2011 | lr 1.71e-05 | (113.92 ms | 35954 tok/s)\n",
      "step 2277/5000 | train loss 0.064932 | norm 0.2383 | lr 1.71e-05 | (116.10 ms | 35280 tok/s)\n",
      "step 2278/5000 | train loss 0.064943 | norm 0.2767 | lr 1.71e-05 | (114.00 ms | 35929 tok/s)\n",
      "step 2279/5000 | train loss 0.064927 | norm 0.2745 | lr 1.71e-05 | (113.83 ms | 35982 tok/s)\n",
      "step 2280/5000 | train loss 0.064939 | norm 0.2885 | lr 1.71e-05 | (115.93 ms | 35331 tok/s)\n",
      "step 2281/5000 | train loss 0.064924 | norm 0.2771 | lr 1.71e-05 | (117.09 ms | 34983 tok/s)\n",
      "step 2282/5000 | train loss 0.064913 | norm 0.2687 | lr 1.71e-05 | (117.51 ms | 34858 tok/s)\n",
      "step 2283/5000 | train loss 0.064894 | norm 0.2499 | lr 1.70e-05 | (119.70 ms | 34218 tok/s)\n",
      "step 2284/5000 | train loss 0.064879 | norm 0.2349 | lr 1.70e-05 | (119.77 ms | 34200 tok/s)\n",
      "step 2285/5000 | train loss 0.064857 | norm 0.2086 | lr 1.70e-05 | (117.27 ms | 34928 tok/s)\n",
      "step 2286/5000 | train loss 0.064851 | norm 0.2080 | lr 1.70e-05 | (115.95 ms | 35326 tok/s)\n",
      "step 2287/5000 | train loss 0.064847 | norm 0.2178 | lr 1.70e-05 | (116.45 ms | 35174 tok/s)\n",
      "step 2288/5000 | train loss 0.064829 | norm 0.1976 | lr 1.70e-05 | (114.82 ms | 35673 tok/s)\n",
      "step 2289/5000 | train loss 0.064807 | norm 0.1773 | lr 1.70e-05 | (121.30 ms | 33768 tok/s)\n",
      "step 2290/5000 | train loss 0.064825 | norm 0.2205 | lr 1.70e-05 | (116.64 ms | 35117 tok/s)\n",
      "step 2291/5000 | train loss 0.064808 | norm 0.2188 | lr 1.70e-05 | (116.39 ms | 35192 tok/s)\n",
      "step 2292/5000 | train loss 0.064812 | norm 0.2462 | lr 1.70e-05 | (114.97 ms | 35627 tok/s)\n",
      "step 2293/5000 | train loss 0.064832 | norm 0.2899 | lr 1.70e-05 | (115.14 ms | 35575 tok/s)\n",
      "step 2294/5000 | train loss 0.064812 | norm 0.2795 | lr 1.69e-05 | (115.37 ms | 35504 tok/s)\n",
      "step 2295/5000 | train loss 0.064791 | norm 0.2480 | lr 1.69e-05 | (115.23 ms | 35546 tok/s)\n",
      "step 2296/5000 | train loss 0.064778 | norm 0.2238 | lr 1.69e-05 | (113.65 ms | 36040 tok/s)\n",
      "step 2297/5000 | train loss 0.064758 | norm 0.2054 | lr 1.69e-05 | (117.42 ms | 34884 tok/s)\n",
      "step 2298/5000 | train loss 0.064767 | norm 0.2334 | lr 1.69e-05 | (119.12 ms | 34387 tok/s)\n",
      "step 2299/5000 | train loss 0.064761 | norm 0.2449 | lr 1.69e-05 | (116.94 ms | 35026 tok/s)\n",
      "step 2300/5000 | train loss 0.064762 | norm 0.2497 | lr 1.69e-05 | (118.63 ms | 34527 tok/s)\n",
      "step 2301/5000 | train loss 0.064721 | norm 0.2022 | lr 1.69e-05 | (123.18 ms | 33251 tok/s)\n",
      "step 2302/5000 | train loss 0.064716 | norm 0.1903 | lr 1.69e-05 | (118.14 ms | 34672 tok/s)\n",
      "step 2303/5000 | train loss 0.064702 | norm 0.1877 | lr 1.69e-05 | (121.01 ms | 33848 tok/s)\n",
      "step 2304/5000 | train loss 0.064704 | norm 0.2093 | lr 1.69e-05 | (116.01 ms | 35307 tok/s)\n",
      "step 2305/5000 | train loss 0.064695 | norm 0.2036 | lr 1.68e-05 | (116.76 ms | 35081 tok/s)\n",
      "step 2306/5000 | train loss 0.064672 | norm 0.1742 | lr 1.68e-05 | (118.55 ms | 34552 tok/s)\n",
      "step 2307/5000 | train loss 0.064682 | norm 0.2099 | lr 1.68e-05 | (116.46 ms | 35172 tok/s)\n",
      "step 2308/5000 | train loss 0.064700 | norm 0.2613 | lr 1.68e-05 | (114.23 ms | 35858 tok/s)\n",
      "step 2309/5000 | train loss 0.064710 | norm 0.2997 | lr 1.68e-05 | (115.02 ms | 35611 tok/s)\n",
      "step 2310/5000 | train loss 0.064709 | norm 0.2977 | lr 1.68e-05 | (113.45 ms | 36103 tok/s)\n",
      "step 2311/5000 | train loss 0.064659 | norm 0.2265 | lr 1.68e-05 | (114.85 ms | 35665 tok/s)\n",
      "step 2312/5000 | train loss 0.064643 | norm 0.2030 | lr 1.68e-05 | (113.16 ms | 36197 tok/s)\n",
      "step 2313/5000 | train loss 0.064654 | norm 0.2444 | lr 1.68e-05 | (114.86 ms | 35661 tok/s)\n",
      "step 2314/5000 | train loss 0.064650 | norm 0.2552 | lr 1.68e-05 | (115.02 ms | 35610 tok/s)\n",
      "step 2315/5000 | train loss 0.064627 | norm 0.2203 | lr 1.68e-05 | (114.75 ms | 35694 tok/s)\n",
      "step 2316/5000 | train loss 0.064615 | norm 0.2103 | lr 1.67e-05 | (113.15 ms | 36199 tok/s)\n",
      "step 2317/5000 | train loss 0.064622 | norm 0.2394 | lr 1.67e-05 | (114.10 ms | 35898 tok/s)\n",
      "step 2318/5000 | train loss 0.064612 | norm 0.2324 | lr 1.67e-05 | (113.17 ms | 36193 tok/s)\n",
      "step 2319/5000 | train loss 0.064583 | norm 0.1853 | lr 1.67e-05 | (125.48 ms | 32642 tok/s)\n",
      "step 2320/5000 | train loss 0.064576 | norm 0.1934 | lr 1.67e-05 | (113.58 ms | 36063 tok/s)\n",
      "step 2321/5000 | train loss 0.064590 | norm 0.2316 | lr 1.67e-05 | (114.92 ms | 35643 tok/s)\n",
      "step 2322/5000 | train loss 0.064566 | norm 0.1990 | lr 1.67e-05 | (113.52 ms | 36082 tok/s)\n",
      "step 2323/5000 | train loss 0.064557 | norm 0.1987 | lr 1.67e-05 | (114.46 ms | 35785 tok/s)\n",
      "step 2324/5000 | train loss 0.064580 | norm 0.2560 | lr 1.67e-05 | (112.67 ms | 36355 tok/s)\n",
      "step 2325/5000 | train loss 0.064566 | norm 0.2491 | lr 1.67e-05 | (115.04 ms | 35605 tok/s)\n",
      "step 2326/5000 | train loss 0.064537 | norm 0.2099 | lr 1.66e-05 | (113.87 ms | 35970 tok/s)\n",
      "step 2327/5000 | train loss 0.064541 | norm 0.2262 | lr 1.66e-05 | (115.63 ms | 35422 tok/s)\n",
      "step 2328/5000 | train loss 0.064537 | norm 0.2370 | lr 1.66e-05 | (113.28 ms | 36157 tok/s)\n",
      "step 2329/5000 | train loss 0.064533 | norm 0.2374 | lr 1.66e-05 | (114.35 ms | 35819 tok/s)\n",
      "step 2330/5000 | train loss 0.064528 | norm 0.2498 | lr 1.66e-05 | (113.28 ms | 36159 tok/s)\n",
      "step 2331/5000 | train loss 0.064535 | norm 0.2686 | lr 1.66e-05 | (114.53 ms | 35764 tok/s)\n",
      "step 2332/5000 | train loss 0.064509 | norm 0.2394 | lr 1.66e-05 | (113.79 ms | 35996 tok/s)\n",
      "step 2333/5000 | train loss 0.064499 | norm 0.2237 | lr 1.66e-05 | (113.67 ms | 36034 tok/s)\n",
      "step 2334/5000 | train loss 0.064482 | norm 0.2097 | lr 1.66e-05 | (113.45 ms | 36105 tok/s)\n",
      "step 2335/5000 | train loss 0.064501 | norm 0.2453 | lr 1.66e-05 | (114.51 ms | 35768 tok/s)\n",
      "step 2336/5000 | train loss 0.064481 | norm 0.2275 | lr 1.66e-05 | (113.35 ms | 36135 tok/s)\n",
      "step 2337/5000 | train loss 0.064459 | norm 0.2038 | lr 1.65e-05 | (115.36 ms | 35505 tok/s)\n",
      "step 2338/5000 | train loss 0.064472 | norm 0.2373 | lr 1.65e-05 | (112.97 ms | 36256 tok/s)\n",
      "step 2339/5000 | train loss 0.064453 | norm 0.2214 | lr 1.65e-05 | (114.53 ms | 35764 tok/s)\n",
      "step 2340/5000 | train loss 0.064441 | norm 0.2121 | lr 1.65e-05 | (115.04 ms | 35604 tok/s)\n",
      "step 2341/5000 | train loss 0.064430 | norm 0.2004 | lr 1.65e-05 | (114.56 ms | 35754 tok/s)\n",
      "step 2342/5000 | train loss 0.064417 | norm 0.1839 | lr 1.65e-05 | (113.57 ms | 36064 tok/s)\n",
      "step 2343/5000 | train loss 0.064408 | norm 0.1914 | lr 1.65e-05 | (115.73 ms | 35394 tok/s)\n",
      "step 2344/5000 | train loss 0.064418 | norm 0.2142 | lr 1.65e-05 | (114.46 ms | 35787 tok/s)\n",
      "step 2345/5000 | train loss 0.064393 | norm 0.1904 | lr 1.65e-05 | (114.87 ms | 35656 tok/s)\n",
      "step 2346/5000 | train loss 0.064406 | norm 0.2279 | lr 1.65e-05 | (119.25 ms | 34347 tok/s)\n",
      "step 2347/5000 | train loss 0.064410 | norm 0.2523 | lr 1.65e-05 | (122.24 ms | 33507 tok/s)\n",
      "step 2348/5000 | train loss 0.064416 | norm 0.2789 | lr 1.64e-05 | (129.72 ms | 31575 tok/s)\n",
      "step 2349/5000 | train loss 0.064404 | norm 0.2697 | lr 1.64e-05 | (121.80 ms | 33629 tok/s)\n",
      "step 2350/5000 | train loss 0.064369 | norm 0.2234 | lr 1.64e-05 | (126.22 ms | 32451 tok/s)\n",
      "step 2351/5000 | train loss 0.064384 | norm 0.2395 | lr 1.64e-05 | (140.22 ms | 29212 tok/s)\n",
      "step 2352/5000 | train loss 0.064348 | norm 0.1938 | lr 1.64e-05 | (120.27 ms | 34056 tok/s)\n",
      "step 2353/5000 | train loss 0.064335 | norm 0.1804 | lr 1.64e-05 | (122.56 ms | 33419 tok/s)\n",
      "step 2354/5000 | train loss 0.064346 | norm 0.2176 | lr 1.64e-05 | (126.12 ms | 32478 tok/s)\n",
      "step 2355/5000 | train loss 0.064333 | norm 0.1957 | lr 1.64e-05 | (128.31 ms | 31922 tok/s)\n",
      "step 2356/5000 | train loss 0.064300 | norm 0.1490 | lr 1.64e-05 | (116.35 ms | 35204 tok/s)\n",
      "step 2357/5000 | train loss 0.064322 | norm 0.1975 | lr 1.64e-05 | (115.80 ms | 35371 tok/s)\n",
      "step 2358/5000 | train loss 0.064295 | norm 0.1741 | lr 1.63e-05 | (116.53 ms | 35148 tok/s)\n",
      "step 2359/5000 | train loss 0.064302 | norm 0.2022 | lr 1.63e-05 | (116.41 ms | 35185 tok/s)\n",
      "step 2360/5000 | train loss 0.064313 | norm 0.2391 | lr 1.63e-05 | (114.62 ms | 35735 tok/s)\n",
      "step 2361/5000 | train loss 0.064332 | norm 0.2789 | lr 1.63e-05 | (113.88 ms | 35967 tok/s)\n",
      "step 2362/5000 | train loss 0.064347 | norm 0.3070 | lr 1.63e-05 | (112.75 ms | 36327 tok/s)\n",
      "step 2363/5000 | train loss 0.064311 | norm 0.2685 | lr 1.63e-05 | (114.88 ms | 35654 tok/s)\n",
      "step 2364/5000 | train loss 0.064286 | norm 0.2317 | lr 1.63e-05 | (113.69 ms | 36028 tok/s)\n",
      "step 2365/5000 | train loss 0.064285 | norm 0.2387 | lr 1.63e-05 | (112.49 ms | 36413 tok/s)\n",
      "step 2366/5000 | train loss 0.064279 | norm 0.2437 | lr 1.63e-05 | (113.19 ms | 36187 tok/s)\n",
      "step 2367/5000 | train loss 0.064274 | norm 0.2345 | lr 1.63e-05 | (115.14 ms | 35573 tok/s)\n",
      "step 2368/5000 | train loss 0.064245 | norm 0.2018 | lr 1.63e-05 | (113.07 ms | 36227 tok/s)\n",
      "step 2369/5000 | train loss 0.064241 | norm 0.2149 | lr 1.62e-05 | (113.50 ms | 36088 tok/s)\n",
      "step 2370/5000 | train loss 0.064248 | norm 0.2360 | lr 1.62e-05 | (113.40 ms | 36119 tok/s)\n",
      "step 2371/5000 | train loss 0.064236 | norm 0.2263 | lr 1.62e-05 | (122.27 ms | 33499 tok/s)\n",
      "step 2372/5000 | train loss 0.064234 | norm 0.2351 | lr 1.62e-05 | (113.05 ms | 36233 tok/s)\n",
      "step 2373/5000 | train loss 0.064234 | norm 0.2550 | lr 1.62e-05 | (117.08 ms | 34985 tok/s)\n",
      "step 2374/5000 | train loss 0.064232 | norm 0.2621 | lr 1.62e-05 | (114.92 ms | 35642 tok/s)\n",
      "step 2375/5000 | train loss 0.064217 | norm 0.2386 | lr 1.62e-05 | (115.79 ms | 35373 tok/s)\n",
      "step 2376/5000 | train loss 0.064186 | norm 0.1886 | lr 1.62e-05 | (114.38 ms | 35811 tok/s)\n",
      "step 2377/5000 | train loss 0.064186 | norm 0.1953 | lr 1.62e-05 | (113.47 ms | 36096 tok/s)\n",
      "step 2378/5000 | train loss 0.064174 | norm 0.1886 | lr 1.62e-05 | (114.29 ms | 35839 tok/s)\n",
      "step 2379/5000 | train loss 0.064169 | norm 0.1917 | lr 1.62e-05 | (117.06 ms | 34991 tok/s)\n",
      "step 2380/5000 | train loss 0.064161 | norm 0.1909 | lr 1.61e-05 | (136.55 ms | 29996 tok/s)\n",
      "step 2381/5000 | train loss 0.064156 | norm 0.1847 | lr 1.61e-05 | (115.11 ms | 35585 tok/s)\n",
      "step 2382/5000 | train loss 0.064134 | norm 0.1548 | lr 1.61e-05 | (127.26 ms | 32185 tok/s)\n",
      "step 2383/5000 | train loss 0.064132 | norm 0.1612 | lr 1.61e-05 | (118.46 ms | 34577 tok/s)\n",
      "step 2384/5000 | train loss 0.064136 | norm 0.1878 | lr 1.61e-05 | (124.44 ms | 32915 tok/s)\n",
      "step 2385/5000 | train loss 0.064144 | norm 0.2197 | lr 1.61e-05 | (135.10 ms | 30318 tok/s)\n",
      "step 2386/5000 | train loss 0.064149 | norm 0.2442 | lr 1.61e-05 | (113.40 ms | 36120 tok/s)\n",
      "step 2387/5000 | train loss 0.064153 | norm 0.2587 | lr 1.61e-05 | (115.38 ms | 35502 tok/s)\n",
      "step 2388/5000 | train loss 0.064116 | norm 0.2120 | lr 1.61e-05 | (115.15 ms | 35570 tok/s)\n",
      "step 2389/5000 | train loss 0.064112 | norm 0.2033 | lr 1.61e-05 | (119.96 ms | 34145 tok/s)\n",
      "step 2390/5000 | train loss 0.064117 | norm 0.2284 | lr 1.60e-05 | (118.35 ms | 34608 tok/s)\n",
      "step 2391/5000 | train loss 0.064120 | norm 0.2390 | lr 1.60e-05 | (116.56 ms | 35141 tok/s)\n",
      "step 2392/5000 | train loss 0.064088 | norm 0.1941 | lr 1.60e-05 | (113.52 ms | 36081 tok/s)\n",
      "step 2393/5000 | train loss 0.064077 | norm 0.1856 | lr 1.60e-05 | (114.34 ms | 35822 tok/s)\n",
      "step 2394/5000 | train loss 0.064091 | norm 0.2201 | lr 1.60e-05 | (113.71 ms | 36022 tok/s)\n",
      "step 2395/5000 | train loss 0.064068 | norm 0.2014 | lr 1.60e-05 | (115.28 ms | 35529 tok/s)\n",
      "step 2396/5000 | train loss 0.064075 | norm 0.2165 | lr 1.60e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 2397/5000 | train loss 0.064069 | norm 0.2216 | lr 1.60e-05 | (113.98 ms | 35936 tok/s)\n",
      "step 2398/5000 | train loss 0.064055 | norm 0.2185 | lr 1.60e-05 | (113.01 ms | 36244 tok/s)\n",
      "step 2399/5000 | train loss 0.064067 | norm 0.2379 | lr 1.60e-05 | (112.69 ms | 36347 tok/s)\n",
      "step 2400/5000 | train loss 0.064042 | norm 0.2082 | lr 1.60e-05 | (112.39 ms | 36444 tok/s)\n",
      "step 2401/5000 | train loss 0.064030 | norm 0.1926 | lr 1.59e-05 | (113.66 ms | 36037 tok/s)\n",
      "step 2402/5000 | train loss 0.064038 | norm 0.2195 | lr 1.59e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 2403/5000 | train loss 0.064038 | norm 0.2351 | lr 1.59e-05 | (113.55 ms | 36071 tok/s)\n",
      "step 2404/5000 | train loss 0.064025 | norm 0.2181 | lr 1.59e-05 | (113.85 ms | 35976 tok/s)\n",
      "step 2405/5000 | train loss 0.064003 | norm 0.1817 | lr 1.59e-05 | (123.93 ms | 33051 tok/s)\n",
      "step 2406/5000 | train loss 0.063993 | norm 0.1777 | lr 1.59e-05 | (115.12 ms | 35581 tok/s)\n",
      "step 2407/5000 | train loss 0.064006 | norm 0.2104 | lr 1.59e-05 | (129.29 ms | 31682 tok/s)\n",
      "step 2408/5000 | train loss 0.063998 | norm 0.2122 | lr 1.59e-05 | (118.41 ms | 34593 tok/s)\n",
      "step 2409/5000 | train loss 0.063990 | norm 0.2013 | lr 1.59e-05 | (114.93 ms | 35638 tok/s)\n",
      "step 2410/5000 | train loss 0.063973 | norm 0.1856 | lr 1.59e-05 | (113.55 ms | 36073 tok/s)\n",
      "step 2411/5000 | train loss 0.063976 | norm 0.1932 | lr 1.58e-05 | (114.96 ms | 35628 tok/s)\n",
      "step 2412/5000 | train loss 0.063963 | norm 0.1835 | lr 1.58e-05 | (112.35 ms | 36459 tok/s)\n",
      "step 2413/5000 | train loss 0.063963 | norm 0.2025 | lr 1.58e-05 | (122.61 ms | 33407 tok/s)\n",
      "step 2414/5000 | train loss 0.063980 | norm 0.2431 | lr 1.58e-05 | (117.77 ms | 34778 tok/s)\n",
      "step 2415/5000 | train loss 0.063975 | norm 0.2507 | lr 1.58e-05 | (114.45 ms | 35788 tok/s)\n",
      "step 2416/5000 | train loss 0.063975 | norm 0.2717 | lr 1.58e-05 | (117.52 ms | 34855 tok/s)\n",
      "step 2417/5000 | train loss 0.063988 | norm 0.2906 | lr 1.58e-05 | (116.65 ms | 35115 tok/s)\n",
      "step 2418/5000 | train loss 0.063953 | norm 0.2496 | lr 1.58e-05 | (112.93 ms | 36271 tok/s)\n",
      "step 2419/5000 | train loss 0.063953 | norm 0.2490 | lr 1.58e-05 | (113.96 ms | 35943 tok/s)\n",
      "step 2420/5000 | train loss 0.063944 | norm 0.2425 | lr 1.58e-05 | (113.12 ms | 36210 tok/s)\n",
      "step 2421/5000 | train loss 0.063907 | norm 0.1915 | lr 1.58e-05 | (117.77 ms | 34781 tok/s)\n",
      "step 2422/5000 | train loss 0.063929 | norm 0.2280 | lr 1.57e-05 | (120.53 ms | 33982 tok/s)\n",
      "step 2423/5000 | train loss 0.063906 | norm 0.2021 | lr 1.57e-05 | (117.08 ms | 34986 tok/s)\n",
      "step 2424/5000 | train loss 0.063890 | norm 0.1724 | lr 1.57e-05 | (112.78 ms | 36319 tok/s)\n",
      "step 2425/5000 | train loss 0.063897 | norm 0.2015 | lr 1.57e-05 | (114.39 ms | 35807 tok/s)\n",
      "step 2426/5000 | train loss 0.063887 | norm 0.1924 | lr 1.57e-05 | (114.61 ms | 35739 tok/s)\n",
      "step 2427/5000 | train loss 0.063867 | norm 0.1707 | lr 1.57e-05 | (115.49 ms | 35468 tok/s)\n",
      "step 2428/5000 | train loss 0.063873 | norm 0.1932 | lr 1.57e-05 | (115.27 ms | 35535 tok/s)\n",
      "step 2429/5000 | train loss 0.063870 | norm 0.2017 | lr 1.57e-05 | (114.59 ms | 35744 tok/s)\n",
      "step 2430/5000 | train loss 0.063862 | norm 0.1988 | lr 1.57e-05 | (114.82 ms | 35674 tok/s)\n",
      "step 2431/5000 | train loss 0.063855 | norm 0.1965 | lr 1.57e-05 | (114.54 ms | 35762 tok/s)\n",
      "step 2432/5000 | train loss 0.063850 | norm 0.1981 | lr 1.57e-05 | (113.92 ms | 35956 tok/s)\n",
      "step 2433/5000 | train loss 0.063842 | norm 0.1868 | lr 1.56e-05 | (115.24 ms | 35543 tok/s)\n",
      "step 2434/5000 | train loss 0.063825 | norm 0.1647 | lr 1.56e-05 | (113.14 ms | 36203 tok/s)\n",
      "step 2435/5000 | train loss 0.063823 | norm 0.1707 | lr 1.56e-05 | (114.06 ms | 35912 tok/s)\n",
      "step 2436/5000 | train loss 0.063823 | norm 0.1896 | lr 1.56e-05 | (113.06 ms | 36230 tok/s)\n",
      "step 2437/5000 | train loss 0.063834 | norm 0.2229 | lr 1.56e-05 | (114.71 ms | 35707 tok/s)\n",
      "step 2438/5000 | train loss 0.063837 | norm 0.2345 | lr 1.56e-05 | (113.68 ms | 36031 tok/s)\n",
      "step 2439/5000 | train loss 0.063814 | norm 0.2085 | lr 1.56e-05 | (114.09 ms | 35901 tok/s)\n",
      "step 2440/5000 | train loss 0.063794 | norm 0.1784 | lr 1.56e-05 | (112.91 ms | 36275 tok/s)\n",
      "step 2441/5000 | train loss 0.063800 | norm 0.2026 | lr 1.56e-05 | (113.97 ms | 35940 tok/s)\n",
      "step 2442/5000 | train loss 0.063812 | norm 0.2339 | lr 1.56e-05 | (112.90 ms | 36281 tok/s)\n",
      "step 2443/5000 | train loss 0.063808 | norm 0.2381 | lr 1.55e-05 | (112.61 ms | 36372 tok/s)\n",
      "step 2444/5000 | train loss 0.063806 | norm 0.2445 | lr 1.55e-05 | (111.07 ms | 36878 tok/s)\n",
      "step 2445/5000 | train loss 0.063787 | norm 0.2240 | lr 1.55e-05 | (112.75 ms | 36327 tok/s)\n",
      "step 2446/5000 | train loss 0.063787 | norm 0.2175 | lr 1.55e-05 | (111.87 ms | 36615 tok/s)\n",
      "step 2447/5000 | train loss 0.063770 | norm 0.2024 | lr 1.55e-05 | (112.34 ms | 36462 tok/s)\n",
      "step 2448/5000 | train loss 0.063771 | norm 0.2194 | lr 1.55e-05 | (111.81 ms | 36634 tok/s)\n",
      "step 2449/5000 | train loss 0.063773 | norm 0.2243 | lr 1.55e-05 | (113.64 ms | 36042 tok/s)\n",
      "step 2450/5000 | train loss 0.063742 | norm 0.1817 | lr 1.55e-05 | (112.48 ms | 36414 tok/s)\n",
      "step 2451/5000 | train loss 0.063746 | norm 0.1961 | lr 1.55e-05 | (112.83 ms | 36302 tok/s)\n",
      "step 2452/5000 | train loss 0.063749 | norm 0.2121 | lr 1.55e-05 | (111.95 ms | 36589 tok/s)\n",
      "step 2453/5000 | train loss 0.063721 | norm 0.1694 | lr 1.55e-05 | (112.59 ms | 36381 tok/s)\n",
      "step 2454/5000 | train loss 0.063715 | norm 0.1579 | lr 1.54e-05 | (111.32 ms | 36796 tok/s)\n",
      "step 2455/5000 | train loss 0.063718 | norm 0.1825 | lr 1.54e-05 | (112.27 ms | 36485 tok/s)\n",
      "step 2456/5000 | train loss 0.063715 | norm 0.1931 | lr 1.54e-05 | (111.81 ms | 36634 tok/s)\n",
      "step 2457/5000 | train loss 0.063716 | norm 0.2066 | lr 1.54e-05 | (112.42 ms | 36436 tok/s)\n",
      "step 2458/5000 | train loss 0.063720 | norm 0.2281 | lr 1.54e-05 | (112.98 ms | 36255 tok/s)\n",
      "step 2459/5000 | train loss 0.063708 | norm 0.2132 | lr 1.54e-05 | (116.87 ms | 35047 tok/s)\n",
      "step 2460/5000 | train loss 0.063691 | norm 0.1903 | lr 1.54e-05 | (113.58 ms | 36064 tok/s)\n",
      "step 2461/5000 | train loss 0.063691 | norm 0.1954 | lr 1.54e-05 | (114.23 ms | 35856 tok/s)\n",
      "step 2462/5000 | train loss 0.063676 | norm 0.1758 | lr 1.54e-05 | (112.66 ms | 36356 tok/s)\n",
      "step 2463/5000 | train loss 0.063677 | norm 0.1880 | lr 1.54e-05 | (113.46 ms | 36100 tok/s)\n",
      "step 2464/5000 | train loss 0.063683 | norm 0.2159 | lr 1.54e-05 | (112.96 ms | 36261 tok/s)\n",
      "step 2465/5000 | train loss 0.063689 | norm 0.2363 | lr 1.53e-05 | (113.87 ms | 35971 tok/s)\n",
      "step 2466/5000 | train loss 0.063691 | norm 0.2500 | lr 1.53e-05 | (112.88 ms | 36287 tok/s)\n",
      "step 2467/5000 | train loss 0.063692 | norm 0.2668 | lr 1.53e-05 | (114.31 ms | 35834 tok/s)\n",
      "step 2468/5000 | train loss 0.063695 | norm 0.2770 | lr 1.53e-05 | (112.70 ms | 36344 tok/s)\n",
      "step 2469/5000 | train loss 0.063672 | norm 0.2414 | lr 1.53e-05 | (114.17 ms | 35876 tok/s)\n",
      "step 2470/5000 | train loss 0.063642 | norm 0.1858 | lr 1.53e-05 | (113.19 ms | 36188 tok/s)\n",
      "step 2471/5000 | train loss 0.063641 | norm 0.2010 | lr 1.53e-05 | (114.69 ms | 35713 tok/s)\n",
      "step 2472/5000 | train loss 0.063655 | norm 0.2403 | lr 1.53e-05 | (113.43 ms | 36109 tok/s)\n",
      "step 2473/5000 | train loss 0.063627 | norm 0.1970 | lr 1.53e-05 | (114.43 ms | 35796 tok/s)\n",
      "step 2474/5000 | train loss 0.063618 | norm 0.1853 | lr 1.53e-05 | (112.68 ms | 36351 tok/s)\n",
      "step 2475/5000 | train loss 0.063628 | norm 0.2113 | lr 1.52e-05 | (113.18 ms | 36190 tok/s)\n",
      "step 2476/5000 | train loss 0.063610 | norm 0.1889 | lr 1.52e-05 | (112.99 ms | 36252 tok/s)\n",
      "step 2477/5000 | train loss 0.063613 | norm 0.2049 | lr 1.52e-05 | (113.38 ms | 36125 tok/s)\n",
      "step 2478/5000 | train loss 0.063611 | norm 0.2138 | lr 1.52e-05 | (115.71 ms | 35400 tok/s)\n",
      "step 2479/5000 | train loss 0.063593 | norm 0.1939 | lr 1.52e-05 | (114.55 ms | 35759 tok/s)\n",
      "step 2480/5000 | train loss 0.063595 | norm 0.2013 | lr 1.52e-05 | (113.51 ms | 36085 tok/s)\n",
      "step 2481/5000 | train loss 0.063573 | norm 0.1680 | lr 1.52e-05 | (112.97 ms | 36256 tok/s)\n",
      "step 2482/5000 | train loss 0.063573 | norm 0.1714 | lr 1.52e-05 | (118.72 ms | 34500 tok/s)\n",
      "step 2483/5000 | train loss 0.063567 | norm 0.1725 | lr 1.52e-05 | (127.47 ms | 32134 tok/s)\n",
      "step 2484/5000 | train loss 0.063564 | norm 0.1761 | lr 1.52e-05 | (121.68 ms | 33661 tok/s)\n",
      "step 2485/5000 | train loss 0.063566 | norm 0.1939 | lr 1.52e-05 | (126.23 ms | 32449 tok/s)\n",
      "step 2486/5000 | train loss 0.063569 | norm 0.2143 | lr 1.51e-05 | (128.18 ms | 31955 tok/s)\n",
      "step 2487/5000 | train loss 0.063577 | norm 0.2365 | lr 1.51e-05 | (125.81 ms | 32556 tok/s)\n",
      "step 2488/5000 | train loss 0.063565 | norm 0.2207 | lr 1.51e-05 | (114.03 ms | 35920 tok/s)\n",
      "step 2489/5000 | train loss 0.063544 | norm 0.1902 | lr 1.51e-05 | (115.41 ms | 35492 tok/s)\n",
      "step 2490/5000 | train loss 0.063543 | norm 0.1906 | lr 1.51e-05 | (113.54 ms | 36074 tok/s)\n",
      "step 2491/5000 | train loss 0.063528 | norm 0.1807 | lr 1.51e-05 | (115.54 ms | 35450 tok/s)\n",
      "step 2492/5000 | train loss 0.063531 | norm 0.1991 | lr 1.51e-05 | (116.60 ms | 35130 tok/s)\n",
      "step 2493/5000 | train loss 0.063527 | norm 0.1979 | lr 1.51e-05 | (118.34 ms | 34611 tok/s)\n",
      "step 2494/5000 | train loss 0.063511 | norm 0.1785 | lr 1.51e-05 | (115.54 ms | 35452 tok/s)\n",
      "step 2495/5000 | train loss 0.063512 | norm 0.1878 | lr 1.51e-05 | (113.88 ms | 35967 tok/s)\n",
      "step 2496/5000 | train loss 0.063514 | norm 0.1983 | lr 1.50e-05 | (113.95 ms | 35946 tok/s)\n",
      "step 2497/5000 | train loss 0.063513 | norm 0.2123 | lr 1.50e-05 | (113.72 ms | 36018 tok/s)\n",
      "step 2498/5000 | train loss 0.063519 | norm 0.2289 | lr 1.50e-05 | (113.93 ms | 35952 tok/s)\n",
      "step 2499/5000 | train loss 0.063504 | norm 0.2145 | lr 1.50e-05 | (114.71 ms | 35708 tok/s)\n",
      "step 2500/5000 | train loss 0.063504 | norm 0.2179 | lr 1.50e-05 | (112.76 ms | 36325 tok/s)\n",
      "step 2501/5000 | train loss 0.063497 | norm 0.2138 | lr 1.50e-05 | (132.69 ms | 30869 tok/s)\n",
      "step 2502/5000 | train loss 0.063484 | norm 0.1957 | lr 1.50e-05 | (123.86 ms | 33070 tok/s)\n",
      "step 2503/5000 | train loss 0.063475 | norm 0.1891 | lr 1.50e-05 | (121.69 ms | 33660 tok/s)\n",
      "step 2504/5000 | train loss 0.063481 | norm 0.2096 | lr 1.50e-05 | (113.96 ms | 35942 tok/s)\n",
      "step 2505/5000 | train loss 0.063478 | norm 0.2181 | lr 1.50e-05 | (115.12 ms | 35580 tok/s)\n",
      "step 2506/5000 | train loss 0.063481 | norm 0.2357 | lr 1.50e-05 | (116.40 ms | 35188 tok/s)\n",
      "step 2507/5000 | train loss 0.063490 | norm 0.2586 | lr 1.49e-05 | (116.41 ms | 35186 tok/s)\n",
      "step 2508/5000 | train loss 0.063471 | norm 0.2273 | lr 1.49e-05 | (118.03 ms | 34704 tok/s)\n",
      "step 2509/5000 | train loss 0.063428 | norm 0.1495 | lr 1.49e-05 | (119.92 ms | 34156 tok/s)\n",
      "step 2510/5000 | train loss 0.063451 | norm 0.2013 | lr 1.49e-05 | (113.63 ms | 36047 tok/s)\n",
      "step 2511/5000 | train loss 0.063443 | norm 0.2026 | lr 1.49e-05 | (113.19 ms | 36187 tok/s)\n",
      "step 2512/5000 | train loss 0.063419 | norm 0.1556 | lr 1.49e-05 | (119.40 ms | 34304 tok/s)\n",
      "step 2513/5000 | train loss 0.063417 | norm 0.1663 | lr 1.49e-05 | (116.61 ms | 35126 tok/s)\n",
      "step 2514/5000 | train loss 0.063424 | norm 0.1874 | lr 1.49e-05 | (112.61 ms | 36374 tok/s)\n",
      "step 2515/5000 | train loss 0.063403 | norm 0.1525 | lr 1.49e-05 | (115.01 ms | 35614 tok/s)\n",
      "step 2516/5000 | train loss 0.063401 | norm 0.1601 | lr 1.49e-05 | (113.03 ms | 36237 tok/s)\n",
      "step 2517/5000 | train loss 0.063409 | norm 0.1908 | lr 1.49e-05 | (113.41 ms | 36116 tok/s)\n",
      "step 2518/5000 | train loss 0.063410 | norm 0.2007 | lr 1.48e-05 | (113.25 ms | 36168 tok/s)\n",
      "step 2519/5000 | train loss 0.063410 | norm 0.2137 | lr 1.48e-05 | (115.17 ms | 35565 tok/s)\n",
      "step 2520/5000 | train loss 0.063420 | norm 0.2438 | lr 1.48e-05 | (116.12 ms | 35273 tok/s)\n",
      "step 2521/5000 | train loss 0.063406 | norm 0.2320 | lr 1.48e-05 | (117.82 ms | 34766 tok/s)\n",
      "step 2522/5000 | train loss 0.063401 | norm 0.2300 | lr 1.48e-05 | (114.64 ms | 35730 tok/s)\n",
      "step 2523/5000 | train loss 0.063413 | norm 0.2452 | lr 1.48e-05 | (113.49 ms | 36091 tok/s)\n",
      "step 2524/5000 | train loss 0.063382 | norm 0.2076 | lr 1.48e-05 | (120.59 ms | 33967 tok/s)\n",
      "step 2525/5000 | train loss 0.063381 | norm 0.2045 | lr 1.48e-05 | (114.65 ms | 35727 tok/s)\n",
      "step 2526/5000 | train loss 0.063375 | norm 0.1973 | lr 1.48e-05 | (113.51 ms | 36086 tok/s)\n",
      "step 2527/5000 | train loss 0.063365 | norm 0.2016 | lr 1.48e-05 | (113.70 ms | 36026 tok/s)\n",
      "step 2528/5000 | train loss 0.063393 | norm 0.2526 | lr 1.47e-05 | (112.92 ms | 36272 tok/s)\n",
      "step 2529/5000 | train loss 0.063364 | norm 0.2119 | lr 1.47e-05 | (115.51 ms | 35459 tok/s)\n",
      "step 2530/5000 | train loss 0.063357 | norm 0.2055 | lr 1.47e-05 | (117.25 ms | 34934 tok/s)\n",
      "step 2531/5000 | train loss 0.063365 | norm 0.2312 | lr 1.47e-05 | (116.96 ms | 35022 tok/s)\n",
      "step 2532/5000 | train loss 0.063353 | norm 0.2165 | lr 1.47e-05 | (113.31 ms | 36149 tok/s)\n",
      "step 2533/5000 | train loss 0.063341 | norm 0.1951 | lr 1.47e-05 | (113.54 ms | 36074 tok/s)\n",
      "step 2534/5000 | train loss 0.063321 | norm 0.1617 | lr 1.47e-05 | (112.57 ms | 36385 tok/s)\n",
      "step 2535/5000 | train loss 0.063318 | norm 0.1621 | lr 1.47e-05 | (114.34 ms | 35821 tok/s)\n",
      "step 2536/5000 | train loss 0.063314 | norm 0.1611 | lr 1.47e-05 | (112.54 ms | 36396 tok/s)\n",
      "step 2537/5000 | train loss 0.063301 | norm 0.1449 | lr 1.47e-05 | (115.12 ms | 35581 tok/s)\n",
      "step 2538/5000 | train loss 0.063302 | norm 0.1569 | lr 1.47e-05 | (113.50 ms | 36089 tok/s)\n",
      "step 2539/5000 | train loss 0.063299 | norm 0.1631 | lr 1.46e-05 | (114.51 ms | 35768 tok/s)\n",
      "step 2540/5000 | train loss 0.063289 | norm 0.1477 | lr 1.46e-05 | (113.46 ms | 36102 tok/s)\n",
      "step 2541/5000 | train loss 0.063280 | norm 0.1463 | lr 1.46e-05 | (114.48 ms | 35780 tok/s)\n",
      "step 2542/5000 | train loss 0.063292 | norm 0.1780 | lr 1.46e-05 | (113.61 ms | 36053 tok/s)\n",
      "step 2543/5000 | train loss 0.063283 | norm 0.1755 | lr 1.46e-05 | (127.40 ms | 32151 tok/s)\n",
      "step 2544/5000 | train loss 0.063288 | norm 0.1912 | lr 1.46e-05 | (114.51 ms | 35768 tok/s)\n",
      "step 2545/5000 | train loss 0.063288 | norm 0.2063 | lr 1.46e-05 | (115.34 ms | 35511 tok/s)\n",
      "step 2546/5000 | train loss 0.063302 | norm 0.2404 | lr 1.46e-05 | (113.78 ms | 35998 tok/s)\n",
      "step 2547/5000 | train loss 0.063297 | norm 0.2476 | lr 1.46e-05 | (113.73 ms | 36014 tok/s)\n",
      "step 2548/5000 | train loss 0.063288 | norm 0.2394 | lr 1.46e-05 | (113.15 ms | 36199 tok/s)\n",
      "step 2549/5000 | train loss 0.063283 | norm 0.2327 | lr 1.45e-05 | (114.59 ms | 35744 tok/s)\n",
      "step 2550/5000 | train loss 0.063278 | norm 0.2226 | lr 1.45e-05 | (114.61 ms | 35737 tok/s)\n",
      "step 2551/5000 | train loss 0.063260 | norm 0.1993 | lr 1.45e-05 | (122.88 ms | 33334 tok/s)\n",
      "step 2552/5000 | train loss 0.063251 | norm 0.1982 | lr 1.45e-05 | (114.40 ms | 35803 tok/s)\n",
      "step 2553/5000 | train loss 0.063270 | norm 0.2294 | lr 1.45e-05 | (116.38 ms | 35194 tok/s)\n",
      "step 2554/5000 | train loss 0.063230 | norm 0.1633 | lr 1.45e-05 | (114.00 ms | 35929 tok/s)\n",
      "step 2555/5000 | train loss 0.063236 | norm 0.1759 | lr 1.45e-05 | (113.75 ms | 36008 tok/s)\n",
      "step 2556/5000 | train loss 0.063236 | norm 0.2026 | lr 1.45e-05 | (117.74 ms | 34790 tok/s)\n",
      "step 2557/5000 | train loss 0.063232 | norm 0.1976 | lr 1.45e-05 | (119.51 ms | 34274 tok/s)\n",
      "step 2558/5000 | train loss 0.063218 | norm 0.1743 | lr 1.45e-05 | (116.84 ms | 35056 tok/s)\n",
      "step 2559/5000 | train loss 0.063218 | norm 0.1843 | lr 1.45e-05 | (115.21 ms | 35553 tok/s)\n",
      "step 2560/5000 | train loss 0.063224 | norm 0.2042 | lr 1.44e-05 | (113.46 ms | 36102 tok/s)\n",
      "step 2561/5000 | train loss 0.063212 | norm 0.1939 | lr 1.44e-05 | (114.55 ms | 35758 tok/s)\n",
      "step 2562/5000 | train loss 0.063218 | norm 0.2164 | lr 1.44e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 2563/5000 | train loss 0.063214 | norm 0.2253 | lr 1.44e-05 | (113.82 ms | 35987 tok/s)\n",
      "step 2564/5000 | train loss 0.063212 | norm 0.2191 | lr 1.44e-05 | (113.44 ms | 36106 tok/s)\n",
      "step 2565/5000 | train loss 0.063190 | norm 0.1812 | lr 1.44e-05 | (114.65 ms | 35727 tok/s)\n",
      "step 2566/5000 | train loss 0.063183 | norm 0.1695 | lr 1.44e-05 | (113.40 ms | 36120 tok/s)\n",
      "step 2567/5000 | train loss 0.063184 | norm 0.1817 | lr 1.44e-05 | (114.01 ms | 35926 tok/s)\n",
      "step 2568/5000 | train loss 0.063179 | norm 0.1804 | lr 1.44e-05 | (112.94 ms | 36268 tok/s)\n",
      "step 2569/5000 | train loss 0.063168 | norm 0.1661 | lr 1.44e-05 | (114.41 ms | 35802 tok/s)\n",
      "step 2570/5000 | train loss 0.063165 | norm 0.1707 | lr 1.44e-05 | (113.42 ms | 36115 tok/s)\n",
      "step 2571/5000 | train loss 0.063161 | norm 0.1666 | lr 1.43e-05 | (113.44 ms | 36107 tok/s)\n",
      "step 2572/5000 | train loss 0.063155 | norm 0.1663 | lr 1.43e-05 | (112.73 ms | 36334 tok/s)\n",
      "step 2573/5000 | train loss 0.063167 | norm 0.2036 | lr 1.43e-05 | (114.51 ms | 35770 tok/s)\n",
      "step 2574/5000 | train loss 0.063170 | norm 0.2224 | lr 1.43e-05 | (113.17 ms | 36195 tok/s)\n",
      "step 2575/5000 | train loss 0.063171 | norm 0.2333 | lr 1.43e-05 | (115.27 ms | 35534 tok/s)\n",
      "step 2576/5000 | train loss 0.063163 | norm 0.2244 | lr 1.43e-05 | (114.07 ms | 35908 tok/s)\n",
      "step 2577/5000 | train loss 0.063152 | norm 0.2086 | lr 1.43e-05 | (113.82 ms | 35986 tok/s)\n",
      "step 2578/5000 | train loss 0.063151 | norm 0.2083 | lr 1.43e-05 | (112.19 ms | 36508 tok/s)\n",
      "step 2579/5000 | train loss 0.063146 | norm 0.2088 | lr 1.43e-05 | (113.91 ms | 35958 tok/s)\n",
      "step 2580/5000 | train loss 0.063144 | norm 0.2119 | lr 1.43e-05 | (112.67 ms | 36355 tok/s)\n",
      "step 2581/5000 | train loss 0.063134 | norm 0.1955 | lr 1.42e-05 | (113.20 ms | 36183 tok/s)\n",
      "step 2582/5000 | train loss 0.063112 | norm 0.1607 | lr 1.42e-05 | (113.31 ms | 36149 tok/s)\n",
      "step 2583/5000 | train loss 0.063121 | norm 0.1894 | lr 1.42e-05 | (113.82 ms | 35987 tok/s)\n",
      "step 2584/5000 | train loss 0.063112 | norm 0.1779 | lr 1.42e-05 | (113.25 ms | 36167 tok/s)\n",
      "step 2585/5000 | train loss 0.063097 | norm 0.1488 | lr 1.42e-05 | (140.25 ms | 29204 tok/s)\n",
      "step 2586/5000 | train loss 0.063096 | norm 0.1621 | lr 1.42e-05 | (118.77 ms | 34486 tok/s)\n",
      "step 2587/5000 | train loss 0.063101 | norm 0.1793 | lr 1.42e-05 | (115.84 ms | 35358 tok/s)\n",
      "step 2588/5000 | train loss 0.063087 | norm 0.1598 | lr 1.42e-05 | (113.87 ms | 35969 tok/s)\n",
      "step 2589/5000 | train loss 0.063092 | norm 0.1805 | lr 1.42e-05 | (114.77 ms | 35690 tok/s)\n",
      "step 2590/5000 | train loss 0.063097 | norm 0.2077 | lr 1.42e-05 | (114.13 ms | 35889 tok/s)\n",
      "step 2591/5000 | train loss 0.063094 | norm 0.2125 | lr 1.42e-05 | (119.60 ms | 34247 tok/s)\n",
      "step 2592/5000 | train loss 0.063087 | norm 0.1984 | lr 1.41e-05 | (115.50 ms | 35462 tok/s)\n",
      "step 2593/5000 | train loss 0.063070 | norm 0.1641 | lr 1.41e-05 | (116.32 ms | 35214 tok/s)\n",
      "step 2594/5000 | train loss 0.063064 | norm 0.1596 | lr 1.41e-05 | (112.97 ms | 36259 tok/s)\n",
      "step 2595/5000 | train loss 0.063068 | norm 0.1735 | lr 1.41e-05 | (113.36 ms | 36133 tok/s)\n",
      "step 2596/5000 | train loss 0.063060 | norm 0.1719 | lr 1.41e-05 | (120.71 ms | 33934 tok/s)\n",
      "step 2597/5000 | train loss 0.063068 | norm 0.1933 | lr 1.41e-05 | (118.85 ms | 34464 tok/s)\n",
      "step 2598/5000 | train loss 0.063057 | norm 0.1843 | lr 1.41e-05 | (114.32 ms | 35830 tok/s)\n",
      "step 2599/5000 | train loss 0.063050 | norm 0.1784 | lr 1.41e-05 | (115.83 ms | 35362 tok/s)\n",
      "step 2600/5000 | train loss 0.063065 | norm 0.2075 | lr 1.41e-05 | (113.78 ms | 35999 tok/s)\n",
      "step 2601/5000 | train loss 0.063047 | norm 0.1862 | lr 1.41e-05 | (116.94 ms | 35027 tok/s)\n",
      "step 2602/5000 | train loss 0.063041 | norm 0.1779 | lr 1.41e-05 | (117.98 ms | 34719 tok/s)\n",
      "step 2603/5000 | train loss 0.063039 | norm 0.1833 | lr 1.40e-05 | (116.47 ms | 35167 tok/s)\n",
      "step 2604/5000 | train loss 0.063038 | norm 0.1945 | lr 1.40e-05 | (115.21 ms | 35551 tok/s)\n",
      "step 2605/5000 | train loss 0.063035 | norm 0.1987 | lr 1.40e-05 | (115.09 ms | 35588 tok/s)\n",
      "step 2606/5000 | train loss 0.063027 | norm 0.1821 | lr 1.40e-05 | (114.49 ms | 35777 tok/s)\n",
      "step 2607/5000 | train loss 0.063016 | norm 0.1669 | lr 1.40e-05 | (114.98 ms | 35623 tok/s)\n",
      "step 2608/5000 | train loss 0.063023 | norm 0.1866 | lr 1.40e-05 | (113.67 ms | 36035 tok/s)\n",
      "step 2609/5000 | train loss 0.063013 | norm 0.1792 | lr 1.40e-05 | (120.99 ms | 33853 tok/s)\n",
      "step 2610/5000 | train loss 0.063011 | norm 0.1851 | lr 1.40e-05 | (121.12 ms | 33817 tok/s)\n",
      "step 2611/5000 | train loss 0.063016 | norm 0.2027 | lr 1.40e-05 | (115.98 ms | 35318 tok/s)\n",
      "step 2612/5000 | train loss 0.063014 | norm 0.2067 | lr 1.40e-05 | (114.41 ms | 35801 tok/s)\n",
      "step 2613/5000 | train loss 0.063009 | norm 0.2015 | lr 1.39e-05 | (125.43 ms | 32656 tok/s)\n",
      "step 2614/5000 | train loss 0.062998 | norm 0.1964 | lr 1.39e-05 | (113.57 ms | 36067 tok/s)\n",
      "step 2615/5000 | train loss 0.063016 | norm 0.2322 | lr 1.39e-05 | (118.21 ms | 34649 tok/s)\n",
      "step 2616/5000 | train loss 0.063000 | norm 0.2122 | lr 1.39e-05 | (116.31 ms | 35216 tok/s)\n",
      "step 2617/5000 | train loss 0.062977 | norm 0.1634 | lr 1.39e-05 | (117.05 ms | 34994 tok/s)\n",
      "step 2618/5000 | train loss 0.062979 | norm 0.1717 | lr 1.39e-05 | (136.05 ms | 30107 tok/s)\n",
      "step 2619/5000 | train loss 0.062976 | norm 0.1820 | lr 1.39e-05 | (118.85 ms | 34463 tok/s)\n",
      "step 2620/5000 | train loss 0.062966 | norm 0.1644 | lr 1.39e-05 | (114.47 ms | 35782 tok/s)\n",
      "step 2621/5000 | train loss 0.062956 | norm 0.1460 | lr 1.39e-05 | (115.00 ms | 35618 tok/s)\n",
      "step 2622/5000 | train loss 0.062954 | norm 0.1510 | lr 1.39e-05 | (113.24 ms | 36171 tok/s)\n",
      "step 2623/5000 | train loss 0.062949 | norm 0.1559 | lr 1.39e-05 | (115.46 ms | 35476 tok/s)\n",
      "step 2624/5000 | train loss 0.062957 | norm 0.1791 | lr 1.38e-05 | (116.62 ms | 35122 tok/s)\n",
      "step 2625/5000 | train loss 0.062956 | norm 0.1867 | lr 1.38e-05 | (114.85 ms | 35663 tok/s)\n",
      "step 2626/5000 | train loss 0.062941 | norm 0.1717 | lr 1.38e-05 | (113.55 ms | 36073 tok/s)\n",
      "step 2627/5000 | train loss 0.062953 | norm 0.2017 | lr 1.38e-05 | (123.53 ms | 33157 tok/s)\n",
      "step 2628/5000 | train loss 0.062959 | norm 0.2225 | lr 1.38e-05 | (120.24 ms | 34065 tok/s)\n",
      "step 2629/5000 | train loss 0.062942 | norm 0.1931 | lr 1.38e-05 | (120.99 ms | 33855 tok/s)\n",
      "step 2630/5000 | train loss 0.062935 | norm 0.1771 | lr 1.38e-05 | (114.15 ms | 35884 tok/s)\n",
      "step 2631/5000 | train loss 0.062936 | norm 0.1899 | lr 1.38e-05 | (114.31 ms | 35833 tok/s)\n",
      "step 2632/5000 | train loss 0.062929 | norm 0.1918 | lr 1.38e-05 | (113.11 ms | 36211 tok/s)\n",
      "step 2633/5000 | train loss 0.062934 | norm 0.2070 | lr 1.38e-05 | (114.45 ms | 35789 tok/s)\n",
      "step 2634/5000 | train loss 0.062926 | norm 0.1981 | lr 1.37e-05 | (114.72 ms | 35703 tok/s)\n",
      "step 2635/5000 | train loss 0.062915 | norm 0.1843 | lr 1.37e-05 | (116.49 ms | 35162 tok/s)\n",
      "step 2636/5000 | train loss 0.062928 | norm 0.2168 | lr 1.37e-05 | (116.11 ms | 35277 tok/s)\n",
      "step 2637/5000 | train loss 0.062927 | norm 0.2190 | lr 1.37e-05 | (114.62 ms | 35735 tok/s)\n",
      "step 2638/5000 | train loss 0.062897 | norm 0.1686 | lr 1.37e-05 | (113.23 ms | 36176 tok/s)\n",
      "step 2639/5000 | train loss 0.062906 | norm 0.1828 | lr 1.37e-05 | (114.55 ms | 35758 tok/s)\n",
      "step 2640/5000 | train loss 0.062902 | norm 0.1858 | lr 1.37e-05 | (114.23 ms | 35857 tok/s)\n",
      "step 2641/5000 | train loss 0.062889 | norm 0.1636 | lr 1.37e-05 | (114.32 ms | 35830 tok/s)\n",
      "step 2642/5000 | train loss 0.062886 | norm 0.1645 | lr 1.37e-05 | (111.90 ms | 36605 tok/s)\n",
      "step 2643/5000 | train loss 0.062886 | norm 0.1742 | lr 1.37e-05 | (113.26 ms | 36166 tok/s)\n",
      "step 2644/5000 | train loss 0.062877 | norm 0.1657 | lr 1.37e-05 | (112.80 ms | 36312 tok/s)\n",
      "step 2645/5000 | train loss 0.062874 | norm 0.1617 | lr 1.36e-05 | (115.68 ms | 35407 tok/s)\n",
      "step 2646/5000 | train loss 0.062873 | norm 0.1662 | lr 1.36e-05 | (114.05 ms | 35915 tok/s)\n",
      "step 2647/5000 | train loss 0.062866 | norm 0.1683 | lr 1.36e-05 | (115.86 ms | 35351 tok/s)\n",
      "step 2648/5000 | train loss 0.062878 | norm 0.2045 | lr 1.36e-05 | (113.65 ms | 36040 tok/s)\n",
      "step 2649/5000 | train loss 0.062890 | norm 0.2372 | lr 1.36e-05 | (114.13 ms | 35889 tok/s)\n",
      "step 2650/5000 | train loss 0.062878 | norm 0.2306 | lr 1.36e-05 | (112.96 ms | 36261 tok/s)\n",
      "step 2651/5000 | train loss 0.062878 | norm 0.2195 | lr 1.36e-05 | (114.63 ms | 35731 tok/s)\n",
      "step 2652/5000 | train loss 0.062861 | norm 0.1851 | lr 1.36e-05 | (113.49 ms | 36092 tok/s)\n",
      "step 2653/5000 | train loss 0.062851 | norm 0.1767 | lr 1.36e-05 | (113.82 ms | 35987 tok/s)\n",
      "step 2654/5000 | train loss 0.062864 | norm 0.2150 | lr 1.36e-05 | (113.47 ms | 36096 tok/s)\n",
      "step 2655/5000 | train loss 0.062861 | norm 0.2143 | lr 1.36e-05 | (115.11 ms | 35585 tok/s)\n",
      "step 2656/5000 | train loss 0.062847 | norm 0.1883 | lr 1.35e-05 | (113.61 ms | 36055 tok/s)\n",
      "step 2657/5000 | train loss 0.062835 | norm 0.1684 | lr 1.35e-05 | (115.94 ms | 35329 tok/s)\n",
      "step 2658/5000 | train loss 0.062833 | norm 0.1733 | lr 1.35e-05 | (113.76 ms | 36007 tok/s)\n",
      "step 2659/5000 | train loss 0.062835 | norm 0.1842 | lr 1.35e-05 | (115.25 ms | 35540 tok/s)\n",
      "step 2660/5000 | train loss 0.062823 | norm 0.1672 | lr 1.35e-05 | (113.60 ms | 36057 tok/s)\n",
      "step 2661/5000 | train loss 0.062819 | norm 0.1618 | lr 1.35e-05 | (115.36 ms | 35506 tok/s)\n",
      "step 2662/5000 | train loss 0.062822 | norm 0.1723 | lr 1.35e-05 | (114.06 ms | 35910 tok/s)\n",
      "step 2663/5000 | train loss 0.062806 | norm 0.1462 | lr 1.35e-05 | (114.10 ms | 35898 tok/s)\n",
      "step 2664/5000 | train loss 0.062800 | norm 0.1391 | lr 1.35e-05 | (112.78 ms | 36320 tok/s)\n",
      "step 2665/5000 | train loss 0.062804 | norm 0.1597 | lr 1.35e-05 | (115.70 ms | 35403 tok/s)\n",
      "step 2666/5000 | train loss 0.062799 | norm 0.1593 | lr 1.34e-05 | (113.85 ms | 35976 tok/s)\n",
      "step 2667/5000 | train loss 0.062792 | norm 0.1551 | lr 1.34e-05 | (115.56 ms | 35445 tok/s)\n",
      "step 2668/5000 | train loss 0.062799 | norm 0.1762 | lr 1.34e-05 | (113.52 ms | 36081 tok/s)\n",
      "step 2669/5000 | train loss 0.062797 | norm 0.1880 | lr 1.34e-05 | (114.59 ms | 35744 tok/s)\n",
      "step 2670/5000 | train loss 0.062803 | norm 0.2033 | lr 1.34e-05 | (113.52 ms | 36083 tok/s)\n",
      "step 2671/5000 | train loss 0.062787 | norm 0.1818 | lr 1.34e-05 | (114.47 ms | 35783 tok/s)\n",
      "step 2672/5000 | train loss 0.062783 | norm 0.1723 | lr 1.34e-05 | (113.18 ms | 36191 tok/s)\n",
      "step 2673/5000 | train loss 0.062773 | norm 0.1622 | lr 1.34e-05 | (114.97 ms | 35626 tok/s)\n",
      "step 2674/5000 | train loss 0.062792 | norm 0.2011 | lr 1.34e-05 | (113.06 ms | 36229 tok/s)\n",
      "step 2675/5000 | train loss 0.062780 | norm 0.1975 | lr 1.34e-05 | (115.07 ms | 35596 tok/s)\n",
      "step 2676/5000 | train loss 0.062769 | norm 0.1800 | lr 1.34e-05 | (114.91 ms | 35647 tok/s)\n",
      "step 2677/5000 | train loss 0.062771 | norm 0.1826 | lr 1.33e-05 | (114.49 ms | 35778 tok/s)\n",
      "step 2678/5000 | train loss 0.062765 | norm 0.1755 | lr 1.33e-05 | (112.14 ms | 36525 tok/s)\n",
      "step 2679/5000 | train loss 0.062757 | norm 0.1672 | lr 1.33e-05 | (113.93 ms | 35952 tok/s)\n",
      "step 2680/5000 | train loss 0.062757 | norm 0.1802 | lr 1.33e-05 | (114.73 ms | 35703 tok/s)\n",
      "step 2681/5000 | train loss 0.062763 | norm 0.1940 | lr 1.33e-05 | (115.21 ms | 35552 tok/s)\n",
      "step 2682/5000 | train loss 0.062753 | norm 0.1774 | lr 1.33e-05 | (113.78 ms | 35998 tok/s)\n",
      "step 2683/5000 | train loss 0.062743 | norm 0.1642 | lr 1.33e-05 | (113.48 ms | 36095 tok/s)\n",
      "step 2684/5000 | train loss 0.062748 | norm 0.1797 | lr 1.33e-05 | (115.37 ms | 35505 tok/s)\n",
      "step 2685/5000 | train loss 0.062750 | norm 0.1921 | lr 1.33e-05 | (114.06 ms | 35911 tok/s)\n",
      "step 2686/5000 | train loss 0.062746 | norm 0.1891 | lr 1.33e-05 | (113.24 ms | 36170 tok/s)\n",
      "step 2687/5000 | train loss 0.062733 | norm 0.1650 | lr 1.33e-05 | (112.88 ms | 36285 tok/s)\n",
      "step 2688/5000 | train loss 0.062719 | norm 0.1398 | lr 1.32e-05 | (112.83 ms | 36302 tok/s)\n",
      "step 2689/5000 | train loss 0.062725 | norm 0.1668 | lr 1.32e-05 | (112.60 ms | 36376 tok/s)\n",
      "step 2690/5000 | train loss 0.062723 | norm 0.1684 | lr 1.32e-05 | (112.93 ms | 36269 tok/s)\n",
      "step 2691/5000 | train loss 0.062707 | norm 0.1407 | lr 1.32e-05 | (114.02 ms | 35922 tok/s)\n",
      "step 2692/5000 | train loss 0.062713 | norm 0.1632 | lr 1.32e-05 | (113.07 ms | 36225 tok/s)\n",
      "step 2693/5000 | train loss 0.062719 | norm 0.1842 | lr 1.32e-05 | (113.15 ms | 36201 tok/s)\n",
      "step 2694/5000 | train loss 0.062710 | norm 0.1750 | lr 1.32e-05 | (113.00 ms | 36249 tok/s)\n",
      "step 2695/5000 | train loss 0.062711 | norm 0.1841 | lr 1.32e-05 | (113.23 ms | 36173 tok/s)\n",
      "step 2696/5000 | train loss 0.062712 | norm 0.1935 | lr 1.32e-05 | (113.34 ms | 36140 tok/s)\n",
      "step 2697/5000 | train loss 0.062705 | norm 0.1833 | lr 1.32e-05 | (114.32 ms | 35830 tok/s)\n",
      "step 2698/5000 | train loss 0.062707 | norm 0.1887 | lr 1.31e-05 | (113.41 ms | 36117 tok/s)\n",
      "step 2699/5000 | train loss 0.062706 | norm 0.1956 | lr 1.31e-05 | (114.32 ms | 35830 tok/s)\n",
      "step 2700/5000 | train loss 0.062696 | norm 0.1832 | lr 1.31e-05 | (113.50 ms | 36089 tok/s)\n",
      "step 2701/5000 | train loss 0.062693 | norm 0.1806 | lr 1.31e-05 | (131.90 ms | 31054 tok/s)\n",
      "step 2702/5000 | train loss 0.062689 | norm 0.1824 | lr 1.31e-05 | (120.42 ms | 34013 tok/s)\n",
      "step 2703/5000 | train loss 0.062687 | norm 0.1824 | lr 1.31e-05 | (115.89 ms | 35345 tok/s)\n",
      "step 2704/5000 | train loss 0.062678 | norm 0.1693 | lr 1.31e-05 | (119.05 ms | 34406 tok/s)\n",
      "step 2705/5000 | train loss 0.062672 | norm 0.1680 | lr 1.31e-05 | (121.20 ms | 33796 tok/s)\n",
      "step 2706/5000 | train loss 0.062688 | norm 0.2080 | lr 1.31e-05 | (113.92 ms | 35954 tok/s)\n",
      "step 2707/5000 | train loss 0.062681 | norm 0.2031 | lr 1.31e-05 | (115.06 ms | 35599 tok/s)\n",
      "step 2708/5000 | train loss 0.062663 | norm 0.1668 | lr 1.31e-05 | (113.56 ms | 36068 tok/s)\n",
      "step 2709/5000 | train loss 0.062659 | norm 0.1568 | lr 1.30e-05 | (115.40 ms | 35493 tok/s)\n",
      "step 2710/5000 | train loss 0.062653 | norm 0.1517 | lr 1.30e-05 | (113.82 ms | 35985 tok/s)\n",
      "step 2711/5000 | train loss 0.062655 | norm 0.1570 | lr 1.30e-05 | (115.29 ms | 35529 tok/s)\n",
      "step 2712/5000 | train loss 0.062638 | norm 0.1294 | lr 1.30e-05 | (113.19 ms | 36188 tok/s)\n",
      "step 2713/5000 | train loss 0.062644 | norm 0.1509 | lr 1.30e-05 | (114.82 ms | 35673 tok/s)\n",
      "step 2714/5000 | train loss 0.062643 | norm 0.1569 | lr 1.30e-05 | (114.66 ms | 35722 tok/s)\n",
      "step 2715/5000 | train loss 0.062642 | norm 0.1711 | lr 1.30e-05 | (115.09 ms | 35591 tok/s)\n",
      "step 2716/5000 | train loss 0.062659 | norm 0.2161 | lr 1.30e-05 | (123.36 ms | 33205 tok/s)\n",
      "step 2717/5000 | train loss 0.062667 | norm 0.2507 | lr 1.30e-05 | (123.40 ms | 33192 tok/s)\n",
      "step 2718/5000 | train loss 0.062674 | norm 0.2647 | lr 1.30e-05 | (122.42 ms | 33460 tok/s)\n",
      "step 2719/5000 | train loss 0.062651 | norm 0.2310 | lr 1.30e-05 | (117.82 ms | 34766 tok/s)\n",
      "step 2720/5000 | train loss 0.062649 | norm 0.2185 | lr 1.29e-05 | (113.63 ms | 36046 tok/s)\n",
      "step 2721/5000 | train loss 0.062646 | norm 0.2095 | lr 1.29e-05 | (112.48 ms | 36414 tok/s)\n",
      "step 2722/5000 | train loss 0.062618 | norm 0.1633 | lr 1.29e-05 | (123.19 ms | 33250 tok/s)\n",
      "step 2723/5000 | train loss 0.062629 | norm 0.1868 | lr 1.29e-05 | (118.70 ms | 34506 tok/s)\n",
      "step 2724/5000 | train loss 0.062623 | norm 0.1809 | lr 1.29e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 2725/5000 | train loss 0.062610 | norm 0.1520 | lr 1.29e-05 | (114.39 ms | 35807 tok/s)\n",
      "step 2726/5000 | train loss 0.062605 | norm 0.1510 | lr 1.29e-05 | (113.21 ms | 36179 tok/s)\n",
      "step 2727/5000 | train loss 0.062603 | norm 0.1522 | lr 1.29e-05 | (114.82 ms | 35674 tok/s)\n",
      "step 2728/5000 | train loss 0.062592 | norm 0.1325 | lr 1.29e-05 | (118.25 ms | 34639 tok/s)\n",
      "step 2729/5000 | train loss 0.062596 | norm 0.1466 | lr 1.29e-05 | (117.83 ms | 34763 tok/s)\n",
      "step 2730/5000 | train loss 0.062584 | norm 0.1245 | lr 1.29e-05 | (112.75 ms | 36329 tok/s)\n",
      "step 2731/5000 | train loss 0.062577 | norm 0.1125 | lr 1.28e-05 | (114.03 ms | 35919 tok/s)\n",
      "step 2732/5000 | train loss 0.062582 | norm 0.1355 | lr 1.28e-05 | (113.44 ms | 36106 tok/s)\n",
      "step 2733/5000 | train loss 0.062577 | norm 0.1393 | lr 1.28e-05 | (119.68 ms | 34225 tok/s)\n",
      "step 2734/5000 | train loss 0.062588 | norm 0.1731 | lr 1.28e-05 | (123.29 ms | 33223 tok/s)\n",
      "step 2735/5000 | train loss 0.062598 | norm 0.2142 | lr 1.28e-05 | (115.68 ms | 35406 tok/s)\n",
      "step 2736/5000 | train loss 0.062620 | norm 0.2624 | lr 1.28e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 2737/5000 | train loss 0.062604 | norm 0.2364 | lr 1.28e-05 | (115.22 ms | 35550 tok/s)\n",
      "step 2738/5000 | train loss 0.062568 | norm 0.1641 | lr 1.28e-05 | (113.79 ms | 35996 tok/s)\n",
      "step 2739/5000 | train loss 0.062579 | norm 0.1926 | lr 1.28e-05 | (117.72 ms | 34794 tok/s)\n",
      "step 2740/5000 | train loss 0.062580 | norm 0.2051 | lr 1.28e-05 | (116.53 ms | 35150 tok/s)\n",
      "step 2741/5000 | train loss 0.062570 | norm 0.1745 | lr 1.27e-05 | (115.98 ms | 35315 tok/s)\n",
      "step 2742/5000 | train loss 0.062551 | norm 0.1390 | lr 1.27e-05 | (113.94 ms | 35948 tok/s)\n",
      "step 2743/5000 | train loss 0.062561 | norm 0.1666 | lr 1.27e-05 | (114.46 ms | 35786 tok/s)\n",
      "step 2744/5000 | train loss 0.062551 | norm 0.1554 | lr 1.27e-05 | (112.77 ms | 36320 tok/s)\n",
      "step 2745/5000 | train loss 0.062545 | norm 0.1398 | lr 1.27e-05 | (115.15 ms | 35570 tok/s)\n",
      "step 2746/5000 | train loss 0.062545 | norm 0.1488 | lr 1.27e-05 | (113.48 ms | 36094 tok/s)\n",
      "step 2747/5000 | train loss 0.062545 | norm 0.1582 | lr 1.27e-05 | (115.35 ms | 35511 tok/s)\n",
      "step 2748/5000 | train loss 0.062533 | norm 0.1358 | lr 1.27e-05 | (113.35 ms | 36137 tok/s)\n",
      "step 2749/5000 | train loss 0.062540 | norm 0.1574 | lr 1.27e-05 | (115.04 ms | 35606 tok/s)\n",
      "step 2750/5000 | train loss 0.062551 | norm 0.1917 | lr 1.27e-05 | (114.07 ms | 35908 tok/s)\n",
      "step 2751/5000 | train loss 0.062542 | norm 0.1845 | lr 1.27e-05 | (114.66 ms | 35722 tok/s)\n",
      "step 2752/5000 | train loss 0.062546 | norm 0.1997 | lr 1.26e-05 | (113.58 ms | 36064 tok/s)\n",
      "step 2753/5000 | train loss 0.062542 | norm 0.1991 | lr 1.26e-05 | (112.64 ms | 36362 tok/s)\n",
      "step 2754/5000 | train loss 0.062528 | norm 0.1774 | lr 1.26e-05 | (113.18 ms | 36190 tok/s)\n",
      "step 2755/5000 | train loss 0.062537 | norm 0.1935 | lr 1.26e-05 | (115.23 ms | 35545 tok/s)\n",
      "step 2756/5000 | train loss 0.062522 | norm 0.1672 | lr 1.26e-05 | (113.97 ms | 35939 tok/s)\n",
      "step 2757/5000 | train loss 0.062509 | norm 0.1395 | lr 1.26e-05 | (114.64 ms | 35730 tok/s)\n",
      "step 2758/5000 | train loss 0.062513 | norm 0.1603 | lr 1.26e-05 | (112.97 ms | 36257 tok/s)\n",
      "step 2759/5000 | train loss 0.062511 | norm 0.1581 | lr 1.26e-05 | (114.13 ms | 35890 tok/s)\n",
      "step 2760/5000 | train loss 0.062497 | norm 0.1357 | lr 1.26e-05 | (113.90 ms | 35960 tok/s)\n",
      "step 2761/5000 | train loss 0.062509 | norm 0.1627 | lr 1.26e-05 | (116.45 ms | 35173 tok/s)\n",
      "step 2762/5000 | train loss 0.062496 | norm 0.1483 | lr 1.26e-05 | (114.72 ms | 35705 tok/s)\n",
      "step 2763/5000 | train loss 0.062496 | norm 0.1600 | lr 1.25e-05 | (113.90 ms | 35961 tok/s)\n",
      "step 2764/5000 | train loss 0.062508 | norm 0.1957 | lr 1.25e-05 | (113.47 ms | 36097 tok/s)\n",
      "step 2765/5000 | train loss 0.062512 | norm 0.2133 | lr 1.25e-05 | (114.60 ms | 35741 tok/s)\n",
      "step 2766/5000 | train loss 0.062500 | norm 0.1933 | lr 1.25e-05 | (114.10 ms | 35899 tok/s)\n",
      "step 2767/5000 | train loss 0.062494 | norm 0.1699 | lr 1.25e-05 | (115.19 ms | 35559 tok/s)\n",
      "step 2768/5000 | train loss 0.062490 | norm 0.1720 | lr 1.25e-05 | (113.78 ms | 35998 tok/s)\n",
      "step 2769/5000 | train loss 0.062502 | norm 0.2080 | lr 1.25e-05 | (115.20 ms | 35557 tok/s)\n",
      "step 2770/5000 | train loss 0.062497 | norm 0.2073 | lr 1.25e-05 | (113.41 ms | 36117 tok/s)\n",
      "step 2771/5000 | train loss 0.062486 | norm 0.1861 | lr 1.25e-05 | (113.93 ms | 35952 tok/s)\n",
      "step 2772/5000 | train loss 0.062476 | norm 0.1718 | lr 1.25e-05 | (115.97 ms | 35321 tok/s)\n",
      "step 2773/5000 | train loss 0.062476 | norm 0.1737 | lr 1.25e-05 | (114.85 ms | 35664 tok/s)\n",
      "step 2774/5000 | train loss 0.062471 | norm 0.1661 | lr 1.24e-05 | (116.27 ms | 35228 tok/s)\n",
      "step 2775/5000 | train loss 0.062459 | norm 0.1383 | lr 1.24e-05 | (113.81 ms | 35989 tok/s)\n",
      "step 2776/5000 | train loss 0.062454 | norm 0.1325 | lr 1.24e-05 | (113.61 ms | 36055 tok/s)\n",
      "step 2777/5000 | train loss 0.062460 | norm 0.1597 | lr 1.24e-05 | (116.07 ms | 35289 tok/s)\n",
      "step 2778/5000 | train loss 0.062454 | norm 0.1496 | lr 1.24e-05 | (112.66 ms | 36356 tok/s)\n",
      "step 2779/5000 | train loss 0.062445 | norm 0.1310 | lr 1.24e-05 | (113.88 ms | 35968 tok/s)\n",
      "step 2780/5000 | train loss 0.062445 | norm 0.1393 | lr 1.24e-05 | (114.42 ms | 35797 tok/s)\n",
      "step 2781/5000 | train loss 0.062444 | norm 0.1485 | lr 1.24e-05 | (124.23 ms | 32971 tok/s)\n",
      "step 2782/5000 | train loss 0.062443 | norm 0.1518 | lr 1.24e-05 | (121.42 ms | 33735 tok/s)\n",
      "step 2783/5000 | train loss 0.062442 | norm 0.1554 | lr 1.24e-05 | (117.40 ms | 34889 tok/s)\n",
      "step 2784/5000 | train loss 0.062441 | norm 0.1634 | lr 1.23e-05 | (121.35 ms | 33753 tok/s)\n",
      "step 2785/5000 | train loss 0.062444 | norm 0.1745 | lr 1.23e-05 | (140.55 ms | 29143 tok/s)\n",
      "step 2786/5000 | train loss 0.062440 | norm 0.1709 | lr 1.23e-05 | (126.20 ms | 32456 tok/s)\n",
      "step 2787/5000 | train loss 0.062437 | norm 0.1669 | lr 1.23e-05 | (117.49 ms | 34864 tok/s)\n",
      "step 2788/5000 | train loss 0.062434 | norm 0.1617 | lr 1.23e-05 | (114.42 ms | 35799 tok/s)\n",
      "step 2789/5000 | train loss 0.062422 | norm 0.1436 | lr 1.23e-05 | (114.99 ms | 35621 tok/s)\n",
      "step 2790/5000 | train loss 0.062430 | norm 0.1729 | lr 1.23e-05 | (114.39 ms | 35808 tok/s)\n",
      "step 2791/5000 | train loss 0.062435 | norm 0.1974 | lr 1.23e-05 | (123.88 ms | 33063 tok/s)\n",
      "step 2792/5000 | train loss 0.062428 | norm 0.1933 | lr 1.23e-05 | (122.89 ms | 33332 tok/s)\n",
      "step 2793/5000 | train loss 0.062431 | norm 0.2019 | lr 1.23e-05 | (121.07 ms | 33831 tok/s)\n",
      "step 2794/5000 | train loss 0.062432 | norm 0.2052 | lr 1.23e-05 | (115.58 ms | 35438 tok/s)\n",
      "step 2795/5000 | train loss 0.062417 | norm 0.1807 | lr 1.22e-05 | (115.51 ms | 35460 tok/s)\n",
      "step 2796/5000 | train loss 0.062415 | norm 0.1796 | lr 1.22e-05 | (113.62 ms | 36048 tok/s)\n",
      "step 2797/5000 | train loss 0.062411 | norm 0.1774 | lr 1.22e-05 | (116.14 ms | 35267 tok/s)\n",
      "step 2798/5000 | train loss 0.062410 | norm 0.1743 | lr 1.22e-05 | (122.25 ms | 33504 tok/s)\n",
      "step 2799/5000 | train loss 0.062397 | norm 0.1523 | lr 1.22e-05 | (126.49 ms | 32382 tok/s)\n",
      "step 2800/5000 | train loss 0.062397 | norm 0.1584 | lr 1.22e-05 | (123.30 ms | 33221 tok/s)\n",
      "step 2801/5000 | train loss 0.062404 | norm 0.1805 | lr 1.22e-05 | (116.73 ms | 35088 tok/s)\n",
      "step 2802/5000 | train loss 0.062391 | norm 0.1570 | lr 1.22e-05 | (113.54 ms | 36075 tok/s)\n",
      "step 2803/5000 | train loss 0.062388 | norm 0.1533 | lr 1.22e-05 | (115.86 ms | 35353 tok/s)\n",
      "step 2804/5000 | train loss 0.062391 | norm 0.1663 | lr 1.22e-05 | (114.04 ms | 35916 tok/s)\n",
      "step 2805/5000 | train loss 0.062379 | norm 0.1477 | lr 1.22e-05 | (119.02 ms | 34413 tok/s)\n",
      "step 2806/5000 | train loss 0.062384 | norm 0.1572 | lr 1.21e-05 | (117.26 ms | 34930 tok/s)\n",
      "step 2807/5000 | train loss 0.062375 | norm 0.1459 | lr 1.21e-05 | (116.81 ms | 35065 tok/s)\n",
      "step 2808/5000 | train loss 0.062372 | norm 0.1473 | lr 1.21e-05 | (114.22 ms | 35861 tok/s)\n",
      "step 2809/5000 | train loss 0.062378 | norm 0.1666 | lr 1.21e-05 | (115.23 ms | 35547 tok/s)\n",
      "step 2810/5000 | train loss 0.062376 | norm 0.1690 | lr 1.21e-05 | (113.99 ms | 35933 tok/s)\n",
      "step 2811/5000 | train loss 0.062375 | norm 0.1700 | lr 1.21e-05 | (115.90 ms | 35340 tok/s)\n",
      "step 2812/5000 | train loss 0.062363 | norm 0.1460 | lr 1.21e-05 | (113.80 ms | 35993 tok/s)\n",
      "step 2813/5000 | train loss 0.062352 | norm 0.1204 | lr 1.21e-05 | (113.58 ms | 36063 tok/s)\n",
      "step 2814/5000 | train loss 0.062353 | norm 0.1266 | lr 1.21e-05 | (113.97 ms | 35938 tok/s)\n",
      "step 2815/5000 | train loss 0.062348 | norm 0.1278 | lr 1.21e-05 | (113.79 ms | 35998 tok/s)\n",
      "step 2816/5000 | train loss 0.062354 | norm 0.1543 | lr 1.21e-05 | (113.65 ms | 36040 tok/s)\n",
      "step 2817/5000 | train loss 0.062353 | norm 0.1604 | lr 1.20e-05 | (114.26 ms | 35847 tok/s)\n",
      "step 2818/5000 | train loss 0.062352 | norm 0.1644 | lr 1.20e-05 | (113.15 ms | 36201 tok/s)\n",
      "step 2819/5000 | train loss 0.062354 | norm 0.1756 | lr 1.20e-05 | (131.53 ms | 31142 tok/s)\n",
      "step 2820/5000 | train loss 0.062346 | norm 0.1640 | lr 1.20e-05 | (123.44 ms | 33183 tok/s)\n",
      "step 2821/5000 | train loss 0.062341 | norm 0.1582 | lr 1.20e-05 | (122.07 ms | 33553 tok/s)\n",
      "step 2822/5000 | train loss 0.062350 | norm 0.1796 | lr 1.20e-05 | (114.02 ms | 35924 tok/s)\n",
      "step 2823/5000 | train loss 0.062342 | norm 0.1759 | lr 1.20e-05 | (114.90 ms | 35650 tok/s)\n",
      "step 2824/5000 | train loss 0.062343 | norm 0.1816 | lr 1.20e-05 | (114.14 ms | 35885 tok/s)\n",
      "step 2825/5000 | train loss 0.062343 | norm 0.1887 | lr 1.20e-05 | (114.76 ms | 35693 tok/s)\n",
      "step 2826/5000 | train loss 0.062350 | norm 0.2069 | lr 1.20e-05 | (118.31 ms | 34621 tok/s)\n",
      "step 2827/5000 | train loss 0.062343 | norm 0.1987 | lr 1.20e-05 | (119.67 ms | 34227 tok/s)\n",
      "step 2828/5000 | train loss 0.062326 | norm 0.1568 | lr 1.19e-05 | (114.65 ms | 35725 tok/s)\n",
      "step 2829/5000 | train loss 0.062319 | norm 0.1432 | lr 1.19e-05 | (112.25 ms | 36489 tok/s)\n",
      "step 2830/5000 | train loss 0.062326 | norm 0.1716 | lr 1.19e-05 | (113.60 ms | 36055 tok/s)\n",
      "step 2831/5000 | train loss 0.062320 | norm 0.1616 | lr 1.19e-05 | (115.28 ms | 35531 tok/s)\n",
      "step 2832/5000 | train loss 0.062304 | norm 0.1170 | lr 1.19e-05 | (113.04 ms | 36236 tok/s)\n",
      "step 2833/5000 | train loss 0.062303 | norm 0.1238 | lr 1.19e-05 | (115.33 ms | 35516 tok/s)\n",
      "step 2834/5000 | train loss 0.062311 | norm 0.1539 | lr 1.19e-05 | (122.37 ms | 33472 tok/s)\n",
      "step 2835/5000 | train loss 0.062297 | norm 0.1264 | lr 1.19e-05 | (123.83 ms | 33077 tok/s)\n",
      "step 2836/5000 | train loss 0.062293 | norm 0.1161 | lr 1.19e-05 | (113.78 ms | 36001 tok/s)\n",
      "step 2837/5000 | train loss 0.062300 | norm 0.1430 | lr 1.19e-05 | (114.45 ms | 35789 tok/s)\n",
      "step 2838/5000 | train loss 0.062296 | norm 0.1470 | lr 1.18e-05 | (114.67 ms | 35719 tok/s)\n",
      "step 2839/5000 | train loss 0.062307 | norm 0.1818 | lr 1.18e-05 | (122.28 ms | 33496 tok/s)\n",
      "step 2840/5000 | train loss 0.062316 | norm 0.2128 | lr 1.18e-05 | (121.80 ms | 33630 tok/s)\n",
      "step 2841/5000 | train loss 0.062317 | norm 0.2191 | lr 1.18e-05 | (118.18 ms | 34658 tok/s)\n",
      "step 2842/5000 | train loss 0.062307 | norm 0.1998 | lr 1.18e-05 | (114.57 ms | 35750 tok/s)\n",
      "step 2843/5000 | train loss 0.062289 | norm 0.1607 | lr 1.18e-05 | (124.64 ms | 32861 tok/s)\n",
      "step 2844/5000 | train loss 0.062297 | norm 0.1764 | lr 1.18e-05 | (124.40 ms | 32925 tok/s)\n",
      "step 2845/5000 | train loss 0.062294 | norm 0.1812 | lr 1.18e-05 | (124.72 ms | 32842 tok/s)\n",
      "step 2846/5000 | train loss 0.062288 | norm 0.1690 | lr 1.18e-05 | (115.24 ms | 35544 tok/s)\n",
      "step 2847/5000 | train loss 0.062278 | norm 0.1458 | lr 1.18e-05 | (114.26 ms | 35850 tok/s)\n",
      "step 2848/5000 | train loss 0.062270 | norm 0.1382 | lr 1.18e-05 | (113.44 ms | 36108 tok/s)\n",
      "step 2849/5000 | train loss 0.062277 | norm 0.1584 | lr 1.17e-05 | (115.12 ms | 35581 tok/s)\n",
      "step 2850/5000 | train loss 0.062265 | norm 0.1326 | lr 1.17e-05 | (120.29 ms | 34051 tok/s)\n",
      "step 2851/5000 | train loss 0.062260 | norm 0.1209 | lr 1.17e-05 | (123.94 ms | 33048 tok/s)\n",
      "step 2852/5000 | train loss 0.062256 | norm 0.1260 | lr 1.17e-05 | (120.41 ms | 34017 tok/s)\n",
      "step 2853/5000 | train loss 0.062263 | norm 0.1432 | lr 1.17e-05 | (115.07 ms | 35594 tok/s)\n",
      "step 2854/5000 | train loss 0.062252 | norm 0.1244 | lr 1.17e-05 | (113.99 ms | 35932 tok/s)\n",
      "step 2855/5000 | train loss 0.062254 | norm 0.1360 | lr 1.17e-05 | (115.17 ms | 35566 tok/s)\n",
      "step 2856/5000 | train loss 0.062255 | norm 0.1489 | lr 1.17e-05 | (121.04 ms | 33841 tok/s)\n",
      "step 2857/5000 | train loss 0.062257 | norm 0.1569 | lr 1.17e-05 | (122.29 ms | 33494 tok/s)\n",
      "step 2858/5000 | train loss 0.062253 | norm 0.1526 | lr 1.17e-05 | (120.33 ms | 34039 tok/s)\n",
      "step 2859/5000 | train loss 0.062244 | norm 0.1405 | lr 1.17e-05 | (115.98 ms | 35315 tok/s)\n",
      "step 2860/5000 | train loss 0.062245 | norm 0.1603 | lr 1.16e-05 | (113.87 ms | 35970 tok/s)\n",
      "step 2861/5000 | train loss 0.062262 | norm 0.2033 | lr 1.16e-05 | (120.04 ms | 34123 tok/s)\n",
      "step 2862/5000 | train loss 0.062257 | norm 0.2028 | lr 1.16e-05 | (118.06 ms | 34695 tok/s)\n",
      "step 2863/5000 | train loss 0.062253 | norm 0.1897 | lr 1.16e-05 | (125.48 ms | 32642 tok/s)\n",
      "step 2864/5000 | train loss 0.062243 | norm 0.1680 | lr 1.16e-05 | (121.93 ms | 33592 tok/s)\n",
      "step 2865/5000 | train loss 0.062239 | norm 0.1675 | lr 1.16e-05 | (124.41 ms | 32924 tok/s)\n",
      "step 2866/5000 | train loss 0.062254 | norm 0.2122 | lr 1.16e-05 | (123.15 ms | 33259 tok/s)\n",
      "step 2867/5000 | train loss 0.062262 | norm 0.2329 | lr 1.16e-05 | (124.29 ms | 32955 tok/s)\n",
      "step 2868/5000 | train loss 0.062237 | norm 0.1874 | lr 1.16e-05 | (123.07 ms | 33281 tok/s)\n",
      "step 2869/5000 | train loss 0.062226 | norm 0.1528 | lr 1.16e-05 | (130.48 ms | 31392 tok/s)\n",
      "step 2870/5000 | train loss 0.062227 | norm 0.1669 | lr 1.16e-05 | (118.71 ms | 34505 tok/s)\n",
      "step 2871/5000 | train loss 0.062232 | norm 0.1754 | lr 1.15e-05 | (118.63 ms | 34526 tok/s)\n",
      "step 2872/5000 | train loss 0.062209 | norm 0.1228 | lr 1.15e-05 | (116.76 ms | 35080 tok/s)\n",
      "step 2873/5000 | train loss 0.062211 | norm 0.1301 | lr 1.15e-05 | (115.47 ms | 35473 tok/s)\n",
      "step 2874/5000 | train loss 0.062213 | norm 0.1469 | lr 1.15e-05 | (113.99 ms | 35931 tok/s)\n",
      "step 2875/5000 | train loss 0.062204 | norm 0.1204 | lr 1.15e-05 | (122.74 ms | 33372 tok/s)\n",
      "step 2876/5000 | train loss 0.062195 | norm 0.0986 | lr 1.15e-05 | (124.00 ms | 33033 tok/s)\n",
      "step 2877/5000 | train loss 0.062200 | norm 0.1279 | lr 1.15e-05 | (120.52 ms | 33986 tok/s)\n",
      "step 2878/5000 | train loss 0.062197 | norm 0.1244 | lr 1.15e-05 | (133.68 ms | 30640 tok/s)\n",
      "step 2879/5000 | train loss 0.062189 | norm 0.1039 | lr 1.15e-05 | (118.85 ms | 34464 tok/s)\n",
      "step 2880/5000 | train loss 0.062189 | norm 0.1133 | lr 1.15e-05 | (119.72 ms | 34213 tok/s)\n",
      "step 2881/5000 | train loss 0.062190 | norm 0.1239 | lr 1.15e-05 | (120.71 ms | 33933 tok/s)\n",
      "step 2882/5000 | train loss 0.062189 | norm 0.1339 | lr 1.14e-05 | (116.82 ms | 35062 tok/s)\n",
      "step 2883/5000 | train loss 0.062194 | norm 0.1509 | lr 1.14e-05 | (117.61 ms | 34828 tok/s)\n",
      "step 2884/5000 | train loss 0.062200 | norm 0.1736 | lr 1.14e-05 | (119.72 ms | 34214 tok/s)\n",
      "step 2885/5000 | train loss 0.062213 | norm 0.2076 | lr 1.14e-05 | (120.23 ms | 34069 tok/s)\n",
      "step 2886/5000 | train loss 0.062205 | norm 0.1958 | lr 1.14e-05 | (119.05 ms | 34405 tok/s)\n",
      "step 2887/5000 | train loss 0.062183 | norm 0.1497 | lr 1.14e-05 | (120.48 ms | 33998 tok/s)\n",
      "step 2888/5000 | train loss 0.062194 | norm 0.1817 | lr 1.14e-05 | (120.83 ms | 33900 tok/s)\n",
      "step 2889/5000 | train loss 0.062206 | norm 0.2162 | lr 1.14e-05 | (119.84 ms | 34179 tok/s)\n",
      "step 2890/5000 | train loss 0.062183 | norm 0.1707 | lr 1.14e-05 | (118.45 ms | 34579 tok/s)\n",
      "step 2891/5000 | train loss 0.062173 | norm 0.1445 | lr 1.14e-05 | (120.64 ms | 33951 tok/s)\n",
      "step 2892/5000 | train loss 0.062189 | norm 0.1931 | lr 1.14e-05 | (119.89 ms | 34165 tok/s)\n",
      "step 2893/5000 | train loss 0.062182 | norm 0.1885 | lr 1.13e-05 | (119.45 ms | 34290 tok/s)\n",
      "step 2894/5000 | train loss 0.062176 | norm 0.1677 | lr 1.13e-05 | (119.97 ms | 34143 tok/s)\n",
      "step 2895/5000 | train loss 0.062176 | norm 0.1755 | lr 1.13e-05 | (122.85 ms | 33342 tok/s)\n",
      "step 2896/5000 | train loss 0.062170 | norm 0.1613 | lr 1.13e-05 | (130.93 ms | 31285 tok/s)\n",
      "step 2897/5000 | train loss 0.062157 | norm 0.1333 | lr 1.13e-05 | (125.37 ms | 32671 tok/s)\n",
      "step 2898/5000 | train loss 0.062166 | norm 0.1594 | lr 1.13e-05 | (121.13 ms | 33815 tok/s)\n",
      "step 2899/5000 | train loss 0.062156 | norm 0.1366 | lr 1.13e-05 | (120.41 ms | 34016 tok/s)\n",
      "step 2900/5000 | train loss 0.062145 | norm 0.1101 | lr 1.13e-05 | (118.83 ms | 34468 tok/s)\n",
      "step 2901/5000 | train loss 0.062151 | norm 0.1343 | lr 1.13e-05 | (141.76 ms | 28894 tok/s)\n",
      "step 2902/5000 | train loss 0.062142 | norm 0.1193 | lr 1.13e-05 | (123.28 ms | 33225 tok/s)\n",
      "step 2903/5000 | train loss 0.062142 | norm 0.1278 | lr 1.13e-05 | (123.16 ms | 33257 tok/s)\n",
      "step 2904/5000 | train loss 0.062148 | norm 0.1548 | lr 1.12e-05 | (121.68 ms | 33663 tok/s)\n",
      "step 2905/5000 | train loss 0.062150 | norm 0.1727 | lr 1.12e-05 | (120.34 ms | 34038 tok/s)\n",
      "step 2906/5000 | train loss 0.062160 | norm 0.2042 | lr 1.12e-05 | (118.74 ms | 34497 tok/s)\n",
      "step 2907/5000 | train loss 0.062165 | norm 0.2174 | lr 1.12e-05 | (120.28 ms | 34055 tok/s)\n",
      "step 2908/5000 | train loss 0.062147 | norm 0.1768 | lr 1.12e-05 | (119.12 ms | 34384 tok/s)\n",
      "step 2909/5000 | train loss 0.062136 | norm 0.1475 | lr 1.12e-05 | (118.85 ms | 34463 tok/s)\n",
      "step 2910/5000 | train loss 0.062143 | norm 0.1717 | lr 1.12e-05 | (119.83 ms | 34181 tok/s)\n",
      "step 2911/5000 | train loss 0.062134 | norm 0.1606 | lr 1.12e-05 | (118.74 ms | 34497 tok/s)\n",
      "step 2912/5000 | train loss 0.062128 | norm 0.1382 | lr 1.12e-05 | (116.62 ms | 35122 tok/s)\n",
      "step 2913/5000 | train loss 0.062120 | norm 0.1216 | lr 1.12e-05 | (122.89 ms | 33330 tok/s)\n",
      "step 2914/5000 | train loss 0.062123 | norm 0.1388 | lr 1.12e-05 | (122.71 ms | 33380 tok/s)\n",
      "step 2915/5000 | train loss 0.062119 | norm 0.1324 | lr 1.11e-05 | (123.16 ms | 33256 tok/s)\n",
      "step 2916/5000 | train loss 0.062109 | norm 0.1057 | lr 1.11e-05 | (120.14 ms | 34093 tok/s)\n",
      "step 2917/5000 | train loss 0.062110 | norm 0.1106 | lr 1.11e-05 | (116.93 ms | 35029 tok/s)\n",
      "step 2918/5000 | train loss 0.062108 | norm 0.1180 | lr 1.11e-05 | (114.95 ms | 35632 tok/s)\n",
      "step 2919/5000 | train loss 0.062106 | norm 0.1182 | lr 1.11e-05 | (114.40 ms | 35804 tok/s)\n",
      "step 2920/5000 | train loss 0.062101 | norm 0.1069 | lr 1.11e-05 | (113.55 ms | 36072 tok/s)\n",
      "step 2921/5000 | train loss 0.062102 | norm 0.1181 | lr 1.11e-05 | (116.96 ms | 35022 tok/s)\n",
      "step 2922/5000 | train loss 0.062109 | norm 0.1499 | lr 1.11e-05 | (116.95 ms | 35023 tok/s)\n",
      "step 2923/5000 | train loss 0.062119 | norm 0.1827 | lr 1.11e-05 | (118.34 ms | 34612 tok/s)\n",
      "step 2924/5000 | train loss 0.062117 | norm 0.1877 | lr 1.11e-05 | (117.03 ms | 35001 tok/s)\n",
      "step 2925/5000 | train loss 0.062112 | norm 0.1785 | lr 1.11e-05 | (119.79 ms | 34192 tok/s)\n",
      "step 2926/5000 | train loss 0.062111 | norm 0.1775 | lr 1.10e-05 | (118.24 ms | 34643 tok/s)\n",
      "step 2927/5000 | train loss 0.062116 | norm 0.1994 | lr 1.10e-05 | (120.77 ms | 33915 tok/s)\n",
      "step 2928/5000 | train loss 0.062117 | norm 0.1988 | lr 1.10e-05 | (118.10 ms | 34681 tok/s)\n",
      "step 2929/5000 | train loss 0.062095 | norm 0.1544 | lr 1.10e-05 | (118.98 ms | 34427 tok/s)\n",
      "step 2930/5000 | train loss 0.062103 | norm 0.1699 | lr 1.10e-05 | (121.64 ms | 33673 tok/s)\n",
      "step 2931/5000 | train loss 0.062095 | norm 0.1581 | lr 1.10e-05 | (121.99 ms | 33578 tok/s)\n",
      "step 2932/5000 | train loss 0.062088 | norm 0.1432 | lr 1.10e-05 | (117.51 ms | 34858 tok/s)\n",
      "step 2933/5000 | train loss 0.062090 | norm 0.1498 | lr 1.10e-05 | (119.09 ms | 34394 tok/s)\n",
      "step 2934/5000 | train loss 0.062079 | norm 0.1327 | lr 1.10e-05 | (117.79 ms | 34773 tok/s)\n",
      "step 2935/5000 | train loss 0.062079 | norm 0.1334 | lr 1.10e-05 | (138.14 ms | 29652 tok/s)\n",
      "step 2936/5000 | train loss 0.062077 | norm 0.1292 | lr 1.10e-05 | (118.28 ms | 34631 tok/s)\n",
      "step 2937/5000 | train loss 0.062070 | norm 0.1220 | lr 1.09e-05 | (117.48 ms | 34866 tok/s)\n",
      "step 2938/5000 | train loss 0.062075 | norm 0.1381 | lr 1.09e-05 | (119.18 ms | 34367 tok/s)\n",
      "step 2939/5000 | train loss 0.062066 | norm 0.1186 | lr 1.09e-05 | (117.26 ms | 34931 tok/s)\n",
      "step 2940/5000 | train loss 0.062066 | norm 0.1244 | lr 1.09e-05 | (121.77 ms | 33638 tok/s)\n",
      "step 2941/5000 | train loss 0.062069 | norm 0.1402 | lr 1.09e-05 | (120.49 ms | 33994 tok/s)\n",
      "step 2942/5000 | train loss 0.062066 | norm 0.1426 | lr 1.09e-05 | (117.17 ms | 34958 tok/s)\n",
      "step 2943/5000 | train loss 0.062066 | norm 0.1463 | lr 1.09e-05 | (120.14 ms | 34093 tok/s)\n",
      "step 2944/5000 | train loss 0.062062 | norm 0.1382 | lr 1.09e-05 | (117.37 ms | 34899 tok/s)\n",
      "step 2945/5000 | train loss 0.062053 | norm 0.1169 | lr 1.09e-05 | (116.82 ms | 35064 tok/s)\n",
      "step 2946/5000 | train loss 0.062049 | norm 0.1078 | lr 1.09e-05 | (116.22 ms | 35244 tok/s)\n",
      "step 2947/5000 | train loss 0.062045 | norm 0.1015 | lr 1.09e-05 | (121.78 ms | 33634 tok/s)\n",
      "step 2948/5000 | train loss 0.062046 | norm 0.1125 | lr 1.08e-05 | (117.60 ms | 34830 tok/s)\n",
      "step 2949/5000 | train loss 0.062052 | norm 0.1447 | lr 1.08e-05 | (119.64 ms | 34236 tok/s)\n",
      "step 2950/5000 | train loss 0.062059 | norm 0.1663 | lr 1.08e-05 | (115.86 ms | 35352 tok/s)\n",
      "step 2951/5000 | train loss 0.062053 | norm 0.1629 | lr 1.08e-05 | (125.27 ms | 32697 tok/s)\n",
      "step 2952/5000 | train loss 0.062053 | norm 0.1656 | lr 1.08e-05 | (117.25 ms | 34934 tok/s)\n",
      "step 2953/5000 | train loss 0.062059 | norm 0.1932 | lr 1.08e-05 | (118.75 ms | 34494 tok/s)\n",
      "step 2954/5000 | train loss 0.062074 | norm 0.2285 | lr 1.08e-05 | (118.27 ms | 34634 tok/s)\n",
      "step 2955/5000 | train loss 0.062071 | norm 0.2224 | lr 1.08e-05 | (117.42 ms | 34883 tok/s)\n",
      "step 2956/5000 | train loss 0.062051 | norm 0.1838 | lr 1.08e-05 | (118.89 ms | 34451 tok/s)\n",
      "step 2957/5000 | train loss 0.062056 | norm 0.1899 | lr 1.08e-05 | (116.79 ms | 35073 tok/s)\n",
      "step 2958/5000 | train loss 0.062044 | norm 0.1766 | lr 1.08e-05 | (113.66 ms | 36037 tok/s)\n",
      "step 2959/5000 | train loss 0.062039 | norm 0.1593 | lr 1.07e-05 | (116.70 ms | 35100 tok/s)\n",
      "step 2960/5000 | train loss 0.062031 | norm 0.1386 | lr 1.07e-05 | (117.91 ms | 34739 tok/s)\n",
      "step 2961/5000 | train loss 0.062032 | norm 0.1501 | lr 1.07e-05 | (116.71 ms | 35095 tok/s)\n",
      "step 2962/5000 | train loss 0.062030 | norm 0.1484 | lr 1.07e-05 | (118.25 ms | 34638 tok/s)\n",
      "step 2963/5000 | train loss 0.062019 | norm 0.1141 | lr 1.07e-05 | (121.50 ms | 33712 tok/s)\n",
      "step 2964/5000 | train loss 0.062019 | norm 0.1261 | lr 1.07e-05 | (120.18 ms | 34082 tok/s)\n",
      "step 2965/5000 | train loss 0.062018 | norm 0.1292 | lr 1.07e-05 | (123.13 ms | 33266 tok/s)\n",
      "step 2966/5000 | train loss 0.062007 | norm 0.0972 | lr 1.07e-05 | (115.51 ms | 35460 tok/s)\n",
      "step 2967/5000 | train loss 0.062011 | norm 0.1154 | lr 1.07e-05 | (116.66 ms | 35110 tok/s)\n",
      "step 2968/5000 | train loss 0.062007 | norm 0.1091 | lr 1.07e-05 | (120.94 ms | 33868 tok/s)\n",
      "step 2969/5000 | train loss 0.062001 | norm 0.0941 | lr 1.07e-05 | (123.88 ms | 33064 tok/s)\n",
      "step 2970/5000 | train loss 0.062004 | norm 0.1164 | lr 1.06e-05 | (120.70 ms | 33936 tok/s)\n",
      "step 2971/5000 | train loss 0.062008 | norm 0.1382 | lr 1.06e-05 | (114.74 ms | 35697 tok/s)\n",
      "step 2972/5000 | train loss 0.062011 | norm 0.1565 | lr 1.06e-05 | (114.69 ms | 35715 tok/s)\n",
      "step 2973/5000 | train loss 0.062019 | norm 0.1821 | lr 1.06e-05 | (115.38 ms | 35500 tok/s)\n",
      "step 2974/5000 | train loss 0.062023 | norm 0.1957 | lr 1.06e-05 | (113.80 ms | 35994 tok/s)\n",
      "step 2975/5000 | train loss 0.062010 | norm 0.1631 | lr 1.06e-05 | (113.35 ms | 36137 tok/s)\n",
      "step 2976/5000 | train loss 0.061988 | norm 0.1009 | lr 1.06e-05 | (113.16 ms | 36197 tok/s)\n",
      "step 2977/5000 | train loss 0.062000 | norm 0.1403 | lr 1.06e-05 | (121.55 ms | 33697 tok/s)\n",
      "step 2978/5000 | train loss 0.061999 | norm 0.1519 | lr 1.06e-05 | (116.75 ms | 35083 tok/s)\n",
      "step 2979/5000 | train loss 0.061992 | norm 0.1339 | lr 1.06e-05 | (123.20 ms | 33248 tok/s)\n",
      "step 2980/5000 | train loss 0.061990 | norm 0.1333 | lr 1.06e-05 | (120.04 ms | 34122 tok/s)\n",
      "step 2981/5000 | train loss 0.061996 | norm 0.1561 | lr 1.05e-05 | (115.69 ms | 35404 tok/s)\n",
      "step 2982/5000 | train loss 0.062001 | norm 0.1785 | lr 1.05e-05 | (114.60 ms | 35741 tok/s)\n",
      "step 2983/5000 | train loss 0.062001 | norm 0.1862 | lr 1.05e-05 | (116.24 ms | 35239 tok/s)\n",
      "step 2984/5000 | train loss 0.061994 | norm 0.1746 | lr 1.05e-05 | (116.20 ms | 35248 tok/s)\n",
      "step 2985/5000 | train loss 0.061991 | norm 0.1657 | lr 1.05e-05 | (120.95 ms | 33866 tok/s)\n",
      "step 2986/5000 | train loss 0.061986 | norm 0.1515 | lr 1.05e-05 | (115.72 ms | 35395 tok/s)\n",
      "step 2987/5000 | train loss 0.061981 | norm 0.1432 | lr 1.05e-05 | (116.38 ms | 35195 tok/s)\n",
      "step 2988/5000 | train loss 0.061985 | norm 0.1656 | lr 1.05e-05 | (114.89 ms | 35653 tok/s)\n",
      "step 2989/5000 | train loss 0.061983 | norm 0.1625 | lr 1.05e-05 | (122.63 ms | 33401 tok/s)\n",
      "step 2990/5000 | train loss 0.061974 | norm 0.1378 | lr 1.05e-05 | (123.00 ms | 33301 tok/s)\n",
      "step 2991/5000 | train loss 0.061970 | norm 0.1324 | lr 1.05e-05 | (119.39 ms | 34307 tok/s)\n",
      "step 2992/5000 | train loss 0.061972 | norm 0.1408 | lr 1.04e-05 | (113.93 ms | 35953 tok/s)\n",
      "step 2993/5000 | train loss 0.061966 | norm 0.1312 | lr 1.04e-05 | (114.71 ms | 35708 tok/s)\n",
      "step 2994/5000 | train loss 0.061962 | norm 0.1225 | lr 1.04e-05 | (120.61 ms | 33962 tok/s)\n",
      "step 2995/5000 | train loss 0.061956 | norm 0.1073 | lr 1.04e-05 | (124.16 ms | 32991 tok/s)\n",
      "step 2996/5000 | train loss 0.061954 | norm 0.1074 | lr 1.04e-05 | (124.11 ms | 33003 tok/s)\n",
      "step 2997/5000 | train loss 0.061954 | norm 0.1165 | lr 1.04e-05 | (118.54 ms | 34553 tok/s)\n",
      "step 2998/5000 | train loss 0.061953 | norm 0.1192 | lr 1.04e-05 | (118.36 ms | 34605 tok/s)\n",
      "step 2999/5000 | train loss 0.061951 | norm 0.1190 | lr 1.04e-05 | (123.92 ms | 33053 tok/s)\n",
      "step 3000/5000 | train loss 0.061953 | norm 0.1363 | lr 1.04e-05 | (118.53 ms | 34557 tok/s)\n",
      "step 3001/5000 | train loss 0.061960 | norm 0.1629 | lr 1.04e-05 | (116.09 ms | 35283 tok/s)\n",
      "step 3002/5000 | train loss 0.061960 | norm 0.1770 | lr 1.04e-05 | (115.40 ms | 35495 tok/s)\n",
      "step 3003/5000 | train loss 0.061964 | norm 0.1830 | lr 1.03e-05 | (120.21 ms | 34073 tok/s)\n",
      "step 3004/5000 | train loss 0.061949 | norm 0.1437 | lr 1.03e-05 | (139.18 ms | 29430 tok/s)\n",
      "step 3005/5000 | train loss 0.061943 | norm 0.1290 | lr 1.03e-05 | (113.38 ms | 36125 tok/s)\n",
      "step 3006/5000 | train loss 0.061947 | norm 0.1492 | lr 1.03e-05 | (113.69 ms | 36029 tok/s)\n",
      "step 3007/5000 | train loss 0.061944 | norm 0.1523 | lr 1.03e-05 | (113.91 ms | 35957 tok/s)\n",
      "step 3008/5000 | train loss 0.061944 | norm 0.1528 | lr 1.03e-05 | (113.93 ms | 35950 tok/s)\n",
      "step 3009/5000 | train loss 0.061931 | norm 0.1184 | lr 1.03e-05 | (114.38 ms | 35811 tok/s)\n",
      "step 3010/5000 | train loss 0.061940 | norm 0.1458 | lr 1.03e-05 | (119.21 ms | 34359 tok/s)\n",
      "step 3011/5000 | train loss 0.061943 | norm 0.1667 | lr 1.03e-05 | (115.95 ms | 35325 tok/s)\n",
      "step 3012/5000 | train loss 0.061938 | norm 0.1604 | lr 1.03e-05 | (115.89 ms | 35343 tok/s)\n",
      "step 3013/5000 | train loss 0.061941 | norm 0.1693 | lr 1.03e-05 | (116.89 ms | 35041 tok/s)\n",
      "step 3014/5000 | train loss 0.061933 | norm 0.1514 | lr 1.03e-05 | (114.84 ms | 35666 tok/s)\n",
      "step 3015/5000 | train loss 0.061926 | norm 0.1351 | lr 1.02e-05 | (114.75 ms | 35695 tok/s)\n",
      "step 3016/5000 | train loss 0.061930 | norm 0.1480 | lr 1.02e-05 | (114.57 ms | 35752 tok/s)\n",
      "step 3017/5000 | train loss 0.061921 | norm 0.1288 | lr 1.02e-05 | (116.10 ms | 35280 tok/s)\n",
      "step 3018/5000 | train loss 0.061918 | norm 0.1213 | lr 1.02e-05 | (114.70 ms | 35712 tok/s)\n",
      "step 3019/5000 | train loss 0.061918 | norm 0.1285 | lr 1.02e-05 | (114.94 ms | 35637 tok/s)\n",
      "step 3020/5000 | train loss 0.061912 | norm 0.1196 | lr 1.02e-05 | (113.96 ms | 35941 tok/s)\n",
      "step 3021/5000 | train loss 0.061913 | norm 0.1220 | lr 1.02e-05 | (115.37 ms | 35504 tok/s)\n",
      "step 3022/5000 | train loss 0.061908 | norm 0.1115 | lr 1.02e-05 | (114.19 ms | 35869 tok/s)\n",
      "step 3023/5000 | train loss 0.061909 | norm 0.1209 | lr 1.02e-05 | (114.91 ms | 35646 tok/s)\n",
      "step 3024/5000 | train loss 0.061913 | norm 0.1425 | lr 1.02e-05 | (115.93 ms | 35333 tok/s)\n",
      "step 3025/5000 | train loss 0.061911 | norm 0.1425 | lr 1.02e-05 | (125.11 ms | 32739 tok/s)\n",
      "step 3026/5000 | train loss 0.061911 | norm 0.1456 | lr 1.01e-05 | (123.77 ms | 33094 tok/s)\n",
      "step 3027/5000 | train loss 0.061908 | norm 0.1467 | lr 1.01e-05 | (121.64 ms | 33673 tok/s)\n",
      "step 3028/5000 | train loss 0.061909 | norm 0.1534 | lr 1.01e-05 | (115.21 ms | 35553 tok/s)\n",
      "step 3029/5000 | train loss 0.061906 | norm 0.1503 | lr 1.01e-05 | (113.35 ms | 36135 tok/s)\n",
      "step 3030/5000 | train loss 0.061901 | norm 0.1401 | lr 1.01e-05 | (114.63 ms | 35732 tok/s)\n",
      "step 3031/5000 | train loss 0.061900 | norm 0.1346 | lr 1.01e-05 | (117.24 ms | 34938 tok/s)\n",
      "step 3032/5000 | train loss 0.061891 | norm 0.1179 | lr 1.01e-05 | (116.32 ms | 35214 tok/s)\n",
      "step 3033/5000 | train loss 0.061895 | norm 0.1354 | lr 1.01e-05 | (119.40 ms | 34305 tok/s)\n",
      "step 3034/5000 | train loss 0.061895 | norm 0.1447 | lr 1.01e-05 | (115.00 ms | 35617 tok/s)\n",
      "step 3035/5000 | train loss 0.061895 | norm 0.1478 | lr 1.01e-05 | (114.07 ms | 35908 tok/s)\n",
      "step 3036/5000 | train loss 0.061895 | norm 0.1510 | lr 1.01e-05 | (113.82 ms | 35985 tok/s)\n",
      "step 3037/5000 | train loss 0.061893 | norm 0.1505 | lr 1.00e-05 | (114.35 ms | 35819 tok/s)\n",
      "step 3038/5000 | train loss 0.061893 | norm 0.1508 | lr 1.00e-05 | (117.41 ms | 34888 tok/s)\n",
      "step 3039/5000 | train loss 0.061885 | norm 0.1346 | lr 1.00e-05 | (120.38 ms | 34025 tok/s)\n",
      "step 3040/5000 | train loss 0.061885 | norm 0.1378 | lr 1.00e-05 | (112.90 ms | 36280 tok/s)\n",
      "step 3041/5000 | train loss 0.061889 | norm 0.1594 | lr 1.00e-05 | (115.80 ms | 35372 tok/s)\n",
      "step 3042/5000 | train loss 0.061886 | norm 0.1541 | lr 1.00e-05 | (113.85 ms | 35978 tok/s)\n",
      "step 3043/5000 | train loss 0.061876 | norm 0.1292 | lr 9.99e-06 | (115.96 ms | 35321 tok/s)\n",
      "step 3044/5000 | train loss 0.061879 | norm 0.1337 | lr 9.98e-06 | (114.04 ms | 35918 tok/s)\n",
      "step 3045/5000 | train loss 0.061871 | norm 0.1288 | lr 9.97e-06 | (114.02 ms | 35924 tok/s)\n",
      "step 3046/5000 | train loss 0.061877 | norm 0.1410 | lr 9.97e-06 | (120.19 ms | 34079 tok/s)\n",
      "step 3047/5000 | train loss 0.061864 | norm 0.1040 | lr 9.96e-06 | (120.42 ms | 34013 tok/s)\n",
      "step 3048/5000 | train loss 0.061862 | norm 0.1062 | lr 9.95e-06 | (114.19 ms | 35870 tok/s)\n",
      "step 3049/5000 | train loss 0.061869 | norm 0.1325 | lr 9.94e-06 | (113.57 ms | 36065 tok/s)\n",
      "step 3050/5000 | train loss 0.061861 | norm 0.1182 | lr 9.93e-06 | (115.05 ms | 35602 tok/s)\n",
      "step 3051/5000 | train loss 0.061861 | norm 0.1219 | lr 9.92e-06 | (116.25 ms | 35234 tok/s)\n",
      "step 3052/5000 | train loss 0.061861 | norm 0.1324 | lr 9.91e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 3053/5000 | train loss 0.061865 | norm 0.1466 | lr 9.90e-06 | (115.66 ms | 35413 tok/s)\n",
      "step 3054/5000 | train loss 0.061860 | norm 0.1413 | lr 9.89e-06 | (114.23 ms | 35858 tok/s)\n",
      "step 3055/5000 | train loss 0.061862 | norm 0.1472 | lr 9.89e-06 | (114.99 ms | 35621 tok/s)\n",
      "step 3056/5000 | train loss 0.061863 | norm 0.1523 | lr 9.88e-06 | (113.80 ms | 35993 tok/s)\n",
      "step 3057/5000 | train loss 0.061858 | norm 0.1480 | lr 9.87e-06 | (113.16 ms | 36196 tok/s)\n",
      "step 3058/5000 | train loss 0.061857 | norm 0.1488 | lr 9.86e-06 | (113.18 ms | 36191 tok/s)\n",
      "step 3059/5000 | train loss 0.061853 | norm 0.1433 | lr 9.85e-06 | (114.98 ms | 35623 tok/s)\n",
      "step 3060/5000 | train loss 0.061856 | norm 0.1567 | lr 9.84e-06 | (113.43 ms | 36109 tok/s)\n",
      "step 3061/5000 | train loss 0.061854 | norm 0.1563 | lr 9.83e-06 | (132.65 ms | 30878 tok/s)\n",
      "step 3062/5000 | train loss 0.061844 | norm 0.1246 | lr 9.82e-06 | (114.29 ms | 35839 tok/s)\n",
      "step 3063/5000 | train loss 0.061838 | norm 0.1128 | lr 9.81e-06 | (121.72 ms | 33652 tok/s)\n",
      "step 3064/5000 | train loss 0.061844 | norm 0.1364 | lr 9.81e-06 | (123.66 ms | 33123 tok/s)\n",
      "step 3065/5000 | train loss 0.061841 | norm 0.1301 | lr 9.80e-06 | (120.73 ms | 33928 tok/s)\n",
      "step 3066/5000 | train loss 0.061832 | norm 0.1022 | lr 9.79e-06 | (120.45 ms | 34005 tok/s)\n",
      "step 3067/5000 | train loss 0.061832 | norm 0.1091 | lr 9.78e-06 | (121.39 ms | 33742 tok/s)\n",
      "step 3068/5000 | train loss 0.061837 | norm 0.1321 | lr 9.77e-06 | (117.79 ms | 34773 tok/s)\n",
      "step 3069/5000 | train loss 0.061835 | norm 0.1355 | lr 9.76e-06 | (118.91 ms | 34446 tok/s)\n",
      "step 3070/5000 | train loss 0.061839 | norm 0.1477 | lr 9.75e-06 | (117.55 ms | 34845 tok/s)\n",
      "step 3071/5000 | train loss 0.061838 | norm 0.1517 | lr 9.74e-06 | (117.15 ms | 34964 tok/s)\n",
      "step 3072/5000 | train loss 0.061834 | norm 0.1405 | lr 9.74e-06 | (119.81 ms | 34187 tok/s)\n",
      "step 3073/5000 | train loss 0.061827 | norm 0.1232 | lr 9.73e-06 | (117.71 ms | 34797 tok/s)\n",
      "step 3074/5000 | train loss 0.061825 | norm 0.1214 | lr 9.72e-06 | (114.50 ms | 35774 tok/s)\n",
      "step 3075/5000 | train loss 0.061825 | norm 0.1297 | lr 9.71e-06 | (120.53 ms | 33982 tok/s)\n",
      "step 3076/5000 | train loss 0.061825 | norm 0.1349 | lr 9.70e-06 | (119.09 ms | 34395 tok/s)\n",
      "step 3077/5000 | train loss 0.061823 | norm 0.1348 | lr 9.69e-06 | (117.60 ms | 34831 tok/s)\n",
      "step 3078/5000 | train loss 0.061821 | norm 0.1346 | lr 9.68e-06 | (116.03 ms | 35300 tok/s)\n",
      "step 3079/5000 | train loss 0.061823 | norm 0.1467 | lr 9.67e-06 | (116.18 ms | 35257 tok/s)\n",
      "step 3080/5000 | train loss 0.061825 | norm 0.1564 | lr 9.66e-06 | (116.67 ms | 35107 tok/s)\n",
      "step 3081/5000 | train loss 0.061822 | norm 0.1533 | lr 9.66e-06 | (116.87 ms | 35047 tok/s)\n",
      "step 3082/5000 | train loss 0.061822 | norm 0.1600 | lr 9.65e-06 | (115.07 ms | 35596 tok/s)\n",
      "step 3083/5000 | train loss 0.061822 | norm 0.1616 | lr 9.64e-06 | (117.69 ms | 34804 tok/s)\n",
      "step 3084/5000 | train loss 0.061816 | norm 0.1463 | lr 9.63e-06 | (113.60 ms | 36056 tok/s)\n",
      "step 3085/5000 | train loss 0.061809 | norm 0.1281 | lr 9.62e-06 | (117.70 ms | 34801 tok/s)\n",
      "step 3086/5000 | train loss 0.061811 | norm 0.1375 | lr 9.61e-06 | (117.12 ms | 34974 tok/s)\n",
      "step 3087/5000 | train loss 0.061807 | norm 0.1335 | lr 9.60e-06 | (117.25 ms | 34935 tok/s)\n",
      "step 3088/5000 | train loss 0.061803 | norm 0.1236 | lr 9.59e-06 | (115.30 ms | 35525 tok/s)\n",
      "step 3089/5000 | train loss 0.061799 | norm 0.1140 | lr 9.59e-06 | (116.60 ms | 35127 tok/s)\n",
      "step 3090/5000 | train loss 0.061795 | norm 0.1037 | lr 9.58e-06 | (114.24 ms | 35855 tok/s)\n",
      "step 3091/5000 | train loss 0.061793 | norm 0.1070 | lr 9.57e-06 | (115.23 ms | 35546 tok/s)\n",
      "step 3092/5000 | train loss 0.061792 | norm 0.1070 | lr 9.56e-06 | (114.48 ms | 35780 tok/s)\n",
      "step 3093/5000 | train loss 0.061789 | norm 0.1033 | lr 9.55e-06 | (116.74 ms | 35085 tok/s)\n",
      "step 3094/5000 | train loss 0.061789 | norm 0.1101 | lr 9.54e-06 | (116.31 ms | 35215 tok/s)\n",
      "step 3095/5000 | train loss 0.061787 | norm 0.1066 | lr 9.53e-06 | (116.71 ms | 35096 tok/s)\n",
      "step 3096/5000 | train loss 0.061784 | norm 0.1047 | lr 9.52e-06 | (121.67 ms | 33666 tok/s)\n",
      "step 3097/5000 | train loss 0.061789 | norm 0.1284 | lr 9.52e-06 | (119.98 ms | 34140 tok/s)\n",
      "step 3098/5000 | train loss 0.061790 | norm 0.1404 | lr 9.51e-06 | (119.23 ms | 34355 tok/s)\n",
      "step 3099/5000 | train loss 0.061792 | norm 0.1571 | lr 9.50e-06 | (119.15 ms | 34377 tok/s)\n",
      "step 3100/5000 | train loss 0.061800 | norm 0.1806 | lr 9.49e-06 | (117.34 ms | 34908 tok/s)\n",
      "step 3101/5000 | train loss 0.061798 | norm 0.1724 | lr 9.48e-06 | (117.99 ms | 34714 tok/s)\n",
      "step 3102/5000 | train loss 0.061784 | norm 0.1352 | lr 9.47e-06 | (118.64 ms | 34525 tok/s)\n",
      "step 3103/5000 | train loss 0.061782 | norm 0.1358 | lr 9.46e-06 | (118.42 ms | 34589 tok/s)\n",
      "step 3104/5000 | train loss 0.061787 | norm 0.1586 | lr 9.45e-06 | (116.46 ms | 35170 tok/s)\n",
      "step 3105/5000 | train loss 0.061787 | norm 0.1572 | lr 9.45e-06 | (122.44 ms | 33453 tok/s)\n",
      "step 3106/5000 | train loss 0.061770 | norm 0.1070 | lr 9.44e-06 | (119.97 ms | 34142 tok/s)\n",
      "step 3107/5000 | train loss 0.061772 | norm 0.1124 | lr 9.43e-06 | (115.50 ms | 35462 tok/s)\n",
      "step 3108/5000 | train loss 0.061774 | norm 0.1394 | lr 9.42e-06 | (114.20 ms | 35866 tok/s)\n",
      "step 3109/5000 | train loss 0.061776 | norm 0.1430 | lr 9.41e-06 | (115.01 ms | 35615 tok/s)\n",
      "step 3110/5000 | train loss 0.061766 | norm 0.1123 | lr 9.40e-06 | (113.94 ms | 35949 tok/s)\n",
      "step 3111/5000 | train loss 0.061765 | norm 0.1197 | lr 9.39e-06 | (115.64 ms | 35419 tok/s)\n",
      "step 3112/5000 | train loss 0.061774 | norm 0.1501 | lr 9.38e-06 | (114.26 ms | 35849 tok/s)\n",
      "step 3113/5000 | train loss 0.061764 | norm 0.1303 | lr 9.38e-06 | (117.76 ms | 34783 tok/s)\n",
      "step 3114/5000 | train loss 0.061761 | norm 0.1179 | lr 9.37e-06 | (113.69 ms | 36028 tok/s)\n",
      "step 3115/5000 | train loss 0.061762 | norm 0.1305 | lr 9.36e-06 | (117.60 ms | 34830 tok/s)\n",
      "step 3116/5000 | train loss 0.061762 | norm 0.1351 | lr 9.35e-06 | (117.30 ms | 34919 tok/s)\n",
      "step 3117/5000 | train loss 0.061761 | norm 0.1329 | lr 9.34e-06 | (118.11 ms | 34679 tok/s)\n",
      "step 3118/5000 | train loss 0.061761 | norm 0.1364 | lr 9.33e-06 | (116.27 ms | 35229 tok/s)\n",
      "step 3119/5000 | train loss 0.061762 | norm 0.1453 | lr 9.32e-06 | (118.81 ms | 34474 tok/s)\n",
      "step 3120/5000 | train loss 0.061754 | norm 0.1292 | lr 9.31e-06 | (115.20 ms | 35555 tok/s)\n",
      "step 3121/5000 | train loss 0.061749 | norm 0.1164 | lr 9.31e-06 | (116.68 ms | 35106 tok/s)\n",
      "step 3122/5000 | train loss 0.061754 | norm 0.1304 | lr 9.30e-06 | (117.62 ms | 34824 tok/s)\n",
      "step 3123/5000 | train loss 0.061746 | norm 0.1177 | lr 9.29e-06 | (117.98 ms | 34717 tok/s)\n",
      "step 3124/5000 | train loss 0.061749 | norm 0.1297 | lr 9.28e-06 | (116.44 ms | 35178 tok/s)\n",
      "step 3125/5000 | train loss 0.061748 | norm 0.1243 | lr 9.27e-06 | (117.85 ms | 34755 tok/s)\n",
      "step 3126/5000 | train loss 0.061741 | norm 0.1050 | lr 9.26e-06 | (115.56 ms | 35443 tok/s)\n",
      "step 3127/5000 | train loss 0.061740 | norm 0.1095 | lr 9.25e-06 | (114.62 ms | 35735 tok/s)\n",
      "step 3128/5000 | train loss 0.061736 | norm 0.1058 | lr 9.24e-06 | (113.80 ms | 35994 tok/s)\n",
      "step 3129/5000 | train loss 0.061739 | norm 0.1172 | lr 9.24e-06 | (114.47 ms | 35781 tok/s)\n",
      "step 3130/5000 | train loss 0.061738 | norm 0.1184 | lr 9.23e-06 | (113.49 ms | 36091 tok/s)\n",
      "step 3131/5000 | train loss 0.061730 | norm 0.0988 | lr 9.22e-06 | (112.65 ms | 36361 tok/s)\n",
      "step 3132/5000 | train loss 0.061733 | norm 0.1159 | lr 9.21e-06 | (114.85 ms | 35664 tok/s)\n",
      "step 3133/5000 | train loss 0.061734 | norm 0.1238 | lr 9.20e-06 | (131.25 ms | 31207 tok/s)\n",
      "step 3134/5000 | train loss 0.061734 | norm 0.1291 | lr 9.19e-06 | (114.28 ms | 35841 tok/s)\n",
      "step 3135/5000 | train loss 0.061738 | norm 0.1523 | lr 9.18e-06 | (118.37 ms | 34605 tok/s)\n",
      "step 3136/5000 | train loss 0.061753 | norm 0.1965 | lr 9.17e-06 | (115.71 ms | 35400 tok/s)\n",
      "step 3137/5000 | train loss 0.061760 | norm 0.2126 | lr 9.17e-06 | (117.16 ms | 34960 tok/s)\n",
      "step 3138/5000 | train loss 0.061739 | norm 0.1669 | lr 9.16e-06 | (116.14 ms | 35269 tok/s)\n",
      "step 3139/5000 | train loss 0.061735 | norm 0.1450 | lr 9.15e-06 | (115.21 ms | 35553 tok/s)\n",
      "step 3140/5000 | train loss 0.061733 | norm 0.1552 | lr 9.14e-06 | (115.89 ms | 35343 tok/s)\n",
      "step 3141/5000 | train loss 0.061736 | norm 0.1648 | lr 9.13e-06 | (117.61 ms | 34827 tok/s)\n",
      "step 3142/5000 | train loss 0.061722 | norm 0.1222 | lr 9.12e-06 | (117.33 ms | 34911 tok/s)\n",
      "step 3143/5000 | train loss 0.061723 | norm 0.1245 | lr 9.11e-06 | (119.84 ms | 34178 tok/s)\n",
      "step 3144/5000 | train loss 0.061722 | norm 0.1346 | lr 9.11e-06 | (115.27 ms | 35535 tok/s)\n",
      "step 3145/5000 | train loss 0.061716 | norm 0.1146 | lr 9.10e-06 | (115.51 ms | 35461 tok/s)\n",
      "step 3146/5000 | train loss 0.061714 | norm 0.1079 | lr 9.09e-06 | (114.87 ms | 35659 tok/s)\n",
      "step 3147/5000 | train loss 0.061711 | norm 0.1057 | lr 9.08e-06 | (115.31 ms | 35523 tok/s)\n",
      "step 3148/5000 | train loss 0.061710 | norm 0.1069 | lr 9.07e-06 | (113.44 ms | 36106 tok/s)\n",
      "step 3149/5000 | train loss 0.061706 | norm 0.0974 | lr 9.06e-06 | (116.46 ms | 35170 tok/s)\n",
      "step 3150/5000 | train loss 0.061704 | norm 0.0917 | lr 9.05e-06 | (114.66 ms | 35724 tok/s)\n",
      "step 3151/5000 | train loss 0.061702 | norm 0.0945 | lr 9.04e-06 | (115.41 ms | 35491 tok/s)\n",
      "step 3152/5000 | train loss 0.061705 | norm 0.1102 | lr 9.04e-06 | (113.45 ms | 36106 tok/s)\n",
      "step 3153/5000 | train loss 0.061703 | norm 0.1087 | lr 9.03e-06 | (114.95 ms | 35632 tok/s)\n",
      "step 3154/5000 | train loss 0.061705 | norm 0.1226 | lr 9.02e-06 | (114.02 ms | 35923 tok/s)\n",
      "step 3155/5000 | train loss 0.061710 | norm 0.1444 | lr 9.01e-06 | (115.38 ms | 35501 tok/s)\n",
      "step 3156/5000 | train loss 0.061708 | norm 0.1463 | lr 9.00e-06 | (114.70 ms | 35712 tok/s)\n",
      "step 3157/5000 | train loss 0.061702 | norm 0.1320 | lr 8.99e-06 | (115.33 ms | 35516 tok/s)\n",
      "step 3158/5000 | train loss 0.061698 | norm 0.1157 | lr 8.98e-06 | (114.76 ms | 35690 tok/s)\n",
      "step 3159/5000 | train loss 0.061696 | norm 0.1159 | lr 8.98e-06 | (115.63 ms | 35423 tok/s)\n",
      "step 3160/5000 | train loss 0.061699 | norm 0.1291 | lr 8.97e-06 | (114.24 ms | 35853 tok/s)\n",
      "step 3161/5000 | train loss 0.061698 | norm 0.1285 | lr 8.96e-06 | (114.67 ms | 35720 tok/s)\n",
      "step 3162/5000 | train loss 0.061691 | norm 0.1112 | lr 8.95e-06 | (113.72 ms | 36018 tok/s)\n",
      "step 3163/5000 | train loss 0.061690 | norm 0.1115 | lr 8.94e-06 | (113.78 ms | 35998 tok/s)\n",
      "step 3164/5000 | train loss 0.061690 | norm 0.1201 | lr 8.93e-06 | (114.08 ms | 35903 tok/s)\n",
      "step 3165/5000 | train loss 0.061688 | norm 0.1205 | lr 8.92e-06 | (117.24 ms | 34937 tok/s)\n",
      "step 3166/5000 | train loss 0.061686 | norm 0.1183 | lr 8.92e-06 | (115.54 ms | 35452 tok/s)\n",
      "step 3167/5000 | train loss 0.061689 | norm 0.1328 | lr 8.91e-06 | (114.70 ms | 35712 tok/s)\n",
      "step 3168/5000 | train loss 0.061693 | norm 0.1530 | lr 8.90e-06 | (117.21 ms | 34947 tok/s)\n",
      "step 3169/5000 | train loss 0.061692 | norm 0.1542 | lr 8.89e-06 | (117.14 ms | 34966 tok/s)\n",
      "step 3170/5000 | train loss 0.061684 | norm 0.1298 | lr 8.88e-06 | (114.63 ms | 35731 tok/s)\n",
      "step 3171/5000 | train loss 0.061683 | norm 0.1250 | lr 8.87e-06 | (116.97 ms | 35016 tok/s)\n",
      "step 3172/5000 | train loss 0.061681 | norm 0.1242 | lr 8.86e-06 | (114.90 ms | 35649 tok/s)\n",
      "step 3173/5000 | train loss 0.061678 | norm 0.1198 | lr 8.86e-06 | (115.99 ms | 35313 tok/s)\n",
      "step 3174/5000 | train loss 0.061677 | norm 0.1170 | lr 8.85e-06 | (114.91 ms | 35644 tok/s)\n",
      "step 3175/5000 | train loss 0.061673 | norm 0.1110 | lr 8.84e-06 | (115.36 ms | 35507 tok/s)\n",
      "step 3176/5000 | train loss 0.061674 | norm 0.1177 | lr 8.83e-06 | (115.64 ms | 35420 tok/s)\n",
      "step 3177/5000 | train loss 0.061671 | norm 0.1133 | lr 8.82e-06 | (116.92 ms | 35034 tok/s)\n",
      "step 3178/5000 | train loss 0.061669 | norm 0.1135 | lr 8.81e-06 | (114.47 ms | 35784 tok/s)\n",
      "step 3179/5000 | train loss 0.061673 | norm 0.1292 | lr 8.80e-06 | (114.04 ms | 35917 tok/s)\n",
      "step 3180/5000 | train loss 0.061670 | norm 0.1249 | lr 8.80e-06 | (113.73 ms | 36015 tok/s)\n",
      "step 3181/5000 | train loss 0.061667 | norm 0.1214 | lr 8.79e-06 | (117.42 ms | 34882 tok/s)\n",
      "step 3182/5000 | train loss 0.061670 | norm 0.1306 | lr 8.78e-06 | (117.60 ms | 34830 tok/s)\n",
      "step 3183/5000 | train loss 0.061665 | norm 0.1211 | lr 8.77e-06 | (116.50 ms | 35160 tok/s)\n",
      "step 3184/5000 | train loss 0.061663 | norm 0.1163 | lr 8.76e-06 | (115.52 ms | 35458 tok/s)\n",
      "step 3185/5000 | train loss 0.061663 | norm 0.1223 | lr 8.75e-06 | (118.44 ms | 34584 tok/s)\n",
      "step 3186/5000 | train loss 0.061662 | norm 0.1248 | lr 8.74e-06 | (115.92 ms | 35335 tok/s)\n",
      "step 3187/5000 | train loss 0.061662 | norm 0.1286 | lr 8.74e-06 | (117.72 ms | 34795 tok/s)\n",
      "step 3188/5000 | train loss 0.061658 | norm 0.1196 | lr 8.73e-06 | (117.07 ms | 34987 tok/s)\n",
      "step 3189/5000 | train loss 0.061653 | norm 0.1088 | lr 8.72e-06 | (114.79 ms | 35681 tok/s)\n",
      "step 3190/5000 | train loss 0.061657 | norm 0.1247 | lr 8.71e-06 | (114.48 ms | 35778 tok/s)\n",
      "step 3191/5000 | train loss 0.061655 | norm 0.1236 | lr 8.70e-06 | (113.93 ms | 35951 tok/s)\n",
      "step 3192/5000 | train loss 0.061652 | norm 0.1184 | lr 8.69e-06 | (112.90 ms | 36280 tok/s)\n",
      "step 3193/5000 | train loss 0.061653 | norm 0.1302 | lr 8.68e-06 | (116.94 ms | 35026 tok/s)\n",
      "step 3194/5000 | train loss 0.061655 | norm 0.1424 | lr 8.68e-06 | (113.68 ms | 36031 tok/s)\n",
      "step 3195/5000 | train loss 0.061650 | norm 0.1276 | lr 8.67e-06 | (114.47 ms | 35783 tok/s)\n",
      "step 3196/5000 | train loss 0.061643 | norm 0.1054 | lr 8.66e-06 | (116.43 ms | 35179 tok/s)\n",
      "step 3197/5000 | train loss 0.061644 | norm 0.1104 | lr 8.65e-06 | (115.66 ms | 35415 tok/s)\n",
      "step 3198/5000 | train loss 0.061645 | norm 0.1207 | lr 8.64e-06 | (116.03 ms | 35302 tok/s)\n",
      "step 3199/5000 | train loss 0.061641 | norm 0.1117 | lr 8.63e-06 | (115.23 ms | 35548 tok/s)\n",
      "step 3200/5000 | train loss 0.061638 | norm 0.1018 | lr 8.62e-06 | (116.82 ms | 35063 tok/s)\n",
      "step 3201/5000 | train loss 0.061638 | norm 0.1105 | lr 8.62e-06 | (115.97 ms | 35321 tok/s)\n",
      "step 3202/5000 | train loss 0.061639 | norm 0.1157 | lr 8.61e-06 | (115.05 ms | 35603 tok/s)\n",
      "step 3203/5000 | train loss 0.061636 | norm 0.1095 | lr 8.60e-06 | (115.24 ms | 35544 tok/s)\n",
      "step 3204/5000 | train loss 0.061634 | norm 0.1067 | lr 8.59e-06 | (114.82 ms | 35674 tok/s)\n",
      "step 3205/5000 | train loss 0.061636 | norm 0.1238 | lr 8.58e-06 | (115.83 ms | 35362 tok/s)\n",
      "step 3206/5000 | train loss 0.061638 | norm 0.1389 | lr 8.57e-06 | (114.25 ms | 35851 tok/s)\n",
      "step 3207/5000 | train loss 0.061636 | norm 0.1379 | lr 8.56e-06 | (117.01 ms | 35006 tok/s)\n",
      "step 3208/5000 | train loss 0.061637 | norm 0.1433 | lr 8.56e-06 | (114.72 ms | 35704 tok/s)\n",
      "step 3209/5000 | train loss 0.061635 | norm 0.1435 | lr 8.55e-06 | (114.68 ms | 35716 tok/s)\n",
      "step 3210/5000 | train loss 0.061633 | norm 0.1388 | lr 8.54e-06 | (114.44 ms | 35793 tok/s)\n",
      "step 3211/5000 | train loss 0.061631 | norm 0.1253 | lr 8.53e-06 | (114.29 ms | 35840 tok/s)\n",
      "step 3212/5000 | train loss 0.061623 | norm 0.1031 | lr 8.52e-06 | (114.57 ms | 35750 tok/s)\n",
      "step 3213/5000 | train loss 0.061623 | norm 0.1070 | lr 8.51e-06 | (115.32 ms | 35519 tok/s)\n",
      "step 3214/5000 | train loss 0.061620 | norm 0.1020 | lr 8.50e-06 | (115.53 ms | 35453 tok/s)\n",
      "step 3215/5000 | train loss 0.061620 | norm 0.1091 | lr 8.50e-06 | (115.88 ms | 35348 tok/s)\n",
      "step 3216/5000 | train loss 0.061619 | norm 0.1095 | lr 8.49e-06 | (114.89 ms | 35651 tok/s)\n",
      "step 3217/5000 | train loss 0.061615 | norm 0.0955 | lr 8.48e-06 | (115.74 ms | 35389 tok/s)\n",
      "step 3218/5000 | train loss 0.061615 | norm 0.1047 | lr 8.47e-06 | (115.79 ms | 35374 tok/s)\n",
      "step 3219/5000 | train loss 0.061622 | norm 0.1366 | lr 8.46e-06 | (114.72 ms | 35704 tok/s)\n",
      "step 3220/5000 | train loss 0.061624 | norm 0.1554 | lr 8.45e-06 | (113.56 ms | 36068 tok/s)\n",
      "step 3221/5000 | train loss 0.061624 | norm 0.1579 | lr 8.45e-06 | (114.19 ms | 35872 tok/s)\n",
      "step 3222/5000 | train loss 0.061617 | norm 0.1388 | lr 8.44e-06 | (116.49 ms | 35161 tok/s)\n",
      "step 3223/5000 | train loss 0.061616 | norm 0.1312 | lr 8.43e-06 | (115.16 ms | 35569 tok/s)\n",
      "step 3224/5000 | train loss 0.061610 | norm 0.1142 | lr 8.42e-06 | (113.97 ms | 35940 tok/s)\n",
      "step 3225/5000 | train loss 0.061608 | norm 0.1170 | lr 8.41e-06 | (114.33 ms | 35825 tok/s)\n",
      "step 3226/5000 | train loss 0.061618 | norm 0.1448 | lr 8.40e-06 | (114.01 ms | 35926 tok/s)\n",
      "step 3227/5000 | train loss 0.061604 | norm 0.1100 | lr 8.39e-06 | (117.44 ms | 34879 tok/s)\n",
      "step 3228/5000 | train loss 0.061602 | norm 0.0963 | lr 8.39e-06 | (115.72 ms | 35395 tok/s)\n",
      "step 3229/5000 | train loss 0.061604 | norm 0.1109 | lr 8.38e-06 | (115.74 ms | 35389 tok/s)\n",
      "step 3230/5000 | train loss 0.061602 | norm 0.1152 | lr 8.37e-06 | (114.28 ms | 35843 tok/s)\n",
      "step 3231/5000 | train loss 0.061599 | norm 0.1054 | lr 8.36e-06 | (115.94 ms | 35327 tok/s)\n",
      "step 3232/5000 | train loss 0.061596 | norm 0.0945 | lr 8.35e-06 | (112.73 ms | 36335 tok/s)\n",
      "step 3233/5000 | train loss 0.061596 | norm 0.1031 | lr 8.34e-06 | (114.09 ms | 35901 tok/s)\n",
      "step 3234/5000 | train loss 0.061595 | norm 0.1069 | lr 8.34e-06 | (114.47 ms | 35783 tok/s)\n",
      "step 3235/5000 | train loss 0.061593 | norm 0.1014 | lr 8.33e-06 | (114.79 ms | 35682 tok/s)\n",
      "step 3236/5000 | train loss 0.061591 | norm 0.0970 | lr 8.32e-06 | (117.18 ms | 34955 tok/s)\n",
      "step 3237/5000 | train loss 0.061593 | norm 0.1105 | lr 8.31e-06 | (115.66 ms | 35415 tok/s)\n",
      "step 3238/5000 | train loss 0.061594 | norm 0.1201 | lr 8.30e-06 | (113.89 ms | 35963 tok/s)\n",
      "step 3239/5000 | train loss 0.061598 | norm 0.1375 | lr 8.29e-06 | (114.84 ms | 35669 tok/s)\n",
      "step 3240/5000 | train loss 0.061595 | norm 0.1379 | lr 8.28e-06 | (114.77 ms | 35689 tok/s)\n",
      "step 3241/5000 | train loss 0.061594 | norm 0.1349 | lr 8.28e-06 | (115.61 ms | 35428 tok/s)\n",
      "step 3242/5000 | train loss 0.061589 | norm 0.1214 | lr 8.27e-06 | (114.26 ms | 35848 tok/s)\n",
      "step 3243/5000 | train loss 0.061589 | norm 0.1251 | lr 8.26e-06 | (116.09 ms | 35284 tok/s)\n",
      "step 3244/5000 | train loss 0.061594 | norm 0.1413 | lr 8.25e-06 | (115.35 ms | 35510 tok/s)\n",
      "step 3245/5000 | train loss 0.061587 | norm 0.1236 | lr 8.24e-06 | (115.67 ms | 35410 tok/s)\n",
      "step 3246/5000 | train loss 0.061582 | norm 0.1068 | lr 8.23e-06 | (114.37 ms | 35815 tok/s)\n",
      "step 3247/5000 | train loss 0.061580 | norm 0.1028 | lr 8.23e-06 | (116.50 ms | 35159 tok/s)\n",
      "step 3248/5000 | train loss 0.061578 | norm 0.1084 | lr 8.22e-06 | (117.11 ms | 34977 tok/s)\n",
      "step 3249/5000 | train loss 0.061583 | norm 0.1251 | lr 8.21e-06 | (114.43 ms | 35794 tok/s)\n",
      "step 3250/5000 | train loss 0.061578 | norm 0.1150 | lr 8.20e-06 | (114.44 ms | 35791 tok/s)\n",
      "step 3251/5000 | train loss 0.061578 | norm 0.1177 | lr 8.19e-06 | (114.93 ms | 35640 tok/s)\n",
      "step 3252/5000 | train loss 0.061581 | norm 0.1362 | lr 8.18e-06 | (113.82 ms | 35988 tok/s)\n",
      "step 3253/5000 | train loss 0.061582 | norm 0.1459 | lr 8.18e-06 | (114.80 ms | 35680 tok/s)\n",
      "step 3254/5000 | train loss 0.061580 | norm 0.1397 | lr 8.17e-06 | (115.78 ms | 35377 tok/s)\n",
      "step 3255/5000 | train loss 0.061572 | norm 0.1153 | lr 8.16e-06 | (114.57 ms | 35751 tok/s)\n",
      "step 3256/5000 | train loss 0.061569 | norm 0.1009 | lr 8.15e-06 | (113.75 ms | 36010 tok/s)\n",
      "step 3257/5000 | train loss 0.061567 | norm 0.1003 | lr 8.14e-06 | (113.17 ms | 36193 tok/s)\n",
      "step 3258/5000 | train loss 0.061569 | norm 0.1143 | lr 8.13e-06 | (115.18 ms | 35562 tok/s)\n",
      "step 3259/5000 | train loss 0.061566 | norm 0.1085 | lr 8.13e-06 | (115.66 ms | 35415 tok/s)\n",
      "step 3260/5000 | train loss 0.061562 | norm 0.0953 | lr 8.12e-06 | (114.22 ms | 35861 tok/s)\n",
      "step 3261/5000 | train loss 0.061562 | norm 0.0980 | lr 8.11e-06 | (113.57 ms | 36065 tok/s)\n",
      "step 3262/5000 | train loss 0.061558 | norm 0.0888 | lr 8.10e-06 | (114.38 ms | 35809 tok/s)\n",
      "step 3263/5000 | train loss 0.061560 | norm 0.0996 | lr 8.09e-06 | (114.32 ms | 35829 tok/s)\n",
      "step 3264/5000 | train loss 0.061558 | norm 0.0998 | lr 8.08e-06 | (113.67 ms | 36034 tok/s)\n",
      "step 3265/5000 | train loss 0.061556 | norm 0.1037 | lr 8.08e-06 | (114.94 ms | 35635 tok/s)\n",
      "step 3266/5000 | train loss 0.061562 | norm 0.1275 | lr 8.07e-06 | (115.68 ms | 35408 tok/s)\n",
      "step 3267/5000 | train loss 0.061561 | norm 0.1299 | lr 8.06e-06 | (116.51 ms | 35156 tok/s)\n",
      "step 3268/5000 | train loss 0.061561 | norm 0.1265 | lr 8.05e-06 | (114.49 ms | 35776 tok/s)\n",
      "step 3269/5000 | train loss 0.061556 | norm 0.1146 | lr 8.04e-06 | (114.55 ms | 35757 tok/s)\n",
      "step 3270/5000 | train loss 0.061554 | norm 0.1135 | lr 8.03e-06 | (114.58 ms | 35747 tok/s)\n",
      "step 3271/5000 | train loss 0.061554 | norm 0.1173 | lr 8.02e-06 | (112.55 ms | 36392 tok/s)\n",
      "step 3272/5000 | train loss 0.061554 | norm 0.1240 | lr 8.02e-06 | (112.97 ms | 36257 tok/s)\n",
      "step 3273/5000 | train loss 0.061552 | norm 0.1194 | lr 8.01e-06 | (133.86 ms | 30600 tok/s)\n",
      "step 3274/5000 | train loss 0.061547 | norm 0.1030 | lr 8.00e-06 | (119.01 ms | 34417 tok/s)\n",
      "step 3275/5000 | train loss 0.061544 | norm 0.0931 | lr 7.99e-06 | (117.16 ms | 34962 tok/s)\n",
      "step 3276/5000 | train loss 0.061547 | norm 0.1107 | lr 7.98e-06 | (117.11 ms | 34976 tok/s)\n",
      "step 3277/5000 | train loss 0.061549 | norm 0.1242 | lr 7.97e-06 | (116.99 ms | 35012 tok/s)\n",
      "step 3278/5000 | train loss 0.061547 | norm 0.1216 | lr 7.97e-06 | (115.53 ms | 35454 tok/s)\n",
      "step 3279/5000 | train loss 0.061546 | norm 0.1239 | lr 7.96e-06 | (115.39 ms | 35497 tok/s)\n",
      "step 3280/5000 | train loss 0.061548 | norm 0.1380 | lr 7.95e-06 | (114.90 ms | 35649 tok/s)\n",
      "step 3281/5000 | train loss 0.061553 | norm 0.1568 | lr 7.94e-06 | (116.50 ms | 35159 tok/s)\n",
      "step 3282/5000 | train loss 0.061547 | norm 0.1414 | lr 7.93e-06 | (115.07 ms | 35596 tok/s)\n",
      "step 3283/5000 | train loss 0.061539 | norm 0.1148 | lr 7.93e-06 | (115.44 ms | 35480 tok/s)\n",
      "step 3284/5000 | train loss 0.061544 | norm 0.1331 | lr 7.92e-06 | (116.26 ms | 35231 tok/s)\n",
      "step 3285/5000 | train loss 0.061544 | norm 0.1366 | lr 7.91e-06 | (116.27 ms | 35228 tok/s)\n",
      "step 3286/5000 | train loss 0.061533 | norm 0.1020 | lr 7.90e-06 | (114.40 ms | 35804 tok/s)\n",
      "step 3287/5000 | train loss 0.061536 | norm 0.1147 | lr 7.89e-06 | (116.12 ms | 35272 tok/s)\n",
      "step 3288/5000 | train loss 0.061537 | norm 0.1207 | lr 7.88e-06 | (114.64 ms | 35728 tok/s)\n",
      "step 3289/5000 | train loss 0.061529 | norm 0.0911 | lr 7.88e-06 | (118.65 ms | 34523 tok/s)\n",
      "step 3290/5000 | train loss 0.061524 | norm 0.0754 | lr 7.87e-06 | (116.39 ms | 35193 tok/s)\n",
      "step 3291/5000 | train loss 0.061528 | norm 0.0970 | lr 7.86e-06 | (118.43 ms | 34585 tok/s)\n",
      "step 3292/5000 | train loss 0.061526 | norm 0.0950 | lr 7.85e-06 | (115.71 ms | 35399 tok/s)\n",
      "step 3293/5000 | train loss 0.061521 | norm 0.0750 | lr 7.84e-06 | (115.03 ms | 35608 tok/s)\n",
      "step 3294/5000 | train loss 0.061522 | norm 0.0846 | lr 7.83e-06 | (116.95 ms | 35025 tok/s)\n",
      "step 3295/5000 | train loss 0.061520 | norm 0.0836 | lr 7.83e-06 | (119.77 ms | 34198 tok/s)\n",
      "step 3296/5000 | train loss 0.061516 | norm 0.0699 | lr 7.82e-06 | (117.64 ms | 34819 tok/s)\n",
      "step 3297/5000 | train loss 0.061518 | norm 0.0843 | lr 7.81e-06 | (114.04 ms | 35917 tok/s)\n",
      "step 3298/5000 | train loss 0.061518 | norm 0.0953 | lr 7.80e-06 | (114.13 ms | 35889 tok/s)\n",
      "step 3299/5000 | train loss 0.061520 | norm 0.1107 | lr 7.79e-06 | (116.68 ms | 35106 tok/s)\n",
      "step 3300/5000 | train loss 0.061526 | norm 0.1361 | lr 7.78e-06 | (115.34 ms | 35512 tok/s)\n",
      "step 3301/5000 | train loss 0.061529 | norm 0.1508 | lr 7.78e-06 | (117.60 ms | 34831 tok/s)\n",
      "step 3302/5000 | train loss 0.061524 | norm 0.1375 | lr 7.77e-06 | (114.82 ms | 35673 tok/s)\n",
      "step 3303/5000 | train loss 0.061514 | norm 0.1028 | lr 7.76e-06 | (119.26 ms | 34345 tok/s)\n",
      "step 3304/5000 | train loss 0.061517 | norm 0.1146 | lr 7.75e-06 | (118.31 ms | 34622 tok/s)\n",
      "step 3305/5000 | train loss 0.061519 | norm 0.1316 | lr 7.74e-06 | (118.46 ms | 34576 tok/s)\n",
      "step 3306/5000 | train loss 0.061518 | norm 0.1328 | lr 7.73e-06 | (118.84 ms | 34467 tok/s)\n",
      "step 3307/5000 | train loss 0.061517 | norm 0.1259 | lr 7.73e-06 | (118.69 ms | 34509 tok/s)\n",
      "step 3308/5000 | train loss 0.061513 | norm 0.1182 | lr 7.72e-06 | (116.29 ms | 35224 tok/s)\n",
      "step 3309/5000 | train loss 0.061511 | norm 0.1151 | lr 7.71e-06 | (118.25 ms | 34638 tok/s)\n",
      "step 3310/5000 | train loss 0.061509 | norm 0.1105 | lr 7.70e-06 | (116.38 ms | 35196 tok/s)\n",
      "step 3311/5000 | train loss 0.061509 | norm 0.1128 | lr 7.69e-06 | (120.41 ms | 34016 tok/s)\n",
      "step 3312/5000 | train loss 0.061506 | norm 0.1083 | lr 7.69e-06 | (116.50 ms | 35160 tok/s)\n",
      "step 3313/5000 | train loss 0.061506 | norm 0.1133 | lr 7.68e-06 | (114.86 ms | 35661 tok/s)\n",
      "step 3314/5000 | train loss 0.061506 | norm 0.1135 | lr 7.67e-06 | (114.61 ms | 35740 tok/s)\n",
      "step 3315/5000 | train loss 0.061501 | norm 0.0977 | lr 7.66e-06 | (115.90 ms | 35340 tok/s)\n",
      "step 3316/5000 | train loss 0.061500 | norm 0.0969 | lr 7.65e-06 | (114.23 ms | 35857 tok/s)\n",
      "step 3317/5000 | train loss 0.061497 | norm 0.0884 | lr 7.64e-06 | (115.22 ms | 35548 tok/s)\n",
      "step 3318/5000 | train loss 0.061496 | norm 0.0892 | lr 7.64e-06 | (113.77 ms | 36003 tok/s)\n",
      "step 3319/5000 | train loss 0.061498 | norm 0.1049 | lr 7.63e-06 | (116.03 ms | 35300 tok/s)\n",
      "step 3320/5000 | train loss 0.061496 | norm 0.1048 | lr 7.62e-06 | (113.71 ms | 36022 tok/s)\n",
      "step 3321/5000 | train loss 0.061496 | norm 0.1057 | lr 7.61e-06 | (113.54 ms | 36075 tok/s)\n",
      "step 3322/5000 | train loss 0.061495 | norm 0.1094 | lr 7.60e-06 | (114.78 ms | 35685 tok/s)\n",
      "step 3323/5000 | train loss 0.061496 | norm 0.1167 | lr 7.59e-06 | (116.28 ms | 35225 tok/s)\n",
      "step 3324/5000 | train loss 0.061494 | norm 0.1164 | lr 7.59e-06 | (114.46 ms | 35787 tok/s)\n",
      "step 3325/5000 | train loss 0.061495 | norm 0.1241 | lr 7.58e-06 | (115.02 ms | 35611 tok/s)\n",
      "step 3326/5000 | train loss 0.061496 | norm 0.1288 | lr 7.57e-06 | (114.52 ms | 35768 tok/s)\n",
      "step 3327/5000 | train loss 0.061491 | norm 0.1137 | lr 7.56e-06 | (114.67 ms | 35719 tok/s)\n",
      "step 3328/5000 | train loss 0.061486 | norm 0.0929 | lr 7.55e-06 | (114.35 ms | 35821 tok/s)\n",
      "step 3329/5000 | train loss 0.061487 | norm 0.1024 | lr 7.55e-06 | (118.93 ms | 34441 tok/s)\n",
      "step 3330/5000 | train loss 0.061487 | norm 0.1084 | lr 7.54e-06 | (118.10 ms | 34682 tok/s)\n",
      "step 3331/5000 | train loss 0.061484 | norm 0.1007 | lr 7.53e-06 | (116.26 ms | 35231 tok/s)\n",
      "step 3332/5000 | train loss 0.061484 | norm 0.0991 | lr 7.52e-06 | (118.41 ms | 34591 tok/s)\n",
      "step 3333/5000 | train loss 0.061479 | norm 0.0872 | lr 7.51e-06 | (120.82 ms | 33901 tok/s)\n",
      "step 3334/5000 | train loss 0.061482 | norm 0.1034 | lr 7.50e-06 | (120.82 ms | 33900 tok/s)\n",
      "step 3335/5000 | train loss 0.061481 | norm 0.1047 | lr 7.50e-06 | (116.32 ms | 35214 tok/s)\n",
      "step 3336/5000 | train loss 0.061477 | norm 0.0942 | lr 7.49e-06 | (116.04 ms | 35298 tok/s)\n",
      "step 3337/5000 | train loss 0.061479 | norm 0.1057 | lr 7.48e-06 | (115.57 ms | 35440 tok/s)\n",
      "step 3338/5000 | train loss 0.061481 | norm 0.1180 | lr 7.47e-06 | (114.31 ms | 35833 tok/s)\n",
      "step 3339/5000 | train loss 0.061479 | norm 0.1133 | lr 7.46e-06 | (115.97 ms | 35318 tok/s)\n",
      "step 3340/5000 | train loss 0.061475 | norm 0.1026 | lr 7.46e-06 | (114.76 ms | 35691 tok/s)\n",
      "step 3341/5000 | train loss 0.061475 | norm 0.1087 | lr 7.45e-06 | (114.93 ms | 35640 tok/s)\n",
      "step 3342/5000 | train loss 0.061475 | norm 0.1104 | lr 7.44e-06 | (135.47 ms | 30236 tok/s)\n",
      "step 3343/5000 | train loss 0.061474 | norm 0.1138 | lr 7.43e-06 | (115.63 ms | 35424 tok/s)\n",
      "step 3344/5000 | train loss 0.061477 | norm 0.1272 | lr 7.42e-06 | (115.87 ms | 35350 tok/s)\n",
      "step 3345/5000 | train loss 0.061473 | norm 0.1207 | lr 7.42e-06 | (115.67 ms | 35412 tok/s)\n",
      "step 3346/5000 | train loss 0.061472 | norm 0.1193 | lr 7.41e-06 | (114.48 ms | 35780 tok/s)\n",
      "step 3347/5000 | train loss 0.061474 | norm 0.1268 | lr 7.40e-06 | (115.61 ms | 35429 tok/s)\n",
      "step 3348/5000 | train loss 0.061468 | norm 0.1120 | lr 7.39e-06 | (114.71 ms | 35708 tok/s)\n",
      "step 3349/5000 | train loss 0.061467 | norm 0.1054 | lr 7.38e-06 | (116.01 ms | 35308 tok/s)\n",
      "step 3350/5000 | train loss 0.061464 | norm 0.0975 | lr 7.37e-06 | (118.80 ms | 34478 tok/s)\n",
      "step 3351/5000 | train loss 0.061462 | norm 0.0911 | lr 7.37e-06 | (116.18 ms | 35254 tok/s)\n",
      "step 3352/5000 | train loss 0.061461 | norm 0.0914 | lr 7.36e-06 | (115.15 ms | 35570 tok/s)\n",
      "step 3353/5000 | train loss 0.061460 | norm 0.0895 | lr 7.35e-06 | (116.70 ms | 35098 tok/s)\n",
      "step 3354/5000 | train loss 0.061456 | norm 0.0767 | lr 7.34e-06 | (120.13 ms | 34096 tok/s)\n",
      "step 3355/5000 | train loss 0.061454 | norm 0.0686 | lr 7.33e-06 | (122.03 ms | 33565 tok/s)\n",
      "step 3356/5000 | train loss 0.061455 | norm 0.0817 | lr 7.33e-06 | (118.42 ms | 34590 tok/s)\n",
      "step 3357/5000 | train loss 0.061454 | norm 0.0799 | lr 7.32e-06 | (116.30 ms | 35221 tok/s)\n",
      "step 3358/5000 | train loss 0.061451 | norm 0.0748 | lr 7.31e-06 | (114.18 ms | 35873 tok/s)\n",
      "step 3359/5000 | train loss 0.061453 | norm 0.0874 | lr 7.30e-06 | (114.31 ms | 35832 tok/s)\n",
      "step 3360/5000 | train loss 0.061455 | norm 0.1073 | lr 7.29e-06 | (128.21 ms | 31948 tok/s)\n",
      "step 3361/5000 | train loss 0.061462 | norm 0.1353 | lr 7.29e-06 | (118.31 ms | 34621 tok/s)\n",
      "step 3362/5000 | train loss 0.061463 | norm 0.1464 | lr 7.28e-06 | (122.72 ms | 33378 tok/s)\n",
      "step 3363/5000 | train loss 0.061462 | norm 0.1387 | lr 7.27e-06 | (117.81 ms | 34768 tok/s)\n",
      "step 3364/5000 | train loss 0.061452 | norm 0.1071 | lr 7.26e-06 | (113.91 ms | 35959 tok/s)\n",
      "step 3365/5000 | train loss 0.061454 | norm 0.1182 | lr 7.25e-06 | (115.17 ms | 35565 tok/s)\n",
      "step 3366/5000 | train loss 0.061459 | norm 0.1392 | lr 7.25e-06 | (114.12 ms | 35892 tok/s)\n",
      "step 3367/5000 | train loss 0.061451 | norm 0.1156 | lr 7.24e-06 | (114.14 ms | 35885 tok/s)\n",
      "step 3368/5000 | train loss 0.061446 | norm 0.0989 | lr 7.23e-06 | (113.59 ms | 36059 tok/s)\n",
      "step 3369/5000 | train loss 0.061450 | norm 0.1200 | lr 7.22e-06 | (118.60 ms | 34535 tok/s)\n",
      "step 3370/5000 | train loss 0.061449 | norm 0.1192 | lr 7.21e-06 | (118.87 ms | 34457 tok/s)\n",
      "step 3371/5000 | train loss 0.061441 | norm 0.0904 | lr 7.21e-06 | (119.83 ms | 34182 tok/s)\n",
      "step 3372/5000 | train loss 0.061443 | norm 0.0989 | lr 7.20e-06 | (114.96 ms | 35629 tok/s)\n",
      "step 3373/5000 | train loss 0.061442 | norm 0.1038 | lr 7.19e-06 | (115.75 ms | 35388 tok/s)\n",
      "step 3374/5000 | train loss 0.061439 | norm 0.0909 | lr 7.18e-06 | (113.95 ms | 35947 tok/s)\n",
      "step 3375/5000 | train loss 0.061438 | norm 0.0917 | lr 7.17e-06 | (112.98 ms | 36255 tok/s)\n",
      "step 3376/5000 | train loss 0.061435 | norm 0.0885 | lr 7.16e-06 | (114.41 ms | 35802 tok/s)\n",
      "step 3377/5000 | train loss 0.061439 | norm 0.1030 | lr 7.16e-06 | (114.27 ms | 35846 tok/s)\n",
      "step 3378/5000 | train loss 0.061433 | norm 0.0882 | lr 7.15e-06 | (113.80 ms | 35992 tok/s)\n",
      "step 3379/5000 | train loss 0.061436 | norm 0.1072 | lr 7.14e-06 | (122.91 ms | 33326 tok/s)\n",
      "step 3380/5000 | train loss 0.061439 | norm 0.1265 | lr 7.13e-06 | (122.67 ms | 33391 tok/s)\n",
      "step 3381/5000 | train loss 0.061435 | norm 0.1117 | lr 7.12e-06 | (122.02 ms | 33568 tok/s)\n",
      "step 3382/5000 | train loss 0.061434 | norm 0.1074 | lr 7.12e-06 | (116.43 ms | 35179 tok/s)\n",
      "step 3383/5000 | train loss 0.061435 | norm 0.1110 | lr 7.11e-06 | (118.88 ms | 34456 tok/s)\n",
      "step 3384/5000 | train loss 0.061429 | norm 0.0962 | lr 7.10e-06 | (125.32 ms | 32684 tok/s)\n",
      "step 3385/5000 | train loss 0.061430 | norm 0.1016 | lr 7.09e-06 | (119.80 ms | 34192 tok/s)\n",
      "step 3386/5000 | train loss 0.061430 | norm 0.1061 | lr 7.08e-06 | (114.60 ms | 35742 tok/s)\n",
      "step 3387/5000 | train loss 0.061425 | norm 0.0901 | lr 7.08e-06 | (116.51 ms | 35156 tok/s)\n",
      "step 3388/5000 | train loss 0.061425 | norm 0.0873 | lr 7.07e-06 | (114.14 ms | 35885 tok/s)\n",
      "step 3389/5000 | train loss 0.061425 | norm 0.0962 | lr 7.06e-06 | (117.11 ms | 34977 tok/s)\n",
      "step 3390/5000 | train loss 0.061428 | norm 0.1191 | lr 7.05e-06 | (115.50 ms | 35465 tok/s)\n",
      "step 3391/5000 | train loss 0.061434 | norm 0.1456 | lr 7.04e-06 | (134.41 ms | 30473 tok/s)\n",
      "step 3392/5000 | train loss 0.061430 | norm 0.1361 | lr 7.04e-06 | (114.98 ms | 35625 tok/s)\n",
      "step 3393/5000 | train loss 0.061425 | norm 0.1166 | lr 7.03e-06 | (114.89 ms | 35651 tok/s)\n",
      "step 3394/5000 | train loss 0.061422 | norm 0.1020 | lr 7.02e-06 | (114.24 ms | 35856 tok/s)\n",
      "step 3395/5000 | train loss 0.061419 | norm 0.0982 | lr 7.01e-06 | (116.22 ms | 35243 tok/s)\n",
      "step 3396/5000 | train loss 0.061420 | norm 0.1048 | lr 7.00e-06 | (114.45 ms | 35787 tok/s)\n",
      "step 3397/5000 | train loss 0.061416 | norm 0.0935 | lr 7.00e-06 | (114.23 ms | 35857 tok/s)\n",
      "step 3398/5000 | train loss 0.061415 | norm 0.0917 | lr 6.99e-06 | (114.04 ms | 35917 tok/s)\n",
      "step 3399/5000 | train loss 0.061414 | norm 0.0887 | lr 6.98e-06 | (114.84 ms | 35667 tok/s)\n",
      "step 3400/5000 | train loss 0.061412 | norm 0.0833 | lr 6.97e-06 | (113.87 ms | 35972 tok/s)\n",
      "step 3401/5000 | train loss 0.061412 | norm 0.0903 | lr 6.96e-06 | (115.21 ms | 35553 tok/s)\n",
      "step 3402/5000 | train loss 0.061410 | norm 0.0856 | lr 6.96e-06 | (113.97 ms | 35940 tok/s)\n",
      "step 3403/5000 | train loss 0.061409 | norm 0.0856 | lr 6.95e-06 | (114.20 ms | 35868 tok/s)\n",
      "step 3404/5000 | train loss 0.061411 | norm 0.1017 | lr 6.94e-06 | (118.17 ms | 34661 tok/s)\n",
      "step 3405/5000 | train loss 0.061409 | norm 0.0997 | lr 6.93e-06 | (121.27 ms | 33775 tok/s)\n",
      "step 3406/5000 | train loss 0.061410 | norm 0.1059 | lr 6.93e-06 | (133.98 ms | 30572 tok/s)\n",
      "step 3407/5000 | train loss 0.061412 | norm 0.1154 | lr 6.92e-06 | (121.52 ms | 33706 tok/s)\n",
      "step 3408/5000 | train loss 0.061408 | norm 0.1060 | lr 6.91e-06 | (121.60 ms | 33683 tok/s)\n",
      "step 3409/5000 | train loss 0.061405 | norm 0.0943 | lr 6.90e-06 | (115.48 ms | 35469 tok/s)\n",
      "step 3410/5000 | train loss 0.061407 | norm 0.1001 | lr 6.89e-06 | (114.28 ms | 35841 tok/s)\n",
      "step 3411/5000 | train loss 0.061405 | norm 0.1026 | lr 6.89e-06 | (115.01 ms | 35616 tok/s)\n",
      "step 3412/5000 | train loss 0.061409 | norm 0.1185 | lr 6.88e-06 | (113.95 ms | 35947 tok/s)\n",
      "step 3413/5000 | train loss 0.061409 | norm 0.1227 | lr 6.87e-06 | (114.00 ms | 35931 tok/s)\n",
      "step 3414/5000 | train loss 0.061404 | norm 0.1085 | lr 6.86e-06 | (113.35 ms | 36137 tok/s)\n",
      "step 3415/5000 | train loss 0.061401 | norm 0.0977 | lr 6.85e-06 | (115.35 ms | 35509 tok/s)\n",
      "step 3416/5000 | train loss 0.061400 | norm 0.0941 | lr 6.85e-06 | (114.00 ms | 35929 tok/s)\n",
      "step 3417/5000 | train loss 0.061399 | norm 0.0975 | lr 6.84e-06 | (114.12 ms | 35893 tok/s)\n",
      "step 3418/5000 | train loss 0.061395 | norm 0.0857 | lr 6.83e-06 | (118.98 ms | 34425 tok/s)\n",
      "step 3419/5000 | train loss 0.061395 | norm 0.0839 | lr 6.82e-06 | (124.10 ms | 33006 tok/s)\n",
      "step 3420/5000 | train loss 0.061396 | norm 0.0961 | lr 6.81e-06 | (124.30 ms | 32952 tok/s)\n",
      "step 3421/5000 | train loss 0.061394 | norm 0.0921 | lr 6.81e-06 | (118.49 ms | 34569 tok/s)\n",
      "step 3422/5000 | train loss 0.061392 | norm 0.0840 | lr 6.80e-06 | (116.37 ms | 35198 tok/s)\n",
      "step 3423/5000 | train loss 0.061393 | norm 0.0924 | lr 6.79e-06 | (115.57 ms | 35443 tok/s)\n",
      "step 3424/5000 | train loss 0.061391 | norm 0.0878 | lr 6.78e-06 | (116.44 ms | 35177 tok/s)\n",
      "step 3425/5000 | train loss 0.061387 | norm 0.0771 | lr 6.77e-06 | (115.77 ms | 35381 tok/s)\n",
      "step 3426/5000 | train loss 0.061388 | norm 0.0856 | lr 6.77e-06 | (114.49 ms | 35777 tok/s)\n",
      "step 3427/5000 | train loss 0.061388 | norm 0.0871 | lr 6.76e-06 | (114.91 ms | 35645 tok/s)\n",
      "step 3428/5000 | train loss 0.061387 | norm 0.0925 | lr 6.75e-06 | (114.33 ms | 35826 tok/s)\n",
      "step 3429/5000 | train loss 0.061389 | norm 0.1044 | lr 6.74e-06 | (115.20 ms | 35556 tok/s)\n",
      "step 3430/5000 | train loss 0.061389 | norm 0.1112 | lr 6.74e-06 | (124.85 ms | 32807 tok/s)\n",
      "step 3431/5000 | train loss 0.061390 | norm 0.1188 | lr 6.73e-06 | (123.87 ms | 33066 tok/s)\n",
      "step 3432/5000 | train loss 0.061389 | norm 0.1211 | lr 6.72e-06 | (120.89 ms | 33883 tok/s)\n",
      "step 3433/5000 | train loss 0.061393 | norm 0.1342 | lr 6.71e-06 | (133.27 ms | 30735 tok/s)\n",
      "step 3434/5000 | train loss 0.061388 | norm 0.1174 | lr 6.70e-06 | (114.43 ms | 35795 tok/s)\n",
      "step 3435/5000 | train loss 0.061380 | norm 0.0841 | lr 6.70e-06 | (118.81 ms | 34476 tok/s)\n",
      "step 3436/5000 | train loss 0.061382 | norm 0.0945 | lr 6.69e-06 | (123.36 ms | 33205 tok/s)\n",
      "step 3437/5000 | train loss 0.061382 | norm 0.1061 | lr 6.68e-06 | (121.96 ms | 33585 tok/s)\n",
      "step 3438/5000 | train loss 0.061381 | norm 0.0988 | lr 6.67e-06 | (120.59 ms | 33966 tok/s)\n",
      "step 3439/5000 | train loss 0.061373 | norm 0.0669 | lr 6.66e-06 | (116.66 ms | 35110 tok/s)\n",
      "step 3440/5000 | train loss 0.061376 | norm 0.0855 | lr 6.66e-06 | (115.92 ms | 35335 tok/s)\n",
      "step 3441/5000 | train loss 0.061376 | norm 0.0931 | lr 6.65e-06 | (121.49 ms | 33715 tok/s)\n",
      "step 3442/5000 | train loss 0.061377 | norm 0.0988 | lr 6.64e-06 | (121.82 ms | 33622 tok/s)\n",
      "step 3443/5000 | train loss 0.061375 | norm 0.0943 | lr 6.63e-06 | (129.45 ms | 31641 tok/s)\n",
      "step 3444/5000 | train loss 0.061374 | norm 0.0993 | lr 6.63e-06 | (120.94 ms | 33868 tok/s)\n",
      "step 3445/5000 | train loss 0.061376 | norm 0.1088 | lr 6.62e-06 | (118.09 ms | 34684 tok/s)\n",
      "step 3446/5000 | train loss 0.061371 | norm 0.0911 | lr 6.61e-06 | (116.03 ms | 35300 tok/s)\n",
      "step 3447/5000 | train loss 0.061370 | norm 0.0854 | lr 6.60e-06 | (114.69 ms | 35714 tok/s)\n",
      "step 3448/5000 | train loss 0.061370 | norm 0.0912 | lr 6.59e-06 | (116.45 ms | 35175 tok/s)\n",
      "step 3449/5000 | train loss 0.061370 | norm 0.0957 | lr 6.59e-06 | (124.79 ms | 32824 tok/s)\n",
      "step 3450/5000 | train loss 0.061370 | norm 0.0992 | lr 6.58e-06 | (124.36 ms | 32937 tok/s)\n",
      "step 3451/5000 | train loss 0.061368 | norm 0.0921 | lr 6.57e-06 | (118.67 ms | 34515 tok/s)\n",
      "step 3452/5000 | train loss 0.061364 | norm 0.0844 | lr 6.56e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 3453/5000 | train loss 0.061367 | norm 0.1008 | lr 6.56e-06 | (114.89 ms | 35652 tok/s)\n",
      "step 3454/5000 | train loss 0.061366 | norm 0.1018 | lr 6.55e-06 | (120.25 ms | 34063 tok/s)\n",
      "step 3455/5000 | train loss 0.061363 | norm 0.0880 | lr 6.54e-06 | (123.51 ms | 33164 tok/s)\n",
      "step 3456/5000 | train loss 0.061362 | norm 0.0859 | lr 6.53e-06 | (119.37 ms | 34314 tok/s)\n",
      "step 3457/5000 | train loss 0.061360 | norm 0.0822 | lr 6.52e-06 | (119.74 ms | 34206 tok/s)\n",
      "step 3458/5000 | train loss 0.061360 | norm 0.0849 | lr 6.52e-06 | (121.21 ms | 33793 tok/s)\n",
      "step 3459/5000 | train loss 0.061360 | norm 0.0910 | lr 6.51e-06 | (121.61 ms | 33681 tok/s)\n",
      "step 3460/5000 | train loss 0.061360 | norm 0.0967 | lr 6.50e-06 | (117.29 ms | 34921 tok/s)\n",
      "step 3461/5000 | train loss 0.061361 | norm 0.1054 | lr 6.49e-06 | (116.81 ms | 35067 tok/s)\n",
      "step 3462/5000 | train loss 0.061361 | norm 0.1075 | lr 6.49e-06 | (114.47 ms | 35781 tok/s)\n",
      "step 3463/5000 | train loss 0.061358 | norm 0.1015 | lr 6.48e-06 | (115.84 ms | 35359 tok/s)\n",
      "step 3464/5000 | train loss 0.061357 | norm 0.0968 | lr 6.47e-06 | (112.61 ms | 36373 tok/s)\n",
      "step 3465/5000 | train loss 0.061359 | norm 0.1099 | lr 6.46e-06 | (141.59 ms | 28928 tok/s)\n",
      "step 3466/5000 | train loss 0.061363 | norm 0.1238 | lr 6.45e-06 | (118.67 ms | 34516 tok/s)\n",
      "step 3467/5000 | train loss 0.061355 | norm 0.1025 | lr 6.45e-06 | (116.86 ms | 35049 tok/s)\n",
      "step 3468/5000 | train loss 0.061353 | norm 0.0920 | lr 6.44e-06 | (113.61 ms | 36053 tok/s)\n",
      "step 3469/5000 | train loss 0.061354 | norm 0.0980 | lr 6.43e-06 | (119.19 ms | 34364 tok/s)\n",
      "step 3470/5000 | train loss 0.061350 | norm 0.0864 | lr 6.42e-06 | (114.57 ms | 35751 tok/s)\n",
      "step 3471/5000 | train loss 0.061350 | norm 0.0883 | lr 6.42e-06 | (116.06 ms | 35292 tok/s)\n",
      "step 3472/5000 | train loss 0.061351 | norm 0.0953 | lr 6.41e-06 | (114.02 ms | 35922 tok/s)\n",
      "step 3473/5000 | train loss 0.061346 | norm 0.0763 | lr 6.40e-06 | (116.02 ms | 35303 tok/s)\n",
      "step 3474/5000 | train loss 0.061344 | norm 0.0703 | lr 6.39e-06 | (113.68 ms | 36030 tok/s)\n",
      "step 3475/5000 | train loss 0.061346 | norm 0.0827 | lr 6.38e-06 | (114.68 ms | 35716 tok/s)\n",
      "step 3476/5000 | train loss 0.061343 | norm 0.0741 | lr 6.38e-06 | (114.37 ms | 35813 tok/s)\n",
      "step 3477/5000 | train loss 0.061341 | norm 0.0677 | lr 6.37e-06 | (115.07 ms | 35597 tok/s)\n",
      "step 3478/5000 | train loss 0.061343 | norm 0.0824 | lr 6.36e-06 | (113.85 ms | 35978 tok/s)\n",
      "step 3479/5000 | train loss 0.061342 | norm 0.0857 | lr 6.35e-06 | (116.47 ms | 35168 tok/s)\n",
      "step 3480/5000 | train loss 0.061342 | norm 0.0897 | lr 6.35e-06 | (115.27 ms | 35533 tok/s)\n",
      "step 3481/5000 | train loss 0.061344 | norm 0.1050 | lr 6.34e-06 | (118.59 ms | 34539 tok/s)\n",
      "step 3482/5000 | train loss 0.061343 | norm 0.1039 | lr 6.33e-06 | (118.71 ms | 34505 tok/s)\n",
      "step 3483/5000 | train loss 0.061342 | norm 0.1015 | lr 6.32e-06 | (113.60 ms | 36056 tok/s)\n",
      "step 3484/5000 | train loss 0.061338 | norm 0.0888 | lr 6.32e-06 | (113.52 ms | 36080 tok/s)\n",
      "step 3485/5000 | train loss 0.061335 | norm 0.0772 | lr 6.31e-06 | (114.55 ms | 35756 tok/s)\n",
      "step 3486/5000 | train loss 0.061338 | norm 0.0952 | lr 6.30e-06 | (114.20 ms | 35866 tok/s)\n",
      "step 3487/5000 | train loss 0.061340 | norm 0.1053 | lr 6.29e-06 | (112.12 ms | 36531 tok/s)\n",
      "step 3488/5000 | train loss 0.061336 | norm 0.0956 | lr 6.29e-06 | (114.52 ms | 35767 tok/s)\n",
      "step 3489/5000 | train loss 0.061336 | norm 0.0987 | lr 6.28e-06 | (117.03 ms | 34999 tok/s)\n",
      "step 3490/5000 | train loss 0.061334 | norm 0.0983 | lr 6.27e-06 | (114.42 ms | 35797 tok/s)\n",
      "step 3491/5000 | train loss 0.061336 | norm 0.1070 | lr 6.26e-06 | (115.64 ms | 35422 tok/s)\n",
      "step 3492/5000 | train loss 0.061335 | norm 0.1027 | lr 6.25e-06 | (117.76 ms | 34782 tok/s)\n",
      "step 3493/5000 | train loss 0.061331 | norm 0.0898 | lr 6.25e-06 | (118.45 ms | 34580 tok/s)\n",
      "step 3494/5000 | train loss 0.061331 | norm 0.0950 | lr 6.24e-06 | (115.77 ms | 35381 tok/s)\n",
      "step 3495/5000 | train loss 0.061333 | norm 0.1021 | lr 6.23e-06 | (117.90 ms | 34741 tok/s)\n",
      "step 3496/5000 | train loss 0.061329 | norm 0.0910 | lr 6.22e-06 | (115.70 ms | 35402 tok/s)\n",
      "step 3497/5000 | train loss 0.061329 | norm 0.0905 | lr 6.22e-06 | (114.02 ms | 35924 tok/s)\n",
      "step 3498/5000 | train loss 0.061327 | norm 0.0848 | lr 6.21e-06 | (114.04 ms | 35918 tok/s)\n",
      "step 3499/5000 | train loss 0.061323 | norm 0.0714 | lr 6.20e-06 | (125.84 ms | 32548 tok/s)\n",
      "step 3500/5000 | train loss 0.061326 | norm 0.0892 | lr 6.19e-06 | (112.66 ms | 36356 tok/s)\n",
      "step 3501/5000 | train loss 0.061325 | norm 0.0905 | lr 6.19e-06 | (114.55 ms | 35758 tok/s)\n",
      "step 3502/5000 | train loss 0.061323 | norm 0.0877 | lr 6.18e-06 | (113.85 ms | 35977 tok/s)\n",
      "step 3503/5000 | train loss 0.061325 | norm 0.0978 | lr 6.17e-06 | (114.50 ms | 35771 tok/s)\n",
      "step 3504/5000 | train loss 0.061323 | norm 0.0927 | lr 6.16e-06 | (113.62 ms | 36050 tok/s)\n",
      "step 3505/5000 | train loss 0.061320 | norm 0.0865 | lr 6.16e-06 | (115.59 ms | 35436 tok/s)\n",
      "step 3506/5000 | train loss 0.061322 | norm 0.0948 | lr 6.15e-06 | (114.79 ms | 35681 tok/s)\n",
      "step 3507/5000 | train loss 0.061321 | norm 0.0970 | lr 6.14e-06 | (134.05 ms | 30555 tok/s)\n",
      "step 3508/5000 | train loss 0.061323 | norm 0.1081 | lr 6.13e-06 | (114.08 ms | 35905 tok/s)\n",
      "step 3509/5000 | train loss 0.061321 | norm 0.1045 | lr 6.12e-06 | (114.59 ms | 35744 tok/s)\n",
      "step 3510/5000 | train loss 0.061317 | norm 0.0892 | lr 6.12e-06 | (113.05 ms | 36232 tok/s)\n",
      "step 3511/5000 | train loss 0.061318 | norm 0.0908 | lr 6.11e-06 | (114.27 ms | 35845 tok/s)\n",
      "step 3512/5000 | train loss 0.061316 | norm 0.0869 | lr 6.10e-06 | (113.92 ms | 35956 tok/s)\n",
      "step 3513/5000 | train loss 0.061315 | norm 0.0893 | lr 6.09e-06 | (115.35 ms | 35508 tok/s)\n",
      "step 3514/5000 | train loss 0.061315 | norm 0.0923 | lr 6.09e-06 | (119.33 ms | 34324 tok/s)\n",
      "step 3515/5000 | train loss 0.061312 | norm 0.0800 | lr 6.08e-06 | (122.43 ms | 33457 tok/s)\n",
      "step 3516/5000 | train loss 0.061312 | norm 0.0808 | lr 6.07e-06 | (116.82 ms | 35064 tok/s)\n",
      "step 3517/5000 | train loss 0.061310 | norm 0.0763 | lr 6.06e-06 | (116.61 ms | 35124 tok/s)\n",
      "step 3518/5000 | train loss 0.061310 | norm 0.0832 | lr 6.06e-06 | (116.98 ms | 35015 tok/s)\n",
      "step 3519/5000 | train loss 0.061311 | norm 0.0906 | lr 6.05e-06 | (117.85 ms | 34756 tok/s)\n",
      "step 3520/5000 | train loss 0.061308 | norm 0.0808 | lr 6.04e-06 | (114.42 ms | 35798 tok/s)\n",
      "step 3521/5000 | train loss 0.061308 | norm 0.0851 | lr 6.03e-06 | (115.06 ms | 35600 tok/s)\n",
      "step 3522/5000 | train loss 0.061309 | norm 0.0959 | lr 6.03e-06 | (113.11 ms | 36212 tok/s)\n",
      "step 3523/5000 | train loss 0.061309 | norm 0.1000 | lr 6.02e-06 | (115.03 ms | 35609 tok/s)\n",
      "step 3524/5000 | train loss 0.061307 | norm 0.0927 | lr 6.01e-06 | (113.55 ms | 36071 tok/s)\n",
      "step 3525/5000 | train loss 0.061305 | norm 0.0805 | lr 6.00e-06 | (116.07 ms | 35289 tok/s)\n",
      "step 3526/5000 | train loss 0.061302 | norm 0.0758 | lr 6.00e-06 | (123.72 ms | 33106 tok/s)\n",
      "step 3527/5000 | train loss 0.061305 | norm 0.0914 | lr 5.99e-06 | (120.88 ms | 33885 tok/s)\n",
      "step 3528/5000 | train loss 0.061302 | norm 0.0863 | lr 5.98e-06 | (118.64 ms | 34525 tok/s)\n",
      "step 3529/5000 | train loss 0.061302 | norm 0.0866 | lr 5.97e-06 | (117.18 ms | 34956 tok/s)\n",
      "step 3530/5000 | train loss 0.061302 | norm 0.0870 | lr 5.97e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 3531/5000 | train loss 0.061298 | norm 0.0741 | lr 5.96e-06 | (115.27 ms | 35535 tok/s)\n",
      "step 3532/5000 | train loss 0.061299 | norm 0.0798 | lr 5.95e-06 | (115.20 ms | 35555 tok/s)\n",
      "step 3533/5000 | train loss 0.061300 | norm 0.0917 | lr 5.94e-06 | (119.02 ms | 34413 tok/s)\n",
      "step 3534/5000 | train loss 0.061299 | norm 0.0889 | lr 5.94e-06 | (118.19 ms | 34656 tok/s)\n",
      "step 3535/5000 | train loss 0.061298 | norm 0.0866 | lr 5.93e-06 | (118.10 ms | 34682 tok/s)\n",
      "step 3536/5000 | train loss 0.061296 | norm 0.0832 | lr 5.92e-06 | (114.80 ms | 35678 tok/s)\n",
      "step 3537/5000 | train loss 0.061296 | norm 0.0822 | lr 5.91e-06 | (115.64 ms | 35420 tok/s)\n",
      "step 3538/5000 | train loss 0.061295 | norm 0.0816 | lr 5.91e-06 | (115.62 ms | 35427 tok/s)\n",
      "step 3539/5000 | train loss 0.061293 | norm 0.0766 | lr 5.90e-06 | (113.27 ms | 36162 tok/s)\n",
      "step 3540/5000 | train loss 0.061294 | norm 0.0856 | lr 5.89e-06 | (113.89 ms | 35964 tok/s)\n",
      "step 3541/5000 | train loss 0.061294 | norm 0.0916 | lr 5.88e-06 | (116.01 ms | 35306 tok/s)\n",
      "step 3542/5000 | train loss 0.061293 | norm 0.0896 | lr 5.88e-06 | (116.52 ms | 35153 tok/s)\n",
      "step 3543/5000 | train loss 0.061294 | norm 0.1009 | lr 5.87e-06 | (117.36 ms | 34900 tok/s)\n",
      "step 3544/5000 | train loss 0.061293 | norm 0.0993 | lr 5.86e-06 | (114.21 ms | 35864 tok/s)\n",
      "step 3545/5000 | train loss 0.061288 | norm 0.0781 | lr 5.85e-06 | (114.89 ms | 35653 tok/s)\n",
      "step 3546/5000 | train loss 0.061291 | norm 0.0959 | lr 5.85e-06 | (119.74 ms | 34209 tok/s)\n",
      "step 3547/5000 | train loss 0.061290 | norm 0.0969 | lr 5.84e-06 | (121.05 ms | 33836 tok/s)\n",
      "step 3548/5000 | train loss 0.061288 | norm 0.0868 | lr 5.83e-06 | (118.72 ms | 34502 tok/s)\n",
      "step 3549/5000 | train loss 0.061288 | norm 0.0867 | lr 5.82e-06 | (117.51 ms | 34857 tok/s)\n",
      "step 3550/5000 | train loss 0.061285 | norm 0.0810 | lr 5.82e-06 | (114.41 ms | 35800 tok/s)\n",
      "step 3551/5000 | train loss 0.061286 | norm 0.0841 | lr 5.81e-06 | (115.47 ms | 35473 tok/s)\n",
      "step 3552/5000 | train loss 0.061284 | norm 0.0763 | lr 5.80e-06 | (114.41 ms | 35802 tok/s)\n",
      "step 3553/5000 | train loss 0.061281 | norm 0.0661 | lr 5.79e-06 | (114.70 ms | 35711 tok/s)\n",
      "step 3554/5000 | train loss 0.061281 | norm 0.0699 | lr 5.79e-06 | (113.11 ms | 36213 tok/s)\n",
      "step 3555/5000 | train loss 0.061282 | norm 0.0825 | lr 5.78e-06 | (113.91 ms | 35957 tok/s)\n",
      "step 3556/5000 | train loss 0.061283 | norm 0.0975 | lr 5.77e-06 | (117.80 ms | 34772 tok/s)\n",
      "step 3557/5000 | train loss 0.061285 | norm 0.1098 | lr 5.76e-06 | (122.44 ms | 33453 tok/s)\n",
      "step 3558/5000 | train loss 0.061285 | norm 0.1113 | lr 5.76e-06 | (118.45 ms | 34580 tok/s)\n",
      "step 3559/5000 | train loss 0.061284 | norm 0.1051 | lr 5.75e-06 | (118.11 ms | 34679 tok/s)\n",
      "step 3560/5000 | train loss 0.061278 | norm 0.0795 | lr 5.74e-06 | (120.08 ms | 34111 tok/s)\n",
      "step 3561/5000 | train loss 0.061276 | norm 0.0758 | lr 5.73e-06 | (118.87 ms | 34459 tok/s)\n",
      "step 3562/5000 | train loss 0.061280 | norm 0.0984 | lr 5.73e-06 | (115.42 ms | 35487 tok/s)\n",
      "step 3563/5000 | train loss 0.061276 | norm 0.0821 | lr 5.72e-06 | (116.70 ms | 35099 tok/s)\n",
      "step 3564/5000 | train loss 0.061274 | norm 0.0745 | lr 5.71e-06 | (118.96 ms | 34432 tok/s)\n",
      "step 3565/5000 | train loss 0.061274 | norm 0.0743 | lr 5.70e-06 | (118.95 ms | 34436 tok/s)\n",
      "step 3566/5000 | train loss 0.061273 | norm 0.0777 | lr 5.70e-06 | (115.92 ms | 35334 tok/s)\n",
      "step 3567/5000 | train loss 0.061275 | norm 0.0934 | lr 5.69e-06 | (114.82 ms | 35673 tok/s)\n",
      "step 3568/5000 | train loss 0.061273 | norm 0.0843 | lr 5.68e-06 | (133.66 ms | 30644 tok/s)\n",
      "step 3569/5000 | train loss 0.061270 | norm 0.0750 | lr 5.68e-06 | (116.82 ms | 35062 tok/s)\n",
      "step 3570/5000 | train loss 0.061272 | norm 0.0901 | lr 5.67e-06 | (116.54 ms | 35147 tok/s)\n",
      "step 3571/5000 | train loss 0.061272 | norm 0.0962 | lr 5.66e-06 | (115.93 ms | 35333 tok/s)\n",
      "step 3572/5000 | train loss 0.061271 | norm 0.0943 | lr 5.65e-06 | (113.58 ms | 36062 tok/s)\n",
      "step 3573/5000 | train loss 0.061270 | norm 0.0906 | lr 5.65e-06 | (116.70 ms | 35100 tok/s)\n",
      "step 3574/5000 | train loss 0.061270 | norm 0.0925 | lr 5.64e-06 | (113.98 ms | 35936 tok/s)\n",
      "step 3575/5000 | train loss 0.061268 | norm 0.0858 | lr 5.63e-06 | (113.65 ms | 36040 tok/s)\n",
      "step 3576/5000 | train loss 0.061265 | norm 0.0722 | lr 5.62e-06 | (114.53 ms | 35765 tok/s)\n",
      "step 3577/5000 | train loss 0.061264 | norm 0.0713 | lr 5.62e-06 | (115.16 ms | 35569 tok/s)\n",
      "step 3578/5000 | train loss 0.061265 | norm 0.0792 | lr 5.61e-06 | (115.28 ms | 35530 tok/s)\n",
      "step 3579/5000 | train loss 0.061262 | norm 0.0723 | lr 5.60e-06 | (115.00 ms | 35618 tok/s)\n",
      "step 3580/5000 | train loss 0.061263 | norm 0.0748 | lr 5.59e-06 | (114.18 ms | 35873 tok/s)\n",
      "step 3581/5000 | train loss 0.061260 | norm 0.0604 | lr 5.59e-06 | (113.88 ms | 35969 tok/s)\n",
      "step 3582/5000 | train loss 0.061260 | norm 0.0669 | lr 5.58e-06 | (114.10 ms | 35897 tok/s)\n",
      "step 3583/5000 | train loss 0.061260 | norm 0.0712 | lr 5.57e-06 | (113.97 ms | 35941 tok/s)\n",
      "step 3584/5000 | train loss 0.061259 | norm 0.0734 | lr 5.57e-06 | (113.62 ms | 36051 tok/s)\n",
      "step 3585/5000 | train loss 0.061262 | norm 0.0932 | lr 5.56e-06 | (115.35 ms | 35510 tok/s)\n",
      "step 3586/5000 | train loss 0.061261 | norm 0.0999 | lr 5.55e-06 | (114.38 ms | 35809 tok/s)\n",
      "step 3587/5000 | train loss 0.061262 | norm 0.1048 | lr 5.54e-06 | (115.36 ms | 35506 tok/s)\n",
      "step 3588/5000 | train loss 0.061259 | norm 0.0936 | lr 5.54e-06 | (115.23 ms | 35546 tok/s)\n",
      "step 3589/5000 | train loss 0.061257 | norm 0.0824 | lr 5.53e-06 | (116.19 ms | 35252 tok/s)\n",
      "step 3590/5000 | train loss 0.061258 | norm 0.0899 | lr 5.52e-06 | (114.09 ms | 35903 tok/s)\n",
      "step 3591/5000 | train loss 0.061260 | norm 0.1051 | lr 5.51e-06 | (116.16 ms | 35261 tok/s)\n",
      "step 3592/5000 | train loss 0.061259 | norm 0.1025 | lr 5.51e-06 | (114.39 ms | 35808 tok/s)\n",
      "step 3593/5000 | train loss 0.061256 | norm 0.0912 | lr 5.50e-06 | (115.46 ms | 35476 tok/s)\n",
      "step 3594/5000 | train loss 0.061256 | norm 0.0976 | lr 5.49e-06 | (114.33 ms | 35825 tok/s)\n",
      "step 3595/5000 | train loss 0.061255 | norm 0.0917 | lr 5.48e-06 | (114.54 ms | 35761 tok/s)\n",
      "step 3596/5000 | train loss 0.061251 | norm 0.0708 | lr 5.48e-06 | (112.99 ms | 36251 tok/s)\n",
      "step 3597/5000 | train loss 0.061251 | norm 0.0784 | lr 5.47e-06 | (113.41 ms | 36118 tok/s)\n",
      "step 3598/5000 | train loss 0.061251 | norm 0.0813 | lr 5.46e-06 | (113.08 ms | 36224 tok/s)\n",
      "step 3599/5000 | train loss 0.061248 | norm 0.0630 | lr 5.46e-06 | (113.49 ms | 36092 tok/s)\n",
      "step 3600/5000 | train loss 0.061247 | norm 0.0640 | lr 5.45e-06 | (114.37 ms | 35815 tok/s)\n",
      "step 3601/5000 | train loss 0.061247 | norm 0.0697 | lr 5.44e-06 | (116.54 ms | 35146 tok/s)\n",
      "step 3602/5000 | train loss 0.061245 | norm 0.0576 | lr 5.43e-06 | (116.38 ms | 35195 tok/s)\n",
      "step 3603/5000 | train loss 0.061244 | norm 0.0573 | lr 5.43e-06 | (115.71 ms | 35400 tok/s)\n",
      "step 3604/5000 | train loss 0.061245 | norm 0.0666 | lr 5.42e-06 | (114.34 ms | 35824 tok/s)\n",
      "step 3605/5000 | train loss 0.061243 | norm 0.0612 | lr 5.41e-06 | (113.58 ms | 36064 tok/s)\n",
      "step 3606/5000 | train loss 0.061244 | norm 0.0708 | lr 5.40e-06 | (113.47 ms | 36098 tok/s)\n",
      "step 3607/5000 | train loss 0.061244 | norm 0.0803 | lr 5.40e-06 | (116.11 ms | 35275 tok/s)\n",
      "step 3608/5000 | train loss 0.061246 | norm 0.0924 | lr 5.39e-06 | (114.63 ms | 35734 tok/s)\n",
      "step 3609/5000 | train loss 0.061247 | norm 0.1008 | lr 5.38e-06 | (114.63 ms | 35732 tok/s)\n",
      "step 3610/5000 | train loss 0.061244 | norm 0.0899 | lr 5.38e-06 | (115.75 ms | 35386 tok/s)\n",
      "step 3611/5000 | train loss 0.061241 | norm 0.0775 | lr 5.37e-06 | (116.33 ms | 35211 tok/s)\n",
      "step 3612/5000 | train loss 0.061242 | norm 0.0844 | lr 5.36e-06 | (113.21 ms | 36181 tok/s)\n",
      "step 3613/5000 | train loss 0.061243 | norm 0.1003 | lr 5.35e-06 | (115.71 ms | 35398 tok/s)\n",
      "step 3614/5000 | train loss 0.061245 | norm 0.1088 | lr 5.35e-06 | (113.53 ms | 36077 tok/s)\n",
      "step 3615/5000 | train loss 0.061242 | norm 0.1011 | lr 5.34e-06 | (116.59 ms | 35132 tok/s)\n",
      "step 3616/5000 | train loss 0.061241 | norm 0.0949 | lr 5.33e-06 | (115.86 ms | 35352 tok/s)\n",
      "step 3617/5000 | train loss 0.061240 | norm 0.0941 | lr 5.33e-06 | (114.01 ms | 35927 tok/s)\n",
      "step 3618/5000 | train loss 0.061238 | norm 0.0828 | lr 5.32e-06 | (113.68 ms | 36030 tok/s)\n",
      "step 3619/5000 | train loss 0.061235 | norm 0.0719 | lr 5.31e-06 | (113.88 ms | 35968 tok/s)\n",
      "step 3620/5000 | train loss 0.061235 | norm 0.0767 | lr 5.30e-06 | (113.14 ms | 36202 tok/s)\n",
      "step 3621/5000 | train loss 0.061235 | norm 0.0820 | lr 5.30e-06 | (114.28 ms | 35843 tok/s)\n",
      "step 3622/5000 | train loss 0.061234 | norm 0.0779 | lr 5.29e-06 | (135.12 ms | 30313 tok/s)\n",
      "step 3623/5000 | train loss 0.061234 | norm 0.0811 | lr 5.28e-06 | (117.76 ms | 34784 tok/s)\n",
      "step 3624/5000 | train loss 0.061234 | norm 0.0840 | lr 5.28e-06 | (113.72 ms | 36017 tok/s)\n",
      "step 3625/5000 | train loss 0.061232 | norm 0.0805 | lr 5.27e-06 | (114.24 ms | 35855 tok/s)\n",
      "step 3626/5000 | train loss 0.061231 | norm 0.0760 | lr 5.26e-06 | (114.17 ms | 35876 tok/s)\n",
      "step 3627/5000 | train loss 0.061229 | norm 0.0633 | lr 5.25e-06 | (115.28 ms | 35530 tok/s)\n",
      "step 3628/5000 | train loss 0.061228 | norm 0.0611 | lr 5.25e-06 | (115.23 ms | 35547 tok/s)\n",
      "step 3629/5000 | train loss 0.061228 | norm 0.0670 | lr 5.24e-06 | (114.97 ms | 35626 tok/s)\n",
      "step 3630/5000 | train loss 0.061228 | norm 0.0725 | lr 5.23e-06 | (114.87 ms | 35657 tok/s)\n",
      "step 3631/5000 | train loss 0.061226 | norm 0.0693 | lr 5.22e-06 | (115.55 ms | 35447 tok/s)\n",
      "step 3632/5000 | train loss 0.061226 | norm 0.0720 | lr 5.22e-06 | (113.71 ms | 36021 tok/s)\n",
      "step 3633/5000 | train loss 0.061226 | norm 0.0786 | lr 5.21e-06 | (113.13 ms | 36206 tok/s)\n",
      "step 3634/5000 | train loss 0.061227 | norm 0.0859 | lr 5.20e-06 | (114.15 ms | 35883 tok/s)\n",
      "step 3635/5000 | train loss 0.061226 | norm 0.0859 | lr 5.20e-06 | (116.07 ms | 35288 tok/s)\n",
      "step 3636/5000 | train loss 0.061223 | norm 0.0728 | lr 5.19e-06 | (111.37 ms | 36779 tok/s)\n",
      "step 3637/5000 | train loss 0.061223 | norm 0.0701 | lr 5.18e-06 | (119.48 ms | 34282 tok/s)\n",
      "step 3638/5000 | train loss 0.061220 | norm 0.0549 | lr 5.18e-06 | (114.90 ms | 35648 tok/s)\n",
      "step 3639/5000 | train loss 0.061220 | norm 0.0584 | lr 5.17e-06 | (114.44 ms | 35791 tok/s)\n",
      "step 3640/5000 | train loss 0.061222 | norm 0.0748 | lr 5.16e-06 | (112.87 ms | 36289 tok/s)\n",
      "step 3641/5000 | train loss 0.061221 | norm 0.0776 | lr 5.15e-06 | (115.60 ms | 35433 tok/s)\n",
      "step 3642/5000 | train loss 0.061220 | norm 0.0762 | lr 5.15e-06 | (114.59 ms | 35744 tok/s)\n",
      "step 3643/5000 | train loss 0.061220 | norm 0.0807 | lr 5.14e-06 | (114.68 ms | 35716 tok/s)\n",
      "step 3644/5000 | train loss 0.061221 | norm 0.0876 | lr 5.13e-06 | (113.09 ms | 36218 tok/s)\n",
      "step 3645/5000 | train loss 0.061220 | norm 0.0902 | lr 5.13e-06 | (115.61 ms | 35431 tok/s)\n",
      "step 3646/5000 | train loss 0.061218 | norm 0.0837 | lr 5.12e-06 | (114.03 ms | 35921 tok/s)\n",
      "step 3647/5000 | train loss 0.061218 | norm 0.0823 | lr 5.11e-06 | (114.49 ms | 35776 tok/s)\n",
      "step 3648/5000 | train loss 0.061220 | norm 0.0916 | lr 5.10e-06 | (112.75 ms | 36330 tok/s)\n",
      "step 3649/5000 | train loss 0.061221 | norm 0.0998 | lr 5.10e-06 | (114.80 ms | 35679 tok/s)\n",
      "step 3650/5000 | train loss 0.061218 | norm 0.0948 | lr 5.09e-06 | (113.16 ms | 36196 tok/s)\n",
      "step 3651/5000 | train loss 0.061218 | norm 0.0935 | lr 5.08e-06 | (116.35 ms | 35203 tok/s)\n",
      "step 3652/5000 | train loss 0.061217 | norm 0.0903 | lr 5.08e-06 | (116.60 ms | 35130 tok/s)\n",
      "step 3653/5000 | train loss 0.061213 | norm 0.0729 | lr 5.07e-06 | (116.04 ms | 35299 tok/s)\n",
      "step 3654/5000 | train loss 0.061212 | norm 0.0708 | lr 5.06e-06 | (115.68 ms | 35409 tok/s)\n",
      "step 3655/5000 | train loss 0.061214 | norm 0.0807 | lr 5.05e-06 | (150.93 ms | 27139 tok/s)\n",
      "step 3656/5000 | train loss 0.061210 | norm 0.0655 | lr 5.05e-06 | (116.57 ms | 35139 tok/s)\n",
      "step 3657/5000 | train loss 0.061209 | norm 0.0583 | lr 5.04e-06 | (114.19 ms | 35869 tok/s)\n",
      "step 3658/5000 | train loss 0.061209 | norm 0.0651 | lr 5.03e-06 | (118.49 ms | 34570 tok/s)\n",
      "step 3659/5000 | train loss 0.061208 | norm 0.0605 | lr 5.03e-06 | (118.13 ms | 34674 tok/s)\n",
      "step 3660/5000 | train loss 0.061206 | norm 0.0561 | lr 5.02e-06 | (114.20 ms | 35866 tok/s)\n",
      "step 3661/5000 | train loss 0.061206 | norm 0.0570 | lr 5.01e-06 | (114.02 ms | 35923 tok/s)\n",
      "step 3662/5000 | train loss 0.061205 | norm 0.0559 | lr 5.01e-06 | (116.11 ms | 35278 tok/s)\n",
      "step 3663/5000 | train loss 0.061206 | norm 0.0681 | lr 5.00e-06 | (117.21 ms | 34945 tok/s)\n",
      "step 3664/5000 | train loss 0.061205 | norm 0.0685 | lr 4.99e-06 | (114.58 ms | 35748 tok/s)\n",
      "step 3665/5000 | train loss 0.061208 | norm 0.0866 | lr 4.98e-06 | (114.06 ms | 35910 tok/s)\n",
      "step 3666/5000 | train loss 0.061208 | norm 0.0958 | lr 4.98e-06 | (113.92 ms | 35956 tok/s)\n",
      "step 3667/5000 | train loss 0.061207 | norm 0.0901 | lr 4.97e-06 | (116.18 ms | 35256 tok/s)\n",
      "step 3668/5000 | train loss 0.061205 | norm 0.0849 | lr 4.96e-06 | (123.42 ms | 33187 tok/s)\n",
      "step 3669/5000 | train loss 0.061203 | norm 0.0722 | lr 4.96e-06 | (119.71 ms | 34215 tok/s)\n",
      "step 3670/5000 | train loss 0.061202 | norm 0.0736 | lr 4.95e-06 | (115.72 ms | 35396 tok/s)\n",
      "step 3671/5000 | train loss 0.061205 | norm 0.0946 | lr 4.94e-06 | (116.04 ms | 35297 tok/s)\n",
      "step 3672/5000 | train loss 0.061204 | norm 0.0923 | lr 4.94e-06 | (117.69 ms | 34804 tok/s)\n",
      "step 3673/5000 | train loss 0.061200 | norm 0.0710 | lr 4.93e-06 | (115.72 ms | 35395 tok/s)\n",
      "step 3674/5000 | train loss 0.061201 | norm 0.0771 | lr 4.92e-06 | (118.51 ms | 34562 tok/s)\n",
      "step 3675/5000 | train loss 0.061200 | norm 0.0810 | lr 4.91e-06 | (117.70 ms | 34801 tok/s)\n",
      "step 3676/5000 | train loss 0.061200 | norm 0.0783 | lr 4.91e-06 | (114.20 ms | 35868 tok/s)\n",
      "step 3677/5000 | train loss 0.061196 | norm 0.0595 | lr 4.90e-06 | (115.63 ms | 35424 tok/s)\n",
      "step 3678/5000 | train loss 0.061198 | norm 0.0745 | lr 4.89e-06 | (112.24 ms | 36492 tok/s)\n",
      "step 3679/5000 | train loss 0.061198 | norm 0.0790 | lr 4.89e-06 | (112.35 ms | 36457 tok/s)\n",
      "step 3680/5000 | train loss 0.061195 | norm 0.0633 | lr 4.88e-06 | (112.70 ms | 36345 tok/s)\n",
      "step 3681/5000 | train loss 0.061194 | norm 0.0613 | lr 4.87e-06 | (114.60 ms | 35741 tok/s)\n",
      "step 3682/5000 | train loss 0.061193 | norm 0.0605 | lr 4.87e-06 | (113.53 ms | 36080 tok/s)\n",
      "step 3683/5000 | train loss 0.061195 | norm 0.0759 | lr 4.86e-06 | (112.97 ms | 36258 tok/s)\n",
      "step 3684/5000 | train loss 0.061194 | norm 0.0750 | lr 4.85e-06 | (128.13 ms | 31967 tok/s)\n",
      "step 3685/5000 | train loss 0.061194 | norm 0.0826 | lr 4.84e-06 | (127.14 ms | 32217 tok/s)\n",
      "step 3686/5000 | train loss 0.061196 | norm 0.0936 | lr 4.84e-06 | (116.60 ms | 35130 tok/s)\n",
      "step 3687/5000 | train loss 0.061193 | norm 0.0790 | lr 4.83e-06 | (116.63 ms | 35121 tok/s)\n",
      "step 3688/5000 | train loss 0.061191 | norm 0.0676 | lr 4.82e-06 | (124.62 ms | 32867 tok/s)\n",
      "step 3689/5000 | train loss 0.061192 | norm 0.0783 | lr 4.82e-06 | (120.13 ms | 34095 tok/s)\n",
      "step 3690/5000 | train loss 0.061191 | norm 0.0802 | lr 4.81e-06 | (113.50 ms | 36089 tok/s)\n",
      "step 3691/5000 | train loss 0.061191 | norm 0.0805 | lr 4.80e-06 | (123.73 ms | 33103 tok/s)\n",
      "step 3692/5000 | train loss 0.061189 | norm 0.0719 | lr 4.80e-06 | (116.02 ms | 35304 tok/s)\n",
      "step 3693/5000 | train loss 0.061187 | norm 0.0629 | lr 4.79e-06 | (126.93 ms | 32269 tok/s)\n",
      "step 3694/5000 | train loss 0.061188 | norm 0.0733 | lr 4.78e-06 | (116.02 ms | 35304 tok/s)\n",
      "step 3695/5000 | train loss 0.061187 | norm 0.0727 | lr 4.78e-06 | (114.21 ms | 35864 tok/s)\n",
      "step 3696/5000 | train loss 0.061185 | norm 0.0632 | lr 4.77e-06 | (112.52 ms | 36404 tok/s)\n",
      "step 3697/5000 | train loss 0.061185 | norm 0.0645 | lr 4.76e-06 | (116.10 ms | 35279 tok/s)\n",
      "step 3698/5000 | train loss 0.061186 | norm 0.0737 | lr 4.75e-06 | (114.43 ms | 35795 tok/s)\n",
      "step 3699/5000 | train loss 0.061184 | norm 0.0699 | lr 4.75e-06 | (114.52 ms | 35768 tok/s)\n",
      "step 3700/5000 | train loss 0.061182 | norm 0.0603 | lr 4.74e-06 | (113.47 ms | 36096 tok/s)\n",
      "step 3701/5000 | train loss 0.061183 | norm 0.0664 | lr 4.73e-06 | (114.83 ms | 35669 tok/s)\n",
      "step 3702/5000 | train loss 0.061182 | norm 0.0671 | lr 4.73e-06 | (113.65 ms | 36041 tok/s)\n",
      "step 3703/5000 | train loss 0.061181 | norm 0.0673 | lr 4.72e-06 | (114.17 ms | 35876 tok/s)\n",
      "step 3704/5000 | train loss 0.061181 | norm 0.0707 | lr 4.71e-06 | (113.01 ms | 36244 tok/s)\n",
      "step 3705/5000 | train loss 0.061181 | norm 0.0769 | lr 4.71e-06 | (119.10 ms | 34392 tok/s)\n",
      "step 3706/5000 | train loss 0.061182 | norm 0.0832 | lr 4.70e-06 | (117.08 ms | 34986 tok/s)\n",
      "step 3707/5000 | train loss 0.061180 | norm 0.0763 | lr 4.69e-06 | (117.24 ms | 34935 tok/s)\n",
      "step 3708/5000 | train loss 0.061179 | norm 0.0723 | lr 4.69e-06 | (112.73 ms | 36336 tok/s)\n",
      "step 3709/5000 | train loss 0.061180 | norm 0.0834 | lr 4.68e-06 | (113.64 ms | 36044 tok/s)\n",
      "step 3710/5000 | train loss 0.061179 | norm 0.0782 | lr 4.67e-06 | (115.43 ms | 35483 tok/s)\n",
      "step 3711/5000 | train loss 0.061177 | norm 0.0712 | lr 4.67e-06 | (114.60 ms | 35742 tok/s)\n",
      "step 3712/5000 | train loss 0.061177 | norm 0.0746 | lr 4.66e-06 | (117.47 ms | 34868 tok/s)\n",
      "step 3713/5000 | train loss 0.061177 | norm 0.0767 | lr 4.65e-06 | (114.46 ms | 35784 tok/s)\n",
      "step 3714/5000 | train loss 0.061176 | norm 0.0762 | lr 4.65e-06 | (140.60 ms | 29131 tok/s)\n",
      "step 3715/5000 | train loss 0.061174 | norm 0.0657 | lr 4.64e-06 | (117.47 ms | 34870 tok/s)\n",
      "step 3716/5000 | train loss 0.061173 | norm 0.0616 | lr 4.63e-06 | (116.33 ms | 35211 tok/s)\n",
      "step 3717/5000 | train loss 0.061174 | norm 0.0709 | lr 4.62e-06 | (116.16 ms | 35262 tok/s)\n",
      "step 3718/5000 | train loss 0.061172 | norm 0.0624 | lr 4.62e-06 | (116.29 ms | 35223 tok/s)\n",
      "step 3719/5000 | train loss 0.061171 | norm 0.0530 | lr 4.61e-06 | (117.57 ms | 34838 tok/s)\n",
      "step 3720/5000 | train loss 0.061170 | norm 0.0531 | lr 4.60e-06 | (114.59 ms | 35745 tok/s)\n",
      "step 3721/5000 | train loss 0.061169 | norm 0.0486 | lr 4.60e-06 | (116.64 ms | 35115 tok/s)\n",
      "step 3722/5000 | train loss 0.061169 | norm 0.0563 | lr 4.59e-06 | (113.30 ms | 36151 tok/s)\n",
      "step 3723/5000 | train loss 0.061169 | norm 0.0555 | lr 4.58e-06 | (113.34 ms | 36140 tok/s)\n",
      "step 3724/5000 | train loss 0.061168 | norm 0.0547 | lr 4.58e-06 | (112.01 ms | 36568 tok/s)\n",
      "step 3725/5000 | train loss 0.061169 | norm 0.0665 | lr 4.57e-06 | (113.75 ms | 36010 tok/s)\n",
      "step 3726/5000 | train loss 0.061171 | norm 0.0846 | lr 4.56e-06 | (112.60 ms | 36378 tok/s)\n",
      "step 3727/5000 | train loss 0.061173 | norm 0.0978 | lr 4.56e-06 | (117.48 ms | 34866 tok/s)\n",
      "step 3728/5000 | train loss 0.061170 | norm 0.0876 | lr 4.55e-06 | (116.15 ms | 35265 tok/s)\n",
      "step 3729/5000 | train loss 0.061167 | norm 0.0710 | lr 4.54e-06 | (115.34 ms | 35511 tok/s)\n",
      "step 3730/5000 | train loss 0.061165 | norm 0.0608 | lr 4.54e-06 | (116.19 ms | 35254 tok/s)\n",
      "step 3731/5000 | train loss 0.061166 | norm 0.0738 | lr 4.53e-06 | (114.99 ms | 35621 tok/s)\n",
      "step 3732/5000 | train loss 0.061167 | norm 0.0830 | lr 4.52e-06 | (112.83 ms | 36303 tok/s)\n",
      "step 3733/5000 | train loss 0.061164 | norm 0.0658 | lr 4.52e-06 | (113.18 ms | 36189 tok/s)\n",
      "step 3734/5000 | train loss 0.061163 | norm 0.0652 | lr 4.51e-06 | (112.58 ms | 36382 tok/s)\n",
      "step 3735/5000 | train loss 0.061165 | norm 0.0816 | lr 4.50e-06 | (119.50 ms | 34276 tok/s)\n",
      "step 3736/5000 | train loss 0.061163 | norm 0.0711 | lr 4.50e-06 | (114.61 ms | 35738 tok/s)\n",
      "step 3737/5000 | train loss 0.061162 | norm 0.0648 | lr 4.49e-06 | (113.95 ms | 35944 tok/s)\n",
      "step 3738/5000 | train loss 0.061162 | norm 0.0740 | lr 4.48e-06 | (112.31 ms | 36470 tok/s)\n",
      "step 3739/5000 | train loss 0.061161 | norm 0.0665 | lr 4.48e-06 | (114.79 ms | 35681 tok/s)\n",
      "step 3740/5000 | train loss 0.061160 | norm 0.0645 | lr 4.47e-06 | (113.24 ms | 36170 tok/s)\n",
      "step 3741/5000 | train loss 0.061159 | norm 0.0645 | lr 4.46e-06 | (114.62 ms | 35736 tok/s)\n",
      "step 3742/5000 | train loss 0.061160 | norm 0.0725 | lr 4.46e-06 | (112.58 ms | 36384 tok/s)\n",
      "step 3743/5000 | train loss 0.061159 | norm 0.0736 | lr 4.45e-06 | (115.60 ms | 35433 tok/s)\n",
      "step 3744/5000 | train loss 0.061160 | norm 0.0798 | lr 4.44e-06 | (116.73 ms | 35089 tok/s)\n",
      "step 3745/5000 | train loss 0.061160 | norm 0.0851 | lr 4.44e-06 | (115.99 ms | 35312 tok/s)\n",
      "step 3746/5000 | train loss 0.061160 | norm 0.0872 | lr 4.43e-06 | (112.94 ms | 36267 tok/s)\n",
      "step 3747/5000 | train loss 0.061158 | norm 0.0773 | lr 4.42e-06 | (114.55 ms | 35757 tok/s)\n",
      "step 3748/5000 | train loss 0.061157 | norm 0.0786 | lr 4.42e-06 | (114.10 ms | 35900 tok/s)\n",
      "step 3749/5000 | train loss 0.061157 | norm 0.0804 | lr 4.41e-06 | (115.38 ms | 35500 tok/s)\n",
      "step 3750/5000 | train loss 0.061156 | norm 0.0724 | lr 4.40e-06 | (114.51 ms | 35771 tok/s)\n",
      "step 3751/5000 | train loss 0.061154 | norm 0.0618 | lr 4.40e-06 | (115.33 ms | 35515 tok/s)\n",
      "step 3752/5000 | train loss 0.061153 | norm 0.0610 | lr 4.39e-06 | (114.09 ms | 35901 tok/s)\n",
      "step 3753/5000 | train loss 0.061153 | norm 0.0659 | lr 4.38e-06 | (114.11 ms | 35895 tok/s)\n",
      "step 3754/5000 | train loss 0.061152 | norm 0.0599 | lr 4.38e-06 | (114.05 ms | 35915 tok/s)\n",
      "step 3755/5000 | train loss 0.061151 | norm 0.0536 | lr 4.37e-06 | (114.50 ms | 35772 tok/s)\n",
      "step 3756/5000 | train loss 0.061150 | norm 0.0525 | lr 4.36e-06 | (115.37 ms | 35504 tok/s)\n",
      "step 3757/5000 | train loss 0.061150 | norm 0.0563 | lr 4.36e-06 | (117.15 ms | 34964 tok/s)\n",
      "step 3758/5000 | train loss 0.061149 | norm 0.0549 | lr 4.35e-06 | (114.06 ms | 35909 tok/s)\n",
      "step 3759/5000 | train loss 0.061149 | norm 0.0559 | lr 4.34e-06 | (113.52 ms | 36083 tok/s)\n",
      "step 3760/5000 | train loss 0.061148 | norm 0.0581 | lr 4.34e-06 | (113.69 ms | 36027 tok/s)\n",
      "step 3761/5000 | train loss 0.061149 | norm 0.0656 | lr 4.33e-06 | (113.57 ms | 36065 tok/s)\n",
      "step 3762/5000 | train loss 0.061148 | norm 0.0682 | lr 4.32e-06 | (113.23 ms | 36174 tok/s)\n",
      "step 3763/5000 | train loss 0.061150 | norm 0.0807 | lr 4.32e-06 | (113.63 ms | 36046 tok/s)\n",
      "step 3764/5000 | train loss 0.061149 | norm 0.0786 | lr 4.31e-06 | (116.58 ms | 35134 tok/s)\n",
      "step 3765/5000 | train loss 0.061146 | norm 0.0630 | lr 4.30e-06 | (118.27 ms | 34632 tok/s)\n",
      "step 3766/5000 | train loss 0.061146 | norm 0.0624 | lr 4.30e-06 | (113.97 ms | 35940 tok/s)\n",
      "step 3767/5000 | train loss 0.061147 | norm 0.0725 | lr 4.29e-06 | (114.35 ms | 35821 tok/s)\n",
      "step 3768/5000 | train loss 0.061146 | norm 0.0726 | lr 4.28e-06 | (113.62 ms | 36050 tok/s)\n",
      "step 3769/5000 | train loss 0.061144 | norm 0.0606 | lr 4.28e-06 | (113.07 ms | 36226 tok/s)\n",
      "step 3770/5000 | train loss 0.061144 | norm 0.0648 | lr 4.27e-06 | (112.93 ms | 36271 tok/s)\n",
      "step 3771/5000 | train loss 0.061143 | norm 0.0634 | lr 4.26e-06 | (115.70 ms | 35401 tok/s)\n",
      "step 3772/5000 | train loss 0.061142 | norm 0.0544 | lr 4.26e-06 | (113.10 ms | 36215 tok/s)\n",
      "step 3773/5000 | train loss 0.061141 | norm 0.0574 | lr 4.25e-06 | (116.09 ms | 35283 tok/s)\n",
      "step 3774/5000 | train loss 0.061141 | norm 0.0601 | lr 4.24e-06 | (113.80 ms | 35993 tok/s)\n",
      "step 3775/5000 | train loss 0.061140 | norm 0.0594 | lr 4.24e-06 | (114.07 ms | 35908 tok/s)\n",
      "step 3776/5000 | train loss 0.061140 | norm 0.0622 | lr 4.23e-06 | (112.11 ms | 36535 tok/s)\n",
      "step 3777/5000 | train loss 0.061140 | norm 0.0659 | lr 4.22e-06 | (112.87 ms | 36291 tok/s)\n",
      "step 3778/5000 | train loss 0.061140 | norm 0.0659 | lr 4.22e-06 | (112.48 ms | 36414 tok/s)\n",
      "step 3779/5000 | train loss 0.061138 | norm 0.0558 | lr 4.21e-06 | (129.93 ms | 31524 tok/s)\n",
      "step 3780/5000 | train loss 0.061138 | norm 0.0620 | lr 4.20e-06 | (113.30 ms | 36151 tok/s)\n",
      "step 3781/5000 | train loss 0.061139 | norm 0.0717 | lr 4.20e-06 | (113.22 ms | 36178 tok/s)\n",
      "step 3782/5000 | train loss 0.061138 | norm 0.0678 | lr 4.19e-06 | (128.88 ms | 31780 tok/s)\n",
      "step 3783/5000 | train loss 0.061136 | norm 0.0561 | lr 4.18e-06 | (115.92 ms | 35334 tok/s)\n",
      "step 3784/5000 | train loss 0.061136 | norm 0.0555 | lr 4.18e-06 | (117.18 ms | 34954 tok/s)\n",
      "step 3785/5000 | train loss 0.061136 | norm 0.0605 | lr 4.17e-06 | (116.22 ms | 35245 tok/s)\n",
      "step 3786/5000 | train loss 0.061136 | norm 0.0674 | lr 4.17e-06 | (113.60 ms | 36055 tok/s)\n",
      "step 3787/5000 | train loss 0.061136 | norm 0.0726 | lr 4.16e-06 | (114.26 ms | 35847 tok/s)\n",
      "step 3788/5000 | train loss 0.061135 | norm 0.0685 | lr 4.15e-06 | (113.81 ms | 35990 tok/s)\n",
      "step 3789/5000 | train loss 0.061134 | norm 0.0694 | lr 4.15e-06 | (114.18 ms | 35872 tok/s)\n",
      "step 3790/5000 | train loss 0.061134 | norm 0.0742 | lr 4.14e-06 | (118.79 ms | 34482 tok/s)\n",
      "step 3791/5000 | train loss 0.061135 | norm 0.0777 | lr 4.13e-06 | (116.74 ms | 35086 tok/s)\n",
      "step 3792/5000 | train loss 0.061133 | norm 0.0748 | lr 4.13e-06 | (117.41 ms | 34885 tok/s)\n",
      "step 3793/5000 | train loss 0.061132 | norm 0.0693 | lr 4.12e-06 | (115.33 ms | 35515 tok/s)\n",
      "step 3794/5000 | train loss 0.061133 | norm 0.0712 | lr 4.11e-06 | (114.43 ms | 35793 tok/s)\n",
      "step 3795/5000 | train loss 0.061130 | norm 0.0605 | lr 4.11e-06 | (114.24 ms | 35854 tok/s)\n",
      "step 3796/5000 | train loss 0.061129 | norm 0.0553 | lr 4.10e-06 | (113.49 ms | 36091 tok/s)\n",
      "step 3797/5000 | train loss 0.061130 | norm 0.0633 | lr 4.09e-06 | (113.50 ms | 36087 tok/s)\n",
      "step 3798/5000 | train loss 0.061129 | norm 0.0635 | lr 4.09e-06 | (114.61 ms | 35739 tok/s)\n",
      "step 3799/5000 | train loss 0.061128 | norm 0.0587 | lr 4.08e-06 | (114.37 ms | 35814 tok/s)\n",
      "step 3800/5000 | train loss 0.061126 | norm 0.0486 | lr 4.07e-06 | (113.09 ms | 36219 tok/s)\n",
      "step 3801/5000 | train loss 0.061126 | norm 0.0502 | lr 4.07e-06 | (130.94 ms | 31281 tok/s)\n",
      "step 3802/5000 | train loss 0.061126 | norm 0.0563 | lr 4.06e-06 | (113.05 ms | 36232 tok/s)\n",
      "step 3803/5000 | train loss 0.061126 | norm 0.0588 | lr 4.06e-06 | (114.40 ms | 35805 tok/s)\n",
      "step 3804/5000 | train loss 0.061124 | norm 0.0501 | lr 4.05e-06 | (114.12 ms | 35891 tok/s)\n",
      "step 3805/5000 | train loss 0.061125 | norm 0.0551 | lr 4.04e-06 | (114.02 ms | 35924 tok/s)\n",
      "step 3806/5000 | train loss 0.061124 | norm 0.0553 | lr 4.04e-06 | (114.95 ms | 35633 tok/s)\n",
      "step 3807/5000 | train loss 0.061123 | norm 0.0525 | lr 4.03e-06 | (115.72 ms | 35396 tok/s)\n",
      "step 3808/5000 | train loss 0.061123 | norm 0.0576 | lr 4.02e-06 | (113.47 ms | 36098 tok/s)\n",
      "step 3809/5000 | train loss 0.061123 | norm 0.0603 | lr 4.02e-06 | (114.08 ms | 35904 tok/s)\n",
      "step 3810/5000 | train loss 0.061123 | norm 0.0603 | lr 4.01e-06 | (112.94 ms | 36265 tok/s)\n",
      "step 3811/5000 | train loss 0.061123 | norm 0.0657 | lr 4.00e-06 | (113.65 ms | 36040 tok/s)\n",
      "step 3812/5000 | train loss 0.061124 | norm 0.0784 | lr 4.00e-06 | (113.03 ms | 36239 tok/s)\n",
      "step 3813/5000 | train loss 0.061124 | norm 0.0807 | lr 3.99e-06 | (114.43 ms | 35796 tok/s)\n",
      "step 3814/5000 | train loss 0.061123 | norm 0.0761 | lr 3.98e-06 | (113.47 ms | 36097 tok/s)\n",
      "step 3815/5000 | train loss 0.061121 | norm 0.0704 | lr 3.98e-06 | (114.80 ms | 35679 tok/s)\n",
      "step 3816/5000 | train loss 0.061120 | norm 0.0652 | lr 3.97e-06 | (113.98 ms | 35935 tok/s)\n",
      "step 3817/5000 | train loss 0.061120 | norm 0.0660 | lr 3.97e-06 | (113.64 ms | 36045 tok/s)\n",
      "step 3818/5000 | train loss 0.061119 | norm 0.0647 | lr 3.96e-06 | (112.91 ms | 36276 tok/s)\n",
      "step 3819/5000 | train loss 0.061118 | norm 0.0586 | lr 3.95e-06 | (113.72 ms | 36019 tok/s)\n",
      "step 3820/5000 | train loss 0.061117 | norm 0.0557 | lr 3.95e-06 | (114.28 ms | 35843 tok/s)\n",
      "step 3821/5000 | train loss 0.061117 | norm 0.0577 | lr 3.94e-06 | (114.66 ms | 35724 tok/s)\n",
      "step 3822/5000 | train loss 0.061117 | norm 0.0563 | lr 3.93e-06 | (112.87 ms | 36289 tok/s)\n",
      "step 3823/5000 | train loss 0.061116 | norm 0.0513 | lr 3.93e-06 | (115.44 ms | 35482 tok/s)\n",
      "step 3824/5000 | train loss 0.061115 | norm 0.0478 | lr 3.92e-06 | (113.00 ms | 36248 tok/s)\n",
      "step 3825/5000 | train loss 0.061115 | norm 0.0570 | lr 3.91e-06 | (112.80 ms | 36313 tok/s)\n",
      "step 3826/5000 | train loss 0.061115 | norm 0.0575 | lr 3.91e-06 | (114.15 ms | 35883 tok/s)\n",
      "step 3827/5000 | train loss 0.061114 | norm 0.0580 | lr 3.90e-06 | (114.79 ms | 35683 tok/s)\n",
      "step 3828/5000 | train loss 0.061115 | norm 0.0701 | lr 3.90e-06 | (116.01 ms | 35307 tok/s)\n",
      "step 3829/5000 | train loss 0.061114 | norm 0.0717 | lr 3.89e-06 | (117.37 ms | 34897 tok/s)\n",
      "step 3830/5000 | train loss 0.061114 | norm 0.0683 | lr 3.88e-06 | (115.24 ms | 35542 tok/s)\n",
      "step 3831/5000 | train loss 0.061112 | norm 0.0600 | lr 3.88e-06 | (115.29 ms | 35528 tok/s)\n",
      "step 3832/5000 | train loss 0.061112 | norm 0.0610 | lr 3.87e-06 | (113.19 ms | 36188 tok/s)\n",
      "step 3833/5000 | train loss 0.061113 | norm 0.0679 | lr 3.86e-06 | (113.06 ms | 36228 tok/s)\n",
      "step 3834/5000 | train loss 0.061111 | norm 0.0643 | lr 3.86e-06 | (112.70 ms | 36343 tok/s)\n",
      "step 3835/5000 | train loss 0.061111 | norm 0.0656 | lr 3.85e-06 | (113.60 ms | 36056 tok/s)\n",
      "step 3836/5000 | train loss 0.061109 | norm 0.0541 | lr 3.84e-06 | (114.04 ms | 35916 tok/s)\n",
      "step 3837/5000 | train loss 0.061109 | norm 0.0533 | lr 3.84e-06 | (114.14 ms | 35887 tok/s)\n",
      "step 3838/5000 | train loss 0.061109 | norm 0.0594 | lr 3.83e-06 | (113.06 ms | 36228 tok/s)\n",
      "step 3839/5000 | train loss 0.061108 | norm 0.0572 | lr 3.83e-06 | (114.52 ms | 35768 tok/s)\n",
      "step 3840/5000 | train loss 0.061108 | norm 0.0557 | lr 3.82e-06 | (112.24 ms | 36494 tok/s)\n",
      "step 3841/5000 | train loss 0.061106 | norm 0.0483 | lr 3.81e-06 | (114.15 ms | 35882 tok/s)\n",
      "step 3842/5000 | train loss 0.061106 | norm 0.0524 | lr 3.81e-06 | (112.43 ms | 36432 tok/s)\n",
      "step 3843/5000 | train loss 0.061106 | norm 0.0535 | lr 3.80e-06 | (114.11 ms | 35894 tok/s)\n",
      "step 3844/5000 | train loss 0.061105 | norm 0.0503 | lr 3.79e-06 | (117.13 ms | 34971 tok/s)\n",
      "step 3845/5000 | train loss 0.061104 | norm 0.0475 | lr 3.79e-06 | (118.92 ms | 34442 tok/s)\n",
      "step 3846/5000 | train loss 0.061105 | norm 0.0536 | lr 3.78e-06 | (114.96 ms | 35630 tok/s)\n",
      "step 3847/5000 | train loss 0.061104 | norm 0.0549 | lr 3.78e-06 | (114.17 ms | 35877 tok/s)\n",
      "step 3848/5000 | train loss 0.061104 | norm 0.0580 | lr 3.77e-06 | (113.58 ms | 36063 tok/s)\n",
      "step 3849/5000 | train loss 0.061104 | norm 0.0596 | lr 3.76e-06 | (112.98 ms | 36254 tok/s)\n",
      "step 3850/5000 | train loss 0.061104 | norm 0.0664 | lr 3.76e-06 | (115.29 ms | 35529 tok/s)\n",
      "step 3851/5000 | train loss 0.061104 | norm 0.0693 | lr 3.75e-06 | (115.40 ms | 35494 tok/s)\n",
      "step 3852/5000 | train loss 0.061102 | norm 0.0598 | lr 3.74e-06 | (113.68 ms | 36032 tok/s)\n",
      "step 3853/5000 | train loss 0.061103 | norm 0.0684 | lr 3.74e-06 | (115.75 ms | 35388 tok/s)\n",
      "step 3854/5000 | train loss 0.061102 | norm 0.0666 | lr 3.73e-06 | (113.43 ms | 36110 tok/s)\n",
      "step 3855/5000 | train loss 0.061100 | norm 0.0554 | lr 3.73e-06 | (113.23 ms | 36174 tok/s)\n",
      "step 3856/5000 | train loss 0.061100 | norm 0.0561 | lr 3.72e-06 | (113.31 ms | 36149 tok/s)\n",
      "step 3857/5000 | train loss 0.061100 | norm 0.0572 | lr 3.71e-06 | (114.23 ms | 35858 tok/s)\n",
      "step 3858/5000 | train loss 0.061099 | norm 0.0553 | lr 3.71e-06 | (113.99 ms | 35934 tok/s)\n",
      "step 3859/5000 | train loss 0.061099 | norm 0.0578 | lr 3.70e-06 | (113.84 ms | 35981 tok/s)\n",
      "step 3860/5000 | train loss 0.061099 | norm 0.0615 | lr 3.70e-06 | (112.91 ms | 36278 tok/s)\n",
      "step 3861/5000 | train loss 0.061098 | norm 0.0614 | lr 3.69e-06 | (113.61 ms | 36055 tok/s)\n",
      "step 3862/5000 | train loss 0.061098 | norm 0.0614 | lr 3.68e-06 | (114.94 ms | 35637 tok/s)\n",
      "step 3863/5000 | train loss 0.061097 | norm 0.0615 | lr 3.68e-06 | (114.87 ms | 35658 tok/s)\n",
      "step 3864/5000 | train loss 0.061097 | norm 0.0587 | lr 3.67e-06 | (113.34 ms | 36137 tok/s)\n",
      "step 3865/5000 | train loss 0.061095 | norm 0.0491 | lr 3.66e-06 | (114.61 ms | 35737 tok/s)\n",
      "step 3866/5000 | train loss 0.061095 | norm 0.0521 | lr 3.66e-06 | (113.03 ms | 36240 tok/s)\n",
      "step 3867/5000 | train loss 0.061096 | norm 0.0655 | lr 3.65e-06 | (114.52 ms | 35768 tok/s)\n",
      "step 3868/5000 | train loss 0.061096 | norm 0.0701 | lr 3.65e-06 | (112.85 ms | 36297 tok/s)\n",
      "step 3869/5000 | train loss 0.061094 | norm 0.0616 | lr 3.64e-06 | (113.63 ms | 36046 tok/s)\n",
      "step 3870/5000 | train loss 0.061094 | norm 0.0552 | lr 3.63e-06 | (113.72 ms | 36019 tok/s)\n",
      "step 3871/5000 | train loss 0.061093 | norm 0.0471 | lr 3.63e-06 | (113.34 ms | 36138 tok/s)\n",
      "step 3872/5000 | train loss 0.061092 | norm 0.0488 | lr 3.62e-06 | (112.37 ms | 36450 tok/s)\n",
      "step 3873/5000 | train loss 0.061093 | norm 0.0605 | lr 3.61e-06 | (113.08 ms | 36223 tok/s)\n",
      "step 3874/5000 | train loss 0.061091 | norm 0.0505 | lr 3.61e-06 | (112.95 ms | 36264 tok/s)\n",
      "step 3875/5000 | train loss 0.061091 | norm 0.0485 | lr 3.60e-06 | (113.24 ms | 36171 tok/s)\n",
      "step 3876/5000 | train loss 0.061091 | norm 0.0563 | lr 3.60e-06 | (114.07 ms | 35906 tok/s)\n",
      "step 3877/5000 | train loss 0.061090 | norm 0.0507 | lr 3.59e-06 | (114.80 ms | 35680 tok/s)\n",
      "step 3878/5000 | train loss 0.061090 | norm 0.0524 | lr 3.58e-06 | (113.98 ms | 35937 tok/s)\n",
      "step 3879/5000 | train loss 0.061089 | norm 0.0517 | lr 3.58e-06 | (114.05 ms | 35915 tok/s)\n",
      "step 3880/5000 | train loss 0.061088 | norm 0.0443 | lr 3.57e-06 | (112.60 ms | 36378 tok/s)\n",
      "step 3881/5000 | train loss 0.061088 | norm 0.0467 | lr 3.57e-06 | (112.01 ms | 36569 tok/s)\n",
      "step 3882/5000 | train loss 0.061088 | norm 0.0508 | lr 3.56e-06 | (111.77 ms | 36647 tok/s)\n",
      "step 3883/5000 | train loss 0.061088 | norm 0.0554 | lr 3.55e-06 | (113.85 ms | 35976 tok/s)\n",
      "step 3884/5000 | train loss 0.061088 | norm 0.0573 | lr 3.55e-06 | (113.74 ms | 36011 tok/s)\n",
      "step 3885/5000 | train loss 0.061087 | norm 0.0567 | lr 3.54e-06 | (114.94 ms | 35636 tok/s)\n",
      "step 3886/5000 | train loss 0.061087 | norm 0.0560 | lr 3.54e-06 | (115.71 ms | 35400 tok/s)\n",
      "step 3887/5000 | train loss 0.061086 | norm 0.0502 | lr 3.53e-06 | (114.26 ms | 35848 tok/s)\n",
      "step 3888/5000 | train loss 0.061085 | norm 0.0507 | lr 3.52e-06 | (112.52 ms | 36402 tok/s)\n",
      "step 3889/5000 | train loss 0.061086 | norm 0.0572 | lr 3.52e-06 | (113.92 ms | 35956 tok/s)\n",
      "step 3890/5000 | train loss 0.061085 | norm 0.0550 | lr 3.51e-06 | (114.07 ms | 35908 tok/s)\n",
      "step 3891/5000 | train loss 0.061084 | norm 0.0543 | lr 3.51e-06 | (114.73 ms | 35701 tok/s)\n",
      "step 3892/5000 | train loss 0.061085 | norm 0.0647 | lr 3.50e-06 | (113.95 ms | 35945 tok/s)\n",
      "step 3893/5000 | train loss 0.061085 | norm 0.0664 | lr 3.49e-06 | (114.92 ms | 35642 tok/s)\n",
      "step 3894/5000 | train loss 0.061084 | norm 0.0618 | lr 3.49e-06 | (112.62 ms | 36371 tok/s)\n",
      "step 3895/5000 | train loss 0.061083 | norm 0.0614 | lr 3.48e-06 | (114.39 ms | 35807 tok/s)\n",
      "step 3896/5000 | train loss 0.061083 | norm 0.0645 | lr 3.48e-06 | (113.54 ms | 36076 tok/s)\n",
      "step 3897/5000 | train loss 0.061082 | norm 0.0599 | lr 3.47e-06 | (113.06 ms | 36230 tok/s)\n",
      "step 3898/5000 | train loss 0.061081 | norm 0.0527 | lr 3.46e-06 | (113.97 ms | 35940 tok/s)\n",
      "step 3899/5000 | train loss 0.061080 | norm 0.0432 | lr 3.46e-06 | (114.76 ms | 35692 tok/s)\n",
      "step 3900/5000 | train loss 0.061080 | norm 0.0491 | lr 3.45e-06 | (113.79 ms | 35995 tok/s)\n",
      "step 3901/5000 | train loss 0.061080 | norm 0.0514 | lr 3.44e-06 | (115.03 ms | 35608 tok/s)\n",
      "step 3902/5000 | train loss 0.061078 | norm 0.0403 | lr 3.44e-06 | (112.88 ms | 36285 tok/s)\n",
      "step 3903/5000 | train loss 0.061078 | norm 0.0403 | lr 3.43e-06 | (114.51 ms | 35770 tok/s)\n",
      "step 3904/5000 | train loss 0.061078 | norm 0.0453 | lr 3.43e-06 | (114.12 ms | 35892 tok/s)\n",
      "step 3905/5000 | train loss 0.061078 | norm 0.0478 | lr 3.42e-06 | (115.42 ms | 35487 tok/s)\n",
      "step 3906/5000 | train loss 0.061077 | norm 0.0494 | lr 3.41e-06 | (113.02 ms | 36240 tok/s)\n",
      "step 3907/5000 | train loss 0.061078 | norm 0.0576 | lr 3.41e-06 | (113.97 ms | 35939 tok/s)\n",
      "step 3908/5000 | train loss 0.061079 | norm 0.0692 | lr 3.40e-06 | (112.48 ms | 36416 tok/s)\n",
      "step 3909/5000 | train loss 0.061078 | norm 0.0708 | lr 3.40e-06 | (113.06 ms | 36228 tok/s)\n",
      "step 3910/5000 | train loss 0.061077 | norm 0.0604 | lr 3.39e-06 | (113.72 ms | 36019 tok/s)\n",
      "step 3911/5000 | train loss 0.061076 | norm 0.0541 | lr 3.39e-06 | (113.83 ms | 35984 tok/s)\n",
      "step 3912/5000 | train loss 0.061075 | norm 0.0532 | lr 3.38e-06 | (113.35 ms | 36136 tok/s)\n",
      "step 3913/5000 | train loss 0.061075 | norm 0.0582 | lr 3.37e-06 | (113.17 ms | 36194 tok/s)\n",
      "step 3914/5000 | train loss 0.061075 | norm 0.0554 | lr 3.37e-06 | (115.29 ms | 35526 tok/s)\n",
      "step 3915/5000 | train loss 0.061073 | norm 0.0403 | lr 3.36e-06 | (115.62 ms | 35427 tok/s)\n",
      "step 3916/5000 | train loss 0.061073 | norm 0.0462 | lr 3.36e-06 | (114.13 ms | 35888 tok/s)\n",
      "step 3917/5000 | train loss 0.061073 | norm 0.0506 | lr 3.35e-06 | (116.22 ms | 35244 tok/s)\n",
      "step 3918/5000 | train loss 0.061072 | norm 0.0507 | lr 3.34e-06 | (113.17 ms | 36195 tok/s)\n",
      "step 3919/5000 | train loss 0.061073 | norm 0.0591 | lr 3.34e-06 | (113.60 ms | 36057 tok/s)\n",
      "step 3920/5000 | train loss 0.061073 | norm 0.0712 | lr 3.33e-06 | (113.24 ms | 36170 tok/s)\n",
      "step 3921/5000 | train loss 0.061074 | norm 0.0763 | lr 3.33e-06 | (113.33 ms | 36142 tok/s)\n",
      "step 3922/5000 | train loss 0.061071 | norm 0.0587 | lr 3.32e-06 | (114.07 ms | 35907 tok/s)\n",
      "step 3923/5000 | train loss 0.061071 | norm 0.0530 | lr 3.31e-06 | (113.41 ms | 36115 tok/s)\n",
      "step 3924/5000 | train loss 0.061070 | norm 0.0582 | lr 3.31e-06 | (113.86 ms | 35973 tok/s)\n",
      "step 3925/5000 | train loss 0.061070 | norm 0.0604 | lr 3.30e-06 | (114.79 ms | 35683 tok/s)\n",
      "step 3926/5000 | train loss 0.061069 | norm 0.0525 | lr 3.30e-06 | (113.90 ms | 35961 tok/s)\n",
      "step 3927/5000 | train loss 0.061068 | norm 0.0426 | lr 3.29e-06 | (114.16 ms | 35879 tok/s)\n",
      "step 3928/5000 | train loss 0.061068 | norm 0.0517 | lr 3.28e-06 | (112.75 ms | 36329 tok/s)\n",
      "step 3929/5000 | train loss 0.061068 | norm 0.0495 | lr 3.28e-06 | (114.27 ms | 35845 tok/s)\n",
      "step 3930/5000 | train loss 0.061066 | norm 0.0345 | lr 3.27e-06 | (113.68 ms | 36031 tok/s)\n",
      "step 3931/5000 | train loss 0.061066 | norm 0.0442 | lr 3.27e-06 | (116.05 ms | 35295 tok/s)\n",
      "step 3932/5000 | train loss 0.061066 | norm 0.0451 | lr 3.26e-06 | (114.18 ms | 35872 tok/s)\n",
      "step 3933/5000 | train loss 0.061065 | norm 0.0410 | lr 3.26e-06 | (113.82 ms | 35988 tok/s)\n",
      "step 3934/5000 | train loss 0.061066 | norm 0.0474 | lr 3.25e-06 | (113.96 ms | 35943 tok/s)\n",
      "step 3935/5000 | train loss 0.061065 | norm 0.0516 | lr 3.24e-06 | (113.17 ms | 36195 tok/s)\n",
      "step 3936/5000 | train loss 0.061065 | norm 0.0531 | lr 3.24e-06 | (112.90 ms | 36281 tok/s)\n",
      "step 3937/5000 | train loss 0.061065 | norm 0.0549 | lr 3.23e-06 | (113.29 ms | 36156 tok/s)\n",
      "step 3938/5000 | train loss 0.061064 | norm 0.0486 | lr 3.23e-06 | (114.51 ms | 35771 tok/s)\n",
      "step 3939/5000 | train loss 0.061063 | norm 0.0462 | lr 3.22e-06 | (114.93 ms | 35640 tok/s)\n",
      "step 3940/5000 | train loss 0.061064 | norm 0.0525 | lr 3.21e-06 | (129.82 ms | 31550 tok/s)\n",
      "step 3941/5000 | train loss 0.061063 | norm 0.0557 | lr 3.21e-06 | (115.13 ms | 35577 tok/s)\n",
      "step 3942/5000 | train loss 0.061063 | norm 0.0579 | lr 3.20e-06 | (112.21 ms | 36503 tok/s)\n",
      "step 3943/5000 | train loss 0.061062 | norm 0.0526 | lr 3.20e-06 | (112.57 ms | 36386 tok/s)\n",
      "step 3944/5000 | train loss 0.061062 | norm 0.0517 | lr 3.19e-06 | (112.30 ms | 36473 tok/s)\n",
      "step 3945/5000 | train loss 0.061062 | norm 0.0546 | lr 3.19e-06 | (114.17 ms | 35875 tok/s)\n",
      "step 3946/5000 | train loss 0.061061 | norm 0.0525 | lr 3.18e-06 | (114.58 ms | 35748 tok/s)\n",
      "step 3947/5000 | train loss 0.061061 | norm 0.0528 | lr 3.17e-06 | (114.14 ms | 35886 tok/s)\n",
      "step 3948/5000 | train loss 0.061061 | norm 0.0544 | lr 3.17e-06 | (113.66 ms | 36037 tok/s)\n",
      "step 3949/5000 | train loss 0.061059 | norm 0.0464 | lr 3.16e-06 | (113.68 ms | 36030 tok/s)\n",
      "step 3950/5000 | train loss 0.061059 | norm 0.0467 | lr 3.16e-06 | (113.02 ms | 36241 tok/s)\n",
      "step 3951/5000 | train loss 0.061059 | norm 0.0469 | lr 3.15e-06 | (112.72 ms | 36339 tok/s)\n",
      "step 3952/5000 | train loss 0.061058 | norm 0.0476 | lr 3.14e-06 | (112.14 ms | 36527 tok/s)\n",
      "step 3953/5000 | train loss 0.061058 | norm 0.0455 | lr 3.14e-06 | (114.50 ms | 35774 tok/s)\n",
      "step 3954/5000 | train loss 0.061057 | norm 0.0417 | lr 3.13e-06 | (116.77 ms | 35077 tok/s)\n",
      "step 3955/5000 | train loss 0.061057 | norm 0.0501 | lr 3.13e-06 | (115.38 ms | 35502 tok/s)\n",
      "step 3956/5000 | train loss 0.061057 | norm 0.0496 | lr 3.12e-06 | (113.28 ms | 36158 tok/s)\n",
      "step 3957/5000 | train loss 0.061056 | norm 0.0414 | lr 3.12e-06 | (113.38 ms | 36125 tok/s)\n",
      "step 3958/5000 | train loss 0.061055 | norm 0.0409 | lr 3.11e-06 | (112.79 ms | 36314 tok/s)\n",
      "step 3959/5000 | train loss 0.061055 | norm 0.0459 | lr 3.10e-06 | (115.77 ms | 35380 tok/s)\n",
      "step 3960/5000 | train loss 0.061055 | norm 0.0495 | lr 3.10e-06 | (113.53 ms | 36079 tok/s)\n",
      "step 3961/5000 | train loss 0.061055 | norm 0.0512 | lr 3.09e-06 | (114.41 ms | 35803 tok/s)\n",
      "step 3962/5000 | train loss 0.061055 | norm 0.0529 | lr 3.09e-06 | (113.80 ms | 35992 tok/s)\n",
      "step 3963/5000 | train loss 0.061055 | norm 0.0555 | lr 3.08e-06 | (114.19 ms | 35869 tok/s)\n",
      "step 3964/5000 | train loss 0.061054 | norm 0.0514 | lr 3.08e-06 | (112.81 ms | 36308 tok/s)\n",
      "step 3965/5000 | train loss 0.061053 | norm 0.0405 | lr 3.07e-06 | (112.14 ms | 36526 tok/s)\n",
      "step 3966/5000 | train loss 0.061052 | norm 0.0399 | lr 3.06e-06 | (111.72 ms | 36662 tok/s)\n",
      "step 3967/5000 | train loss 0.061052 | norm 0.0454 | lr 3.06e-06 | (114.90 ms | 35648 tok/s)\n",
      "step 3968/5000 | train loss 0.061052 | norm 0.0473 | lr 3.05e-06 | (113.60 ms | 36058 tok/s)\n",
      "step 3969/5000 | train loss 0.061052 | norm 0.0495 | lr 3.05e-06 | (115.34 ms | 35512 tok/s)\n",
      "step 3970/5000 | train loss 0.061051 | norm 0.0446 | lr 3.04e-06 | (113.41 ms | 36117 tok/s)\n",
      "step 3971/5000 | train loss 0.061051 | norm 0.0456 | lr 3.04e-06 | (114.36 ms | 35816 tok/s)\n",
      "step 3972/5000 | train loss 0.061051 | norm 0.0529 | lr 3.03e-06 | (113.53 ms | 36077 tok/s)\n",
      "step 3973/5000 | train loss 0.061050 | norm 0.0508 | lr 3.02e-06 | (116.27 ms | 35230 tok/s)\n",
      "step 3974/5000 | train loss 0.061050 | norm 0.0461 | lr 3.02e-06 | (112.48 ms | 36415 tok/s)\n",
      "step 3975/5000 | train loss 0.061049 | norm 0.0437 | lr 3.01e-06 | (113.01 ms | 36243 tok/s)\n",
      "step 3976/5000 | train loss 0.061049 | norm 0.0460 | lr 3.01e-06 | (113.83 ms | 35985 tok/s)\n",
      "step 3977/5000 | train loss 0.061049 | norm 0.0526 | lr 3.00e-06 | (116.31 ms | 35218 tok/s)\n",
      "step 3978/5000 | train loss 0.061048 | norm 0.0493 | lr 3.00e-06 | (113.82 ms | 35987 tok/s)\n",
      "step 3979/5000 | train loss 0.061048 | norm 0.0436 | lr 2.99e-06 | (114.36 ms | 35818 tok/s)\n",
      "step 3980/5000 | train loss 0.061047 | norm 0.0452 | lr 2.98e-06 | (114.85 ms | 35663 tok/s)\n",
      "step 3981/5000 | train loss 0.061047 | norm 0.0480 | lr 2.98e-06 | (114.13 ms | 35888 tok/s)\n",
      "step 3982/5000 | train loss 0.061047 | norm 0.0549 | lr 2.97e-06 | (112.29 ms | 36476 tok/s)\n",
      "step 3983/5000 | train loss 0.061047 | norm 0.0595 | lr 2.97e-06 | (114.10 ms | 35899 tok/s)\n",
      "step 3984/5000 | train loss 0.061047 | norm 0.0604 | lr 2.96e-06 | (114.29 ms | 35839 tok/s)\n",
      "step 3985/5000 | train loss 0.061047 | norm 0.0606 | lr 2.96e-06 | (116.77 ms | 35079 tok/s)\n",
      "step 3986/5000 | train loss 0.061046 | norm 0.0519 | lr 2.95e-06 | (114.46 ms | 35784 tok/s)\n",
      "step 3987/5000 | train loss 0.061045 | norm 0.0500 | lr 2.95e-06 | (114.35 ms | 35818 tok/s)\n",
      "step 3988/5000 | train loss 0.061045 | norm 0.0517 | lr 2.94e-06 | (112.89 ms | 36283 tok/s)\n",
      "step 3989/5000 | train loss 0.061044 | norm 0.0411 | lr 2.93e-06 | (112.66 ms | 36358 tok/s)\n",
      "step 3990/5000 | train loss 0.061043 | norm 0.0406 | lr 2.93e-06 | (113.63 ms | 36046 tok/s)\n",
      "step 3991/5000 | train loss 0.061043 | norm 0.0455 | lr 2.92e-06 | (114.10 ms | 35897 tok/s)\n",
      "step 3992/5000 | train loss 0.061042 | norm 0.0395 | lr 2.92e-06 | (115.26 ms | 35536 tok/s)\n",
      "step 3993/5000 | train loss 0.061042 | norm 0.0388 | lr 2.91e-06 | (114.82 ms | 35673 tok/s)\n",
      "step 3994/5000 | train loss 0.061042 | norm 0.0408 | lr 2.91e-06 | (113.85 ms | 35978 tok/s)\n",
      "step 3995/5000 | train loss 0.061041 | norm 0.0404 | lr 2.90e-06 | (115.16 ms | 35569 tok/s)\n",
      "step 3996/5000 | train loss 0.061041 | norm 0.0455 | lr 2.90e-06 | (113.48 ms | 36094 tok/s)\n",
      "step 3997/5000 | train loss 0.061041 | norm 0.0430 | lr 2.89e-06 | (119.51 ms | 34274 tok/s)\n",
      "step 3998/5000 | train loss 0.061041 | norm 0.0459 | lr 2.88e-06 | (123.33 ms | 33211 tok/s)\n",
      "step 3999/5000 | train loss 0.061040 | norm 0.0471 | lr 2.88e-06 | (115.26 ms | 35537 tok/s)\n",
      "step 4000/5000 | train loss 0.061040 | norm 0.0424 | lr 2.87e-06 | (113.12 ms | 36208 tok/s)\n",
      "step 4001/5000 | train loss 0.061039 | norm 0.0411 | lr 2.87e-06 | (116.19 ms | 35253 tok/s)\n",
      "step 4002/5000 | train loss 0.061039 | norm 0.0405 | lr 2.86e-06 | (114.71 ms | 35707 tok/s)\n",
      "step 4003/5000 | train loss 0.061039 | norm 0.0415 | lr 2.86e-06 | (113.86 ms | 35973 tok/s)\n",
      "step 4004/5000 | train loss 0.061038 | norm 0.0429 | lr 2.85e-06 | (112.57 ms | 36386 tok/s)\n",
      "step 4005/5000 | train loss 0.061038 | norm 0.0449 | lr 2.85e-06 | (115.90 ms | 35340 tok/s)\n",
      "step 4006/5000 | train loss 0.061038 | norm 0.0499 | lr 2.84e-06 | (114.41 ms | 35802 tok/s)\n",
      "step 4007/5000 | train loss 0.061038 | norm 0.0506 | lr 2.83e-06 | (113.80 ms | 35994 tok/s)\n",
      "step 4008/5000 | train loss 0.061038 | norm 0.0510 | lr 2.83e-06 | (113.18 ms | 36189 tok/s)\n",
      "step 4009/5000 | train loss 0.061037 | norm 0.0492 | lr 2.82e-06 | (114.21 ms | 35864 tok/s)\n",
      "step 4010/5000 | train loss 0.061036 | norm 0.0433 | lr 2.82e-06 | (113.36 ms | 36134 tok/s)\n",
      "step 4011/5000 | train loss 0.061036 | norm 0.0434 | lr 2.81e-06 | (113.24 ms | 36171 tok/s)\n",
      "step 4012/5000 | train loss 0.061036 | norm 0.0465 | lr 2.81e-06 | (113.43 ms | 36110 tok/s)\n",
      "step 4013/5000 | train loss 0.061035 | norm 0.0429 | lr 2.80e-06 | (113.72 ms | 36019 tok/s)\n",
      "step 4014/5000 | train loss 0.061035 | norm 0.0422 | lr 2.80e-06 | (113.57 ms | 36066 tok/s)\n",
      "step 4015/5000 | train loss 0.061034 | norm 0.0400 | lr 2.79e-06 | (114.71 ms | 35706 tok/s)\n",
      "step 4016/5000 | train loss 0.061034 | norm 0.0410 | lr 2.78e-06 | (113.84 ms | 35981 tok/s)\n",
      "step 4017/5000 | train loss 0.061034 | norm 0.0476 | lr 2.78e-06 | (115.43 ms | 35484 tok/s)\n",
      "step 4018/5000 | train loss 0.061034 | norm 0.0479 | lr 2.77e-06 | (112.40 ms | 36443 tok/s)\n",
      "step 4019/5000 | train loss 0.061033 | norm 0.0460 | lr 2.77e-06 | (113.59 ms | 36060 tok/s)\n",
      "step 4020/5000 | train loss 0.061033 | norm 0.0449 | lr 2.76e-06 | (113.25 ms | 36169 tok/s)\n",
      "step 4021/5000 | train loss 0.061032 | norm 0.0409 | lr 2.76e-06 | (113.83 ms | 35983 tok/s)\n",
      "step 4022/5000 | train loss 0.061032 | norm 0.0410 | lr 2.75e-06 | (114.47 ms | 35783 tok/s)\n",
      "step 4023/5000 | train loss 0.061032 | norm 0.0444 | lr 2.75e-06 | (115.13 ms | 35578 tok/s)\n",
      "step 4024/5000 | train loss 0.061031 | norm 0.0457 | lr 2.74e-06 | (115.43 ms | 35486 tok/s)\n",
      "step 4025/5000 | train loss 0.061032 | norm 0.0494 | lr 2.74e-06 | (115.46 ms | 35476 tok/s)\n",
      "step 4026/5000 | train loss 0.061031 | norm 0.0443 | lr 2.73e-06 | (114.48 ms | 35778 tok/s)\n",
      "step 4027/5000 | train loss 0.061031 | norm 0.0455 | lr 2.73e-06 | (115.64 ms | 35420 tok/s)\n",
      "step 4028/5000 | train loss 0.061030 | norm 0.0413 | lr 2.72e-06 | (113.89 ms | 35964 tok/s)\n",
      "step 4029/5000 | train loss 0.061029 | norm 0.0368 | lr 2.71e-06 | (114.57 ms | 35750 tok/s)\n",
      "step 4030/5000 | train loss 0.061029 | norm 0.0404 | lr 2.71e-06 | (113.60 ms | 36057 tok/s)\n",
      "step 4031/5000 | train loss 0.061029 | norm 0.0396 | lr 2.70e-06 | (116.05 ms | 35296 tok/s)\n",
      "step 4032/5000 | train loss 0.061028 | norm 0.0343 | lr 2.70e-06 | (113.18 ms | 36191 tok/s)\n",
      "step 4033/5000 | train loss 0.061027 | norm 0.0356 | lr 2.69e-06 | (114.44 ms | 35791 tok/s)\n",
      "step 4034/5000 | train loss 0.061028 | norm 0.0434 | lr 2.69e-06 | (112.72 ms | 36338 tok/s)\n",
      "step 4035/5000 | train loss 0.061027 | norm 0.0416 | lr 2.68e-06 | (112.85 ms | 36295 tok/s)\n",
      "step 4036/5000 | train loss 0.061027 | norm 0.0440 | lr 2.68e-06 | (113.10 ms | 36215 tok/s)\n",
      "step 4037/5000 | train loss 0.061027 | norm 0.0517 | lr 2.67e-06 | (113.75 ms | 36009 tok/s)\n",
      "step 4038/5000 | train loss 0.061027 | norm 0.0486 | lr 2.67e-06 | (112.98 ms | 36254 tok/s)\n",
      "step 4039/5000 | train loss 0.061026 | norm 0.0363 | lr 2.66e-06 | (115.53 ms | 35453 tok/s)\n",
      "step 4040/5000 | train loss 0.061025 | norm 0.0349 | lr 2.66e-06 | (112.89 ms | 36282 tok/s)\n",
      "step 4041/5000 | train loss 0.061025 | norm 0.0452 | lr 2.65e-06 | (113.14 ms | 36203 tok/s)\n",
      "step 4042/5000 | train loss 0.061025 | norm 0.0470 | lr 2.64e-06 | (113.93 ms | 35953 tok/s)\n",
      "step 4043/5000 | train loss 0.061025 | norm 0.0439 | lr 2.64e-06 | (115.71 ms | 35398 tok/s)\n",
      "step 4044/5000 | train loss 0.061024 | norm 0.0395 | lr 2.63e-06 | (113.12 ms | 36211 tok/s)\n",
      "step 4045/5000 | train loss 0.061024 | norm 0.0415 | lr 2.63e-06 | (116.52 ms | 35154 tok/s)\n",
      "step 4046/5000 | train loss 0.061024 | norm 0.0484 | lr 2.62e-06 | (116.20 ms | 35251 tok/s)\n",
      "step 4047/5000 | train loss 0.061023 | norm 0.0437 | lr 2.62e-06 | (117.24 ms | 34937 tok/s)\n",
      "step 4048/5000 | train loss 0.061023 | norm 0.0431 | lr 2.61e-06 | (115.90 ms | 35341 tok/s)\n",
      "step 4049/5000 | train loss 0.061023 | norm 0.0499 | lr 2.61e-06 | (114.57 ms | 35752 tok/s)\n",
      "step 4050/5000 | train loss 0.061023 | norm 0.0459 | lr 2.60e-06 | (113.90 ms | 35963 tok/s)\n",
      "step 4051/5000 | train loss 0.061022 | norm 0.0368 | lr 2.60e-06 | (117.00 ms | 35008 tok/s)\n",
      "step 4052/5000 | train loss 0.061021 | norm 0.0375 | lr 2.59e-06 | (114.74 ms | 35697 tok/s)\n",
      "step 4053/5000 | train loss 0.061021 | norm 0.0408 | lr 2.59e-06 | (115.65 ms | 35417 tok/s)\n",
      "step 4054/5000 | train loss 0.061021 | norm 0.0434 | lr 2.58e-06 | (118.04 ms | 34701 tok/s)\n",
      "step 4055/5000 | train loss 0.061021 | norm 0.0419 | lr 2.58e-06 | (116.75 ms | 35085 tok/s)\n",
      "step 4056/5000 | train loss 0.061020 | norm 0.0428 | lr 2.57e-06 | (112.80 ms | 36312 tok/s)\n",
      "step 4057/5000 | train loss 0.061020 | norm 0.0431 | lr 2.56e-06 | (114.24 ms | 35854 tok/s)\n",
      "step 4058/5000 | train loss 0.061020 | norm 0.0446 | lr 2.56e-06 | (114.60 ms | 35741 tok/s)\n",
      "step 4059/5000 | train loss 0.061019 | norm 0.0447 | lr 2.55e-06 | (114.16 ms | 35880 tok/s)\n",
      "step 4060/5000 | train loss 0.061019 | norm 0.0439 | lr 2.55e-06 | (114.81 ms | 35676 tok/s)\n",
      "step 4061/5000 | train loss 0.061019 | norm 0.0425 | lr 2.54e-06 | (113.85 ms | 35978 tok/s)\n",
      "step 4062/5000 | train loss 0.061018 | norm 0.0379 | lr 2.54e-06 | (113.03 ms | 36239 tok/s)\n",
      "step 4063/5000 | train loss 0.061018 | norm 0.0384 | lr 2.53e-06 | (115.48 ms | 35470 tok/s)\n",
      "step 4064/5000 | train loss 0.061017 | norm 0.0377 | lr 2.53e-06 | (114.94 ms | 35635 tok/s)\n",
      "step 4065/5000 | train loss 0.061017 | norm 0.0362 | lr 2.52e-06 | (113.96 ms | 35944 tok/s)\n",
      "step 4066/5000 | train loss 0.061017 | norm 0.0422 | lr 2.52e-06 | (114.07 ms | 35908 tok/s)\n",
      "step 4067/5000 | train loss 0.061017 | norm 0.0430 | lr 2.51e-06 | (116.09 ms | 35283 tok/s)\n",
      "step 4068/5000 | train loss 0.061016 | norm 0.0404 | lr 2.51e-06 | (115.29 ms | 35529 tok/s)\n",
      "step 4069/5000 | train loss 0.061016 | norm 0.0425 | lr 2.50e-06 | (114.78 ms | 35685 tok/s)\n",
      "step 4070/5000 | train loss 0.061015 | norm 0.0369 | lr 2.50e-06 | (114.12 ms | 35892 tok/s)\n",
      "step 4071/5000 | train loss 0.061015 | norm 0.0352 | lr 2.49e-06 | (114.08 ms | 35905 tok/s)\n",
      "step 4072/5000 | train loss 0.061015 | norm 0.0418 | lr 2.49e-06 | (112.84 ms | 36300 tok/s)\n",
      "step 4073/5000 | train loss 0.061014 | norm 0.0350 | lr 2.48e-06 | (114.35 ms | 35821 tok/s)\n",
      "step 4074/5000 | train loss 0.061014 | norm 0.0298 | lr 2.48e-06 | (112.60 ms | 36376 tok/s)\n",
      "step 4075/5000 | train loss 0.061014 | norm 0.0318 | lr 2.47e-06 | (113.43 ms | 36110 tok/s)\n",
      "step 4076/5000 | train loss 0.061013 | norm 0.0317 | lr 2.47e-06 | (113.46 ms | 36102 tok/s)\n",
      "step 4077/5000 | train loss 0.061013 | norm 0.0377 | lr 2.46e-06 | (114.97 ms | 35627 tok/s)\n",
      "step 4078/5000 | train loss 0.061013 | norm 0.0362 | lr 2.46e-06 | (114.23 ms | 35859 tok/s)\n",
      "step 4079/5000 | train loss 0.061013 | norm 0.0423 | lr 2.45e-06 | (115.22 ms | 35549 tok/s)\n",
      "step 4080/5000 | train loss 0.061014 | norm 0.0535 | lr 2.44e-06 | (111.98 ms | 36578 tok/s)\n",
      "step 4081/5000 | train loss 0.061013 | norm 0.0547 | lr 2.44e-06 | (113.68 ms | 36030 tok/s)\n",
      "step 4082/5000 | train loss 0.061013 | norm 0.0501 | lr 2.43e-06 | (113.34 ms | 36140 tok/s)\n",
      "step 4083/5000 | train loss 0.061011 | norm 0.0378 | lr 2.43e-06 | (114.23 ms | 35857 tok/s)\n",
      "step 4084/5000 | train loss 0.061011 | norm 0.0387 | lr 2.42e-06 | (113.87 ms | 35971 tok/s)\n",
      "step 4085/5000 | train loss 0.061012 | norm 0.0479 | lr 2.42e-06 | (113.89 ms | 35966 tok/s)\n",
      "step 4086/5000 | train loss 0.061011 | norm 0.0455 | lr 2.41e-06 | (113.85 ms | 35976 tok/s)\n",
      "step 4087/5000 | train loss 0.061010 | norm 0.0340 | lr 2.41e-06 | (113.43 ms | 36109 tok/s)\n",
      "step 4088/5000 | train loss 0.061010 | norm 0.0372 | lr 2.40e-06 | (112.11 ms | 36534 tok/s)\n",
      "step 4089/5000 | train loss 0.061010 | norm 0.0417 | lr 2.40e-06 | (113.65 ms | 36040 tok/s)\n",
      "step 4090/5000 | train loss 0.061009 | norm 0.0331 | lr 2.39e-06 | (115.44 ms | 35482 tok/s)\n",
      "step 4091/5000 | train loss 0.061008 | norm 0.0286 | lr 2.39e-06 | (115.10 ms | 35587 tok/s)\n",
      "step 4092/5000 | train loss 0.061008 | norm 0.0335 | lr 2.38e-06 | (114.84 ms | 35667 tok/s)\n",
      "step 4093/5000 | train loss 0.061008 | norm 0.0320 | lr 2.38e-06 | (114.88 ms | 35654 tok/s)\n",
      "step 4094/5000 | train loss 0.061007 | norm 0.0281 | lr 2.37e-06 | (114.95 ms | 35633 tok/s)\n",
      "step 4095/5000 | train loss 0.061007 | norm 0.0298 | lr 2.37e-06 | (116.14 ms | 35269 tok/s)\n",
      "step 4096/5000 | train loss 0.061007 | norm 0.0291 | lr 2.36e-06 | (115.77 ms | 35382 tok/s)\n",
      "step 4097/5000 | train loss 0.061007 | norm 0.0306 | lr 2.36e-06 | (114.78 ms | 35684 tok/s)\n",
      "step 4098/5000 | train loss 0.061007 | norm 0.0341 | lr 2.35e-06 | (114.02 ms | 35924 tok/s)\n",
      "step 4099/5000 | train loss 0.061006 | norm 0.0379 | lr 2.35e-06 | (115.25 ms | 35540 tok/s)\n",
      "step 4100/5000 | train loss 0.061006 | norm 0.0416 | lr 2.34e-06 | (113.32 ms | 36145 tok/s)\n",
      "step 4101/5000 | train loss 0.061007 | norm 0.0472 | lr 2.34e-06 | (114.39 ms | 35807 tok/s)\n",
      "step 4102/5000 | train loss 0.061006 | norm 0.0474 | lr 2.33e-06 | (113.05 ms | 36233 tok/s)\n",
      "step 4103/5000 | train loss 0.061006 | norm 0.0408 | lr 2.33e-06 | (113.27 ms | 36162 tok/s)\n",
      "step 4104/5000 | train loss 0.061005 | norm 0.0419 | lr 2.32e-06 | (113.04 ms | 36234 tok/s)\n",
      "step 4105/5000 | train loss 0.061006 | norm 0.0506 | lr 2.32e-06 | (114.81 ms | 35676 tok/s)\n",
      "step 4106/5000 | train loss 0.061005 | norm 0.0458 | lr 2.31e-06 | (114.78 ms | 35684 tok/s)\n",
      "step 4107/5000 | train loss 0.061004 | norm 0.0354 | lr 2.31e-06 | (114.52 ms | 35768 tok/s)\n",
      "step 4108/5000 | train loss 0.061004 | norm 0.0396 | lr 2.30e-06 | (113.62 ms | 36050 tok/s)\n",
      "step 4109/5000 | train loss 0.061004 | norm 0.0398 | lr 2.30e-06 | (114.19 ms | 35869 tok/s)\n",
      "step 4110/5000 | train loss 0.061003 | norm 0.0375 | lr 2.29e-06 | (113.48 ms | 36095 tok/s)\n",
      "step 4111/5000 | train loss 0.061003 | norm 0.0319 | lr 2.29e-06 | (114.96 ms | 35628 tok/s)\n",
      "step 4112/5000 | train loss 0.061002 | norm 0.0327 | lr 2.28e-06 | (116.34 ms | 35207 tok/s)\n",
      "step 4113/5000 | train loss 0.061002 | norm 0.0349 | lr 2.28e-06 | (115.19 ms | 35557 tok/s)\n",
      "step 4114/5000 | train loss 0.061002 | norm 0.0305 | lr 2.27e-06 | (112.88 ms | 36287 tok/s)\n",
      "step 4115/5000 | train loss 0.061001 | norm 0.0304 | lr 2.27e-06 | (116.65 ms | 35113 tok/s)\n",
      "step 4116/5000 | train loss 0.061001 | norm 0.0310 | lr 2.26e-06 | (113.25 ms | 36166 tok/s)\n",
      "step 4117/5000 | train loss 0.061001 | norm 0.0353 | lr 2.26e-06 | (114.07 ms | 35909 tok/s)\n",
      "step 4118/5000 | train loss 0.061001 | norm 0.0330 | lr 2.25e-06 | (113.79 ms | 35997 tok/s)\n",
      "step 4119/5000 | train loss 0.061000 | norm 0.0356 | lr 2.25e-06 | (115.83 ms | 35363 tok/s)\n",
      "step 4120/5000 | train loss 0.061001 | norm 0.0456 | lr 2.24e-06 | (114.41 ms | 35800 tok/s)\n",
      "step 4121/5000 | train loss 0.061000 | norm 0.0432 | lr 2.24e-06 | (114.64 ms | 35730 tok/s)\n",
      "step 4122/5000 | train loss 0.061000 | norm 0.0369 | lr 2.23e-06 | (113.50 ms | 36087 tok/s)\n",
      "step 4123/5000 | train loss 0.060999 | norm 0.0353 | lr 2.23e-06 | (113.89 ms | 35965 tok/s)\n",
      "step 4124/5000 | train loss 0.060999 | norm 0.0378 | lr 2.22e-06 | (112.22 ms | 36501 tok/s)\n",
      "step 4125/5000 | train loss 0.060999 | norm 0.0343 | lr 2.22e-06 | (113.11 ms | 36212 tok/s)\n",
      "step 4126/5000 | train loss 0.060998 | norm 0.0330 | lr 2.21e-06 | (114.19 ms | 35870 tok/s)\n",
      "step 4127/5000 | train loss 0.060998 | norm 0.0340 | lr 2.21e-06 | (115.02 ms | 35610 tok/s)\n",
      "step 4128/5000 | train loss 0.060998 | norm 0.0308 | lr 2.20e-06 | (114.00 ms | 35930 tok/s)\n",
      "step 4129/5000 | train loss 0.060997 | norm 0.0292 | lr 2.20e-06 | (113.10 ms | 36215 tok/s)\n",
      "step 4130/5000 | train loss 0.060997 | norm 0.0292 | lr 2.19e-06 | (113.48 ms | 36094 tok/s)\n",
      "step 4131/5000 | train loss 0.060997 | norm 0.0304 | lr 2.19e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 4132/5000 | train loss 0.060997 | norm 0.0316 | lr 2.18e-06 | (113.65 ms | 36041 tok/s)\n",
      "step 4133/5000 | train loss 0.060996 | norm 0.0294 | lr 2.18e-06 | (125.54 ms | 32627 tok/s)\n",
      "step 4134/5000 | train loss 0.060996 | norm 0.0306 | lr 2.17e-06 | (113.37 ms | 36130 tok/s)\n",
      "step 4135/5000 | train loss 0.060996 | norm 0.0368 | lr 2.17e-06 | (115.17 ms | 35564 tok/s)\n",
      "step 4136/5000 | train loss 0.060996 | norm 0.0370 | lr 2.16e-06 | (114.07 ms | 35908 tok/s)\n",
      "step 4137/5000 | train loss 0.060996 | norm 0.0390 | lr 2.16e-06 | (113.73 ms | 36014 tok/s)\n",
      "step 4138/5000 | train loss 0.060996 | norm 0.0423 | lr 2.15e-06 | (114.46 ms | 35787 tok/s)\n",
      "step 4139/5000 | train loss 0.060995 | norm 0.0409 | lr 2.15e-06 | (113.42 ms | 36115 tok/s)\n",
      "step 4140/5000 | train loss 0.060995 | norm 0.0372 | lr 2.14e-06 | (112.31 ms | 36469 tok/s)\n",
      "step 4141/5000 | train loss 0.060994 | norm 0.0405 | lr 2.14e-06 | (113.82 ms | 35988 tok/s)\n",
      "step 4142/5000 | train loss 0.060995 | norm 0.0457 | lr 2.14e-06 | (113.87 ms | 35971 tok/s)\n",
      "step 4143/5000 | train loss 0.060994 | norm 0.0386 | lr 2.13e-06 | (115.16 ms | 35568 tok/s)\n",
      "step 4144/5000 | train loss 0.060993 | norm 0.0307 | lr 2.13e-06 | (113.44 ms | 36109 tok/s)\n",
      "step 4145/5000 | train loss 0.060993 | norm 0.0355 | lr 2.12e-06 | (113.52 ms | 36082 tok/s)\n",
      "step 4146/5000 | train loss 0.060993 | norm 0.0318 | lr 2.12e-06 | (112.79 ms | 36315 tok/s)\n",
      "step 4147/5000 | train loss 0.060992 | norm 0.0277 | lr 2.11e-06 | (112.66 ms | 36356 tok/s)\n",
      "step 4148/5000 | train loss 0.060992 | norm 0.0326 | lr 2.11e-06 | (113.04 ms | 36235 tok/s)\n",
      "step 4149/5000 | train loss 0.060992 | norm 0.0304 | lr 2.10e-06 | (113.25 ms | 36167 tok/s)\n",
      "step 4150/5000 | train loss 0.060991 | norm 0.0238 | lr 2.10e-06 | (113.18 ms | 36189 tok/s)\n",
      "step 4151/5000 | train loss 0.060991 | norm 0.0316 | lr 2.09e-06 | (113.95 ms | 35945 tok/s)\n",
      "step 4152/5000 | train loss 0.060991 | norm 0.0313 | lr 2.09e-06 | (112.08 ms | 36546 tok/s)\n",
      "step 4153/5000 | train loss 0.060991 | norm 0.0298 | lr 2.08e-06 | (114.42 ms | 35799 tok/s)\n",
      "step 4154/5000 | train loss 0.060991 | norm 0.0347 | lr 2.08e-06 | (112.23 ms | 36498 tok/s)\n",
      "step 4155/5000 | train loss 0.060990 | norm 0.0345 | lr 2.07e-06 | (113.79 ms | 35997 tok/s)\n",
      "step 4156/5000 | train loss 0.060990 | norm 0.0338 | lr 2.07e-06 | (112.86 ms | 36293 tok/s)\n",
      "step 4157/5000 | train loss 0.060990 | norm 0.0310 | lr 2.06e-06 | (113.66 ms | 36039 tok/s)\n",
      "step 4158/5000 | train loss 0.060989 | norm 0.0260 | lr 2.06e-06 | (113.44 ms | 36107 tok/s)\n",
      "step 4159/5000 | train loss 0.060989 | norm 0.0266 | lr 2.05e-06 | (114.13 ms | 35890 tok/s)\n",
      "step 4160/5000 | train loss 0.060989 | norm 0.0304 | lr 2.05e-06 | (113.86 ms | 35975 tok/s)\n",
      "step 4161/5000 | train loss 0.060988 | norm 0.0294 | lr 2.04e-06 | (115.44 ms | 35482 tok/s)\n",
      "step 4162/5000 | train loss 0.060988 | norm 0.0339 | lr 2.04e-06 | (113.01 ms | 36245 tok/s)\n",
      "step 4163/5000 | train loss 0.060989 | norm 0.0411 | lr 2.03e-06 | (112.85 ms | 36297 tok/s)\n",
      "step 4164/5000 | train loss 0.060988 | norm 0.0403 | lr 2.03e-06 | (112.46 ms | 36421 tok/s)\n",
      "step 4165/5000 | train loss 0.060988 | norm 0.0386 | lr 2.03e-06 | (114.47 ms | 35783 tok/s)\n",
      "step 4166/5000 | train loss 0.060988 | norm 0.0402 | lr 2.02e-06 | (112.37 ms | 36452 tok/s)\n",
      "step 4167/5000 | train loss 0.060987 | norm 0.0388 | lr 2.02e-06 | (113.87 ms | 35972 tok/s)\n",
      "step 4168/5000 | train loss 0.060987 | norm 0.0417 | lr 2.01e-06 | (113.35 ms | 36137 tok/s)\n",
      "step 4169/5000 | train loss 0.060987 | norm 0.0390 | lr 2.01e-06 | (114.56 ms | 35755 tok/s)\n",
      "step 4170/5000 | train loss 0.060986 | norm 0.0341 | lr 2.00e-06 | (113.55 ms | 36071 tok/s)\n",
      "step 4171/5000 | train loss 0.060986 | norm 0.0373 | lr 2.00e-06 | (113.80 ms | 35992 tok/s)\n",
      "step 4172/5000 | train loss 0.060986 | norm 0.0356 | lr 1.99e-06 | (112.74 ms | 36330 tok/s)\n",
      "step 4173/5000 | train loss 0.060985 | norm 0.0272 | lr 1.99e-06 | (112.62 ms | 36371 tok/s)\n",
      "step 4174/5000 | train loss 0.060985 | norm 0.0296 | lr 1.98e-06 | (113.31 ms | 36148 tok/s)\n",
      "step 4175/5000 | train loss 0.060985 | norm 0.0317 | lr 1.98e-06 | (118.26 ms | 34636 tok/s)\n",
      "step 4176/5000 | train loss 0.060984 | norm 0.0251 | lr 1.97e-06 | (114.25 ms | 35851 tok/s)\n",
      "step 4177/5000 | train loss 0.060984 | norm 0.0198 | lr 1.97e-06 | (113.31 ms | 36147 tok/s)\n",
      "step 4178/5000 | train loss 0.060984 | norm 0.0282 | lr 1.96e-06 | (113.73 ms | 36017 tok/s)\n",
      "step 4179/5000 | train loss 0.060983 | norm 0.0248 | lr 1.96e-06 | (113.16 ms | 36197 tok/s)\n",
      "step 4180/5000 | train loss 0.060983 | norm 0.0229 | lr 1.95e-06 | (112.18 ms | 36512 tok/s)\n",
      "step 4181/5000 | train loss 0.060983 | norm 0.0242 | lr 1.95e-06 | (114.22 ms | 35862 tok/s)\n",
      "step 4182/5000 | train loss 0.060983 | norm 0.0260 | lr 1.95e-06 | (116.57 ms | 35138 tok/s)\n",
      "step 4183/5000 | train loss 0.060983 | norm 0.0323 | lr 1.94e-06 | (117.11 ms | 34976 tok/s)\n",
      "step 4184/5000 | train loss 0.060983 | norm 0.0325 | lr 1.94e-06 | (129.66 ms | 31590 tok/s)\n",
      "step 4185/5000 | train loss 0.060983 | norm 0.0383 | lr 1.93e-06 | (114.14 ms | 35886 tok/s)\n",
      "step 4186/5000 | train loss 0.060983 | norm 0.0404 | lr 1.93e-06 | (113.42 ms | 36114 tok/s)\n",
      "step 4187/5000 | train loss 0.060982 | norm 0.0345 | lr 1.92e-06 | (114.52 ms | 35765 tok/s)\n",
      "step 4188/5000 | train loss 0.060982 | norm 0.0325 | lr 1.92e-06 | (114.73 ms | 35702 tok/s)\n",
      "step 4189/5000 | train loss 0.060982 | norm 0.0410 | lr 1.91e-06 | (117.00 ms | 35009 tok/s)\n",
      "step 4190/5000 | train loss 0.060982 | norm 0.0456 | lr 1.91e-06 | (113.66 ms | 36038 tok/s)\n",
      "step 4191/5000 | train loss 0.060981 | norm 0.0392 | lr 1.90e-06 | (113.47 ms | 36096 tok/s)\n",
      "step 4192/5000 | train loss 0.060981 | norm 0.0345 | lr 1.90e-06 | (113.03 ms | 36237 tok/s)\n",
      "step 4193/5000 | train loss 0.060981 | norm 0.0412 | lr 1.89e-06 | (114.70 ms | 35710 tok/s)\n",
      "step 4194/5000 | train loss 0.060980 | norm 0.0361 | lr 1.89e-06 | (115.40 ms | 35493 tok/s)\n",
      "step 4195/5000 | train loss 0.060980 | norm 0.0275 | lr 1.89e-06 | (115.05 ms | 35603 tok/s)\n",
      "step 4196/5000 | train loss 0.060980 | norm 0.0297 | lr 1.88e-06 | (112.95 ms | 36263 tok/s)\n",
      "step 4197/5000 | train loss 0.060979 | norm 0.0298 | lr 1.88e-06 | (115.57 ms | 35443 tok/s)\n",
      "step 4198/5000 | train loss 0.060979 | norm 0.0261 | lr 1.87e-06 | (114.17 ms | 35876 tok/s)\n",
      "step 4199/5000 | train loss 0.060979 | norm 0.0254 | lr 1.87e-06 | (113.51 ms | 36084 tok/s)\n",
      "step 4200/5000 | train loss 0.060978 | norm 0.0254 | lr 1.86e-06 | (112.59 ms | 36380 tok/s)\n",
      "step 4201/5000 | train loss 0.060978 | norm 0.0230 | lr 1.86e-06 | (113.31 ms | 36147 tok/s)\n",
      "step 4202/5000 | train loss 0.060978 | norm 0.0230 | lr 1.85e-06 | (124.51 ms | 32896 tok/s)\n",
      "step 4203/5000 | train loss 0.060977 | norm 0.0209 | lr 1.85e-06 | (115.96 ms | 35322 tok/s)\n",
      "step 4204/5000 | train loss 0.060977 | norm 0.0205 | lr 1.84e-06 | (113.75 ms | 36007 tok/s)\n",
      "step 4205/5000 | train loss 0.060977 | norm 0.0196 | lr 1.84e-06 | (115.40 ms | 35495 tok/s)\n",
      "step 4206/5000 | train loss 0.060977 | norm 0.0208 | lr 1.84e-06 | (113.44 ms | 36108 tok/s)\n",
      "step 4207/5000 | train loss 0.060976 | norm 0.0201 | lr 1.83e-06 | (112.86 ms | 36292 tok/s)\n",
      "step 4208/5000 | train loss 0.060976 | norm 0.0183 | lr 1.83e-06 | (112.89 ms | 36284 tok/s)\n",
      "step 4209/5000 | train loss 0.060976 | norm 0.0247 | lr 1.82e-06 | (114.49 ms | 35775 tok/s)\n",
      "step 4210/5000 | train loss 0.060976 | norm 0.0328 | lr 1.82e-06 | (115.88 ms | 35347 tok/s)\n",
      "step 4211/5000 | train loss 0.060976 | norm 0.0419 | lr 1.81e-06 | (114.62 ms | 35735 tok/s)\n",
      "step 4212/5000 | train loss 0.060977 | norm 0.0473 | lr 1.81e-06 | (113.49 ms | 36091 tok/s)\n",
      "step 4213/5000 | train loss 0.060976 | norm 0.0424 | lr 1.80e-06 | (114.92 ms | 35642 tok/s)\n",
      "step 4214/5000 | train loss 0.060976 | norm 0.0353 | lr 1.80e-06 | (113.62 ms | 36051 tok/s)\n",
      "step 4215/5000 | train loss 0.060976 | norm 0.0418 | lr 1.80e-06 | (115.25 ms | 35541 tok/s)\n",
      "step 4216/5000 | train loss 0.060976 | norm 0.0447 | lr 1.79e-06 | (114.09 ms | 35903 tok/s)\n",
      "step 4217/5000 | train loss 0.060975 | norm 0.0299 | lr 1.79e-06 | (114.87 ms | 35659 tok/s)\n",
      "step 4218/5000 | train loss 0.060974 | norm 0.0301 | lr 1.78e-06 | (115.65 ms | 35418 tok/s)\n",
      "step 4219/5000 | train loss 0.060975 | norm 0.0385 | lr 1.78e-06 | (114.81 ms | 35678 tok/s)\n",
      "step 4220/5000 | train loss 0.060974 | norm 0.0260 | lr 1.77e-06 | (113.11 ms | 36213 tok/s)\n",
      "step 4221/5000 | train loss 0.060973 | norm 0.0274 | lr 1.77e-06 | (113.08 ms | 36224 tok/s)\n",
      "step 4222/5000 | train loss 0.060973 | norm 0.0333 | lr 1.76e-06 | (113.74 ms | 36012 tok/s)\n",
      "step 4223/5000 | train loss 0.060973 | norm 0.0226 | lr 1.76e-06 | (113.67 ms | 36035 tok/s)\n",
      "step 4224/5000 | train loss 0.060973 | norm 0.0235 | lr 1.76e-06 | (112.99 ms | 36252 tok/s)\n",
      "step 4225/5000 | train loss 0.060973 | norm 0.0293 | lr 1.75e-06 | (112.13 ms | 36529 tok/s)\n",
      "step 4226/5000 | train loss 0.060972 | norm 0.0204 | lr 1.75e-06 | (112.61 ms | 36373 tok/s)\n",
      "step 4227/5000 | train loss 0.060972 | norm 0.0217 | lr 1.74e-06 | (113.62 ms | 36049 tok/s)\n",
      "step 4228/5000 | train loss 0.060972 | norm 0.0255 | lr 1.74e-06 | (113.71 ms | 36023 tok/s)\n",
      "step 4229/5000 | train loss 0.060971 | norm 0.0187 | lr 1.73e-06 | (115.46 ms | 35476 tok/s)\n",
      "step 4230/5000 | train loss 0.060971 | norm 0.0225 | lr 1.73e-06 | (128.95 ms | 31765 tok/s)\n",
      "step 4231/5000 | train loss 0.060971 | norm 0.0237 | lr 1.72e-06 | (114.44 ms | 35790 tok/s)\n",
      "step 4232/5000 | train loss 0.060971 | norm 0.0266 | lr 1.72e-06 | (118.35 ms | 34609 tok/s)\n",
      "step 4233/5000 | train loss 0.060971 | norm 0.0292 | lr 1.72e-06 | (114.76 ms | 35692 tok/s)\n",
      "step 4234/5000 | train loss 0.060971 | norm 0.0322 | lr 1.71e-06 | (114.81 ms | 35676 tok/s)\n",
      "step 4235/5000 | train loss 0.060970 | norm 0.0325 | lr 1.71e-06 | (116.09 ms | 35284 tok/s)\n",
      "step 4236/5000 | train loss 0.060970 | norm 0.0252 | lr 1.70e-06 | (112.61 ms | 36374 tok/s)\n",
      "step 4237/5000 | train loss 0.060969 | norm 0.0218 | lr 1.70e-06 | (112.56 ms | 36388 tok/s)\n",
      "step 4238/5000 | train loss 0.060970 | norm 0.0292 | lr 1.69e-06 | (112.20 ms | 36507 tok/s)\n",
      "step 4239/5000 | train loss 0.060970 | norm 0.0356 | lr 1.69e-06 | (113.21 ms | 36180 tok/s)\n",
      "step 4240/5000 | train loss 0.060970 | norm 0.0388 | lr 1.69e-06 | (114.78 ms | 35687 tok/s)\n",
      "step 4241/5000 | train loss 0.060969 | norm 0.0333 | lr 1.68e-06 | (115.93 ms | 35333 tok/s)\n",
      "step 4242/5000 | train loss 0.060969 | norm 0.0274 | lr 1.68e-06 | (114.28 ms | 35842 tok/s)\n",
      "step 4243/5000 | train loss 0.060969 | norm 0.0325 | lr 1.67e-06 | (114.17 ms | 35877 tok/s)\n",
      "step 4244/5000 | train loss 0.060968 | norm 0.0310 | lr 1.67e-06 | (114.30 ms | 35835 tok/s)\n",
      "step 4245/5000 | train loss 0.060968 | norm 0.0226 | lr 1.66e-06 | (114.39 ms | 35806 tok/s)\n",
      "step 4246/5000 | train loss 0.060968 | norm 0.0235 | lr 1.66e-06 | (112.50 ms | 36408 tok/s)\n",
      "step 4247/5000 | train loss 0.060968 | norm 0.0300 | lr 1.65e-06 | (113.54 ms | 36075 tok/s)\n",
      "step 4248/5000 | train loss 0.060967 | norm 0.0234 | lr 1.65e-06 | (113.24 ms | 36170 tok/s)\n",
      "step 4249/5000 | train loss 0.060967 | norm 0.0191 | lr 1.65e-06 | (114.03 ms | 35921 tok/s)\n",
      "step 4250/5000 | train loss 0.060967 | norm 0.0213 | lr 1.64e-06 | (114.92 ms | 35641 tok/s)\n",
      "step 4251/5000 | train loss 0.060966 | norm 0.0236 | lr 1.64e-06 | (116.37 ms | 35199 tok/s)\n",
      "step 4252/5000 | train loss 0.060966 | norm 0.0212 | lr 1.63e-06 | (114.61 ms | 35739 tok/s)\n",
      "step 4253/5000 | train loss 0.060966 | norm 0.0217 | lr 1.63e-06 | (113.73 ms | 36016 tok/s)\n",
      "step 4254/5000 | train loss 0.060966 | norm 0.0258 | lr 1.62e-06 | (112.08 ms | 36546 tok/s)\n",
      "step 4255/5000 | train loss 0.060966 | norm 0.0297 | lr 1.62e-06 | (112.63 ms | 36365 tok/s)\n",
      "step 4256/5000 | train loss 0.060966 | norm 0.0335 | lr 1.62e-06 | (113.76 ms | 36005 tok/s)\n",
      "step 4257/5000 | train loss 0.060966 | norm 0.0341 | lr 1.61e-06 | (113.96 ms | 35942 tok/s)\n",
      "step 4258/5000 | train loss 0.060965 | norm 0.0298 | lr 1.61e-06 | (114.06 ms | 35910 tok/s)\n",
      "step 4259/5000 | train loss 0.060965 | norm 0.0277 | lr 1.60e-06 | (115.17 ms | 35564 tok/s)\n",
      "step 4260/5000 | train loss 0.060965 | norm 0.0262 | lr 1.60e-06 | (113.26 ms | 36165 tok/s)\n",
      "step 4261/5000 | train loss 0.060965 | norm 0.0280 | lr 1.60e-06 | (116.96 ms | 35021 tok/s)\n",
      "step 4262/5000 | train loss 0.060964 | norm 0.0291 | lr 1.59e-06 | (114.30 ms | 35835 tok/s)\n",
      "step 4263/5000 | train loss 0.060964 | norm 0.0234 | lr 1.59e-06 | (129.86 ms | 31543 tok/s)\n",
      "step 4264/5000 | train loss 0.060964 | norm 0.0229 | lr 1.58e-06 | (114.32 ms | 35829 tok/s)\n",
      "step 4265/5000 | train loss 0.060964 | norm 0.0261 | lr 1.58e-06 | (117.39 ms | 34891 tok/s)\n",
      "step 4266/5000 | train loss 0.060963 | norm 0.0270 | lr 1.57e-06 | (114.15 ms | 35882 tok/s)\n",
      "step 4267/5000 | train loss 0.060963 | norm 0.0253 | lr 1.57e-06 | (115.54 ms | 35452 tok/s)\n",
      "step 4268/5000 | train loss 0.060963 | norm 0.0232 | lr 1.57e-06 | (112.82 ms | 36304 tok/s)\n",
      "step 4269/5000 | train loss 0.060963 | norm 0.0249 | lr 1.56e-06 | (117.34 ms | 34906 tok/s)\n",
      "step 4270/5000 | train loss 0.060963 | norm 0.0261 | lr 1.56e-06 | (116.40 ms | 35190 tok/s)\n",
      "step 4271/5000 | train loss 0.060962 | norm 0.0245 | lr 1.55e-06 | (116.27 ms | 35230 tok/s)\n",
      "step 4272/5000 | train loss 0.060962 | norm 0.0238 | lr 1.55e-06 | (115.40 ms | 35494 tok/s)\n",
      "step 4273/5000 | train loss 0.060962 | norm 0.0241 | lr 1.54e-06 | (115.43 ms | 35485 tok/s)\n",
      "step 4274/5000 | train loss 0.060962 | norm 0.0230 | lr 1.54e-06 | (112.99 ms | 36252 tok/s)\n",
      "step 4275/5000 | train loss 0.060961 | norm 0.0245 | lr 1.54e-06 | (114.05 ms | 35914 tok/s)\n",
      "step 4276/5000 | train loss 0.060961 | norm 0.0244 | lr 1.53e-06 | (114.31 ms | 35832 tok/s)\n",
      "step 4277/5000 | train loss 0.060961 | norm 0.0249 | lr 1.53e-06 | (114.16 ms | 35880 tok/s)\n",
      "step 4278/5000 | train loss 0.060961 | norm 0.0268 | lr 1.52e-06 | (115.26 ms | 35538 tok/s)\n",
      "step 4279/5000 | train loss 0.060961 | norm 0.0282 | lr 1.52e-06 | (117.35 ms | 34903 tok/s)\n",
      "step 4280/5000 | train loss 0.060961 | norm 0.0280 | lr 1.52e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 4281/5000 | train loss 0.060960 | norm 0.0252 | lr 1.51e-06 | (116.36 ms | 35202 tok/s)\n",
      "step 4282/5000 | train loss 0.060960 | norm 0.0253 | lr 1.51e-06 | (114.37 ms | 35815 tok/s)\n",
      "step 4283/5000 | train loss 0.060960 | norm 0.0230 | lr 1.50e-06 | (114.96 ms | 35631 tok/s)\n",
      "step 4284/5000 | train loss 0.060960 | norm 0.0246 | lr 1.50e-06 | (113.90 ms | 35961 tok/s)\n",
      "step 4285/5000 | train loss 0.060959 | norm 0.0246 | lr 1.50e-06 | (115.44 ms | 35482 tok/s)\n",
      "step 4286/5000 | train loss 0.060959 | norm 0.0202 | lr 1.49e-06 | (114.75 ms | 35693 tok/s)\n",
      "step 4287/5000 | train loss 0.060959 | norm 0.0181 | lr 1.49e-06 | (115.98 ms | 35316 tok/s)\n",
      "step 4288/5000 | train loss 0.060959 | norm 0.0196 | lr 1.48e-06 | (115.52 ms | 35458 tok/s)\n",
      "step 4289/5000 | train loss 0.060958 | norm 0.0197 | lr 1.48e-06 | (113.57 ms | 36067 tok/s)\n",
      "step 4290/5000 | train loss 0.060958 | norm 0.0206 | lr 1.47e-06 | (112.97 ms | 36259 tok/s)\n",
      "step 4291/5000 | train loss 0.060958 | norm 0.0217 | lr 1.47e-06 | (112.87 ms | 36291 tok/s)\n",
      "step 4292/5000 | train loss 0.060958 | norm 0.0257 | lr 1.47e-06 | (114.51 ms | 35770 tok/s)\n",
      "step 4293/5000 | train loss 0.060958 | norm 0.0273 | lr 1.46e-06 | (113.46 ms | 36099 tok/s)\n",
      "step 4294/5000 | train loss 0.060958 | norm 0.0285 | lr 1.46e-06 | (116.51 ms | 35156 tok/s)\n",
      "step 4295/5000 | train loss 0.060958 | norm 0.0275 | lr 1.45e-06 | (116.41 ms | 35187 tok/s)\n",
      "step 4296/5000 | train loss 0.060957 | norm 0.0230 | lr 1.45e-06 | (115.42 ms | 35489 tok/s)\n",
      "step 4297/5000 | train loss 0.060957 | norm 0.0216 | lr 1.45e-06 | (114.02 ms | 35925 tok/s)\n",
      "step 4298/5000 | train loss 0.060957 | norm 0.0240 | lr 1.44e-06 | (112.66 ms | 36357 tok/s)\n",
      "step 4299/5000 | train loss 0.060957 | norm 0.0270 | lr 1.44e-06 | (114.05 ms | 35913 tok/s)\n",
      "step 4300/5000 | train loss 0.060956 | norm 0.0238 | lr 1.43e-06 | (115.03 ms | 35608 tok/s)\n",
      "step 4301/5000 | train loss 0.060956 | norm 0.0220 | lr 1.43e-06 | (115.21 ms | 35552 tok/s)\n",
      "step 4302/5000 | train loss 0.060956 | norm 0.0234 | lr 1.43e-06 | (114.40 ms | 35804 tok/s)\n",
      "step 4303/5000 | train loss 0.060956 | norm 0.0247 | lr 1.42e-06 | (113.90 ms | 35960 tok/s)\n",
      "step 4304/5000 | train loss 0.060956 | norm 0.0255 | lr 1.42e-06 | (112.38 ms | 36448 tok/s)\n",
      "step 4305/5000 | train loss 0.060955 | norm 0.0221 | lr 1.41e-06 | (113.12 ms | 36210 tok/s)\n",
      "step 4306/5000 | train loss 0.060955 | norm 0.0218 | lr 1.41e-06 | (113.23 ms | 36174 tok/s)\n",
      "step 4307/5000 | train loss 0.060955 | norm 0.0242 | lr 1.41e-06 | (115.67 ms | 35410 tok/s)\n",
      "step 4308/5000 | train loss 0.060955 | norm 0.0201 | lr 1.40e-06 | (113.49 ms | 36091 tok/s)\n",
      "step 4309/5000 | train loss 0.060955 | norm 0.0231 | lr 1.40e-06 | (115.40 ms | 35495 tok/s)\n",
      "step 4310/5000 | train loss 0.060955 | norm 0.0264 | lr 1.39e-06 | (113.77 ms | 36001 tok/s)\n",
      "step 4311/5000 | train loss 0.060954 | norm 0.0236 | lr 1.39e-06 | (112.27 ms | 36485 tok/s)\n",
      "step 4312/5000 | train loss 0.060954 | norm 0.0207 | lr 1.39e-06 | (114.04 ms | 35918 tok/s)\n",
      "step 4313/5000 | train loss 0.060954 | norm 0.0219 | lr 1.38e-06 | (115.36 ms | 35506 tok/s)\n",
      "step 4314/5000 | train loss 0.060954 | norm 0.0221 | lr 1.38e-06 | (115.12 ms | 35581 tok/s)\n",
      "step 4315/5000 | train loss 0.060954 | norm 0.0234 | lr 1.37e-06 | (115.38 ms | 35501 tok/s)\n",
      "step 4316/5000 | train loss 0.060954 | norm 0.0258 | lr 1.37e-06 | (113.32 ms | 36144 tok/s)\n",
      "step 4317/5000 | train loss 0.060953 | norm 0.0237 | lr 1.37e-06 | (114.80 ms | 35680 tok/s)\n",
      "step 4318/5000 | train loss 0.060953 | norm 0.0224 | lr 1.36e-06 | (114.85 ms | 35663 tok/s)\n",
      "step 4319/5000 | train loss 0.060953 | norm 0.0214 | lr 1.36e-06 | (114.07 ms | 35908 tok/s)\n",
      "step 4320/5000 | train loss 0.060953 | norm 0.0235 | lr 1.36e-06 | (115.75 ms | 35385 tok/s)\n",
      "step 4321/5000 | train loss 0.060953 | norm 0.0233 | lr 1.35e-06 | (114.27 ms | 35844 tok/s)\n",
      "step 4322/5000 | train loss 0.060952 | norm 0.0211 | lr 1.35e-06 | (114.05 ms | 35914 tok/s)\n",
      "step 4323/5000 | train loss 0.060952 | norm 0.0229 | lr 1.34e-06 | (113.58 ms | 36061 tok/s)\n",
      "step 4324/5000 | train loss 0.060952 | norm 0.0222 | lr 1.34e-06 | (112.19 ms | 36511 tok/s)\n",
      "step 4325/5000 | train loss 0.060952 | norm 0.0175 | lr 1.34e-06 | (111.46 ms | 36749 tok/s)\n",
      "step 4326/5000 | train loss 0.060951 | norm 0.0162 | lr 1.33e-06 | (113.59 ms | 36060 tok/s)\n",
      "step 4327/5000 | train loss 0.060951 | norm 0.0182 | lr 1.33e-06 | (113.05 ms | 36231 tok/s)\n",
      "step 4328/5000 | train loss 0.060951 | norm 0.0167 | lr 1.32e-06 | (114.16 ms | 35880 tok/s)\n",
      "step 4329/5000 | train loss 0.060951 | norm 0.0165 | lr 1.32e-06 | (115.08 ms | 35592 tok/s)\n",
      "step 4330/5000 | train loss 0.060951 | norm 0.0171 | lr 1.32e-06 | (113.34 ms | 36138 tok/s)\n",
      "step 4331/5000 | train loss 0.060950 | norm 0.0170 | lr 1.31e-06 | (115.84 ms | 35359 tok/s)\n",
      "step 4332/5000 | train loss 0.060950 | norm 0.0182 | lr 1.31e-06 | (113.52 ms | 36080 tok/s)\n",
      "step 4333/5000 | train loss 0.060950 | norm 0.0201 | lr 1.30e-06 | (115.57 ms | 35443 tok/s)\n",
      "step 4334/5000 | train loss 0.060950 | norm 0.0256 | lr 1.30e-06 | (113.31 ms | 36150 tok/s)\n",
      "step 4335/5000 | train loss 0.060950 | norm 0.0292 | lr 1.30e-06 | (113.51 ms | 36084 tok/s)\n",
      "step 4336/5000 | train loss 0.060950 | norm 0.0301 | lr 1.29e-06 | (112.57 ms | 36387 tok/s)\n",
      "step 4337/5000 | train loss 0.060950 | norm 0.0269 | lr 1.29e-06 | (131.88 ms | 31059 tok/s)\n",
      "step 4338/5000 | train loss 0.060949 | norm 0.0212 | lr 1.29e-06 | (114.06 ms | 35910 tok/s)\n",
      "step 4339/5000 | train loss 0.060949 | norm 0.0237 | lr 1.28e-06 | (114.00 ms | 35931 tok/s)\n",
      "step 4340/5000 | train loss 0.060949 | norm 0.0252 | lr 1.28e-06 | (112.92 ms | 36272 tok/s)\n",
      "step 4341/5000 | train loss 0.060949 | norm 0.0201 | lr 1.27e-06 | (114.39 ms | 35806 tok/s)\n",
      "step 4342/5000 | train loss 0.060949 | norm 0.0175 | lr 1.27e-06 | (112.68 ms | 36350 tok/s)\n",
      "step 4343/5000 | train loss 0.060948 | norm 0.0208 | lr 1.27e-06 | (112.52 ms | 36403 tok/s)\n",
      "step 4344/5000 | train loss 0.060948 | norm 0.0198 | lr 1.26e-06 | (112.17 ms | 36517 tok/s)\n",
      "step 4345/5000 | train loss 0.060948 | norm 0.0164 | lr 1.26e-06 | (114.56 ms | 35754 tok/s)\n",
      "step 4346/5000 | train loss 0.060948 | norm 0.0173 | lr 1.26e-06 | (112.70 ms | 36345 tok/s)\n",
      "step 4347/5000 | train loss 0.060948 | norm 0.0194 | lr 1.25e-06 | (112.90 ms | 36280 tok/s)\n",
      "step 4348/5000 | train loss 0.060948 | norm 0.0187 | lr 1.25e-06 | (113.09 ms | 36219 tok/s)\n",
      "step 4349/5000 | train loss 0.060947 | norm 0.0209 | lr 1.24e-06 | (113.49 ms | 36093 tok/s)\n",
      "step 4350/5000 | train loss 0.060947 | norm 0.0233 | lr 1.24e-06 | (112.45 ms | 36425 tok/s)\n",
      "step 4351/5000 | train loss 0.060947 | norm 0.0272 | lr 1.24e-06 | (112.84 ms | 36300 tok/s)\n",
      "step 4352/5000 | train loss 0.060947 | norm 0.0261 | lr 1.23e-06 | (113.00 ms | 36249 tok/s)\n",
      "step 4353/5000 | train loss 0.060947 | norm 0.0224 | lr 1.23e-06 | (114.44 ms | 35793 tok/s)\n",
      "step 4354/5000 | train loss 0.060947 | norm 0.0239 | lr 1.23e-06 | (114.03 ms | 35921 tok/s)\n",
      "step 4355/5000 | train loss 0.060947 | norm 0.0244 | lr 1.22e-06 | (114.14 ms | 35885 tok/s)\n",
      "step 4356/5000 | train loss 0.060946 | norm 0.0226 | lr 1.22e-06 | (113.74 ms | 36013 tok/s)\n",
      "step 4357/5000 | train loss 0.060946 | norm 0.0215 | lr 1.21e-06 | (112.33 ms | 36464 tok/s)\n",
      "step 4358/5000 | train loss 0.060946 | norm 0.0173 | lr 1.21e-06 | (112.52 ms | 36402 tok/s)\n",
      "step 4359/5000 | train loss 0.060946 | norm 0.0196 | lr 1.21e-06 | (113.56 ms | 36067 tok/s)\n",
      "step 4360/5000 | train loss 0.060946 | norm 0.0208 | lr 1.20e-06 | (113.51 ms | 36085 tok/s)\n",
      "step 4361/5000 | train loss 0.060945 | norm 0.0161 | lr 1.20e-06 | (114.81 ms | 35675 tok/s)\n",
      "step 4362/5000 | train loss 0.060945 | norm 0.0149 | lr 1.20e-06 | (113.23 ms | 36175 tok/s)\n",
      "step 4363/5000 | train loss 0.060945 | norm 0.0138 | lr 1.19e-06 | (113.71 ms | 36021 tok/s)\n",
      "step 4364/5000 | train loss 0.060945 | norm 0.0163 | lr 1.19e-06 | (113.98 ms | 35937 tok/s)\n",
      "step 4365/5000 | train loss 0.060945 | norm 0.0178 | lr 1.18e-06 | (113.99 ms | 35934 tok/s)\n",
      "step 4366/5000 | train loss 0.060944 | norm 0.0142 | lr 1.18e-06 | (112.43 ms | 36433 tok/s)\n",
      "step 4367/5000 | train loss 0.060944 | norm 0.0123 | lr 1.18e-06 | (113.43 ms | 36110 tok/s)\n",
      "step 4368/5000 | train loss 0.060944 | norm 0.0158 | lr 1.17e-06 | (113.55 ms | 36072 tok/s)\n",
      "step 4369/5000 | train loss 0.060944 | norm 0.0182 | lr 1.17e-06 | (115.11 ms | 35582 tok/s)\n",
      "step 4370/5000 | train loss 0.060944 | norm 0.0182 | lr 1.17e-06 | (114.33 ms | 35826 tok/s)\n",
      "step 4371/5000 | train loss 0.060944 | norm 0.0215 | lr 1.16e-06 | (114.76 ms | 35691 tok/s)\n",
      "step 4372/5000 | train loss 0.060944 | norm 0.0232 | lr 1.16e-06 | (112.59 ms | 36380 tok/s)\n",
      "step 4373/5000 | train loss 0.060944 | norm 0.0226 | lr 1.16e-06 | (113.15 ms | 36200 tok/s)\n",
      "step 4374/5000 | train loss 0.060943 | norm 0.0215 | lr 1.15e-06 | (112.61 ms | 36373 tok/s)\n",
      "step 4375/5000 | train loss 0.060943 | norm 0.0212 | lr 1.15e-06 | (114.77 ms | 35690 tok/s)\n",
      "step 4376/5000 | train loss 0.060943 | norm 0.0239 | lr 1.14e-06 | (114.21 ms | 35865 tok/s)\n",
      "step 4377/5000 | train loss 0.060943 | norm 0.0243 | lr 1.14e-06 | (116.69 ms | 35102 tok/s)\n",
      "step 4378/5000 | train loss 0.060943 | norm 0.0232 | lr 1.14e-06 | (113.86 ms | 35973 tok/s)\n",
      "step 4379/5000 | train loss 0.060943 | norm 0.0195 | lr 1.13e-06 | (114.84 ms | 35666 tok/s)\n",
      "step 4380/5000 | train loss 0.060942 | norm 0.0180 | lr 1.13e-06 | (113.32 ms | 36145 tok/s)\n",
      "step 4381/5000 | train loss 0.060942 | norm 0.0194 | lr 1.13e-06 | (113.19 ms | 36187 tok/s)\n",
      "step 4382/5000 | train loss 0.060942 | norm 0.0189 | lr 1.12e-06 | (112.18 ms | 36512 tok/s)\n",
      "step 4383/5000 | train loss 0.060942 | norm 0.0153 | lr 1.12e-06 | (112.09 ms | 36541 tok/s)\n",
      "step 4384/5000 | train loss 0.060942 | norm 0.0164 | lr 1.12e-06 | (113.81 ms | 35990 tok/s)\n",
      "step 4385/5000 | train loss 0.060942 | norm 0.0173 | lr 1.11e-06 | (113.60 ms | 36056 tok/s)\n",
      "step 4386/5000 | train loss 0.060941 | norm 0.0159 | lr 1.11e-06 | (113.38 ms | 36127 tok/s)\n",
      "step 4387/5000 | train loss 0.060941 | norm 0.0157 | lr 1.11e-06 | (114.28 ms | 35843 tok/s)\n",
      "step 4388/5000 | train loss 0.060941 | norm 0.0157 | lr 1.10e-06 | (112.44 ms | 36429 tok/s)\n",
      "step 4389/5000 | train loss 0.060941 | norm 0.0195 | lr 1.10e-06 | (113.27 ms | 36162 tok/s)\n",
      "step 4390/5000 | train loss 0.060941 | norm 0.0203 | lr 1.09e-06 | (113.47 ms | 36099 tok/s)\n",
      "step 4391/5000 | train loss 0.060941 | norm 0.0197 | lr 1.09e-06 | (112.99 ms | 36250 tok/s)\n",
      "step 4392/5000 | train loss 0.060941 | norm 0.0209 | lr 1.09e-06 | (113.02 ms | 36240 tok/s)\n",
      "step 4393/5000 | train loss 0.060940 | norm 0.0188 | lr 1.08e-06 | (113.18 ms | 36191 tok/s)\n",
      "step 4394/5000 | train loss 0.060940 | norm 0.0153 | lr 1.08e-06 | (113.26 ms | 36164 tok/s)\n",
      "step 4395/5000 | train loss 0.060940 | norm 0.0138 | lr 1.08e-06 | (114.12 ms | 35893 tok/s)\n",
      "step 4396/5000 | train loss 0.060940 | norm 0.0182 | lr 1.07e-06 | (113.55 ms | 36073 tok/s)\n",
      "step 4397/5000 | train loss 0.060940 | norm 0.0216 | lr 1.07e-06 | (113.76 ms | 36005 tok/s)\n",
      "step 4398/5000 | train loss 0.060940 | norm 0.0199 | lr 1.07e-06 | (112.16 ms | 36520 tok/s)\n",
      "step 4399/5000 | train loss 0.060939 | norm 0.0157 | lr 1.06e-06 | (112.32 ms | 36468 tok/s)\n",
      "step 4400/5000 | train loss 0.060939 | norm 0.0160 | lr 1.06e-06 | (111.84 ms | 36622 tok/s)\n",
      "step 4401/5000 | train loss 0.060939 | norm 0.0170 | lr 1.06e-06 | (113.41 ms | 36117 tok/s)\n",
      "step 4402/5000 | train loss 0.060939 | norm 0.0173 | lr 1.05e-06 | (114.65 ms | 35725 tok/s)\n",
      "step 4403/5000 | train loss 0.060939 | norm 0.0168 | lr 1.05e-06 | (115.89 ms | 35343 tok/s)\n",
      "step 4404/5000 | train loss 0.060939 | norm 0.0137 | lr 1.05e-06 | (114.41 ms | 35801 tok/s)\n",
      "step 4405/5000 | train loss 0.060938 | norm 0.0140 | lr 1.04e-06 | (114.27 ms | 35846 tok/s)\n",
      "step 4406/5000 | train loss 0.060938 | norm 0.0171 | lr 1.04e-06 | (113.35 ms | 36136 tok/s)\n",
      "step 4407/5000 | train loss 0.060938 | norm 0.0180 | lr 1.04e-06 | (113.20 ms | 36182 tok/s)\n",
      "step 4408/5000 | train loss 0.060938 | norm 0.0160 | lr 1.03e-06 | (113.61 ms | 36054 tok/s)\n",
      "step 4409/5000 | train loss 0.060938 | norm 0.0144 | lr 1.03e-06 | (114.40 ms | 35804 tok/s)\n",
      "step 4410/5000 | train loss 0.060938 | norm 0.0154 | lr 1.03e-06 | (113.43 ms | 36111 tok/s)\n",
      "step 4411/5000 | train loss 0.060938 | norm 0.0169 | lr 1.02e-06 | (112.82 ms | 36307 tok/s)\n",
      "step 4412/5000 | train loss 0.060938 | norm 0.0150 | lr 1.02e-06 | (113.86 ms | 35974 tok/s)\n",
      "step 4413/5000 | train loss 0.060937 | norm 0.0152 | lr 1.02e-06 | (113.16 ms | 36196 tok/s)\n",
      "step 4414/5000 | train loss 0.060937 | norm 0.0180 | lr 1.01e-06 | (114.40 ms | 35805 tok/s)\n",
      "step 4415/5000 | train loss 0.060937 | norm 0.0199 | lr 1.01e-06 | (114.98 ms | 35625 tok/s)\n",
      "step 4416/5000 | train loss 0.060937 | norm 0.0205 | lr 1.00e-06 | (113.92 ms | 35956 tok/s)\n",
      "step 4417/5000 | train loss 0.060937 | norm 0.0184 | lr 1.00e-06 | (114.30 ms | 35836 tok/s)\n",
      "step 4418/5000 | train loss 0.060937 | norm 0.0181 | lr 9.98e-07 | (114.05 ms | 35915 tok/s)\n",
      "step 4419/5000 | train loss 0.060937 | norm 0.0191 | lr 9.95e-07 | (115.23 ms | 35547 tok/s)\n",
      "step 4420/5000 | train loss 0.060936 | norm 0.0165 | lr 9.91e-07 | (114.03 ms | 35920 tok/s)\n",
      "step 4421/5000 | train loss 0.060936 | norm 0.0146 | lr 9.88e-07 | (113.63 ms | 36046 tok/s)\n",
      "step 4422/5000 | train loss 0.060936 | norm 0.0160 | lr 9.85e-07 | (113.86 ms | 35974 tok/s)\n",
      "step 4423/5000 | train loss 0.060936 | norm 0.0165 | lr 9.81e-07 | (114.50 ms | 35772 tok/s)\n",
      "step 4424/5000 | train loss 0.060936 | norm 0.0156 | lr 9.78e-07 | (114.22 ms | 35860 tok/s)\n",
      "step 4425/5000 | train loss 0.060936 | norm 0.0166 | lr 9.75e-07 | (114.26 ms | 35847 tok/s)\n",
      "step 4426/5000 | train loss 0.060936 | norm 0.0166 | lr 9.71e-07 | (113.76 ms | 36006 tok/s)\n",
      "step 4427/5000 | train loss 0.060935 | norm 0.0166 | lr 9.68e-07 | (115.32 ms | 35518 tok/s)\n",
      "step 4428/5000 | train loss 0.060935 | norm 0.0170 | lr 9.65e-07 | (112.38 ms | 36447 tok/s)\n",
      "step 4429/5000 | train loss 0.060935 | norm 0.0142 | lr 9.61e-07 | (113.40 ms | 36120 tok/s)\n",
      "step 4430/5000 | train loss 0.060935 | norm 0.0134 | lr 9.58e-07 | (112.97 ms | 36258 tok/s)\n",
      "step 4431/5000 | train loss 0.060935 | norm 0.0126 | lr 9.55e-07 | (113.81 ms | 35989 tok/s)\n",
      "step 4432/5000 | train loss 0.060935 | norm 0.0139 | lr 9.51e-07 | (113.13 ms | 36206 tok/s)\n",
      "step 4433/5000 | train loss 0.060935 | norm 0.0148 | lr 9.48e-07 | (114.04 ms | 35916 tok/s)\n",
      "step 4434/5000 | train loss 0.060935 | norm 0.0147 | lr 9.45e-07 | (113.81 ms | 35989 tok/s)\n",
      "step 4435/5000 | train loss 0.060934 | norm 0.0156 | lr 9.41e-07 | (114.18 ms | 35873 tok/s)\n",
      "step 4436/5000 | train loss 0.060934 | norm 0.0159 | lr 9.38e-07 | (112.84 ms | 36300 tok/s)\n",
      "step 4437/5000 | train loss 0.060934 | norm 0.0134 | lr 9.35e-07 | (112.95 ms | 36264 tok/s)\n",
      "step 4438/5000 | train loss 0.060934 | norm 0.0136 | lr 9.32e-07 | (112.33 ms | 36464 tok/s)\n",
      "step 4439/5000 | train loss 0.060934 | norm 0.0159 | lr 9.28e-07 | (115.35 ms | 35511 tok/s)\n",
      "step 4440/5000 | train loss 0.060934 | norm 0.0160 | lr 9.25e-07 | (112.37 ms | 36452 tok/s)\n",
      "step 4441/5000 | train loss 0.060934 | norm 0.0155 | lr 9.22e-07 | (114.20 ms | 35866 tok/s)\n",
      "step 4442/5000 | train loss 0.060933 | norm 0.0159 | lr 9.19e-07 | (113.59 ms | 36058 tok/s)\n",
      "step 4443/5000 | train loss 0.060933 | norm 0.0167 | lr 9.15e-07 | (113.53 ms | 36077 tok/s)\n",
      "step 4444/5000 | train loss 0.060933 | norm 0.0157 | lr 9.12e-07 | (112.22 ms | 36498 tok/s)\n",
      "step 4445/5000 | train loss 0.060933 | norm 0.0150 | lr 9.09e-07 | (113.11 ms | 36213 tok/s)\n",
      "step 4446/5000 | train loss 0.060933 | norm 0.0152 | lr 9.06e-07 | (113.37 ms | 36128 tok/s)\n",
      "step 4447/5000 | train loss 0.060933 | norm 0.0150 | lr 9.03e-07 | (112.75 ms | 36329 tok/s)\n",
      "step 4448/5000 | train loss 0.060933 | norm 0.0155 | lr 8.99e-07 | (113.42 ms | 36113 tok/s)\n",
      "step 4449/5000 | train loss 0.060933 | norm 0.0162 | lr 8.96e-07 | (112.72 ms | 36337 tok/s)\n",
      "step 4450/5000 | train loss 0.060932 | norm 0.0160 | lr 8.93e-07 | (114.15 ms | 35884 tok/s)\n",
      "step 4451/5000 | train loss 0.060932 | norm 0.0153 | lr 8.90e-07 | (112.14 ms | 36526 tok/s)\n",
      "step 4452/5000 | train loss 0.060932 | norm 0.0164 | lr 8.87e-07 | (115.00 ms | 35617 tok/s)\n",
      "step 4453/5000 | train loss 0.060932 | norm 0.0161 | lr 8.83e-07 | (114.14 ms | 35887 tok/s)\n",
      "step 4454/5000 | train loss 0.060932 | norm 0.0144 | lr 8.80e-07 | (112.35 ms | 36456 tok/s)\n",
      "step 4455/5000 | train loss 0.060932 | norm 0.0138 | lr 8.77e-07 | (112.41 ms | 36439 tok/s)\n",
      "step 4456/5000 | train loss 0.060932 | norm 0.0144 | lr 8.74e-07 | (113.90 ms | 35960 tok/s)\n",
      "step 4457/5000 | train loss 0.060932 | norm 0.0135 | lr 8.71e-07 | (113.27 ms | 36163 tok/s)\n",
      "step 4458/5000 | train loss 0.060931 | norm 0.0120 | lr 8.67e-07 | (114.42 ms | 35799 tok/s)\n",
      "step 4459/5000 | train loss 0.060931 | norm 0.0143 | lr 8.64e-07 | (115.61 ms | 35431 tok/s)\n",
      "step 4460/5000 | train loss 0.060931 | norm 0.0143 | lr 8.61e-07 | (114.24 ms | 35854 tok/s)\n",
      "step 4461/5000 | train loss 0.060931 | norm 0.0126 | lr 8.58e-07 | (112.10 ms | 36540 tok/s)\n",
      "step 4462/5000 | train loss 0.060931 | norm 0.0122 | lr 8.55e-07 | (111.88 ms | 36612 tok/s)\n",
      "step 4463/5000 | train loss 0.060931 | norm 0.0148 | lr 8.52e-07 | (113.08 ms | 36224 tok/s)\n",
      "step 4464/5000 | train loss 0.060931 | norm 0.0152 | lr 8.49e-07 | (114.69 ms | 35713 tok/s)\n",
      "step 4465/5000 | train loss 0.060931 | norm 0.0143 | lr 8.46e-07 | (114.60 ms | 35742 tok/s)\n",
      "step 4466/5000 | train loss 0.060930 | norm 0.0127 | lr 8.42e-07 | (113.18 ms | 36191 tok/s)\n",
      "step 4467/5000 | train loss 0.060930 | norm 0.0114 | lr 8.39e-07 | (113.91 ms | 35959 tok/s)\n",
      "step 4468/5000 | train loss 0.060930 | norm 0.0125 | lr 8.36e-07 | (114.33 ms | 35827 tok/s)\n",
      "step 4469/5000 | train loss 0.060930 | norm 0.0112 | lr 8.33e-07 | (113.86 ms | 35973 tok/s)\n",
      "step 4470/5000 | train loss 0.060930 | norm 0.0111 | lr 8.30e-07 | (112.06 ms | 36552 tok/s)\n",
      "step 4471/5000 | train loss 0.060930 | norm 0.0134 | lr 8.27e-07 | (114.05 ms | 35915 tok/s)\n",
      "step 4472/5000 | train loss 0.060930 | norm 0.0131 | lr 8.24e-07 | (113.60 ms | 36057 tok/s)\n",
      "step 4473/5000 | train loss 0.060930 | norm 0.0139 | lr 8.21e-07 | (115.17 ms | 35565 tok/s)\n",
      "step 4474/5000 | train loss 0.060930 | norm 0.0161 | lr 8.18e-07 | (116.04 ms | 35299 tok/s)\n",
      "step 4475/5000 | train loss 0.060930 | norm 0.0172 | lr 8.15e-07 | (116.25 ms | 35236 tok/s)\n",
      "step 4476/5000 | train loss 0.060929 | norm 0.0171 | lr 8.12e-07 | (113.17 ms | 36192 tok/s)\n",
      "step 4477/5000 | train loss 0.060929 | norm 0.0174 | lr 8.09e-07 | (111.99 ms | 36573 tok/s)\n",
      "step 4478/5000 | train loss 0.060929 | norm 0.0156 | lr 8.06e-07 | (112.48 ms | 36417 tok/s)\n",
      "step 4479/5000 | train loss 0.060929 | norm 0.0145 | lr 8.03e-07 | (113.80 ms | 35994 tok/s)\n",
      "step 4480/5000 | train loss 0.060929 | norm 0.0154 | lr 7.99e-07 | (114.03 ms | 35919 tok/s)\n",
      "step 4481/5000 | train loss 0.060929 | norm 0.0143 | lr 7.96e-07 | (115.47 ms | 35472 tok/s)\n",
      "step 4482/5000 | train loss 0.060929 | norm 0.0127 | lr 7.93e-07 | (112.55 ms | 36392 tok/s)\n",
      "step 4483/5000 | train loss 0.060929 | norm 0.0136 | lr 7.90e-07 | (116.05 ms | 35294 tok/s)\n",
      "step 4484/5000 | train loss 0.060928 | norm 0.0127 | lr 7.87e-07 | (114.00 ms | 35929 tok/s)\n",
      "step 4485/5000 | train loss 0.060928 | norm 0.0120 | lr 7.84e-07 | (113.72 ms | 36018 tok/s)\n",
      "step 4486/5000 | train loss 0.060928 | norm 0.0141 | lr 7.81e-07 | (112.34 ms | 36461 tok/s)\n",
      "step 4487/5000 | train loss 0.060928 | norm 0.0133 | lr 7.78e-07 | (113.63 ms | 36046 tok/s)\n",
      "step 4488/5000 | train loss 0.060928 | norm 0.0126 | lr 7.75e-07 | (113.04 ms | 36235 tok/s)\n",
      "step 4489/5000 | train loss 0.060928 | norm 0.0126 | lr 7.72e-07 | (114.36 ms | 35816 tok/s)\n",
      "step 4490/5000 | train loss 0.060928 | norm 0.0132 | lr 7.69e-07 | (113.86 ms | 35974 tok/s)\n",
      "step 4491/5000 | train loss 0.060928 | norm 0.0105 | lr 7.66e-07 | (113.56 ms | 36069 tok/s)\n",
      "step 4492/5000 | train loss 0.060927 | norm 0.0095 | lr 7.64e-07 | (112.90 ms | 36279 tok/s)\n",
      "step 4493/5000 | train loss 0.060927 | norm 0.0111 | lr 7.61e-07 | (115.76 ms | 35383 tok/s)\n",
      "step 4494/5000 | train loss 0.060927 | norm 0.0104 | lr 7.58e-07 | (112.67 ms | 36354 tok/s)\n",
      "step 4495/5000 | train loss 0.060927 | norm 0.0104 | lr 7.55e-07 | (111.35 ms | 36785 tok/s)\n",
      "step 4496/5000 | train loss 0.060927 | norm 0.0110 | lr 7.52e-07 | (114.00 ms | 35930 tok/s)\n",
      "step 4497/5000 | train loss 0.060927 | norm 0.0108 | lr 7.49e-07 | (116.20 ms | 35249 tok/s)\n",
      "step 4498/5000 | train loss 0.060927 | norm 0.0108 | lr 7.46e-07 | (113.02 ms | 36242 tok/s)\n",
      "step 4499/5000 | train loss 0.060927 | norm 0.0116 | lr 7.43e-07 | (113.22 ms | 36176 tok/s)\n",
      "step 4500/5000 | train loss 0.060927 | norm 0.0118 | lr 7.40e-07 | (113.29 ms | 36156 tok/s)\n",
      "step 4501/5000 | train loss 0.060927 | norm 0.0124 | lr 7.37e-07 | (114.02 ms | 35923 tok/s)\n",
      "step 4502/5000 | train loss 0.060926 | norm 0.0127 | lr 7.34e-07 | (112.49 ms | 36413 tok/s)\n",
      "step 4503/5000 | train loss 0.060926 | norm 0.0128 | lr 7.31e-07 | (113.05 ms | 36230 tok/s)\n",
      "step 4504/5000 | train loss 0.060926 | norm 0.0117 | lr 7.28e-07 | (112.58 ms | 36384 tok/s)\n",
      "step 4505/5000 | train loss 0.060926 | norm 0.0105 | lr 7.25e-07 | (131.05 ms | 31255 tok/s)\n",
      "step 4506/5000 | train loss 0.060926 | norm 0.0125 | lr 7.23e-07 | (113.53 ms | 36080 tok/s)\n",
      "step 4507/5000 | train loss 0.060926 | norm 0.0131 | lr 7.20e-07 | (113.71 ms | 36021 tok/s)\n",
      "step 4508/5000 | train loss 0.060926 | norm 0.0128 | lr 7.17e-07 | (112.80 ms | 36312 tok/s)\n",
      "step 4509/5000 | train loss 0.060926 | norm 0.0110 | lr 7.14e-07 | (112.32 ms | 36467 tok/s)\n",
      "step 4510/5000 | train loss 0.060926 | norm 0.0117 | lr 7.11e-07 | (111.79 ms | 36641 tok/s)\n",
      "step 4511/5000 | train loss 0.060926 | norm 0.0149 | lr 7.08e-07 | (114.25 ms | 35851 tok/s)\n",
      "step 4512/5000 | train loss 0.060926 | norm 0.0152 | lr 7.05e-07 | (112.66 ms | 36357 tok/s)\n",
      "step 4513/5000 | train loss 0.060925 | norm 0.0143 | lr 7.03e-07 | (114.11 ms | 35896 tok/s)\n",
      "step 4514/5000 | train loss 0.060925 | norm 0.0148 | lr 7.00e-07 | (114.89 ms | 35652 tok/s)\n",
      "step 4515/5000 | train loss 0.060925 | norm 0.0150 | lr 6.97e-07 | (113.98 ms | 35935 tok/s)\n",
      "step 4516/5000 | train loss 0.060925 | norm 0.0123 | lr 6.94e-07 | (112.27 ms | 36483 tok/s)\n",
      "step 4517/5000 | train loss 0.060925 | norm 0.0123 | lr 6.91e-07 | (112.87 ms | 36289 tok/s)\n",
      "step 4518/5000 | train loss 0.060925 | norm 0.0126 | lr 6.88e-07 | (114.75 ms | 35694 tok/s)\n",
      "step 4519/5000 | train loss 0.060925 | norm 0.0126 | lr 6.86e-07 | (117.92 ms | 34737 tok/s)\n",
      "step 4520/5000 | train loss 0.060925 | norm 0.0103 | lr 6.83e-07 | (115.84 ms | 35359 tok/s)\n",
      "step 4521/5000 | train loss 0.060924 | norm 0.0090 | lr 6.80e-07 | (116.24 ms | 35238 tok/s)\n",
      "step 4522/5000 | train loss 0.060924 | norm 0.0118 | lr 6.77e-07 | (112.79 ms | 36316 tok/s)\n",
      "step 4523/5000 | train loss 0.060924 | norm 0.0098 | lr 6.74e-07 | (113.43 ms | 36110 tok/s)\n",
      "step 4524/5000 | train loss 0.060924 | norm 0.0082 | lr 6.72e-07 | (112.79 ms | 36316 tok/s)\n",
      "step 4525/5000 | train loss 0.060924 | norm 0.0090 | lr 6.69e-07 | (112.83 ms | 36302 tok/s)\n",
      "step 4526/5000 | train loss 0.060924 | norm 0.0092 | lr 6.66e-07 | (114.15 ms | 35881 tok/s)\n",
      "step 4527/5000 | train loss 0.060924 | norm 0.0088 | lr 6.63e-07 | (115.35 ms | 35511 tok/s)\n",
      "step 4528/5000 | train loss 0.060924 | norm 0.0082 | lr 6.61e-07 | (113.31 ms | 36149 tok/s)\n",
      "step 4529/5000 | train loss 0.060924 | norm 0.0104 | lr 6.58e-07 | (114.75 ms | 35694 tok/s)\n",
      "step 4530/5000 | train loss 0.060924 | norm 0.0115 | lr 6.55e-07 | (113.92 ms | 35955 tok/s)\n",
      "step 4531/5000 | train loss 0.060924 | norm 0.0117 | lr 6.52e-07 | (114.00 ms | 35931 tok/s)\n",
      "step 4532/5000 | train loss 0.060924 | norm 0.0132 | lr 6.50e-07 | (116.89 ms | 35040 tok/s)\n",
      "step 4533/5000 | train loss 0.060923 | norm 0.0130 | lr 6.47e-07 | (116.88 ms | 35045 tok/s)\n",
      "step 4534/5000 | train loss 0.060923 | norm 0.0101 | lr 6.44e-07 | (114.59 ms | 35745 tok/s)\n",
      "step 4535/5000 | train loss 0.060923 | norm 0.0100 | lr 6.41e-07 | (114.47 ms | 35781 tok/s)\n",
      "step 4536/5000 | train loss 0.060923 | norm 0.0114 | lr 6.39e-07 | (114.31 ms | 35832 tok/s)\n",
      "step 4537/5000 | train loss 0.060923 | norm 0.0118 | lr 6.36e-07 | (114.32 ms | 35828 tok/s)\n",
      "step 4538/5000 | train loss 0.060923 | norm 0.0113 | lr 6.33e-07 | (113.01 ms | 36245 tok/s)\n",
      "step 4539/5000 | train loss 0.060923 | norm 0.0117 | lr 6.30e-07 | (114.78 ms | 35687 tok/s)\n",
      "step 4540/5000 | train loss 0.060923 | norm 0.0121 | lr 6.28e-07 | (113.89 ms | 35964 tok/s)\n",
      "step 4541/5000 | train loss 0.060923 | norm 0.0121 | lr 6.25e-07 | (118.17 ms | 34661 tok/s)\n",
      "step 4542/5000 | train loss 0.060923 | norm 0.0110 | lr 6.22e-07 | (116.06 ms | 35291 tok/s)\n",
      "step 4543/5000 | train loss 0.060922 | norm 0.0092 | lr 6.20e-07 | (116.16 ms | 35262 tok/s)\n",
      "step 4544/5000 | train loss 0.060922 | norm 0.0105 | lr 6.17e-07 | (113.91 ms | 35959 tok/s)\n",
      "step 4545/5000 | train loss 0.060922 | norm 0.0094 | lr 6.14e-07 | (113.51 ms | 36085 tok/s)\n",
      "step 4546/5000 | train loss 0.060922 | norm 0.0090 | lr 6.12e-07 | (112.97 ms | 36258 tok/s)\n",
      "step 4547/5000 | train loss 0.060922 | norm 0.0091 | lr 6.09e-07 | (113.14 ms | 36205 tok/s)\n",
      "step 4548/5000 | train loss 0.060922 | norm 0.0086 | lr 6.06e-07 | (111.96 ms | 36585 tok/s)\n",
      "step 4549/5000 | train loss 0.060922 | norm 0.0090 | lr 6.04e-07 | (114.38 ms | 35811 tok/s)\n",
      "step 4550/5000 | train loss 0.060922 | norm 0.0091 | lr 6.01e-07 | (112.97 ms | 36258 tok/s)\n",
      "step 4551/5000 | train loss 0.060922 | norm 0.0087 | lr 5.99e-07 | (115.06 ms | 35599 tok/s)\n",
      "step 4552/5000 | train loss 0.060922 | norm 0.0097 | lr 5.96e-07 | (114.53 ms | 35764 tok/s)\n",
      "step 4553/5000 | train loss 0.060922 | norm 0.0118 | lr 5.93e-07 | (114.71 ms | 35706 tok/s)\n",
      "step 4554/5000 | train loss 0.060922 | norm 0.0124 | lr 5.91e-07 | (114.20 ms | 35868 tok/s)\n",
      "step 4555/5000 | train loss 0.060921 | norm 0.0117 | lr 5.88e-07 | (112.63 ms | 36367 tok/s)\n",
      "step 4556/5000 | train loss 0.060921 | norm 0.0119 | lr 5.85e-07 | (113.17 ms | 36192 tok/s)\n",
      "step 4557/5000 | train loss 0.060921 | norm 0.0111 | lr 5.83e-07 | (113.74 ms | 36012 tok/s)\n",
      "step 4558/5000 | train loss 0.060921 | norm 0.0092 | lr 5.80e-07 | (116.71 ms | 35096 tok/s)\n",
      "step 4559/5000 | train loss 0.060921 | norm 0.0104 | lr 5.78e-07 | (116.73 ms | 35090 tok/s)\n",
      "step 4560/5000 | train loss 0.060921 | norm 0.0109 | lr 5.75e-07 | (114.94 ms | 35637 tok/s)\n",
      "step 4561/5000 | train loss 0.060921 | norm 0.0095 | lr 5.73e-07 | (116.39 ms | 35193 tok/s)\n",
      "step 4562/5000 | train loss 0.060921 | norm 0.0084 | lr 5.70e-07 | (113.48 ms | 36094 tok/s)\n",
      "step 4563/5000 | train loss 0.060921 | norm 0.0085 | lr 5.67e-07 | (113.80 ms | 35992 tok/s)\n",
      "step 4564/5000 | train loss 0.060921 | norm 0.0096 | lr 5.65e-07 | (112.74 ms | 36330 tok/s)\n",
      "step 4565/5000 | train loss 0.060921 | norm 0.0089 | lr 5.62e-07 | (114.19 ms | 35869 tok/s)\n",
      "step 4566/5000 | train loss 0.060920 | norm 0.0073 | lr 5.60e-07 | (114.89 ms | 35652 tok/s)\n",
      "step 4567/5000 | train loss 0.060920 | norm 0.0068 | lr 5.57e-07 | (115.81 ms | 35367 tok/s)\n",
      "step 4568/5000 | train loss 0.060920 | norm 0.0083 | lr 5.55e-07 | (114.33 ms | 35825 tok/s)\n",
      "step 4569/5000 | train loss 0.060920 | norm 0.0083 | lr 5.52e-07 | (113.54 ms | 36075 tok/s)\n",
      "step 4570/5000 | train loss 0.060920 | norm 0.0079 | lr 5.50e-07 | (112.18 ms | 36513 tok/s)\n",
      "step 4571/5000 | train loss 0.060920 | norm 0.0083 | lr 5.47e-07 | (113.55 ms | 36071 tok/s)\n",
      "step 4572/5000 | train loss 0.060920 | norm 0.0096 | lr 5.45e-07 | (114.68 ms | 35717 tok/s)\n",
      "step 4573/5000 | train loss 0.060920 | norm 0.0107 | lr 5.42e-07 | (115.47 ms | 35472 tok/s)\n",
      "step 4574/5000 | train loss 0.060920 | norm 0.0108 | lr 5.40e-07 | (114.84 ms | 35668 tok/s)\n",
      "step 4575/5000 | train loss 0.060920 | norm 0.0112 | lr 5.37e-07 | (116.46 ms | 35170 tok/s)\n",
      "step 4576/5000 | train loss 0.060920 | norm 0.0097 | lr 5.35e-07 | (114.48 ms | 35780 tok/s)\n",
      "step 4577/5000 | train loss 0.060920 | norm 0.0089 | lr 5.32e-07 | (113.70 ms | 36026 tok/s)\n",
      "step 4578/5000 | train loss 0.060920 | norm 0.0088 | lr 5.30e-07 | (114.92 ms | 35641 tok/s)\n",
      "step 4579/5000 | train loss 0.060919 | norm 0.0102 | lr 5.27e-07 | (114.76 ms | 35691 tok/s)\n",
      "step 4580/5000 | train loss 0.060919 | norm 0.0102 | lr 5.25e-07 | (113.79 ms | 35996 tok/s)\n",
      "step 4581/5000 | train loss 0.060919 | norm 0.0074 | lr 5.22e-07 | (115.03 ms | 35609 tok/s)\n",
      "step 4582/5000 | train loss 0.060919 | norm 0.0069 | lr 5.20e-07 | (116.49 ms | 35160 tok/s)\n",
      "step 4583/5000 | train loss 0.060919 | norm 0.0087 | lr 5.17e-07 | (114.14 ms | 35885 tok/s)\n",
      "step 4584/5000 | train loss 0.060919 | norm 0.0088 | lr 5.15e-07 | (114.13 ms | 35890 tok/s)\n",
      "step 4585/5000 | train loss 0.060919 | norm 0.0069 | lr 5.12e-07 | (113.18 ms | 36190 tok/s)\n",
      "step 4586/5000 | train loss 0.060919 | norm 0.0071 | lr 5.10e-07 | (113.38 ms | 36127 tok/s)\n",
      "step 4587/5000 | train loss 0.060919 | norm 0.0075 | lr 5.08e-07 | (116.15 ms | 35266 tok/s)\n",
      "step 4588/5000 | train loss 0.060919 | norm 0.0082 | lr 5.05e-07 | (115.23 ms | 35547 tok/s)\n",
      "step 4589/5000 | train loss 0.060919 | norm 0.0090 | lr 5.03e-07 | (134.93 ms | 30356 tok/s)\n",
      "step 4590/5000 | train loss 0.060919 | norm 0.0087 | lr 5.00e-07 | (112.39 ms | 36445 tok/s)\n",
      "step 4591/5000 | train loss 0.060919 | norm 0.0087 | lr 4.98e-07 | (113.59 ms | 36060 tok/s)\n",
      "step 4592/5000 | train loss 0.060919 | norm 0.0092 | lr 4.96e-07 | (113.41 ms | 36117 tok/s)\n",
      "step 4593/5000 | train loss 0.060918 | norm 0.0092 | lr 4.93e-07 | (114.49 ms | 35777 tok/s)\n",
      "step 4594/5000 | train loss 0.060918 | norm 0.0081 | lr 4.91e-07 | (115.37 ms | 35502 tok/s)\n",
      "step 4595/5000 | train loss 0.060918 | norm 0.0081 | lr 4.88e-07 | (115.84 ms | 35359 tok/s)\n",
      "step 4596/5000 | train loss 0.060918 | norm 0.0093 | lr 4.86e-07 | (115.25 ms | 35540 tok/s)\n",
      "step 4597/5000 | train loss 0.060918 | norm 0.0096 | lr 4.84e-07 | (115.73 ms | 35393 tok/s)\n",
      "step 4598/5000 | train loss 0.060918 | norm 0.0090 | lr 4.81e-07 | (113.61 ms | 36054 tok/s)\n",
      "step 4599/5000 | train loss 0.060918 | norm 0.0083 | lr 4.79e-07 | (116.45 ms | 35174 tok/s)\n",
      "step 4600/5000 | train loss 0.060918 | norm 0.0082 | lr 4.77e-07 | (114.92 ms | 35643 tok/s)\n",
      "step 4601/5000 | train loss 0.060918 | norm 0.0089 | lr 4.74e-07 | (116.91 ms | 35034 tok/s)\n",
      "step 4602/5000 | train loss 0.060918 | norm 0.0092 | lr 4.72e-07 | (114.28 ms | 35841 tok/s)\n",
      "step 4603/5000 | train loss 0.060918 | norm 0.0079 | lr 4.70e-07 | (113.57 ms | 36065 tok/s)\n",
      "step 4604/5000 | train loss 0.060918 | norm 0.0072 | lr 4.67e-07 | (113.25 ms | 36169 tok/s)\n",
      "step 4605/5000 | train loss 0.060918 | norm 0.0063 | lr 4.65e-07 | (113.18 ms | 36191 tok/s)\n",
      "step 4606/5000 | train loss 0.060918 | norm 0.0074 | lr 4.63e-07 | (114.02 ms | 35923 tok/s)\n",
      "step 4607/5000 | train loss 0.060917 | norm 0.0070 | lr 4.60e-07 | (116.71 ms | 35096 tok/s)\n",
      "step 4608/5000 | train loss 0.060917 | norm 0.0059 | lr 4.58e-07 | (114.32 ms | 35829 tok/s)\n",
      "step 4609/5000 | train loss 0.060917 | norm 0.0071 | lr 4.56e-07 | (113.83 ms | 35983 tok/s)\n",
      "step 4610/5000 | train loss 0.060917 | norm 0.0074 | lr 4.53e-07 | (114.19 ms | 35870 tok/s)\n",
      "step 4611/5000 | train loss 0.060917 | norm 0.0072 | lr 4.51e-07 | (113.58 ms | 36062 tok/s)\n",
      "step 4612/5000 | train loss 0.060917 | norm 0.0076 | lr 4.49e-07 | (113.15 ms | 36199 tok/s)\n",
      "step 4613/5000 | train loss 0.060917 | norm 0.0078 | lr 4.46e-07 | (113.56 ms | 36070 tok/s)\n",
      "step 4614/5000 | train loss 0.060917 | norm 0.0079 | lr 4.44e-07 | (114.48 ms | 35778 tok/s)\n",
      "step 4615/5000 | train loss 0.060917 | norm 0.0076 | lr 4.42e-07 | (114.63 ms | 35733 tok/s)\n",
      "step 4616/5000 | train loss 0.060917 | norm 0.0066 | lr 4.40e-07 | (114.78 ms | 35686 tok/s)\n",
      "step 4617/5000 | train loss 0.060917 | norm 0.0072 | lr 4.37e-07 | (114.72 ms | 35705 tok/s)\n",
      "step 4618/5000 | train loss 0.060917 | norm 0.0076 | lr 4.35e-07 | (113.75 ms | 36009 tok/s)\n",
      "step 4619/5000 | train loss 0.060917 | norm 0.0079 | lr 4.33e-07 | (113.67 ms | 36035 tok/s)\n",
      "step 4620/5000 | train loss 0.060917 | norm 0.0080 | lr 4.31e-07 | (112.81 ms | 36307 tok/s)\n",
      "step 4621/5000 | train loss 0.060917 | norm 0.0077 | lr 4.28e-07 | (114.44 ms | 35790 tok/s)\n",
      "step 4622/5000 | train loss 0.060916 | norm 0.0084 | lr 4.26e-07 | (114.30 ms | 35835 tok/s)\n",
      "step 4623/5000 | train loss 0.060916 | norm 0.0081 | lr 4.24e-07 | (116.56 ms | 35141 tok/s)\n",
      "step 4624/5000 | train loss 0.060916 | norm 0.0073 | lr 4.22e-07 | (113.38 ms | 36126 tok/s)\n",
      "step 4625/5000 | train loss 0.060916 | norm 0.0074 | lr 4.20e-07 | (115.44 ms | 35483 tok/s)\n",
      "step 4626/5000 | train loss 0.060916 | norm 0.0077 | lr 4.17e-07 | (113.57 ms | 36066 tok/s)\n",
      "step 4627/5000 | train loss 0.060916 | norm 0.0073 | lr 4.15e-07 | (113.03 ms | 36238 tok/s)\n",
      "step 4628/5000 | train loss 0.060916 | norm 0.0066 | lr 4.13e-07 | (112.44 ms | 36429 tok/s)\n",
      "step 4629/5000 | train loss 0.060916 | norm 0.0068 | lr 4.11e-07 | (113.11 ms | 36213 tok/s)\n",
      "step 4630/5000 | train loss 0.060916 | norm 0.0065 | lr 4.09e-07 | (113.58 ms | 36064 tok/s)\n",
      "step 4631/5000 | train loss 0.060916 | norm 0.0062 | lr 4.06e-07 | (114.69 ms | 35715 tok/s)\n",
      "step 4632/5000 | train loss 0.060916 | norm 0.0060 | lr 4.04e-07 | (113.25 ms | 36168 tok/s)\n",
      "step 4633/5000 | train loss 0.060916 | norm 0.0061 | lr 4.02e-07 | (115.77 ms | 35382 tok/s)\n",
      "step 4634/5000 | train loss 0.060916 | norm 0.0059 | lr 4.00e-07 | (114.44 ms | 35791 tok/s)\n",
      "step 4635/5000 | train loss 0.060916 | norm 0.0060 | lr 3.98e-07 | (115.74 ms | 35389 tok/s)\n",
      "step 4636/5000 | train loss 0.060916 | norm 0.0059 | lr 3.96e-07 | (114.77 ms | 35690 tok/s)\n",
      "step 4637/5000 | train loss 0.060916 | norm 0.0066 | lr 3.94e-07 | (114.70 ms | 35711 tok/s)\n",
      "step 4638/5000 | train loss 0.060916 | norm 0.0071 | lr 3.91e-07 | (113.55 ms | 36073 tok/s)\n",
      "step 4639/5000 | train loss 0.060915 | norm 0.0073 | lr 3.89e-07 | (115.15 ms | 35570 tok/s)\n",
      "step 4640/5000 | train loss 0.060915 | norm 0.0073 | lr 3.87e-07 | (112.97 ms | 36257 tok/s)\n",
      "step 4641/5000 | train loss 0.060915 | norm 0.0072 | lr 3.85e-07 | (114.96 ms | 35629 tok/s)\n",
      "step 4642/5000 | train loss 0.060915 | norm 0.0078 | lr 3.83e-07 | (112.87 ms | 36289 tok/s)\n",
      "step 4643/5000 | train loss 0.060915 | norm 0.0081 | lr 3.81e-07 | (112.92 ms | 36273 tok/s)\n",
      "step 4644/5000 | train loss 0.060915 | norm 0.0081 | lr 3.79e-07 | (111.96 ms | 36584 tok/s)\n",
      "step 4645/5000 | train loss 0.060915 | norm 0.0074 | lr 3.77e-07 | (113.37 ms | 36129 tok/s)\n",
      "step 4646/5000 | train loss 0.060915 | norm 0.0068 | lr 3.75e-07 | (113.41 ms | 36117 tok/s)\n",
      "step 4647/5000 | train loss 0.060915 | norm 0.0067 | lr 3.72e-07 | (114.78 ms | 35687 tok/s)\n",
      "step 4648/5000 | train loss 0.060915 | norm 0.0069 | lr 3.70e-07 | (113.53 ms | 36079 tok/s)\n",
      "step 4649/5000 | train loss 0.060915 | norm 0.0061 | lr 3.68e-07 | (113.52 ms | 36083 tok/s)\n",
      "step 4650/5000 | train loss 0.060915 | norm 0.0060 | lr 3.66e-07 | (113.09 ms | 36218 tok/s)\n",
      "step 4651/5000 | train loss 0.060915 | norm 0.0059 | lr 3.64e-07 | (115.52 ms | 35457 tok/s)\n",
      "step 4652/5000 | train loss 0.060915 | norm 0.0050 | lr 3.62e-07 | (113.95 ms | 35946 tok/s)\n",
      "step 4653/5000 | train loss 0.060915 | norm 0.0057 | lr 3.60e-07 | (114.83 ms | 35670 tok/s)\n",
      "step 4654/5000 | train loss 0.060915 | norm 0.0056 | lr 3.58e-07 | (113.43 ms | 36109 tok/s)\n",
      "step 4655/5000 | train loss 0.060915 | norm 0.0050 | lr 3.56e-07 | (114.05 ms | 35915 tok/s)\n",
      "step 4656/5000 | train loss 0.060915 | norm 0.0050 | lr 3.54e-07 | (111.73 ms | 36659 tok/s)\n",
      "step 4657/5000 | train loss 0.060914 | norm 0.0056 | lr 3.52e-07 | (112.73 ms | 36336 tok/s)\n",
      "step 4658/5000 | train loss 0.060914 | norm 0.0059 | lr 3.50e-07 | (112.85 ms | 36297 tok/s)\n",
      "step 4659/5000 | train loss 0.060914 | norm 0.0060 | lr 3.48e-07 | (113.28 ms | 36157 tok/s)\n",
      "step 4660/5000 | train loss 0.060914 | norm 0.0070 | lr 3.46e-07 | (112.56 ms | 36390 tok/s)\n",
      "step 4661/5000 | train loss 0.060914 | norm 0.0076 | lr 3.44e-07 | (113.81 ms | 35989 tok/s)\n",
      "step 4662/5000 | train loss 0.060914 | norm 0.0066 | lr 3.42e-07 | (111.83 ms | 36626 tok/s)\n",
      "step 4663/5000 | train loss 0.060914 | norm 0.0053 | lr 3.40e-07 | (113.31 ms | 36148 tok/s)\n",
      "step 4664/5000 | train loss 0.060914 | norm 0.0049 | lr 3.38e-07 | (113.07 ms | 36227 tok/s)\n",
      "step 4665/5000 | train loss 0.060914 | norm 0.0059 | lr 3.36e-07 | (132.94 ms | 30811 tok/s)\n",
      "step 4666/5000 | train loss 0.060914 | norm 0.0064 | lr 3.34e-07 | (112.21 ms | 36503 tok/s)\n",
      "step 4667/5000 | train loss 0.060914 | norm 0.0058 | lr 3.32e-07 | (114.52 ms | 35768 tok/s)\n",
      "step 4668/5000 | train loss 0.060914 | norm 0.0062 | lr 3.30e-07 | (113.13 ms | 36206 tok/s)\n",
      "step 4669/5000 | train loss 0.060914 | norm 0.0067 | lr 3.28e-07 | (115.96 ms | 35323 tok/s)\n",
      "step 4670/5000 | train loss 0.060914 | norm 0.0063 | lr 3.26e-07 | (115.51 ms | 35459 tok/s)\n",
      "step 4671/5000 | train loss 0.060914 | norm 0.0061 | lr 3.24e-07 | (114.50 ms | 35774 tok/s)\n",
      "step 4672/5000 | train loss 0.060914 | norm 0.0057 | lr 3.22e-07 | (112.64 ms | 36365 tok/s)\n",
      "step 4673/5000 | train loss 0.060914 | norm 0.0053 | lr 3.20e-07 | (112.89 ms | 36283 tok/s)\n",
      "step 4674/5000 | train loss 0.060914 | norm 0.0055 | lr 3.18e-07 | (111.39 ms | 36772 tok/s)\n",
      "step 4675/5000 | train loss 0.060914 | norm 0.0059 | lr 3.17e-07 | (111.80 ms | 36635 tok/s)\n",
      "step 4676/5000 | train loss 0.060914 | norm 0.0057 | lr 3.15e-07 | (112.87 ms | 36290 tok/s)\n",
      "step 4677/5000 | train loss 0.060913 | norm 0.0055 | lr 3.13e-07 | (113.09 ms | 36219 tok/s)\n",
      "step 4678/5000 | train loss 0.060913 | norm 0.0054 | lr 3.11e-07 | (114.74 ms | 35698 tok/s)\n",
      "step 4679/5000 | train loss 0.060913 | norm 0.0050 | lr 3.09e-07 | (114.83 ms | 35671 tok/s)\n",
      "step 4680/5000 | train loss 0.060913 | norm 0.0053 | lr 3.07e-07 | (112.59 ms | 36380 tok/s)\n",
      "step 4681/5000 | train loss 0.060913 | norm 0.0057 | lr 3.05e-07 | (112.22 ms | 36501 tok/s)\n",
      "step 4682/5000 | train loss 0.060913 | norm 0.0055 | lr 3.03e-07 | (112.43 ms | 36431 tok/s)\n",
      "step 4683/5000 | train loss 0.060913 | norm 0.0058 | lr 3.01e-07 | (115.16 ms | 35568 tok/s)\n",
      "step 4684/5000 | train loss 0.060913 | norm 0.0059 | lr 3.00e-07 | (113.59 ms | 36060 tok/s)\n",
      "step 4685/5000 | train loss 0.060913 | norm 0.0052 | lr 2.98e-07 | (113.72 ms | 36018 tok/s)\n",
      "step 4686/5000 | train loss 0.060913 | norm 0.0052 | lr 2.96e-07 | (116.73 ms | 35088 tok/s)\n",
      "step 4687/5000 | train loss 0.060913 | norm 0.0055 | lr 2.94e-07 | (116.89 ms | 35043 tok/s)\n",
      "step 4688/5000 | train loss 0.060913 | norm 0.0053 | lr 2.92e-07 | (114.03 ms | 35922 tok/s)\n",
      "step 4689/5000 | train loss 0.060913 | norm 0.0055 | lr 2.90e-07 | (112.56 ms | 36391 tok/s)\n",
      "step 4690/5000 | train loss 0.060913 | norm 0.0051 | lr 2.88e-07 | (111.81 ms | 36632 tok/s)\n",
      "step 4691/5000 | train loss 0.060913 | norm 0.0050 | lr 2.87e-07 | (113.55 ms | 36072 tok/s)\n",
      "step 4692/5000 | train loss 0.060913 | norm 0.0054 | lr 2.85e-07 | (113.94 ms | 35947 tok/s)\n",
      "step 4693/5000 | train loss 0.060913 | norm 0.0056 | lr 2.83e-07 | (116.35 ms | 35203 tok/s)\n",
      "step 4694/5000 | train loss 0.060913 | norm 0.0053 | lr 2.81e-07 | (115.22 ms | 35550 tok/s)\n",
      "step 4695/5000 | train loss 0.060913 | norm 0.0048 | lr 2.79e-07 | (114.49 ms | 35775 tok/s)\n",
      "step 4696/5000 | train loss 0.060913 | norm 0.0049 | lr 2.78e-07 | (112.37 ms | 36453 tok/s)\n",
      "step 4697/5000 | train loss 0.060913 | norm 0.0053 | lr 2.76e-07 | (114.32 ms | 35830 tok/s)\n",
      "step 4698/5000 | train loss 0.060913 | norm 0.0050 | lr 2.74e-07 | (115.96 ms | 35321 tok/s)\n",
      "step 4699/5000 | train loss 0.060913 | norm 0.0048 | lr 2.72e-07 | (114.65 ms | 35726 tok/s)\n",
      "step 4700/5000 | train loss 0.060913 | norm 0.0050 | lr 2.70e-07 | (114.01 ms | 35926 tok/s)\n",
      "step 4701/5000 | train loss 0.060912 | norm 0.0051 | lr 2.69e-07 | (113.61 ms | 36054 tok/s)\n",
      "step 4702/5000 | train loss 0.060912 | norm 0.0053 | lr 2.67e-07 | (113.44 ms | 36109 tok/s)\n",
      "step 4703/5000 | train loss 0.060912 | norm 0.0048 | lr 2.65e-07 | (114.33 ms | 35825 tok/s)\n",
      "step 4704/5000 | train loss 0.060912 | norm 0.0044 | lr 2.63e-07 | (113.45 ms | 36104 tok/s)\n",
      "step 4705/5000 | train loss 0.060912 | norm 0.0043 | lr 2.62e-07 | (113.48 ms | 36095 tok/s)\n",
      "step 4706/5000 | train loss 0.060912 | norm 0.0048 | lr 2.60e-07 | (112.18 ms | 36512 tok/s)\n",
      "step 4707/5000 | train loss 0.060912 | norm 0.0043 | lr 2.58e-07 | (115.57 ms | 35443 tok/s)\n",
      "step 4708/5000 | train loss 0.060912 | norm 0.0040 | lr 2.56e-07 | (113.58 ms | 36064 tok/s)\n",
      "step 4709/5000 | train loss 0.060912 | norm 0.0047 | lr 2.55e-07 | (115.41 ms | 35492 tok/s)\n",
      "step 4710/5000 | train loss 0.060912 | norm 0.0044 | lr 2.53e-07 | (113.84 ms | 35979 tok/s)\n",
      "step 4711/5000 | train loss 0.060912 | norm 0.0043 | lr 2.51e-07 | (114.87 ms | 35657 tok/s)\n",
      "step 4712/5000 | train loss 0.060912 | norm 0.0046 | lr 2.50e-07 | (111.92 ms | 36599 tok/s)\n",
      "step 4713/5000 | train loss 0.060912 | norm 0.0045 | lr 2.48e-07 | (113.64 ms | 36042 tok/s)\n",
      "step 4714/5000 | train loss 0.060912 | norm 0.0044 | lr 2.46e-07 | (113.21 ms | 36181 tok/s)\n",
      "step 4715/5000 | train loss 0.060912 | norm 0.0044 | lr 2.45e-07 | (114.67 ms | 35720 tok/s)\n",
      "step 4716/5000 | train loss 0.060912 | norm 0.0042 | lr 2.43e-07 | (113.74 ms | 36012 tok/s)\n",
      "step 4717/5000 | train loss 0.060912 | norm 0.0043 | lr 2.41e-07 | (113.84 ms | 35981 tok/s)\n",
      "step 4718/5000 | train loss 0.060912 | norm 0.0043 | lr 2.39e-07 | (113.07 ms | 36227 tok/s)\n",
      "step 4719/5000 | train loss 0.060912 | norm 0.0043 | lr 2.38e-07 | (113.04 ms | 36235 tok/s)\n",
      "step 4720/5000 | train loss 0.060912 | norm 0.0047 | lr 2.36e-07 | (112.92 ms | 36274 tok/s)\n",
      "step 4721/5000 | train loss 0.060912 | norm 0.0052 | lr 2.35e-07 | (113.04 ms | 36236 tok/s)\n",
      "step 4722/5000 | train loss 0.060912 | norm 0.0055 | lr 2.33e-07 | (113.66 ms | 36037 tok/s)\n",
      "step 4723/5000 | train loss 0.060912 | norm 0.0054 | lr 2.31e-07 | (115.07 ms | 35597 tok/s)\n",
      "step 4724/5000 | train loss 0.060912 | norm 0.0049 | lr 2.30e-07 | (113.16 ms | 36198 tok/s)\n",
      "step 4725/5000 | train loss 0.060912 | norm 0.0041 | lr 2.28e-07 | (112.95 ms | 36263 tok/s)\n",
      "step 4726/5000 | train loss 0.060912 | norm 0.0045 | lr 2.26e-07 | (130.93 ms | 31284 tok/s)\n",
      "step 4727/5000 | train loss 0.060912 | norm 0.0048 | lr 2.25e-07 | (114.49 ms | 35777 tok/s)\n",
      "step 4728/5000 | train loss 0.060911 | norm 0.0042 | lr 2.23e-07 | (112.77 ms | 36322 tok/s)\n",
      "step 4729/5000 | train loss 0.060911 | norm 0.0041 | lr 2.22e-07 | (113.58 ms | 36061 tok/s)\n",
      "step 4730/5000 | train loss 0.060911 | norm 0.0044 | lr 2.20e-07 | (114.31 ms | 35831 tok/s)\n",
      "step 4731/5000 | train loss 0.060911 | norm 0.0044 | lr 2.18e-07 | (114.36 ms | 35815 tok/s)\n",
      "step 4732/5000 | train loss 0.060911 | norm 0.0042 | lr 2.17e-07 | (114.02 ms | 35922 tok/s)\n",
      "step 4733/5000 | train loss 0.060911 | norm 0.0042 | lr 2.15e-07 | (114.96 ms | 35629 tok/s)\n",
      "step 4734/5000 | train loss 0.060911 | norm 0.0043 | lr 2.14e-07 | (137.90 ms | 29702 tok/s)\n",
      "step 4735/5000 | train loss 0.060911 | norm 0.0043 | lr 2.12e-07 | (115.67 ms | 35411 tok/s)\n",
      "step 4736/5000 | train loss 0.060911 | norm 0.0042 | lr 2.10e-07 | (114.41 ms | 35801 tok/s)\n",
      "step 4737/5000 | train loss 0.060911 | norm 0.0043 | lr 2.09e-07 | (114.45 ms | 35789 tok/s)\n",
      "step 4738/5000 | train loss 0.060911 | norm 0.0042 | lr 2.07e-07 | (114.46 ms | 35785 tok/s)\n",
      "step 4739/5000 | train loss 0.060911 | norm 0.0038 | lr 2.06e-07 | (115.45 ms | 35479 tok/s)\n",
      "step 4740/5000 | train loss 0.060911 | norm 0.0041 | lr 2.04e-07 | (113.30 ms | 36152 tok/s)\n",
      "step 4741/5000 | train loss 0.060911 | norm 0.0040 | lr 2.03e-07 | (113.32 ms | 36146 tok/s)\n",
      "step 4742/5000 | train loss 0.060911 | norm 0.0038 | lr 2.01e-07 | (112.71 ms | 36340 tok/s)\n",
      "step 4743/5000 | train loss 0.060911 | norm 0.0039 | lr 2.00e-07 | (113.28 ms | 36157 tok/s)\n",
      "step 4744/5000 | train loss 0.060911 | norm 0.0037 | lr 1.98e-07 | (113.89 ms | 35965 tok/s)\n",
      "step 4745/5000 | train loss 0.060911 | norm 0.0039 | lr 1.97e-07 | (113.52 ms | 36082 tok/s)\n",
      "step 4746/5000 | train loss 0.060911 | norm 0.0041 | lr 1.95e-07 | (115.41 ms | 35490 tok/s)\n",
      "step 4747/5000 | train loss 0.060911 | norm 0.0041 | lr 1.94e-07 | (135.32 ms | 30268 tok/s)\n",
      "step 4748/5000 | train loss 0.060911 | norm 0.0042 | lr 1.92e-07 | (111.45 ms | 36753 tok/s)\n",
      "step 4749/5000 | train loss 0.060911 | norm 0.0043 | lr 1.91e-07 | (112.68 ms | 36350 tok/s)\n",
      "step 4750/5000 | train loss 0.060911 | norm 0.0041 | lr 1.89e-07 | (113.54 ms | 36074 tok/s)\n",
      "step 4751/5000 | train loss 0.060911 | norm 0.0038 | lr 1.88e-07 | (113.11 ms | 36213 tok/s)\n",
      "step 4752/5000 | train loss 0.060911 | norm 0.0039 | lr 1.86e-07 | (115.88 ms | 35347 tok/s)\n",
      "step 4753/5000 | train loss 0.060911 | norm 0.0039 | lr 1.85e-07 | (116.17 ms | 35260 tok/s)\n",
      "step 4754/5000 | train loss 0.060911 | norm 0.0040 | lr 1.83e-07 | (114.47 ms | 35782 tok/s)\n",
      "step 4755/5000 | train loss 0.060911 | norm 0.0038 | lr 1.82e-07 | (113.71 ms | 36021 tok/s)\n",
      "step 4756/5000 | train loss 0.060911 | norm 0.0036 | lr 1.80e-07 | (112.95 ms | 36263 tok/s)\n",
      "step 4757/5000 | train loss 0.060911 | norm 0.0038 | lr 1.79e-07 | (115.44 ms | 35483 tok/s)\n",
      "step 4758/5000 | train loss 0.060911 | norm 0.0038 | lr 1.77e-07 | (115.82 ms | 35365 tok/s)\n",
      "step 4759/5000 | train loss 0.060911 | norm 0.0039 | lr 1.76e-07 | (114.54 ms | 35759 tok/s)\n",
      "step 4760/5000 | train loss 0.060910 | norm 0.0039 | lr 1.75e-07 | (114.28 ms | 35842 tok/s)\n",
      "step 4761/5000 | train loss 0.060910 | norm 0.0036 | lr 1.73e-07 | (114.25 ms | 35851 tok/s)\n",
      "step 4762/5000 | train loss 0.060910 | norm 0.0037 | lr 1.72e-07 | (115.07 ms | 35596 tok/s)\n",
      "step 4763/5000 | train loss 0.060910 | norm 0.0036 | lr 1.70e-07 | (115.16 ms | 35568 tok/s)\n",
      "step 4764/5000 | train loss 0.060910 | norm 0.0034 | lr 1.69e-07 | (112.62 ms | 36370 tok/s)\n",
      "step 4765/5000 | train loss 0.060910 | norm 0.0035 | lr 1.68e-07 | (113.70 ms | 36023 tok/s)\n",
      "step 4766/5000 | train loss 0.060910 | norm 0.0035 | lr 1.66e-07 | (113.16 ms | 36198 tok/s)\n",
      "step 4767/5000 | train loss 0.060910 | norm 0.0037 | lr 1.65e-07 | (115.78 ms | 35377 tok/s)\n",
      "step 4768/5000 | train loss 0.060910 | norm 0.0037 | lr 1.63e-07 | (113.27 ms | 36163 tok/s)\n",
      "step 4769/5000 | train loss 0.060910 | norm 0.0036 | lr 1.62e-07 | (113.63 ms | 36048 tok/s)\n",
      "step 4770/5000 | train loss 0.060910 | norm 0.0037 | lr 1.61e-07 | (113.18 ms | 36191 tok/s)\n",
      "step 4771/5000 | train loss 0.060910 | norm 0.0036 | lr 1.59e-07 | (112.30 ms | 36473 tok/s)\n",
      "step 4772/5000 | train loss 0.060910 | norm 0.0035 | lr 1.58e-07 | (111.96 ms | 36583 tok/s)\n",
      "step 4773/5000 | train loss 0.060910 | norm 0.0035 | lr 1.57e-07 | (117.03 ms | 34999 tok/s)\n",
      "step 4774/5000 | train loss 0.060910 | norm 0.0035 | lr 1.55e-07 | (116.03 ms | 35302 tok/s)\n",
      "step 4775/5000 | train loss 0.060910 | norm 0.0036 | lr 1.54e-07 | (116.48 ms | 35164 tok/s)\n",
      "step 4776/5000 | train loss 0.060910 | norm 0.0037 | lr 1.53e-07 | (114.19 ms | 35870 tok/s)\n",
      "step 4777/5000 | train loss 0.060910 | norm 0.0036 | lr 1.51e-07 | (114.07 ms | 35906 tok/s)\n",
      "step 4778/5000 | train loss 0.060910 | norm 0.0035 | lr 1.50e-07 | (115.48 ms | 35471 tok/s)\n",
      "step 4779/5000 | train loss 0.060910 | norm 0.0034 | lr 1.49e-07 | (114.90 ms | 35650 tok/s)\n",
      "step 4780/5000 | train loss 0.060910 | norm 0.0033 | lr 1.47e-07 | (115.51 ms | 35461 tok/s)\n",
      "step 4781/5000 | train loss 0.060910 | norm 0.0033 | lr 1.46e-07 | (114.45 ms | 35788 tok/s)\n",
      "step 4782/5000 | train loss 0.060910 | norm 0.0034 | lr 1.45e-07 | (112.34 ms | 36462 tok/s)\n",
      "step 4783/5000 | train loss 0.060910 | norm 0.0034 | lr 1.43e-07 | (114.85 ms | 35663 tok/s)\n",
      "step 4784/5000 | train loss 0.060910 | norm 0.0033 | lr 1.42e-07 | (113.19 ms | 36187 tok/s)\n",
      "step 4785/5000 | train loss 0.060910 | norm 0.0033 | lr 1.41e-07 | (113.63 ms | 36047 tok/s)\n",
      "step 4786/5000 | train loss 0.060910 | norm 0.0032 | lr 1.40e-07 | (113.96 ms | 35943 tok/s)\n",
      "step 4787/5000 | train loss 0.060910 | norm 0.0032 | lr 1.38e-07 | (118.19 ms | 34657 tok/s)\n",
      "step 4788/5000 | train loss 0.060910 | norm 0.0032 | lr 1.37e-07 | (115.37 ms | 35503 tok/s)\n",
      "step 4789/5000 | train loss 0.060910 | norm 0.0033 | lr 1.36e-07 | (114.14 ms | 35885 tok/s)\n",
      "step 4790/5000 | train loss 0.060910 | norm 0.0034 | lr 1.35e-07 | (112.84 ms | 36299 tok/s)\n",
      "step 4791/5000 | train loss 0.060910 | norm 0.0034 | lr 1.33e-07 | (115.48 ms | 35470 tok/s)\n",
      "step 4792/5000 | train loss 0.060910 | norm 0.0036 | lr 1.32e-07 | (114.02 ms | 35925 tok/s)\n",
      "step 4793/5000 | train loss 0.060910 | norm 0.0039 | lr 1.31e-07 | (115.74 ms | 35390 tok/s)\n",
      "step 4794/5000 | train loss 0.060910 | norm 0.0038 | lr 1.30e-07 | (115.54 ms | 35451 tok/s)\n",
      "step 4795/5000 | train loss 0.060910 | norm 0.0037 | lr 1.28e-07 | (117.21 ms | 34944 tok/s)\n",
      "step 4796/5000 | train loss 0.060910 | norm 0.0038 | lr 1.27e-07 | (116.21 ms | 35247 tok/s)\n",
      "step 4797/5000 | train loss 0.060910 | norm 0.0037 | lr 1.26e-07 | (118.14 ms | 34670 tok/s)\n",
      "step 4798/5000 | train loss 0.060910 | norm 0.0033 | lr 1.25e-07 | (114.94 ms | 35637 tok/s)\n",
      "step 4799/5000 | train loss 0.060910 | norm 0.0033 | lr 1.24e-07 | (114.48 ms | 35778 tok/s)\n",
      "step 4800/5000 | train loss 0.060910 | norm 0.0035 | lr 1.22e-07 | (113.74 ms | 36011 tok/s)\n",
      "step 4801/5000 | train loss 0.060910 | norm 0.0032 | lr 1.21e-07 | (115.47 ms | 35471 tok/s)\n",
      "step 4802/5000 | train loss 0.060910 | norm 0.0031 | lr 1.20e-07 | (117.44 ms | 34877 tok/s)\n",
      "step 4803/5000 | train loss 0.060910 | norm 0.0032 | lr 1.19e-07 | (116.32 ms | 35213 tok/s)\n",
      "step 4804/5000 | train loss 0.060910 | norm 0.0032 | lr 1.18e-07 | (119.13 ms | 34382 tok/s)\n",
      "step 4805/5000 | train loss 0.060909 | norm 0.0030 | lr 1.17e-07 | (117.81 ms | 34767 tok/s)\n",
      "step 4806/5000 | train loss 0.060909 | norm 0.0030 | lr 1.15e-07 | (117.02 ms | 35002 tok/s)\n",
      "step 4807/5000 | train loss 0.060909 | norm 0.0030 | lr 1.14e-07 | (118.46 ms | 34576 tok/s)\n",
      "step 4808/5000 | train loss 0.060909 | norm 0.0030 | lr 1.13e-07 | (119.96 ms | 34146 tok/s)\n",
      "step 4809/5000 | train loss 0.060909 | norm 0.0030 | lr 1.12e-07 | (117.14 ms | 34968 tok/s)\n",
      "step 4810/5000 | train loss 0.060909 | norm 0.0030 | lr 1.11e-07 | (116.08 ms | 35285 tok/s)\n",
      "step 4811/5000 | train loss 0.060909 | norm 0.0029 | lr 1.10e-07 | (116.82 ms | 35062 tok/s)\n",
      "step 4812/5000 | train loss 0.060909 | norm 0.0030 | lr 1.09e-07 | (113.86 ms | 35974 tok/s)\n",
      "step 4813/5000 | train loss 0.060909 | norm 0.0029 | lr 1.08e-07 | (113.69 ms | 36027 tok/s)\n",
      "step 4814/5000 | train loss 0.060909 | norm 0.0029 | lr 1.06e-07 | (115.17 ms | 35564 tok/s)\n",
      "step 4815/5000 | train loss 0.060909 | norm 0.0030 | lr 1.05e-07 | (116.04 ms | 35299 tok/s)\n",
      "step 4816/5000 | train loss 0.060909 | norm 0.0029 | lr 1.04e-07 | (116.64 ms | 35117 tok/s)\n",
      "step 4817/5000 | train loss 0.060909 | norm 0.0030 | lr 1.03e-07 | (116.76 ms | 35082 tok/s)\n",
      "step 4818/5000 | train loss 0.060909 | norm 0.0032 | lr 1.02e-07 | (114.38 ms | 35811 tok/s)\n",
      "step 4819/5000 | train loss 0.060909 | norm 0.0033 | lr 1.01e-07 | (114.53 ms | 35765 tok/s)\n",
      "step 4820/5000 | train loss 0.060909 | norm 0.0033 | lr 9.99e-08 | (113.60 ms | 36056 tok/s)\n",
      "step 4821/5000 | train loss 0.060909 | norm 0.0031 | lr 9.88e-08 | (112.89 ms | 36282 tok/s)\n",
      "step 4822/5000 | train loss 0.060909 | norm 0.0029 | lr 9.78e-08 | (114.16 ms | 35880 tok/s)\n",
      "step 4823/5000 | train loss 0.060909 | norm 0.0030 | lr 9.67e-08 | (114.98 ms | 35625 tok/s)\n",
      "step 4824/5000 | train loss 0.060909 | norm 0.0031 | lr 9.57e-08 | (114.42 ms | 35797 tok/s)\n",
      "step 4825/5000 | train loss 0.060909 | norm 0.0031 | lr 9.46e-08 | (115.18 ms | 35560 tok/s)\n",
      "step 4826/5000 | train loss 0.060909 | norm 0.0030 | lr 9.36e-08 | (113.33 ms | 36141 tok/s)\n",
      "step 4827/5000 | train loss 0.060909 | norm 0.0030 | lr 9.25e-08 | (112.88 ms | 36285 tok/s)\n",
      "step 4828/5000 | train loss 0.060909 | norm 0.0030 | lr 9.15e-08 | (111.36 ms | 36780 tok/s)\n",
      "step 4829/5000 | train loss 0.060909 | norm 0.0030 | lr 9.05e-08 | (129.79 ms | 31557 tok/s)\n",
      "step 4830/5000 | train loss 0.060909 | norm 0.0030 | lr 8.95e-08 | (114.14 ms | 35885 tok/s)\n",
      "step 4831/5000 | train loss 0.060909 | norm 0.0030 | lr 8.85e-08 | (114.28 ms | 35841 tok/s)\n",
      "step 4832/5000 | train loss 0.060909 | norm 0.0030 | lr 8.75e-08 | (112.41 ms | 36439 tok/s)\n",
      "step 4833/5000 | train loss 0.060909 | norm 0.0030 | lr 8.65e-08 | (114.62 ms | 35735 tok/s)\n",
      "step 4834/5000 | train loss 0.060909 | norm 0.0030 | lr 8.55e-08 | (112.97 ms | 36257 tok/s)\n",
      "step 4835/5000 | train loss 0.060909 | norm 0.0030 | lr 8.45e-08 | (113.22 ms | 36178 tok/s)\n",
      "step 4836/5000 | train loss 0.060909 | norm 0.0030 | lr 8.35e-08 | (113.03 ms | 36237 tok/s)\n",
      "step 4837/5000 | train loss 0.060909 | norm 0.0031 | lr 8.26e-08 | (115.27 ms | 35534 tok/s)\n",
      "step 4838/5000 | train loss 0.060909 | norm 0.0030 | lr 8.16e-08 | (113.55 ms | 36073 tok/s)\n",
      "step 4839/5000 | train loss 0.060909 | norm 0.0029 | lr 8.06e-08 | (114.74 ms | 35697 tok/s)\n",
      "step 4840/5000 | train loss 0.060909 | norm 0.0029 | lr 7.97e-08 | (114.65 ms | 35726 tok/s)\n",
      "step 4841/5000 | train loss 0.060909 | norm 0.0029 | lr 7.87e-08 | (113.85 ms | 35978 tok/s)\n",
      "step 4842/5000 | train loss 0.060909 | norm 0.0030 | lr 7.78e-08 | (112.19 ms | 36510 tok/s)\n",
      "step 4843/5000 | train loss 0.060909 | norm 0.0029 | lr 7.68e-08 | (113.13 ms | 36206 tok/s)\n",
      "step 4844/5000 | train loss 0.060909 | norm 0.0028 | lr 7.59e-08 | (115.06 ms | 35600 tok/s)\n",
      "step 4845/5000 | train loss 0.060909 | norm 0.0029 | lr 7.50e-08 | (113.82 ms | 35985 tok/s)\n",
      "step 4846/5000 | train loss 0.060909 | norm 0.0029 | lr 7.41e-08 | (112.68 ms | 36349 tok/s)\n",
      "step 4847/5000 | train loss 0.060909 | norm 0.0028 | lr 7.32e-08 | (114.46 ms | 35785 tok/s)\n",
      "step 4848/5000 | train loss 0.060909 | norm 0.0028 | lr 7.23e-08 | (116.81 ms | 35067 tok/s)\n",
      "step 4849/5000 | train loss 0.060909 | norm 0.0028 | lr 7.13e-08 | (116.26 ms | 35231 tok/s)\n",
      "step 4850/5000 | train loss 0.060909 | norm 0.0028 | lr 7.05e-08 | (112.99 ms | 36250 tok/s)\n",
      "step 4851/5000 | train loss 0.060909 | norm 0.0028 | lr 6.96e-08 | (114.03 ms | 35921 tok/s)\n",
      "step 4852/5000 | train loss 0.060909 | norm 0.0028 | lr 6.87e-08 | (113.02 ms | 36241 tok/s)\n",
      "step 4853/5000 | train loss 0.060909 | norm 0.0028 | lr 6.78e-08 | (117.79 ms | 34775 tok/s)\n",
      "step 4854/5000 | train loss 0.060909 | norm 0.0028 | lr 6.69e-08 | (117.19 ms | 34952 tok/s)\n",
      "step 4855/5000 | train loss 0.060909 | norm 0.0028 | lr 6.61e-08 | (117.22 ms | 34942 tok/s)\n",
      "step 4856/5000 | train loss 0.060909 | norm 0.0028 | lr 6.52e-08 | (113.35 ms | 36135 tok/s)\n",
      "step 4857/5000 | train loss 0.060909 | norm 0.0028 | lr 6.43e-08 | (113.97 ms | 35938 tok/s)\n",
      "step 4858/5000 | train loss 0.060909 | norm 0.0029 | lr 6.35e-08 | (113.99 ms | 35933 tok/s)\n",
      "step 4859/5000 | train loss 0.060909 | norm 0.0029 | lr 6.27e-08 | (114.65 ms | 35725 tok/s)\n",
      "step 4860/5000 | train loss 0.060909 | norm 0.0030 | lr 6.18e-08 | (114.00 ms | 35929 tok/s)\n",
      "step 4861/5000 | train loss 0.060909 | norm 0.0029 | lr 6.10e-08 | (113.88 ms | 35969 tok/s)\n",
      "step 4862/5000 | train loss 0.060909 | norm 0.0029 | lr 6.02e-08 | (113.78 ms | 36000 tok/s)\n",
      "step 4863/5000 | train loss 0.060909 | norm 0.0028 | lr 5.93e-08 | (114.18 ms | 35872 tok/s)\n",
      "step 4864/5000 | train loss 0.060909 | norm 0.0029 | lr 5.85e-08 | (113.43 ms | 36111 tok/s)\n",
      "step 4865/5000 | train loss 0.060909 | norm 0.0029 | lr 5.77e-08 | (113.83 ms | 35983 tok/s)\n",
      "step 4866/5000 | train loss 0.060909 | norm 0.0029 | lr 5.69e-08 | (113.16 ms | 36198 tok/s)\n",
      "step 4867/5000 | train loss 0.060909 | norm 0.0028 | lr 5.61e-08 | (113.86 ms | 35973 tok/s)\n",
      "step 4868/5000 | train loss 0.060909 | norm 0.0028 | lr 5.53e-08 | (116.03 ms | 35301 tok/s)\n",
      "step 4869/5000 | train loss 0.060909 | norm 0.0029 | lr 5.46e-08 | (117.11 ms | 34975 tok/s)\n",
      "step 4870/5000 | train loss 0.060909 | norm 0.0028 | lr 5.38e-08 | (114.94 ms | 35635 tok/s)\n",
      "step 4871/5000 | train loss 0.060909 | norm 0.0028 | lr 5.30e-08 | (114.55 ms | 35759 tok/s)\n",
      "step 4872/5000 | train loss 0.060909 | norm 0.0028 | lr 5.22e-08 | (114.47 ms | 35783 tok/s)\n",
      "step 4873/5000 | train loss 0.060909 | norm 0.0028 | lr 5.15e-08 | (113.76 ms | 36004 tok/s)\n",
      "step 4874/5000 | train loss 0.060909 | norm 0.0028 | lr 5.07e-08 | (115.98 ms | 35317 tok/s)\n",
      "step 4875/5000 | train loss 0.060909 | norm 0.0028 | lr 5.00e-08 | (117.84 ms | 34759 tok/s)\n",
      "step 4876/5000 | train loss 0.060909 | norm 0.0028 | lr 4.92e-08 | (115.97 ms | 35320 tok/s)\n",
      "step 4877/5000 | train loss 0.060909 | norm 0.0028 | lr 4.85e-08 | (117.17 ms | 34958 tok/s)\n",
      "step 4878/5000 | train loss 0.060909 | norm 0.0028 | lr 4.78e-08 | (114.56 ms | 35755 tok/s)\n",
      "step 4879/5000 | train loss 0.060909 | norm 0.0028 | lr 4.70e-08 | (114.59 ms | 35746 tok/s)\n",
      "step 4880/5000 | train loss 0.060909 | norm 0.0028 | lr 4.63e-08 | (113.70 ms | 36024 tok/s)\n",
      "step 4881/5000 | train loss 0.060909 | norm 0.0028 | lr 4.56e-08 | (116.05 ms | 35294 tok/s)\n",
      "step 4882/5000 | train loss 0.060909 | norm 0.0028 | lr 4.49e-08 | (114.58 ms | 35748 tok/s)\n",
      "step 4883/5000 | train loss 0.060909 | norm 0.0028 | lr 4.42e-08 | (115.99 ms | 35313 tok/s)\n",
      "step 4884/5000 | train loss 0.060908 | norm 0.0028 | lr 4.35e-08 | (117.09 ms | 34982 tok/s)\n",
      "step 4885/5000 | train loss 0.060908 | norm 0.0028 | lr 4.28e-08 | (115.23 ms | 35547 tok/s)\n",
      "step 4886/5000 | train loss 0.060908 | norm 0.0028 | lr 4.21e-08 | (113.36 ms | 36133 tok/s)\n",
      "step 4887/5000 | train loss 0.060908 | norm 0.0028 | lr 4.15e-08 | (113.78 ms | 35999 tok/s)\n",
      "step 4888/5000 | train loss 0.060908 | norm 0.0028 | lr 4.08e-08 | (114.43 ms | 35793 tok/s)\n",
      "step 4889/5000 | train loss 0.060908 | norm 0.0028 | lr 4.01e-08 | (115.01 ms | 35614 tok/s)\n",
      "step 4890/5000 | train loss 0.060908 | norm 0.0028 | lr 3.95e-08 | (114.72 ms | 35705 tok/s)\n",
      "step 4891/5000 | train loss 0.060908 | norm 0.0028 | lr 3.88e-08 | (114.26 ms | 35849 tok/s)\n",
      "step 4892/5000 | train loss 0.060908 | norm 0.0028 | lr 3.82e-08 | (113.54 ms | 36077 tok/s)\n",
      "step 4893/5000 | train loss 0.060908 | norm 0.0028 | lr 3.75e-08 | (113.42 ms | 36114 tok/s)\n",
      "step 4894/5000 | train loss 0.060908 | norm 0.0028 | lr 3.69e-08 | (114.03 ms | 35921 tok/s)\n",
      "step 4895/5000 | train loss 0.060908 | norm 0.0028 | lr 3.63e-08 | (114.84 ms | 35669 tok/s)\n",
      "step 4896/5000 | train loss 0.060908 | norm 0.0028 | lr 3.56e-08 | (114.42 ms | 35798 tok/s)\n",
      "step 4897/5000 | train loss 0.060908 | norm 0.0028 | lr 3.50e-08 | (115.94 ms | 35329 tok/s)\n",
      "step 4898/5000 | train loss 0.060908 | norm 0.0028 | lr 3.44e-08 | (119.22 ms | 34356 tok/s)\n",
      "step 4899/5000 | train loss 0.060908 | norm 0.0027 | lr 3.38e-08 | (117.27 ms | 34928 tok/s)\n",
      "step 4900/5000 | train loss 0.060908 | norm 0.0027 | lr 3.32e-08 | (116.73 ms | 35090 tok/s)\n",
      "step 4901/5000 | train loss 0.060908 | norm 0.0028 | lr 3.26e-08 | (115.51 ms | 35460 tok/s)\n",
      "step 4902/5000 | train loss 0.060908 | norm 0.0028 | lr 3.20e-08 | (114.58 ms | 35749 tok/s)\n",
      "step 4903/5000 | train loss 0.060908 | norm 0.0027 | lr 3.14e-08 | (114.98 ms | 35625 tok/s)\n",
      "step 4904/5000 | train loss 0.060908 | norm 0.0027 | lr 3.08e-08 | (114.33 ms | 35827 tok/s)\n",
      "step 4905/5000 | train loss 0.060908 | norm 0.0027 | lr 3.03e-08 | (115.09 ms | 35590 tok/s)\n",
      "step 4906/5000 | train loss 0.060908 | norm 0.0027 | lr 2.97e-08 | (114.16 ms | 35880 tok/s)\n",
      "step 4907/5000 | train loss 0.060908 | norm 0.0027 | lr 2.92e-08 | (113.80 ms | 35993 tok/s)\n",
      "step 4908/5000 | train loss 0.060908 | norm 0.0027 | lr 2.86e-08 | (114.33 ms | 35826 tok/s)\n",
      "step 4909/5000 | train loss 0.060908 | norm 0.0027 | lr 2.81e-08 | (113.99 ms | 35931 tok/s)\n",
      "step 4910/5000 | train loss 0.060908 | norm 0.0027 | lr 2.75e-08 | (114.45 ms | 35788 tok/s)\n",
      "step 4911/5000 | train loss 0.060908 | norm 0.0027 | lr 2.70e-08 | (114.45 ms | 35790 tok/s)\n",
      "step 4912/5000 | train loss 0.060908 | norm 0.0027 | lr 2.64e-08 | (115.18 ms | 35561 tok/s)\n",
      "step 4913/5000 | train loss 0.060908 | norm 0.0027 | lr 2.59e-08 | (118.50 ms | 34565 tok/s)\n",
      "step 4914/5000 | train loss 0.060908 | norm 0.0027 | lr 2.54e-08 | (115.26 ms | 35536 tok/s)\n",
      "step 4915/5000 | train loss 0.060908 | norm 0.0027 | lr 2.49e-08 | (117.40 ms | 34888 tok/s)\n",
      "step 4916/5000 | train loss 0.060908 | norm 0.0027 | lr 2.44e-08 | (113.95 ms | 35947 tok/s)\n",
      "step 4917/5000 | train loss 0.060908 | norm 0.0027 | lr 2.39e-08 | (131.16 ms | 31229 tok/s)\n",
      "step 4918/5000 | train loss 0.060908 | norm 0.0027 | lr 2.34e-08 | (114.11 ms | 35894 tok/s)\n",
      "step 4919/5000 | train loss 0.060908 | norm 0.0027 | lr 2.29e-08 | (114.52 ms | 35768 tok/s)\n",
      "step 4920/5000 | train loss 0.060908 | norm 0.0027 | lr 2.24e-08 | (115.05 ms | 35603 tok/s)\n",
      "step 4921/5000 | train loss 0.060908 | norm 0.0027 | lr 2.19e-08 | (114.87 ms | 35657 tok/s)\n",
      "step 4922/5000 | train loss 0.060908 | norm 0.0027 | lr 2.15e-08 | (113.78 ms | 36000 tok/s)\n",
      "step 4923/5000 | train loss 0.060908 | norm 0.0027 | lr 2.10e-08 | (116.47 ms | 35167 tok/s)\n",
      "step 4924/5000 | train loss 0.060908 | norm 0.0027 | lr 2.05e-08 | (114.13 ms | 35889 tok/s)\n",
      "step 4925/5000 | train loss 0.060908 | norm 0.0027 | lr 2.01e-08 | (114.90 ms | 35648 tok/s)\n",
      "step 4926/5000 | train loss 0.060908 | norm 0.0027 | lr 1.97e-08 | (113.41 ms | 36118 tok/s)\n",
      "step 4927/5000 | train loss 0.060908 | norm 0.0027 | lr 1.92e-08 | (113.88 ms | 35969 tok/s)\n",
      "step 4928/5000 | train loss 0.060908 | norm 0.0027 | lr 1.88e-08 | (114.64 ms | 35730 tok/s)\n",
      "step 4929/5000 | train loss 0.060908 | norm 0.0027 | lr 1.83e-08 | (113.62 ms | 36049 tok/s)\n",
      "step 4930/5000 | train loss 0.060908 | norm 0.0027 | lr 1.79e-08 | (114.17 ms | 35875 tok/s)\n",
      "step 4931/5000 | train loss 0.060908 | norm 0.0027 | lr 1.75e-08 | (115.22 ms | 35550 tok/s)\n",
      "step 4932/5000 | train loss 0.060908 | norm 0.0027 | lr 1.71e-08 | (113.98 ms | 35937 tok/s)\n",
      "step 4933/5000 | train loss 0.060908 | norm 0.0027 | lr 1.67e-08 | (114.08 ms | 35906 tok/s)\n",
      "step 4934/5000 | train loss 0.060908 | norm 0.0027 | lr 1.63e-08 | (114.95 ms | 35632 tok/s)\n",
      "step 4935/5000 | train loss 0.060908 | norm 0.0027 | lr 1.59e-08 | (115.46 ms | 35476 tok/s)\n",
      "step 4936/5000 | train loss 0.060908 | norm 0.0027 | lr 1.55e-08 | (114.13 ms | 35889 tok/s)\n",
      "step 4937/5000 | train loss 0.060908 | norm 0.0027 | lr 1.51e-08 | (114.40 ms | 35804 tok/s)\n",
      "step 4938/5000 | train loss 0.060908 | norm 0.0027 | lr 1.47e-08 | (113.10 ms | 36215 tok/s)\n",
      "step 4939/5000 | train loss 0.060908 | norm 0.0027 | lr 1.44e-08 | (115.84 ms | 35359 tok/s)\n",
      "step 4940/5000 | train loss 0.060908 | norm 0.0027 | lr 1.40e-08 | (115.35 ms | 35510 tok/s)\n",
      "step 4941/5000 | train loss 0.060908 | norm 0.0027 | lr 1.37e-08 | (113.78 ms | 36000 tok/s)\n",
      "step 4942/5000 | train loss 0.060908 | norm 0.0027 | lr 1.33e-08 | (114.65 ms | 35726 tok/s)\n",
      "step 4943/5000 | train loss 0.060908 | norm 0.0027 | lr 1.30e-08 | (114.78 ms | 35685 tok/s)\n",
      "step 4944/5000 | train loss 0.060908 | norm 0.0027 | lr 1.26e-08 | (115.43 ms | 35484 tok/s)\n",
      "step 4945/5000 | train loss 0.060908 | norm 0.0027 | lr 1.23e-08 | (114.78 ms | 35686 tok/s)\n",
      "step 4946/5000 | train loss 0.060908 | norm 0.0027 | lr 1.20e-08 | (114.34 ms | 35822 tok/s)\n",
      "step 4947/5000 | train loss 0.060908 | norm 0.0027 | lr 1.16e-08 | (115.82 ms | 35366 tok/s)\n",
      "step 4948/5000 | train loss 0.060908 | norm 0.0027 | lr 1.13e-08 | (114.01 ms | 35927 tok/s)\n",
      "step 4949/5000 | train loss 0.060908 | norm 0.0027 | lr 1.10e-08 | (113.40 ms | 36121 tok/s)\n",
      "step 4950/5000 | train loss 0.060908 | norm 0.0027 | lr 1.07e-08 | (111.42 ms | 36762 tok/s)\n",
      "step 4951/5000 | train loss 0.060908 | norm 0.0027 | lr 1.04e-08 | (112.65 ms | 36361 tok/s)\n",
      "step 4952/5000 | train loss 0.060908 | norm 0.0027 | lr 1.01e-08 | (112.80 ms | 36312 tok/s)\n",
      "step 4953/5000 | train loss 0.060908 | norm 0.0027 | lr 9.82e-09 | (115.65 ms | 35416 tok/s)\n",
      "step 4954/5000 | train loss 0.060908 | norm 0.0027 | lr 9.54e-09 | (115.67 ms | 35411 tok/s)\n",
      "step 4955/5000 | train loss 0.060908 | norm 0.0027 | lr 9.26e-09 | (115.24 ms | 35545 tok/s)\n",
      "step 4956/5000 | train loss 0.060908 | norm 0.0027 | lr 8.99e-09 | (114.40 ms | 35805 tok/s)\n",
      "step 4957/5000 | train loss 0.060908 | norm 0.0027 | lr 8.73e-09 | (113.57 ms | 36066 tok/s)\n",
      "step 4958/5000 | train loss 0.060908 | norm 0.0027 | lr 8.47e-09 | (112.56 ms | 36390 tok/s)\n",
      "step 4959/5000 | train loss 0.060908 | norm 0.0027 | lr 8.22e-09 | (115.31 ms | 35521 tok/s)\n",
      "step 4960/5000 | train loss 0.060908 | norm 0.0027 | lr 7.98e-09 | (113.39 ms | 36123 tok/s)\n",
      "step 4961/5000 | train loss 0.060908 | norm 0.0027 | lr 7.74e-09 | (115.13 ms | 35577 tok/s)\n",
      "step 4962/5000 | train loss 0.060908 | norm 0.0027 | lr 7.50e-09 | (114.37 ms | 35814 tok/s)\n",
      "step 4963/5000 | train loss 0.060908 | norm 0.0027 | lr 7.27e-09 | (114.40 ms | 35804 tok/s)\n",
      "step 4964/5000 | train loss 0.060908 | norm 0.0027 | lr 7.05e-09 | (115.19 ms | 35559 tok/s)\n",
      "step 4965/5000 | train loss 0.060908 | norm 0.0027 | lr 6.84e-09 | (115.19 ms | 35559 tok/s)\n",
      "step 4966/5000 | train loss 0.060908 | norm 0.0027 | lr 6.63e-09 | (116.18 ms | 35257 tok/s)\n",
      "step 4967/5000 | train loss 0.060908 | norm 0.0027 | lr 6.42e-09 | (115.95 ms | 35326 tok/s)\n",
      "step 4968/5000 | train loss 0.060908 | norm 0.0027 | lr 6.22e-09 | (113.88 ms | 35969 tok/s)\n",
      "step 4969/5000 | train loss 0.060908 | norm 0.0027 | lr 6.03e-09 | (116.59 ms | 35132 tok/s)\n",
      "step 4970/5000 | train loss 0.060908 | norm 0.0027 | lr 5.85e-09 | (116.17 ms | 35258 tok/s)\n",
      "step 4971/5000 | train loss 0.060908 | norm 0.0027 | lr 5.66e-09 | (112.92 ms | 36274 tok/s)\n",
      "step 4972/5000 | train loss 0.060908 | norm 0.0027 | lr 5.49e-09 | (112.76 ms | 36324 tok/s)\n",
      "step 4973/5000 | train loss 0.060908 | norm 0.0027 | lr 5.32e-09 | (115.11 ms | 35585 tok/s)\n",
      "step 4974/5000 | train loss 0.060908 | norm 0.0027 | lr 5.16e-09 | (115.15 ms | 35572 tok/s)\n",
      "step 4975/5000 | train loss 0.060908 | norm 0.0027 | lr 5.00e-09 | (114.42 ms | 35797 tok/s)\n",
      "step 4976/5000 | train loss 0.060908 | norm 0.0027 | lr 4.85e-09 | (114.19 ms | 35872 tok/s)\n",
      "step 4977/5000 | train loss 0.060908 | norm 0.0027 | lr 4.71e-09 | (114.59 ms | 35745 tok/s)\n",
      "step 4978/5000 | train loss 0.060908 | norm 0.0027 | lr 4.57e-09 | (113.81 ms | 35991 tok/s)\n",
      "step 4979/5000 | train loss 0.060908 | norm 0.0027 | lr 4.43e-09 | (116.52 ms | 35152 tok/s)\n",
      "step 4980/5000 | train loss 0.060908 | norm 0.0027 | lr 4.31e-09 | (115.16 ms | 35568 tok/s)\n",
      "step 4981/5000 | train loss 0.060908 | norm 0.0027 | lr 4.18e-09 | (114.28 ms | 35842 tok/s)\n",
      "step 4982/5000 | train loss 0.060908 | norm 0.0027 | lr 4.07e-09 | (113.85 ms | 35978 tok/s)\n",
      "step 4983/5000 | train loss 0.060908 | norm 0.0027 | lr 3.96e-09 | (114.30 ms | 35835 tok/s)\n",
      "step 4984/5000 | train loss 0.060908 | norm 0.0027 | lr 3.86e-09 | (116.49 ms | 35161 tok/s)\n",
      "step 4985/5000 | train loss 0.060908 | norm 0.0027 | lr 3.76e-09 | (117.22 ms | 34942 tok/s)\n",
      "step 4986/5000 | train loss 0.060908 | norm 0.0027 | lr 3.67e-09 | (113.00 ms | 36247 tok/s)\n",
      "step 4987/5000 | train loss 0.060908 | norm 0.0027 | lr 3.58e-09 | (113.48 ms | 36094 tok/s)\n",
      "step 4988/5000 | train loss 0.060908 | norm 0.0027 | lr 3.50e-09 | (115.23 ms | 35547 tok/s)\n",
      "step 4989/5000 | train loss 0.060908 | norm 0.0027 | lr 3.43e-09 | (115.10 ms | 35586 tok/s)\n",
      "step 4990/5000 | train loss 0.060908 | norm 0.0027 | lr 3.36e-09 | (114.12 ms | 35891 tok/s)\n",
      "step 4991/5000 | train loss 0.060908 | norm 0.0027 | lr 3.30e-09 | (113.68 ms | 36029 tok/s)\n",
      "step 4992/5000 | train loss 0.060908 | norm 0.0027 | lr 3.24e-09 | (114.20 ms | 35867 tok/s)\n",
      "step 4993/5000 | train loss 0.060908 | norm 0.0027 | lr 3.19e-09 | (114.22 ms | 35861 tok/s)\n",
      "step 4994/5000 | train loss 0.060908 | norm 0.0027 | lr 3.15e-09 | (113.95 ms | 35946 tok/s)\n",
      "step 4995/5000 | train loss 0.060908 | norm 0.0027 | lr 3.11e-09 | (112.95 ms | 36263 tok/s)\n",
      "step 4996/5000 | train loss 0.060908 | norm 0.0027 | lr 3.07e-09 | (113.88 ms | 35968 tok/s)\n",
      "step 4997/5000 | train loss 0.060908 | norm 0.0027 | lr 3.05e-09 | (114.95 ms | 35632 tok/s)\n",
      "step 4998/5000 | train loss 0.060908 | norm 0.0027 | lr 3.03e-09 | (113.06 ms | 36228 tok/s)\n",
      "step 4999/5000 | train loss 0.060908 | norm 0.0027 | lr 3.01e-09 | (113.35 ms | 36136 tok/s)\n",
      "step 5000/5000 | train loss 0.060908 | norm 0.0027 | lr 3.00e-09 | (113.32 ms | 36147 tok/s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "timings = []\n",
    "norm = -1.0   # dummy value to print in inference-only mode\n",
    "for step in range(num_iterations + 1):\n",
    "    t0 = time.time()\n",
    "    last_step = (step == num_iterations)\n",
    "\n",
    "    # once in a while evaluate the validation dataset\n",
    "    if (val_loss_every > 0 \\\n",
    "        and (step % val_loss_every == 0 or last_step)) \\\n",
    "        and (val_loader is not None):\n",
    "        model.eval()\n",
    "        val_loader.reset()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            for _ in range(val_max_steps):\n",
    "                x, y = val_loader.next_batch()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, loss = model(x, y, return_logits=False)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= val_max_steps\n",
    "        # log to console and to file\n",
    "        print0(f\"val loss {val_loss}\")\n",
    "\n",
    "\n",
    "    # once in a while perform model inference on the master process\n",
    "    if (sample_every > 0 \\\n",
    "        and (step % sample_every == 0 or last_step)) \\\n",
    "        and master_process:\n",
    "        model.eval()\n",
    "        # before we end, let's also do one round of inference\n",
    "        # we'll kick off the generation with \"<|endoftext|>\", which designates the start of a new sequence\n",
    "        start_ids = [63]\n",
    "        xg = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "        max_new_tokens = 32\n",
    "        temperature = 1.0\n",
    "        top_k = 40\n",
    "        yg = raw_model.generate(xg, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        print0('---------------')\n",
    "        print0(decode(yg[0].tolist()))\n",
    "        print0('---------------')\n",
    "\n",
    "    # bit confusing: we want to make sure to eval and sample on 0th iteration\n",
    "    # but also after the very last iteration. so we loop for step <= num_iterations\n",
    "    # instead of just < num_iterations (one extra due to <=), only to do\n",
    "    # the validation/sampling one last time, and then we break right here as we're done.\n",
    "    if last_step:\n",
    "        break\n",
    "\n",
    "    # --------------- TRAINING SECTION BEGIN -----------------\n",
    "    model.train()\n",
    "    # micro-batch loop where we do gradient accumulation to reach desired total batch size\n",
    "    lossf = 0.0 # for getting the mean loss (as simple float) over the accumulation steps\n",
    "    for micro_step in range(grad_accum_steps):\n",
    "        # fetch a batch\n",
    "        if not overfit_single_batch \\\n",
    "            or (overfit_single_batch and step == 0 and micro_step == 0):\n",
    "            x, y = train_loader.next_batch()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        with ctx:\n",
    "            _, loss = model(x, y, return_logits=False)\n",
    "            # we have to scale the loss to account for gradient accumulation,\n",
    "            # because the gradients just add on each successive backward().\n",
    "            # addition of gradients corresponds to a SUM in the objective, but\n",
    "            # instead of a SUM we want MEAN, so we scale the loss here\n",
    "            loss = loss / grad_accum_steps\n",
    "            lossf += loss.detach() # keep track of the mean loss\n",
    "        # backward pass\n",
    "        if not inference_only:\n",
    "            loss.backward()\n",
    "\n",
    "    lossf = lossf.item()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    # determine and set the learning rate for this iteration\n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    # step the optimizer\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # --------------- TRAINING SECTION END -------------------\n",
    "    # everything that follows now is just diagnostics, prints, logging, etc.\n",
    "\n",
    "    # wait on the CPU for all device work to end so we get accurate per-iteration timings below\n",
    "    if device == \"mps\":\n",
    "        torch.mps.synchronize()\n",
    "    elif device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    # time and print\n",
    "    t1 = time.time()\n",
    "    # the 0th iteration is often an outlier (much slower) => skip logging it\n",
    "    tokens_per_second = grad_accum_steps * ddp_world_size * B * T / (t1-t0)\n",
    "    print0(f\"step {step+1:4d}/{num_iterations} | train loss {lossf:.6f} | norm {norm:.4f} | lr {lr:.2e} | ({(t1-t0)*1000:.2f} ms | {tokens_per_second:.0f} tok/s)\")\n",
    "\n",
    "\n",
    "    # keep track of smooth timings, last 20 iterations\n",
    "    if step > 0 and step > num_iterations - 20:\n",
    "        timings.append(t1-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0964,  0.0818,  0.0594, -0.1002,  0.0632],\n",
       "        [-0.0789,  0.0811,  0.0902,  0.0902,  0.0534],\n",
       "        [ 0.0810, -0.0719, -0.0627, -0.0563, -0.0506],\n",
       "        [-0.0550,  0.0807, -0.0642,  0.0862,  0.0707],\n",
       "        [-0.0672, -0.0743, -0.0200, -0.0691, -0.0966]], device='mps:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final 19 iters avg: 114.230ms\n",
      "peak memory consumption: 0 MiB\n"
     ]
    }
   ],
   "source": [
    "# print the average of the last 20 timings, to get something smooth-ish\n",
    "timings = timings[-20:]\n",
    "print0(f\"final {len(timings)} iters avg: {np.mean(timings)*1000:.3f}ms\")\n",
    "print0(f\"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Example input: te\n",
      "Generated output: teaching politicia\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# write an example for generating text\n",
    "sample_text = \"te\"\n",
    "sample_tokens = encode(sample_text)\n",
    "sample_tokens = torch.tensor(sample_tokens, dtype=torch.long, device=device)[None, ...]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_out = model.generate(sample_tokens, max_new_tokens=16, temperature=0.95871, top_k=10)\n",
    "\n",
    "# print the generated text\n",
    "print0('---------------')\n",
    "print0(f\"Example input: {sample_text}\")\n",
    "print0(f\"Generated output: {decode(sample_out[0].tolist())}\")\n",
    "print0('---------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
