{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ../../video_ve_ozet_havuzu/reproduce_gpt2/tinyshakespeare/tiny_shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BATUHAN ERDURCAN \\r\\n21301855 \\r\\nTURK 101-13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nYalçın Arslan \\r\\n21300458 \\r\\nAslı Uçar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sudenur SOYSAL \\r\\nGÜZELLİK Mİ ÇİRKİNLİK Mİ HA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mars’ta Yaşam mı? \\r\\n \\r\\nHayatım boyunca evr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bir Şehrin İki Yakasında \\r\\n \\r\\n\"İki büyük c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>6839</td>\n",
       "      <td>Dilruba Nilhan Kutlu \\r\\n \\r\\n \\r\\nHAMARAT BRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>6840</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>6841</td>\n",
       "      <td>Yumuşacık Bir Animasyon \\r\\nAnimasyona Giden Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>6842</td>\n",
       "      <td>İlteriş Deniz Kağan CİVELEK    Türkçe 101 - 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>6843</td>\n",
       "      <td>Altuğ Kaya\\r\\nTebessüm...\\r\\n \\r\\nhttp://www.d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6844 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text\n",
       "0              0  BATUHAN ERDURCAN \\r\\n21301855 \\r\\nTURK 101-13 ...\n",
       "1              1   \\r\\nYalçın Arslan \\r\\n21300458 \\r\\nAslı Uçar ...\n",
       "2              2  Sudenur SOYSAL \\r\\nGÜZELLİK Mİ ÇİRKİNLİK Mİ HA...\n",
       "3              3  Mars’ta Yaşam mı? \\r\\n \\r\\nHayatım boyunca evr...\n",
       "4              4  Bir Şehrin İki Yakasında \\r\\n \\r\\n\"İki büyük c...\n",
       "...          ...                                                ...\n",
       "6839        6839  Dilruba Nilhan Kutlu \\r\\n \\r\\n \\r\\nHAMARAT BRA...\n",
       "6840        6840                                                ...\n",
       "6841        6841  Yumuşacık Bir Animasyon \\r\\nAnimasyona Giden Y...\n",
       "6842        6842  İlteriş Deniz Kağan CİVELEK    Türkçe 101 - 12...\n",
       "6843        6843  Altuğ Kaya\\r\\nTebessüm...\\r\\n \\r\\nhttp://www.d...\n",
       "\n",
       "[6844 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tr_texts = pd.read_csv(\"tr_texts.csv\")\n",
    "tr_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text for the first 400 text inside the tr_texts\n",
    "tr_texts = tr_texts.iloc[:400]\n",
    "tr_texts.to_csv(\"tr_texts_400.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1796078"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tr_texts.iloc[0].text\n",
    "\n",
    "for i in range(400):\n",
    "    try:\n",
    "        text += \"\\n\" + tr_texts.iloc[i].text\n",
    "    except:\n",
    "        print(i)\n",
    "        pass\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save text to a file\n",
    "with open(\"tr_texts_400.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_list = ['a', 'b', 'c', 'ç', 'd', 'e', 'f', 'g', 'ğ', 'h', 'ı', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'ö', 'p', 'r', 's', 'ş', 't', 'u', 'ü', 'v', 'y', 'z', \n",
    "               ' ', '.', ',']\n",
    "len(letter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_encoder(letter):\n",
    "  letter = letter.lower()\n",
    "  if letter in letter_list:\n",
    "    return letter_list.index(letter)\n",
    "  else:\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_decoder(index):\n",
    "  return letter_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ç'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_decoder(letter_encoder('ç'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  tokens = []\n",
    "  for letter in text:\n",
    "    token = letter_encoder(letter)\n",
    "    if token != -1:\n",
    "      tokens.append(token)\n",
    "  # %10 of the tokens are for validation and test set\n",
    "  val_test_size = len(tokens) // 10\n",
    "  train_tokens = tokens[:-2*val_test_size]\n",
    "  val_tokens = tokens[-2*val_test_size:-val_test_size]\n",
    "  test_tokens = tokens[-val_test_size:]\n",
    "  # save the tokens as binary files\n",
    "  with open(\"train_tokens_tr.bin\", \"wb\") as f:\n",
    "    f.write(bytes(train_tokens))\n",
    "  with open(\"val_tokens_tr.bin\", \"wb\") as f:\n",
    "    f.write(bytes(val_tokens))\n",
    "  with open(\"test_tokens_tr.bin\", \"wb\") as f:\n",
    "    f.write(bytes(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59581"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_set = set(text.lower().replace('\\n', ' ').split(\" \"))\n",
    "len(text_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796078"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1775634"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.lower().replace('\\n', ' ').replace('  ', ' ')\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59581,\n",
       " ['',\n",
       "  'sektörünün',\n",
       "  'duyuları',\n",
       "  'atıyoruz.',\n",
       "  'şeylerden,',\n",
       "  'melisa',\n",
       "  'geriliyoruz.',\n",
       "  'tartışılabilir...\\t\\r',\n",
       "  'anlaşılmasın,',\n",
       "  'bebeğinize?'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_set = list(set(text.split(\" \")))\n",
    "\n",
    "len(text_set), text_set[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['getiriyor',\n",
       " 'telefon,',\n",
       " 'durumda?',\n",
       " 'başlamıştım',\n",
       " 'yanımızdan',\n",
       " 'etrafımıza',\n",
       " 'hayvan',\n",
       " 'cefanı',\n",
       " '(cid:271)üyük',\n",
       " 'ihtiyaçların',\n",
       " 'pişmanlıklara',\n",
       " 'uğraşmışlar.',\n",
       " 'dipteyse',\n",
       " 'ölçüde\\tçarpıtmaya\\tçalışırsak\\tçalışalım\\tbazı\\tşeylerin\\ther\\tzaman\\tfarkında\\tolmamızda\\t\\r',\n",
       " 'dolambaçlı',\n",
       " 'eğlenin',\n",
       " 'benliğiniz',\n",
       " 'bulursunuz',\n",
       " 'tepeden',\n",
       " 'kalaylı',\n",
       " 'dünyalarımızın,',\n",
       " 'gezindikçe',\n",
       " 'dediklerimizi,',\n",
       " 'geçirilebilir',\n",
       " 'neslimiz',\n",
       " 'aşıracaktı.\\xa0sabahları\\xa0herkes\\xa0uyurken\\xa0etrafı\\xa0gezen\\xa0yaşlı\\xa0bir\\xa0beyaz\\xa0önlüklü\\xa0vardı\\xa0kendine\\xa0hedef\\xa0olarak\\xa0onu\\xa0\\r',\n",
       " 'ödeyeceğinizi',\n",
       " 'soğudum',\n",
       " 'seferinde\\t\\r',\n",
       " 'olamayacağımızdan',\n",
       " 'tutabilmesidir.',\n",
       " 'kapsarken',\n",
       " 'gerçekleşmezken',\n",
       " 'etmese',\n",
       " 'muhtemelen',\n",
       " 'düşünmeden-',\n",
       " 'sunulmuşken',\n",
       " 'eserlerde',\n",
       " 'buyum.',\n",
       " 'bakalım...',\n",
       " 'geliştirebileceğimi',\n",
       " 'alırdım.',\n",
       " 'köşeye',\n",
       " 'müsaadenizle,',\n",
       " 'kalmadı.\\r',\n",
       " 'tartmak',\n",
       " 'araştırmalarla',\n",
       " 'bebekler',\n",
       " 'balıkçılığa',\n",
       " 'fakültesine\\tgirmek\\tistiyormuş.\\tbir\\tgün\\tmatematik\\thocası,\\tanneanneme\\t“bıraksın\\thayal\\t\\r',\n",
       " 'dili:',\n",
       " 'çile',\n",
       " 'dakikayı,',\n",
       " 'umut\\ther\\tzaman\\tvardır.\\t\\t\\r',\n",
       " 'teması,',\n",
       " 'adetlerinin,',\n",
       " 'kazandırarak',\n",
       " 'oradaki',\n",
       " 'yüzyılda',\n",
       " 'yaklaşmanız',\n",
       " 'tanışır',\n",
       " 'tatlı,',\n",
       " 'birleştirmeli.',\n",
       " 'ayrımlar',\n",
       " 'geliştirdi',\n",
       " 'verebileceği',\n",
       " \"i̇stanbul'u,\",\n",
       " 'veremeyen',\n",
       " 'dönerken.',\n",
       " 'asit',\n",
       " 'yüceltilip,',\n",
       " 'anlamayın',\n",
       " 'pop,',\n",
       " 'görebiliyoruz.',\n",
       " 'yapıyorlar.',\n",
       " 'mahvediyor',\n",
       " 'diyenlere',\n",
       " 'dön',\n",
       " 'felsefelerin,',\n",
       " 'efsaneleri',\n",
       " 'önceleri',\n",
       " 'taradı',\n",
       " 'olur...',\n",
       " 'nitelendirmeleri',\n",
       " 'bağlamak;',\n",
       " 'engelliyordu.',\n",
       " 'dersi',\n",
       " 'yaşımız',\n",
       " 'birbirimizden…',\n",
       " 'sunuyordu',\n",
       " 'etkileniyor',\n",
       " 'şekilsizleşmiş,',\n",
       " 'balıklarla',\n",
       " '\\xa0düşünüp\\t\\r',\n",
       " 'tozunu',\n",
       " 'sanatı,',\n",
       " 'barındırdığım',\n",
       " 'kedere',\n",
       " 'indirgenmiş',\n",
       " 'ali’nin']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# generate a random text contains just 100 different words\n",
    "# get random words from the text\n",
    "turkish_word_set = set()\n",
    "\n",
    "while len(turkish_word_set) < 100:\n",
    "  word = np.random.choice(list(text_set))\n",
    "  turkish_word_set.add(word)\n",
    "\n",
    "turkish_word_list = list(turkish_word_set)\n",
    "turkish_word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132520,\n",
       " \"telefon, tartmak sanatı, görebiliyoruz. buyum. adetlerinin, olamayacağımızdan neslimiz i̇stanbul'u, \")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 100 random sentences with 100 words\n",
    "turkish_text = \"\"\n",
    "for i in range(100):\n",
    "  turkish_text += \" \".join(np.random.choice(turkish_word_list, 100)) + \" \"\n",
    "\n",
    "len(turkish_text), turkish_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8453\n",
      "s third-largest kurdish  teaching judge britains toxic. explorers. harvest. cellular  grammminology \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(\"val_tokens2.bin\", \"rb\") as f:\n",
    "  val_tokens = f.read()\n",
    "  val_tokens = [x for x in val_tokens]\n",
    "  print(len(val_tokens))\n",
    "  val_text = \"\".join([letter_decoder(x) for x in val_tokens])\n",
    "  print(val_text[:100])\n",
    "  tokens = np.frombuffer(f.read(), dtype=np.uint16)\n",
    "  print(len(tokens))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
